{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# üåæ Gera√ß√£o Sint√©tica de Gram√≠neas de Pastos Brasileiros\n",
    "\n",
    "Este notebook foca na gera√ß√£o e detec√ß√£o espec√≠fica de gram√≠neas forrageiras t√≠picas dos pastos brasileiros.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "## üì¶ Instala√ß√£o e Configura√ß√£o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalar depend√™ncias espec√≠ficas para gram√≠neas\n",
    "!pip install controlnet-aux ultralytics xformers diffusers transformers --upgrade --quiet\n",
    "!pip install segment-anything opencv-python-headless scikit-image --quiet\n",
    "\n",
    "# Verificar instala√ß√£o GPU\n",
    "import torch\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA dispon√≠vel: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"VRAM dispon√≠vel: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-3",
   "metadata": {},
   "source": [
    "## üîß Importa√ß√µes e Configura√ß√£o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from diffusers import StableDiffusionPipeline, DPMSolverMultistepScheduler\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Configurar device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Usando device: {device}\")\n",
    "\n",
    "# Configurar matplotlib para melhor visualiza√ß√£o\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "plt.rcParams['savefig.dpi'] = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-5",
   "metadata": {},
   "source": [
    "## ü§ñ Carregamento do Modelo Stable Diffusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar modelo Stable Diffusion otimizado para natureza\n",
    "model_id = \"runwayml/stable-diffusion-v1-5\"\n",
    "\n",
    "print(\"Carregando modelo Stable Diffusion para gera√ß√£o de gram√≠neas...\")\n",
    "pipe = StableDiffusionPipeline.from_pretrained(\n",
    "    model_id,\n",
    "    torch_dtype=torch.float16 if device == \"cuda\" else torch.float32,\n",
    "    safety_checker=None,\n",
    "    requires_safety_checker=False\n",
    ").to(device)\n",
    "\n",
    "# Usar scheduler mais r√°pido\n",
    "pipe.scheduler = DPMSolverMultistepScheduler.from_config(pipe.scheduler.config)\n",
    "\n",
    "# Otimiza√ß√£o para Colab\n",
    "if device == \"cuda\":\n",
    "    try:\n",
    "        pipe.enable_model_cpu_offload()\n",
    "        print(\"CPU offload habilitado\")\n",
    "    except:\n",
    "        print(\"CPU offload n√£o dispon√≠vel\")\n",
    "\n",
    "print(\"‚úÖ Modelo carregado com sucesso!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-7",
   "metadata": {},
   "source": [
    "## üåæ Defini√ß√£o de Gram√≠neas Brasileiras\n",
    "\n",
    "Principais gram√≠neas forrageiras dos pastos brasileiros:\n",
    "- **Brachiaria** (decumbens, brizantha, humidicola)\n",
    "- **Panicum** (momba√ßa, tanz√¢nia, massai)\n",
    "- **Cynodon** (tifton, coast-cross)\n",
    "- **Andropogon** (capim-androp√≥gon)\n",
    "- **Setaria** (capim-set√°ria)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompts espec√≠ficos para gram√≠neas brasileiras\n",
    "grass_prompts = [\n",
    "    # Brachiaria - principal gram√≠nea dos pastos brasileiros\n",
    "    \"close up view of Brachiaria brizantha grass field, green forage grass, detailed grass texture, brazilian tropical pasture, natural lighting, high resolution\",\n",
    "    \"Brachiaria decumbens grassland, tropical forage grass, green pasture field, detailed grass blades, sunny day, photorealistic\",\n",
    "    \"aerial view of Brachiaria humidicola field, dense grass coverage, green forage, tropical pasture, natural texture, high quality\",\n",
    "    \n",
    "    # Panicum - gram√≠neas de alto valor nutritivo\n",
    "    \"Panicum maximum momba√ßa grass, tall tropical grass, green forage field, detailed grass structure, natural lighting, realistic\",\n",
    "    \"Panicum tanz√¢nia grassland, tropical forage grass, green field, grass detail, sunny pasture, photographic quality\",\n",
    "    \"Panicum massai grass field, compact tropical grass, green pasture, detailed vegetation, natural scenery\",\n",
    "    \n",
    "    # Cynodon - gram√≠neas resistentes\n",
    "    \"Cynodon dactylon tifton grass, fine textured grass, green lawn, detailed grass blades, uniform coverage, high resolution\",\n",
    "    \"coast-cross Cynodon grass field, tropical pasture grass, green coverage, detailed texture, natural lighting\",\n",
    "    \n",
    "    # Gram√≠neas nativas do cerrado\n",
    "    \"Andropogon gayanus grass field, native brazilian grass, cerrado vegetation, natural grassland, green forage\",\n",
    "    \"native brazilian grassland, mixed tropical grasses, natural pasture, green field, cerrado landscape\",\n",
    "    \"Setaria grass field, tropical forage grass, green pasture, detailed grass texture, brazilian countryside\",\n",
    "    \n",
    "    # Diferentes condi√ß√µes e est√°gios\n",
    "    \"young brazilian grass shoots, fresh green forage, new growth, detailed grass blades, natural lighting\",\n",
    "    \"mature tropical grass field, established pasture, dense green coverage, brazilian forage grass\",\n",
    "    \"mixed brazilian pasture grasses, biodiversity, tropical grassland, natural field, green vegetation\",\n",
    "    \"drought resistant brazilian grass, dry season pasture, adapted tropical grass, resilient vegetation\"\n",
    "]\n",
    "\n",
    "print(f\"üìù Definidos {len(grass_prompts)} prompts espec√≠ficos para gram√≠neas brasileiras\")\n",
    "\n",
    "# Prompt negativo otimizado para gram√≠neas\n",
    "negative_prompt = (\n",
    "    \"animals, cattle, cows, sheep, horses, people, humans, buildings, fences, roads, \"\n",
    "    \"artificial objects, weeds, flowers, trees, bushes, low quality, blurry, distorted, \"\n",
    "    \"ugly, cartoon, painting, drawing, artificial\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-9",
   "metadata": {},
   "source": [
    "## üé® Gera√ß√£o de Imagens de Gram√≠neas Espec√≠ficas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gerar imagens de gram√≠neas espec√≠ficas\n",
    "print(f\"üåæ Gerando {len(grass_prompts)} imagens de gram√≠neas brasileiras...\")\n",
    "grass_images = []\n",
    "\n",
    "for i, prompt in enumerate(grass_prompts):\n",
    "    print(f\"Gerando imagem {i+1}/{len(grass_prompts)}: {prompt[:50]}...\")\n",
    "    \n",
    "    try:\n",
    "        image = pipe(\n",
    "            prompt=prompt,\n",
    "            negative_prompt=negative_prompt,\n",
    "            num_inference_steps=30,  # Mais steps para melhor qualidade\n",
    "            guidance_scale=8.0,      # Guidance mais alto para melhor ader√™ncia ao prompt\n",
    "            width=512,\n",
    "            height=512,\n",
    "            generator=torch.Generator(device=device).manual_seed(100 + i)  # Seeds consistentes\n",
    "        ).images[0]\n",
    "        \n",
    "        grass_images.append(image)\n",
    "        \n",
    "        # Progresso a cada 3 imagens\n",
    "        if (i + 1) % 3 == 0:\n",
    "            print(f\"‚úÖ {i+1} imagens de gram√≠neas conclu√≠das\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Erro ao gerar imagem {i+1}: {e}\")\n",
    "        # Adicionar imagem em branco para manter √≠ndices\n",
    "        grass_images.append(Image.new('RGB', (512, 512), (255, 255, 255)))\n",
    "\n",
    "print(f\"üéâ {len([img for img in grass_images if img.size == (512, 512)])} imagens de gram√≠neas geradas com sucesso!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-11",
   "metadata": {},
   "source": [
    "## üì∏ Visualiza√ß√£o das Gram√≠neas Geradas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exibir galeria de gram√≠neas\n",
    "if grass_images:\n",
    "    num_images = len(grass_images)\n",
    "    cols = 4\n",
    "    rows = (num_images + cols - 1) // cols\n",
    "\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(20, 5 * rows))\n",
    "    fig.suptitle('üåæ Galeria de Gram√≠neas Brasileiras Sint√©ticas', fontsize=16, fontweight='bold')\n",
    "\n",
    "    # Garantir que axes seja 2D\n",
    "    if rows == 1:\n",
    "        axes = axes.reshape(1, -1)\n",
    "    if cols == 1:\n",
    "        axes = axes.reshape(-1, 1)\n",
    "\n",
    "    # Nomes das gram√≠neas para legendas\n",
    "    grass_names = [\n",
    "        \"Brachiaria brizantha\", \"Brachiaria decumbens\", \"Brachiaria humidicola\",\n",
    "        \"Panicum momba√ßa\", \"Panicum tanz√¢nia\", \"Panicum massai\",\n",
    "        \"Cynodon tifton\", \"Cynodon coast-cross\",\n",
    "        \"Andropogon gayanus\", \"Gram√≠neas nativas\", \"Setaria\",\n",
    "        \"Gram√≠neas jovens\", \"Gram√≠neas maduras\", \"Pastagem mista\", \"Gram√≠neas resistentes\"\n",
    "    ]\n",
    "\n",
    "    for i in range(num_images):\n",
    "        row = i // cols\n",
    "        col = i % cols\n",
    "        \n",
    "        axes[row, col].imshow(grass_images[i])\n",
    "        \n",
    "        # T√≠tulo com nome da gram√≠nea\n",
    "        title = grass_names[i] if i < len(grass_names) else f\"Gram√≠nea {i+1}\"\n",
    "        axes[row, col].set_title(title, fontsize=10, fontweight='bold')\n",
    "        axes[row, col].axis('off')\n",
    "\n",
    "    # Esconder eixos vazios\n",
    "    for i in range(num_images, rows * cols):\n",
    "        row = i // cols\n",
    "        col = i % cols\n",
    "        axes[row, col].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Salvar imagens com nomes espec√≠ficos\n",
    "    print(\"\\nüíæ Salvando imagens de gram√≠neas...\")\n",
    "    for i, (image, name) in enumerate(zip(grass_images, grass_names)):\n",
    "        if i < len(grass_names):\n",
    "            filename = f\"graminea_{name.lower().replace(' ', '_').replace('√£', 'a').replace('√ß', 'c')}_{i+1:02d}.png\"\n",
    "        else:\n",
    "            filename = f\"graminea_{i+1:02d}.png\"\n",
    "        \n",
    "        image.save(filename)\n",
    "        print(f\"‚úÖ {filename}\")\n",
    "\n",
    "    print(f\"\\nüåæ {len(grass_images)} imagens de gram√≠neas brasileiras salvas!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-13",
   "metadata": {},
   "source": [
    "## üîç Detec√ß√£o Avan√ßada de Gram√≠neas com YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurar YOLO especificamente para gram√≠neas\n",
    "try:\n",
    "    from ultralytics import YOLO\n",
    "    import cv2\n",
    "    import numpy as np\n",
    "    \n",
    "    print(\"üîç Inicializando detec√ß√£o de gram√≠neas com YOLO...\")\n",
    "    \n",
    "    # Carregar modelo de segmenta√ß√£o (melhor para gram√≠neas)\n",
    "    model = YOLO('yolov8n-seg.pt')\n",
    "    \n",
    "    # Fun√ß√£o para filtrar classes relacionadas a plantas/gram√≠neas\n",
    "    def is_vegetation_class(class_name, confidence):\n",
    "        \"\"\"Determina se a classe detectada √© relacionada √† vegeta√ß√£o\"\"\"\n",
    "        vegetation_keywords = [\n",
    "            'grass', 'plant', 'vegetation', 'field', 'lawn', 'meadow',\n",
    "            'pasture', 'green', 'forage', 'leaf', 'bush', 'shrub'\n",
    "        ]\n",
    "        \n",
    "        class_lower = class_name.lower()\n",
    "        \n",
    "        # Verificar palavras-chave espec√≠ficas\n",
    "        keyword_match = any(keyword in class_lower for keyword in vegetation_keywords)\n",
    "        \n",
    "        # Aceitar tamb√©m classes com alta confian√ßa (podem ser gram√≠neas n√£o categorizadas)\n",
    "        high_confidence = confidence > 0.7\n",
    "        \n",
    "        return keyword_match or high_confidence\n",
    "    \n",
    "    # Analisar algumas imagens de gram√≠neas\n",
    "    if grass_images:\n",
    "        print(f\"Analisando {min(6, len(grass_images))} imagens de gram√≠neas...\")\n",
    "        \n",
    "        grass_analysis_results = []\n",
    "        \n",
    "        for img_idx in range(min(6, len(grass_images))):\n",
    "            print(f\"\\nüåæ Analisando gram√≠nea {img_idx+1}...\")\n",
    "            \n",
    "            # Executar detec√ß√£o YOLO\n",
    "            results = model(grass_images[img_idx], conf=0.25)  # Confian√ßa mais baixa para captar mais vegeta√ß√£o\n",
    "            result = results[0]\n",
    "            \n",
    "            # Analisar resultados\n",
    "            analysis = {\n",
    "                'image_idx': img_idx,\n",
    "                'total_detections': 0,\n",
    "                'vegetation_detections': 0,\n",
    "                'vegetation_classes': [],\n",
    "                'coverage_percentage': 0,\n",
    "                'grass_mask': None\n",
    "            }\n",
    "            \n",
    "            img_array = np.array(grass_images[img_idx])\n",
    "            \n",
    "            if result.masks is not None and len(result.masks) > 0:\n",
    "                # Processar m√°scaras de segmenta√ß√£o\n",
    "                masks = result.masks.data.cpu().numpy()\n",
    "                classes = result.boxes.cls.cpu().numpy()\n",
    "                confidences = result.boxes.conf.cpu().numpy()\n",
    "                \n",
    "                analysis['total_detections'] = len(masks)\n",
    "                \n",
    "                # Combinar m√°scaras de vegeta√ß√£o\n",
    "                vegetation_mask = np.zeros(masks[0].shape)\n",
    "                \n",
    "                for mask, cls, conf in zip(masks, classes, confidences):\n",
    "                    class_name = model.names[int(cls)]\n",
    "                    confidence = float(conf)\n",
    "                    \n",
    "                    if is_vegetation_class(class_name, confidence):\n",
    "                        vegetation_mask += mask\n",
    "                        analysis['vegetation_detections'] += 1\n",
    "                        analysis['vegetation_classes'].append((class_name, confidence))\n",
    "                        print(f\"  Detectado: {class_name} (confian√ßa: {confidence:.2f})\")\n",
    "                \n",
    "                # Normalizar m√°scara\n",
    "                vegetation_mask = np.clip(vegetation_mask, 0, 1)\n",
    "                analysis['grass_mask'] = vegetation_mask\n",
    "                \n",
    "                # Calcular cobertura\n",
    "                total_pixels = vegetation_mask.shape[0] * vegetation_mask.shape[1]\n",
    "                vegetation_pixels = np.sum(vegetation_mask > 0)\n",
    "                analysis['coverage_percentage'] = (vegetation_pixels / total_pixels) * 100\n",
    "                \n",
    "                print(f\"  Cobertura de gram√≠neas: {analysis['coverage_percentage']:.1f}%\")\n",
    "                \n",
    "            else:\n",
    "                print(f\"  ‚ö†Ô∏è Nenhuma m√°scara de segmenta√ß√£o detectada\")\n",
    "            \n",
    "            grass_analysis_results.append(analysis)\n",
    "        \n",
    "        print(\"\\n‚úÖ An√°lise YOLO de gram√≠neas conclu√≠da!\")\n",
    "        \n",
    "    else:\n",
    "        print(\"‚ùå Nenhuma imagem de gram√≠nea dispon√≠vel\")\n",
    "        \n",
    "except ImportError as e:\n",
    "    print(f\"‚ùå YOLO n√£o dispon√≠vel: {e}\")\n",
    "    grass_analysis_results = []\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Erro na an√°lise YOLO: {e}\")\n",
    "    grass_analysis_results = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-15",
   "metadata": {},
   "source": [
    "## üìä Visualiza√ß√£o dos Resultados de Detec√ß√£o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar resultados da detec√ß√£o de gram√≠neas\n",
    "if 'grass_analysis_results' in locals() and grass_analysis_results:\n",
    "    print(\"üìä Visualizando resultados da detec√ß√£o de gram√≠neas...\")\n",
    "    \n",
    "    # Criar figura para mostrar an√°lises\n",
    "    valid_results = [r for r in grass_analysis_results if r['grass_mask'] is not None]\n",
    "    \n",
    "    if valid_results:\n",
    "        num_results = len(valid_results)\n",
    "        cols = 3\n",
    "        rows = num_results\n",
    "        \n",
    "        fig, axes = plt.subplots(rows, cols, figsize=(15, 5 * rows))\n",
    "        fig.suptitle('üåæ An√°lise de Detec√ß√£o de Gram√≠neas', fontsize=16, fontweight='bold')\n",
    "        \n",
    "        if rows == 1:\n",
    "            axes = axes.reshape(1, -1)\n",
    "        \n",
    "        for i, analysis in enumerate(valid_results):\n",
    "            img_idx = analysis['image_idx']\n",
    "            img = grass_images[img_idx]\n",
    "            mask = analysis['grass_mask']\n",
    "            \n",
    "            # Imagem original\n",
    "            axes[i, 0].imshow(img)\n",
    "            axes[i, 0].set_title(f\"Gram√≠nea {img_idx+1} - Original\")\n",
    "            axes[i, 0].axis('off')\n",
    "            \n",
    "            # M√°scara de gram√≠neas\n",
    "            axes[i, 1].imshow(mask, cmap='Greens', alpha=0.8)\n",
    "            axes[i, 1].set_title(f\"M√°scara Detectada\\n{analysis['coverage_percentage']:.1f}% cobertura\")\n",
    "            axes[i, 1].axis('off')\n",
    "            \n",
    "            # Overlay\n",
    "            img_array = np.array(img)\n",
    "            overlay = img_array.copy()\n",
    "            \n",
    "            # Criar overlay verde para √°reas de gram√≠nea\n",
    "            green_overlay = np.zeros_like(img_array)\n",
    "            green_overlay[:, :, 1] = mask * 255  # Canal verde\n",
    "            \n",
    "            # Combinar com imagem original\n",
    "            result_overlay = cv2.addWeighted(img_array, 0.7, green_overlay, 0.3, 0)\n",
    "            \n",
    "            axes[i, 2].imshow(result_overlay)\n",
    "            axes[i, 2].set_title(f\"Gram√≠neas Destacadas\\n{analysis['vegetation_detections']} detec√ß√µes\")\n",
    "            axes[i, 2].axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Estat√≠sticas resumidas\n",
    "        print(\"\\nüìà Estat√≠sticas de Detec√ß√£o:\")\n",
    "        avg_coverage = np.mean([r['coverage_percentage'] for r in valid_results])\n",
    "        avg_detections = np.mean([r['vegetation_detections'] for r in valid_results])\n",
    "        \n",
    "        print(f\"Cobertura m√©dia de gram√≠neas: {avg_coverage:.1f}%\")\n",
    "        print(f\"N√∫mero m√©dio de detec√ß√µes por imagem: {avg_detections:.1f}\")\n",
    "        print(f\"Total de imagens analisadas: {len(valid_results)}\")\n",
    "        \n",
    "        # Classes mais detectadas\n",
    "        all_classes = []\n",
    "        for result in valid_results:\n",
    "            all_classes.extend([cls[0] for cls in result['vegetation_classes']])\n",
    "        \n",
    "        if all_classes:\n",
    "            from collections import Counter\n",
    "            class_counts = Counter(all_classes)\n",
    "            print(f\"\\nClasses mais detectadas:\")\n",
    "            for class_name, count in class_counts.most_common(5):\n",
    "                print(f\"  {class_name}: {count} vezes\")\n",
    "    \n",
    "    else:\n",
    "        print(\"‚ùå Nenhum resultado v√°lido de detec√ß√£o encontrado\")\n",
    "        \n",
    "        # Mostrar estat√≠sticas b√°sicas mesmo sem detec√ß√µes\n",
    "        total_analyzed = len(grass_analysis_results)\n",
    "        with_detections = len([r for r in grass_analysis_results if r['total_detections'] > 0])\n",
    "        \n",
    "        print(f\"\\nüìä Resumo da An√°lise:\")\n",
    "        print(f\"Total de imagens analisadas: {total_analyzed}\")\n",
    "        print(f\"Imagens com detec√ß√µes: {with_detections}\")\n",
    "        print(f\"Taxa de detec√ß√£o: {(with_detections/total_analyzed)*100:.1f}%\" if total_analyzed > 0 else \"N/A\")\n",
    "\n",
    "else:\n",
    "    print(\"‚ùå An√°lise YOLO n√£o foi executada ou n√£o h√° resultados dispon√≠veis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-17",
   "metadata": {},
   "source": [
    "## üå± Segmenta√ß√£o Personalizada de Gram√≠neas por Cor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Segmenta√ß√£o avan√ßada de gram√≠neas baseada em caracter√≠sticas visuais\n",
    "def segment_grass_brazilian(image):\n",
    "    \"\"\"\n",
    "    Segmenta√ß√£o espec√≠fica para gram√≠neas brasileiras\n",
    "    \"\"\"\n",
    "    img_array = np.array(image)\n",
    "    \n",
    "    # Converter para diferentes espa√ßos de cor\n",
    "    hsv = cv2.cvtColor(img_array, cv2.COLOR_RGB2HSV)\n",
    "    lab = cv2.cvtColor(img_array, cv2.COLOR_RGB2LAB)\n",
    "    \n",
    "    # M√°scaras de cor para diferentes tipos de gram√≠neas brasileiras\n",
    "    masks = []\n",
    "    \n",
    "    # 1. Gram√≠neas verdes vibrantes (Brachiaria jovem)\n",
    "    lower_green1 = np.array([30, 50, 50])  # Verde vibrante\n",
    "    upper_green1 = np.array([80, 255, 255])\n",
    "    mask1 = cv2.inRange(hsv, lower_green1, upper_green1)\n",
    "    masks.append(mask1)\n",
    "    \n",
    "    # 2. Gram√≠neas verde-amareladas (Panicum em crescimento)\n",
    "    lower_green2 = np.array([20, 30, 40])  # Verde amarelado\n",
    "    upper_green2 = np.array([60, 255, 200])\n",
    "    mask2 = cv2.inRange(hsv, lower_green2, upper_green2)\n",
    "    masks.append(mask2)\n",
    "    \n",
    "    # 3. Gram√≠neas secas/dormentes (√©poca seca)\n",
    "    lower_brown = np.array([10, 20, 30])   # Tons amarronzados\n",
    "    upper_brown = np.array([30, 150, 150])\n",
    "    mask3 = cv2.inRange(hsv, lower_brown, upper_brown)\n",
    "    masks.append(mask3)\n",
    "    \n",
    "    # Combinar todas as m√°scaras\n",
    "    combined_mask = np.zeros_like(mask1)\n",
    "    for mask in masks:\n",
    "        combined_mask = cv2.bitwise_or(combined_mask, mask)\n",
    "    \n",
    "    # Opera√ß√µes morfol√≥gicas para refinar\n",
    "    kernel_close = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))\n",
    "    kernel_open = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))\n",
    "    \n",
    "    # Fechar buracos pequenos\n",
    "    combined_mask = cv2.morphologyEx(combined_mask, cv2.MORPH_CLOSE, kernel_close)\n",
    "    \n",
    "    # Remover ru√≠dos pequenos\n",
    "    combined_mask = cv2.morphologyEx(combined_mask, cv2.MORPH_OPEN, kernel_open)\n",
    "    \n",
    "    # Filtrar por √°rea (remover regi√µes muito pequenas)\n",
    "    contours, _ = cv2.findContours(combined_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    filtered_mask = np.zeros_like(combined_mask)\n",
    "    \n",
    "    min_area = 200  # √Årea m√≠nima para gram√≠neas\n",
    "    for contour in contours:\n",
    "        area = cv2.contourArea(contour)\n",
    "        if area > min_area:\n",
    "            cv2.fillPoly(filtered_mask, [contour], 255)\n",
    "    \n",
    "    return filtered_mask, masks\n",
    "\n",
    "# Aplicar segmenta√ß√£o personalizada\n",
    "if grass_images:\n",
    "    print(\"üå± Aplicando segmenta√ß√£o personalizada para gram√≠neas brasileiras...\")\n",
    "    \n",
    "    # Analisar primeiras 4 imagens\n",
    "    custom_analysis = []\n",
    "    \n",
    "    for i in range(min(4, len(grass_images))):\n",
    "        print(f\"Segmentando gram√≠nea {i+1}...\")\n",
    "        \n",
    "        grass_mask, individual_masks = segment_grass_brazilian(grass_images[i])\n",
    "        \n",
    "        # Calcular estat√≠sticas\n",
    "        total_pixels = grass_mask.shape[0] * grass_mask.shape[1]\n",
    "        grass_pixels = np.sum(grass_mask > 0)\n",
    "        coverage = (grass_pixels / total_pixels) * 100\n",
    "        \n",
    "        custom_analysis.append({\n",
    "            'image_idx': i,\n",
    "            'mask': grass_mask,\n",
    "            'individual_masks': individual_masks,\n",
    "            'coverage': coverage,\n",
    "            'grass_pixels': grass_pixels,\n",
    "            'total_pixels': total_pixels\n",
    "        })\n",
    "        \n",
    "        print(f\"  Cobertura detectada: {coverage:.1f}%\")\n",
    "    \n",
    "    print(\"‚úÖ Segmenta√ß√£o personalizada conclu√≠da!\")\n",
    "\n",
    "else:\n",
    "    print(\"‚ùå Nenhuma imagem dispon√≠vel para segmenta√ß√£o\")\n",
    "    custom_analysis = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-19",
   "metadata": {},
   "source": [
    "## üìä Compara√ß√£o: YOLO vs Segmenta√ß√£o Personalizada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparar resultados YOLO vs segmenta√ß√£o personalizada\n",
    "if custom_analysis and 'grass_analysis_results' in locals():\n",
    "    print(\"üìä Comparando m√©todos de detec√ß√£o de gram√≠neas...\")\n",
    "    \n",
    "    # Criar visualiza√ß√£o comparativa\n",
    "    num_compare = min(len(custom_analysis), 3)  # Comparar at√© 3 imagens\n",
    "    \n",
    "    fig, axes = plt.subplots(num_compare, 4, figsize=(20, 5 * num_compare))\n",
    "    fig.suptitle('üî¨ Compara√ß√£o: YOLO vs Segmenta√ß√£o Personalizada', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    if num_compare == 1:\n",
    "        axes = axes.reshape(1, -1)\n",
    "    \n",
    "    for i in range(num_compare):\n",
    "        img_idx = custom_analysis[i]['image_idx']\n",
    "        img = grass_images[img_idx]\n",
    "        custom_mask = custom_analysis[i]['mask']\n",
    "        custom_coverage = custom_analysis[i]['coverage']\n",
    "        \n",
    "        # Encontrar resultado YOLO correspondente\n",
    "        yolo_result = None\n",
    "        yolo_coverage = 0\n",
    "        yolo_mask = None\n",
    "        \n",
    "        for result in grass_analysis_results:\n",
    "            if result['image_idx'] == img_idx and result['grass_mask'] is not None:\n",
    "                yolo_result = result\n",
    "                yolo_coverage = result['coverage_percentage']\n",
    "                yolo_mask = result['grass_mask']\n",
    "                break\n",
    "        \n",
    "        # 1. Imagem original\n",
    "        axes[i, 0].imshow(img)\n",
    "        axes[i, 0].set_title(f\"Gram√≠nea {img_idx+1}\\nOriginal\")\n",
    "        axes[i, 0].axis('off')\n",
    "        \n",
    "        # 2. YOLO\n",
    "        if yolo_mask is not None:\n",
    "            axes[i, 1].imshow(yolo_mask, cmap='Blues', alpha=0.8)\n",
    "            axes[i, 1].set_title(f\"YOLO\\n{yolo_coverage:.1f}% cobertura\")\n",
    "        else:\n",
    "            axes[i, 1].text(0.5, 0.5, 'YOLO\\nSem detec√ß√£o', \n",
    "                           ha='center', va='center', transform=axes[i, 1].transAxes)\n",
    "            axes[i, 1].set_title(\"YOLO\\n0% cobertura\")\n",
    "        axes[i, 1].axis('off')\n",
    "        \n",
    "        # 3. Segmenta√ß√£o personalizada\n",
    "        axes[i, 2].imshow(custom_mask, cmap='Greens', alpha=0.8)\n",
    "        axes[i, 2].set_title(f\"Segmenta√ß√£o\\nPersonalizada\\n{custom_coverage:.1f}% cobertura\")\n",
    "        axes[i, 2].axis('off')\n",
    "        \n",
    "        # 4. Compara√ß√£o lado a lado\n",
    "        if yolo_mask is not None:\n",
    "            # Criar imagem comparativa\n",
    "            comparison = np.zeros((*custom_mask.shape, 3))\n",
    "            comparison[:, :, 0] = yolo_mask * 255      # YOLO em vermelho\n",
    "            comparison[:, :, 1] = custom_mask * 255    # Personalizada em verde\n",
    "            # Sobreposi√ß√£o aparece em amarelo\n",
    "            \n",
    "            axes[i, 3].imshow(comparison.astype(np.uint8))\n",
    "            axes[i, 3].set_title(f\"Sobreposi√ß√£o\\nAzul: YOLO\\nVerde: Personalizada\\nAmarelo: Ambos\")\n",
    "        else:\n",
    "            axes[i, 3].imshow(custom_mask, cmap='Greens', alpha=0.8)\n",
    "            axes[i, 3].set_title(f\"Apenas\\nSegmenta√ß√£o\\nPersonalizada\")\n",
    "        axes[i, 3].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Estat√≠sticas comparativas\n",
    "    print(\"\\nüìà Estat√≠sticas Comparativas:\")\n",
    "    \n",
    "    custom_coverages = [analysis['coverage'] for analysis in custom_analysis]\n",
    "    avg_custom = np.mean(custom_coverages)\n",
    "    \n",
    "    if grass_analysis_results:\n",
    "        valid_yolo = [r for r in grass_analysis_results if r['grass_mask'] is not None]\n",
    "        if valid_yolo:\n",
    "            yolo_coverages = [r['coverage_percentage'] for r in valid_yolo]\n",
    "            avg_yolo = np.mean(yolo_coverages)\n",
    "            \n",
    "            print(f\"Cobertura m√©dia - YOLO: {avg_yolo:.1f}%\")\n",
    "            print(f\"Cobertura m√©dia - Personalizada: {avg_custom:.1f}%\")\n",
    "            print(f\"Diferen√ßa m√©dia: {abs(avg_custom - avg_yolo):.1f}%\")\n",
    "        else:\n",
    "            print(f\"Cobertura m√©dia - YOLO: 0% (sem detec√ß√µes v√°lidas)\")\n",
    "            print(f\"Cobertura m√©dia - Personalizada: {avg_custom:.1f}%\")\n",
    "    else:\n",
    "        print(f\"Cobertura m√©dia - Personalizada: {avg_custom:.1f}%\")\n",
    "        print(\"YOLO n√£o foi executado\")\n",
    "\n",
    "elif custom_analysis:\n",
    "    print(\"üìä Mostrando apenas resultados da segmenta√ß√£o personalizada...\")\n",
    "    \n",
    "    # Mostrar apenas resultados personalizados\n",
    "    num_show = min(len(custom_analysis), 4)\n",
    "    \n",
    "    fig, axes = plt.subplots(2, num_show, figsize=(5 * num_show, 10))\n",
    "    fig.suptitle('üå± Segmenta√ß√£o Personalizada de Gram√≠neas', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    if num_show == 1:\n",
    "        axes = axes.reshape(-1, 1)\n",
    "    \n",
    "    for i in range(num_show):\n",
    "        img_idx = custom_analysis[i]['image_idx']\n",
    "        img = grass_images[img_idx]\n",
    "        mask = custom_analysis[i]['mask']\n",
    "        coverage = custom_analysis[i]['coverage']\n",
    "        \n",
    "        # Imagem original\n",
    "        axes[0, i].imshow(img)\n",
    "        axes[0, i].set_title(f\"Gram√≠nea {img_idx+1}\")\n",
    "        axes[0, i].axis('off')\n",
    "        \n",
    "        # M√°scara\n",
    "        axes[1, i].imshow(mask, cmap='Greens', alpha=0.8)\n",
    "        axes[1, i].set_title(f\"Segmenta√ß√£o\\n{coverage:.1f}% cobertura\")\n",
    "        axes[1, i].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Estat√≠sticas\n",
    "    avg_coverage = np.mean([a['coverage'] for a in custom_analysis])\n",
    "    print(f\"\\nüìä Cobertura m√©dia detectada: {avg_coverage:.1f}%\")\n",
    "\n",
    "else:\n",
    "    print(\"‚ùå Nenhuma an√°lise dispon√≠vel para compara√ß√£o\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-21",
   "metadata": {},
   "source": [
    "## üåæ An√°lise de Qualidade das Gram√≠neas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# An√°lise de qualidade espec√≠fica para pastagens brasileiras\n",
    "def analyze_pasture_quality(image, grass_mask, grass_type=\"Desconhecido\"):\n",
    "    \"\"\"\n",
    "    An√°lise de qualidade da pastagem baseada em caracter√≠sticas visuais\n",
    "    \"\"\"\n",
    "    img_array = np.array(image)\n",
    "    hsv = cv2.cvtColor(img_array, cv2.COLOR_RGB2HSV)\n",
    "    \n",
    "    # Extrair regi√µes de gram√≠nea\n",
    "    grass_regions = img_array[grass_mask > 0]\n",
    "    \n",
    "    if len(grass_regions) == 0:\n",
    "        return {\n",
    "            'quality_score': 0,\n",
    "            'quality_class': 'Sem gram√≠neas detectadas',\n",
    "            'coverage': 0,\n",
    "            'vigor_index': 0,\n",
    "            'uniformity': 0\n",
    "        }\n",
    "    \n",
    "    # 1. Cobertura\n",
    "    total_pixels = grass_mask.shape[0] * grass_mask.shape[1]\n",
    "    grass_pixels = np.sum(grass_mask > 0)\n",
    "    coverage = (grass_pixels / total_pixels) * 100\n",
    "    \n",
    "    # 2. √çndice de vigor (baseado na satura√ß√£o e valor do verde)\n",
    "    hsv_grass = hsv[grass_mask > 0]\n",
    "    avg_saturation = np.mean(hsv_grass[:, 1])\n",
    "    avg_value = np.mean(hsv_grass[:, 2])\n",
    "    vigor_index = (avg_saturation + avg_value) / 2\n",
    "    \n",
    "    # 3. Uniformidade (baseada no desvio padr√£o da cor)\n",
    "    color_std = np.mean([np.std(grass_regions[:, i]) for i in range(3)])\n",
    "    uniformity = max(0, 100 - color_std)  # Menor desvio = maior uniformidade\n",
    "    \n",
    "    # 4. Score de qualidade composto\n",
    "    coverage_score = min(coverage / 80 * 40, 40)  # M√°ximo 40 pontos\n",
    "    vigor_score = (vigor_index / 255) * 30        # M√°ximo 30 pontos\n",
    "    uniformity_score = (uniformity / 100) * 30   # M√°ximo 30 pontos\n",
    "    \n",
    "    quality_score = coverage_score + vigor_score + uniformity_score\n",
    "    \n",
    "    # Classifica√ß√£o de qualidade\n",
    "    if quality_score >= 80:\n",
    "        quality_class = \"Excelente üü¢\"\n",
    "    elif quality_score >= 65:\n",
    "        quality_class = \"Boa üü°\"\n",
    "    elif quality_score >= 45:\n",
    "        quality_class = \"Regular üü†\"\n",
    "    else:\n",
    "        quality_class = \"Baixa üî¥\"\n",
    "    \n",
    "    return {\n",
    "        'quality_score': quality_score,\n",
    "        'quality_class': quality_class,\n",
    "        'coverage': coverage,\n",
    "        'vigor_index': vigor_index,\n",
    "        'uniformity': uniformity,\n",
    "        'grass_type': grass_type\n",
    "    }\n",
    "\n",
    "# Analisar qualidade das gram√≠neas\n",
    "if custom_analysis and grass_images:\n",
    "    print(\"üåæ Analisando qualidade das pastagens...\")\n",
    "    \n",
    "    grass_names = [\n",
    "        \"Brachiaria brizantha\", \"Brachiaria decumbens\", \"Brachiaria humidicola\",\n",
    "        \"Panicum momba√ßa\", \"Panicum tanz√¢nia\", \"Panicum massai\",\n",
    "        \"Cynodon tifton\", \"Cynodon coast-cross\"\n",
    "    ]\n",
    "    \n",
    "    quality_results = []\n",
    "    \n",
    "    for analysis in custom_analysis:\n",
    "        img_idx = analysis['image_idx']\n",
    "        img = grass_images[img_idx]\n",
    "        mask = analysis['mask']\n",
    "        \n",
    "        grass_type = grass_names[img_idx] if img_idx < len(grass_names) else \"Gram√≠nea mista\"\n",
    "        \n",
    "        quality = analyze_pasture_quality(img, mask, grass_type)\n",
    "        quality['image_idx'] = img_idx\n",
    "        quality_results.append(quality)\n",
    "        \n",
    "        print(f\"Gram√≠nea {img_idx+1} ({grass_type}): {quality['quality_class']} (Score: {quality['quality_score']:.1f})\")\n",
    "    \n",
    "    # Criar relat√≥rio visual de qualidade\n",
    "    if quality_results:\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "        fig.suptitle('üìä Relat√≥rio de Qualidade das Pastagens', fontsize=16, fontweight='bold')\n",
    "        \n",
    "        # 1. Scores de qualidade por gram√≠nea\n",
    "        grass_types = [q['grass_type'] for q in quality_results]\n",
    "        quality_scores = [q['quality_score'] for q in quality_results]\n",
    "        \n",
    "        colors = ['green' if score >= 80 else 'yellow' if score >= 65 else 'orange' if score >= 45 else 'red' \n",
    "                 for score in quality_scores]\n",
    "        \n",
    "        axes[0, 0].bar(range(len(quality_scores)), quality_scores, color=colors)\n",
    "        axes[0, 0].set_title('Score de Qualidade por Gram√≠nea')\n",
    "        axes[0, 0].set_ylabel('Score (0-100)')\n",
    "        axes[0, 0].set_xticks(range(len(grass_types)))\n",
    "        axes[0, 0].set_xticklabels([f\"G{i+1}\" for i in range(len(grass_types))], rotation=45)\n",
    "        axes[0, 0].grid(True, alpha=0.3)\n",
    "        \n",
    "        # 2. Cobertura vs Vigor\n",
    "        coverages = [q['coverage'] for q in quality_results]\n",
    "        vigors = [q['vigor_index'] for q in quality_results]\n",
    "        \n",
    "        scatter = axes[0, 1].scatter(coverages, vigors, c=quality_scores, cmap='RdYlGn', s=100)\n",
    "        axes[0, 1].set_title('Cobertura vs √çndice de Vigor')\n",
    "        axes[0, 1].set_xlabel('Cobertura (%)')\n",
    "        axes[0, 1].set_ylabel('√çndice de Vigor')\n",
    "        plt.colorbar(scatter, ax=axes[0, 1], label='Score de Qualidade')\n",
    "        \n",
    "        # 3. Distribui√ß√£o de qualidade\n",
    "        quality_classes = [q['quality_class'].split()[0] for q in quality_results]  # Remover emoji\n",
    "        class_counts = {}\n",
    "        for qc in quality_classes:\n",
    "            class_counts[qc] = class_counts.get(qc, 0) + 1\n",
    "        \n",
    "        axes[1, 0].pie(class_counts.values(), labels=class_counts.keys(), autopct='%1.1f%%')\n",
    "        axes[1, 0].set_title('Distribui√ß√£o de Classes de Qualidade')\n",
    "        \n",
    "        # 4. M√©tricas detalhadas\n",
    "        metrics = ['Cobertura', 'Vigor', 'Uniformidade']\n",
    "        avg_coverage = np.mean(coverages)\n",
    "        avg_vigor = np.mean(vigors)\n",
    "        avg_uniformity = np.mean([q['uniformity'] for q in quality_results])\n",
    "        \n",
    "        values = [avg_coverage, avg_vigor, avg_uniformity]\n",
    "        \n",
    "        bars = axes[1, 1].bar(metrics, values, color=['lightblue', 'lightgreen', 'lightcoral'])\n",
    "        axes[1, 1].set_title('M√©tricas M√©dias')\n",
    "        axes[1, 1].set_ylabel('Valor')\n",
    "        \n",
    "        # Adicionar valores nas barras\n",
    "        for bar, value in zip(bars, values):\n",
    "            axes[1, 1].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1,\n",
    "                           f'{value:.1f}', ha='center', va='bottom')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Resumo estat√≠stico\n",
    "        print(\"\\nüìà Resumo Estat√≠stico:\")\n",
    "        avg_quality = np.mean(quality_scores)\n",
    "        print(f\"Score m√©dio de qualidade: {avg_quality:.1f}\")\n",
    "        print(f\"Cobertura m√©dia: {avg_coverage:.1f}%\")\n",
    "        print(f\"Vigor m√©dio: {avg_vigor:.1f}\")\n",
    "        print(f\"Uniformidade m√©dia: {avg_uniformity:.1f}\")\n",
    "        \n",
    "        # Melhor e pior gram√≠nea\n",
    "        best_idx = np.argmax(quality_scores)\n",
    "        worst_idx = np.argmin(quality_scores)\n",
    "        \n",
    "        print(f\"\\nüèÜ Melhor gram√≠nea: {quality_results[best_idx]['grass_type']} (Score: {quality_scores[best_idx]:.1f})\")\n",
    "        print(f\"‚ö†Ô∏è Gram√≠nea que precisa de aten√ß√£o: {quality_results[worst_idx]['grass_type']} (Score: {quality_scores[worst_idx]:.1f})\")\n",
    "\n",
    "else:\n",
    "    print(\"‚ùå An√°lise de qualidade n√£o pode ser executada - dados insuficientes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-23",
   "metadata": {},
   "source": [
    "## üíæ Salvamento e Exporta√ß√£o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvar resultados da an√°lise\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"üíæ Salvando resultados da an√°lise...\")\n",
    "\n",
    "# Preparar dados para exporta√ß√£o\n",
    "export_data = {\n",
    "    'timestamp': datetime.now().isoformat(),\n",
    "    'analysis_type': 'Gram√≠neas de Pastos Brasileiros',\n",
    "    'total_images_generated': len(grass_images) if grass_images else 0,\n",
    "    'total_images_analyzed': len(custom_analysis) if custom_analysis else 0,\n",
    "    'grass_types': [],\n",
    "    'quality_analysis': [],\n",
    "    'detection_summary': {}\n",
    "}\n",
    "\n",
    "# Adicionar dados de qualidade se dispon√≠veis\n",
    "if 'quality_results' in locals() and quality_results:\n",
    "    for result in quality_results:\n",
    "        export_data['quality_analysis'].append({\n",
    "            'grass_type': result['grass_type'],\n",
    "            'quality_score': float(result['quality_score']),\n",
    "            'quality_class': result['quality_class'],\n",
    "            'coverage_percentage': float(result['coverage']),\n",
    "            'vigor_index': float(result['vigor_index']),\n",
    "            'uniformity': float(result['uniformity'])\n",
    "        })\n",
    "    \n",
    "    # Estat√≠sticas resumidas\n",
    "    quality_scores = [r['quality_score'] for r in quality_results]\n",
    "    coverages = [r['coverage'] for r in quality_results]\n",
    "    \n",
    "    export_data['detection_summary'] = {\n",
    "        'average_quality_score': float(np.mean(quality_scores)),\n",
    "        'average_coverage': float(np.mean(coverages)),\n",
    "        'best_grass_score': float(np.max(quality_scores)),\n",
    "        'worst_grass_score': float(np.min(quality_scores)),\n",
    "        'total_grass_types_analyzed': len(quality_results)\n",
    "    }\n",
    "\n",
    "# Adicionar informa√ß√µes sobre gram√≠neas analisadas\n",
    "grass_types_info = [\n",
    "    {'name': 'Brachiaria brizantha', 'characteristics': 'Alta produtividade, resistente √† seca'},\n",
    "    {'name': 'Brachiaria decumbens', 'characteristics': 'Boa adapta√ß√£o, f√°cil estabelecimento'},\n",
    "    {'name': 'Brachiaria humidicola', 'characteristics': 'Tolerante √† umidade, solos pobres'},\n",
    "    {'name': 'Panicum momba√ßa', 'characteristics': 'Alto valor nutritivo, grande porte'},\n",
    "    {'name': 'Panicum tanz√¢nia', 'characteristics': 'Boa digestibilidade, resistente'},\n",
    "    {'name': 'Panicum massai', 'characteristics': 'Compacto, alta qualidade'},\n",
    "    {'name': 'Cynodon tifton', 'characteristics': 'Textura fina, alta digestibilidade'},\n",
    "    {'name': 'Cynodon coast-cross', 'characteristics': 'Resistente ao pisoteio'}\n",
    "]\n",
    "\n",
    "export_data['grass_types'] = grass_types_info\n",
    "\n",
    "# Salvar arquivo JSON\n",
    "filename = f\"analise_gramineas_brasileiras_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json\"\n",
    "with open(filename, 'w', encoding='utf-8') as f:\n",
    "    json.dump(export_data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"‚úÖ Resultados salvos em: {filename}\")\n",
    "\n",
    "# Criar relat√≥rio em texto\n",
    "report_filename = f\"relatorio_gramineas_{datetime.now().strftime('%Y%m%d_%H%M%S')}.txt\"\n",
    "with open(report_filename, 'w', encoding='utf-8') as f:\n",
    "    f.write(\"üåæ RELAT√ìRIO DE AN√ÅLISE DE GRAM√çNEAS DE PASTOS BRASILEIROS\\n\")\n",
    "    f.write(\"=\" * 60 + \"\\n\\n\")\n",
    "    \n",
    "    f.write(f\"Data da an√°lise: {datetime.now().strftime('%d/%m/%Y %H:%M:%S')}\\n\\n\")\n",
    "    \n",
    "    f.write(f\"Total de imagens geradas: {len(grass_images) if grass_images else 0}\\n\")\n",
    "    f.write(f\"Total de imagens analisadas: {len(custom_analysis) if custom_analysis else 0}\\n\\n\")\n",
    "    \n",
    "    if 'quality_results' in locals() and quality_results:\n",
    "        f.write(\"RESULTADOS DE QUALIDADE:\\n\")\n",
    "        f.write(\"-\" * 30 + \"\\n\")\n",
    "        \n",
    "        for i, result in enumerate(quality_results):\n",
    "            f.write(f\"{i+1}. {result['grass_type']}\\n\")\n",
    "            f.write(f\"   Qualidade: {result['quality_class']}\\n\")\n",
    "            f.write(f\"   Score: {result['quality_score']:.1f}/100\\n\")\n",
    "            f.write(f\"   Cobertura: {result['coverage']:.1f}%\\n\")\n",
    "            f.write(f\"   Vigor: {result['vigor_index']:.1f}/255\\n\")\n",
    "            f.write(f\"   Uniformidade: {result['uniformity']:.1f}/100\\n\\n\")\n",
    "        \n",
    "        # Estat√≠sticas gerais\n",
    "        avg_quality = np.mean([r['quality_score'] for r in quality_results])\n",
    "        avg_coverage = np.mean([r['coverage'] for r in quality_results])\n",
    "        \n",
    "        f.write(\"ESTAT√çSTICAS GERAIS:\\n\")\n",
    "        f.write(\"-\" * 20 + \"\\n\")\n",
    "        f.write(f\"Score m√©dio de qualidade: {avg_quality:.1f}\\n\")\n",
    "        f.write(f\"Cobertura m√©dia: {avg_coverage:.1f}%\\n\")\n",
    "    \n",
    "    f.write(\"\\nGRAM√çNEAS ANALISADAS:\\n\")\n",
    "    f.write(\"-\" * 25 + \"\\n\")\n",
    "    for grass in grass_types_info:\n",
    "        f.write(f\"‚Ä¢ {grass['name']}: {grass['characteristics']}\\n\")\n",
    "\n",
    "print(f\"‚úÖ Relat√≥rio salvo em: {report_filename}\")\n",
    "\n",
    "# Informa√ß√µes finais\n",
    "print(\"\\nüìä Informa√ß√µes de Performance:\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"Mem√≥ria GPU alocada: {torch.cuda.memory_allocated() / 1e9:.2f} GB\")\n",
    "    print(f\"Mem√≥ria GPU m√°xima: {torch.cuda.max_memory_allocated() / 1e9:.2f} GB\")\n",
    "\n",
    "print(\"\\n‚úÖ An√°lise de gram√≠neas brasileiras conclu√≠da com sucesso!\")\n",
    "print(\"\\nüéØ Resumo dos Resultados:\")\n",
    "if grass_images:\n",
    "    print(f\"‚Ä¢ {len(grass_images)} imagens sint√©ticas de gram√≠neas geradas\")\n",
    "if custom_analysis:\n",
    "    print(f\"‚Ä¢ {len(custom_analysis)} imagens analisadas com segmenta√ß√£o personalizada\")\n",
    "if 'quality_results' in locals() and quality_results:\n",
    "    avg_score = np.mean([r['quality_score'] for r in quality_results])\n",
    "    print(f\"‚Ä¢ Score m√©dio de qualidade: {avg_score:.1f}/100\")\n",
    "    print(f\"‚Ä¢ {len(quality_results)} gram√≠neas avaliadas\")\n",
    "\n",
    "print(\"\\nüåæ Pr√≥ximos passos sugeridos:\")\n",
    "print(\"‚Ä¢ Expandir dataset com mais variedades de gram√≠neas\")\n",
    "print(\"‚Ä¢ Implementar detec√ß√£o de doen√ßas e pragas\")\n",
    "print(\"‚Ä¢ Desenvolver sistema de monitoramento temporal\")\n",
    "print(\"‚Ä¢ Integrar dados de solo e clima\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}