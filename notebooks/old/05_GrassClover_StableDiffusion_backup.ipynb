{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üåæ GrassClover-Style Generation with Stable Diffusion\n",
    "\n",
    "Este notebook implementa gera√ß√£o de imagens sint√©ticas de pastagens brasileiras usando **Stable Diffusion**, seguindo o estilo visual do **GrassClover Dataset** (Skovsen et al., CVPR 2019).\n",
    "\n",
    "## üéØ Objetivos:\n",
    "- Gerar imagens **top-down** de pastagens com Stable Diffusion\n",
    "- Adaptar para **gram√≠neas brasileiras** (Brachiaria, Panicum, Cynodon)\n",
    "- Seguir **metodologia GrassClover** (densidade, perspectiva, resolu√ß√£o)\n",
    "- **Ultra-compat√≠vel** com Google Colab (debugging extensivo)\n",
    "\n",
    "## üìö Refer√™ncia:\n",
    "- **Paper**: Skovsen et al. \"The GrassClover Image Dataset for Semantic and Hierarchical Species Understanding in Agriculture\" (CVPR Workshops, 2019)\n",
    "- **Adapta√ß√£o**: Esp√©cies temperadas ‚Üí Tropicais brasileiras\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üöÄ Setup Ultra-Compat√≠vel para Colab\n",
    "\n",
    "**IMPORTANTE**: Este notebook foi desenvolvido para m√°xima compatibilidade com Google Colab Free/Pro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîç VERIFICA√á√ÉO INICIAL DO AMBIENTE\n",
    "print(\"=\" * 60)\n",
    "print(\"üåæ GRASSCLOVER STABLE DIFFUSION GENERATOR\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "import sys\n",
    "import platform\n",
    "from datetime import datetime\n",
    "\n",
    "print(f\"üìÖ Timestamp: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"üêç Python: {sys.version.split()[0]}\")\n",
    "print(f\"üíª Platform: {platform.system()} {platform.release()}\")\n",
    "print(f\"üìç Working Directory: {sys.path[0] if sys.path else 'Unknown'}\")\n",
    "\n",
    "# Detectar se estamos no Colab\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "    print(\"üî• Ambiente: Google Colab (DETECTADO)\")\n",
    "except ImportError:\n",
    "    IN_COLAB = False\n",
    "    print(\"üíª Ambiente: Local/Jupyter (DETECTADO)\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üß† VERIFICA√á√ÉO AVAN√áADA DE HARDWARE (GPU/TPU/CPU)\n",
    "print(\"üîç Verificando hardware dispon√≠vel...\\n\")\n",
    "\n",
    "# Vari√°veis de estado\n",
    "device = None\n",
    "device_type = \"unknown\"\n",
    "hardware_info = {}\n",
    "\n",
    "# Tentar importar torch primeiro\n",
    "try:\n",
    "    import torch\n",
    "    TORCH_AVAILABLE = True\n",
    "    print(f\"‚úÖ PyTorch: {torch.__version__}\")\n",
    "    hardware_info['pytorch_version'] = torch.__version__\n",
    "except ImportError:\n",
    "    TORCH_AVAILABLE = False\n",
    "    print(\"‚ùå PyTorch n√£o encontrado - ser√° instalado\")\n",
    "\n",
    "if TORCH_AVAILABLE:\n",
    "    # 1. VERIFICAR TPU (prioridade alta no Colab)\n",
    "    try:\n",
    "        import torch_xla\n",
    "        import torch_xla.core.xla_model as xm\n",
    "        \n",
    "        # Detectar TPU\n",
    "        if xm.xrt_world_size() > 1:\n",
    "            device = xm.xla_device()\n",
    "            device_type = \"tpu\"\n",
    "            print(f\"üî• TPU DETECTADO: {device}\")\n",
    "            print(f\"üöÄ TPU cores: {xm.xrt_world_size()}\")\n",
    "            hardware_info.update({\n",
    "                'device_type': 'tpu',\n",
    "                'tpu_cores': xm.xrt_world_size(),\n",
    "                'device': str(device)\n",
    "            })\n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è  TPU configurado mas n√£o dispon√≠vel\")\n",
    "            \n",
    "    except ImportError:\n",
    "        print(\"üìù torch_xla n√£o encontrado (normal se n√£o usar TPU)\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è  Erro ao verificar TPU: {e}\")\n",
    "    \n",
    "    # 2. VERIFICAR CUDA/GPU (se TPU n√£o dispon√≠vel)\n",
    "    if device is None:\n",
    "        cuda_available = torch.cuda.is_available()\n",
    "        print(f\"üî• CUDA dispon√≠vel: {cuda_available}\")\n",
    "        \n",
    "        if cuda_available:\n",
    "            gpu_count = torch.cuda.device_count()\n",
    "            print(f\"üöÄ N√∫mero de GPUs: {gpu_count}\")\n",
    "            \n",
    "            for i in range(gpu_count):\n",
    "                gpu_name = torch.cuda.get_device_name(i)\n",
    "                gpu_memory = torch.cuda.get_device_properties(i).total_memory\n",
    "                gpu_memory_gb = gpu_memory / (1024**3)\n",
    "                print(f\"  GPU {i}: {gpu_name}\")\n",
    "                print(f\"  Mem√≥ria: {gpu_memory_gb:.1f} GB\")\n",
    "            \n",
    "            device = torch.device(\"cuda\")\n",
    "            device_type = \"gpu\"\n",
    "            hardware_info.update({\n",
    "                'device_type': 'gpu',\n",
    "                'gpu_count': gpu_count,\n",
    "                'gpu_name': torch.cuda.get_device_name(0),\n",
    "                'gpu_memory_gb': torch.cuda.get_device_properties(0).total_memory / (1024**3),\n",
    "                'device': str(device)\n",
    "            })\n",
    "            \n",
    "            # Limpeza inicial de mem√≥ria GPU\n",
    "            torch.cuda.empty_cache()\n",
    "            print(\"üßπ Cache GPU limpo\")\n",
    "            \n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è  CUDA n√£o dispon√≠vel\")\n",
    "    \n",
    "    # 3. FALLBACK PARA CPU\n",
    "    if device is None:\n",
    "        device = torch.device(\"cpu\")\n",
    "        device_type = \"cpu\"\n",
    "        hardware_info.update({\n",
    "            'device_type': 'cpu',\n",
    "            'device': str(device)\n",
    "        })\n",
    "        print(\"üíª Usando CPU (fallback)\")\n",
    "\n",
    "    # Status final do hardware\n",
    "    print(f\"\\nüéØ DEVICE CONFIGURADO: {device} ({device_type.upper()})\")\n",
    "    \n",
    "    # Instru√ß√µes espec√≠ficas para problemas\n",
    "    if device_type == \"cpu\" and IN_COLAB:\n",
    "        print(f\"\\nüö® IMPORTANTE: Voc√™ est√° usando CPU no Colab!\")\n",
    "        print(f\"Para ativar acelera√ß√£o de hardware:\")\n",
    "        print(f\"1. Runtime ‚Üí Change runtime type\")\n",
    "        print(f\"2. Hardware accelerator: GPU ou TPU\") \n",
    "        print(f\"3. Save ‚Üí Connect (reconectar)\")\n",
    "        print(f\"4. Re-executar este notebook\")\n",
    "        \n",
    "    elif device_type == \"tpu\":\n",
    "        print(f\"‚úÖ TPU configurado! Otimizado para treinamento paralelo.\")\n",
    "        \n",
    "    elif device_type == \"gpu\":\n",
    "        print(f\"‚úÖ GPU configurado! Otimizado para infer√™ncia r√°pida.\")\n",
    "\n",
    "else:\n",
    "    device = None\n",
    "    device_type = \"none\"\n",
    "    print(\"\\n‚è≥ PyTorch ser√° instalado na pr√≥xima c√©lula\")\n",
    "\n",
    "print(f\"\\nüìä Hardware Info: {hardware_info}\")\n",
    "print(\"\\n\" + \"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "source": "# üîê AUTENTICA√á√ÉO HUGGINGFACE \nprint(\"üîê Configurando autentica√ß√£o HuggingFace...\\n\")\n\ntry:\n    from huggingface_hub import notebook_login\n    \n    print(\"üìã Para usar Stable Diffusion 3.5 Large, voc√™ precisa fazer login no HuggingFace\")\n    print(\"üí° Aceite os termos em: https://huggingface.co/stabilityai/stable-diffusion-3.5-large\")\n    print(\"‚è≥ Executando login...\")\n    \n    # Login interativo no notebook\n    notebook_login()\n    \n    print(\"‚úÖ Login realizado com sucesso!\")\n    HUGGINGFACE_LOGGED_IN = True\n    \nexcept Exception as e:\n    print(f\"‚ö†Ô∏è  Erro no login: {e}\")\n    print(\"üîÑ Continuando sem autentica√ß√£o (fallback para SD1.5)\")\n    HUGGINGFACE_LOGGED_IN = False\n\nprint(\"=\" * 60)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# üöÄ STABLE DIFFUSION 3.5 LARGE - CONFIGURA√á√ÉO CORRIGIDA\n",
    "print(\"üöÄ Configurando Stable Diffusion 3.5 Large...\\n\")\n",
    "\n",
    "# üéØ VERS√ÉO CORRIGIDA: SD3.5 com fallback robusto\n",
    "def load_stable_diffusion_pipeline_advanced():\n",
    "    \"\"\"\n",
    "    Carrega SD3.5 Large com fallback autom√°tico e tratamento de erros robusto\n",
    "    \"\"\"\n",
    "    print(\"üîÑ Tentando carregar Stable Diffusion 3.5 Large...\")\n",
    "    \n",
    "    # Verificar se temos login do HuggingFace\n",
    "    if not HUGGINGFACE_LOGGED_IN:\n",
    "        print(\"‚ö†Ô∏è  HuggingFace login n√£o realizado, tentando mesmo assim...\")\n",
    "    \n",
    "    try:\n",
    "        # Imports espec√≠ficos para SD3.5\n",
    "        from diffusers import StableDiffusion3Pipeline\n",
    "        import torch\n",
    "        \n",
    "        print(\"üì¶ Imports SD3.5 bem-sucedidos\")\n",
    "        \n",
    "        # Configura√ß√µes mais conservadoras para SD3.5\n",
    "        load_kwargs = {\n",
    "            \"torch_dtype\": torch.bfloat16 if torch.cuda.is_available() else torch.float32,\n",
    "            \"device_map\": \"auto\" if torch.cuda.is_available() else None,\n",
    "            \"low_cpu_mem_usage\": True,\n",
    "        }\n",
    "        \n",
    "        print(f\"üîß Tentando carregar com par√¢metros: {load_kwargs}\")\n",
    "        \n",
    "        # Tentar carregar SD3.5 com tratamento mais robusto\n",
    "        pipe = StableDiffusion3Pipeline.from_pretrained(\n",
    "            \"stabilityai/stable-diffusion-3.5-large\", \n",
    "            **load_kwargs\n",
    "        )\n",
    "        \n",
    "        print(\"‚úÖ Stable Diffusion 3.5 Large carregado com sucesso!\")\n",
    "        \n",
    "        # Mover para device se necess√°rio (j√° pode estar no device certo com device_map)\n",
    "        if not torch.cuda.is_available() or load_kwargs.get(\"device_map\") is None:\n",
    "            pipe = pipe.to(device)\n",
    "        \n",
    "        return pipe, \"3.5\"\n",
    "        \n",
    "    except ImportError as e:\n",
    "        print(f\"‚ùå Erro de import SD3.5: {e}\")\n",
    "        print(\"üí° Pode ser necess√°rio atualizar diffusers: pip install --upgrade diffusers\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è  SD3.5 falhou: {str(e)[:200]}...\")\n",
    "        print(f\"üîç Tipo do erro: {type(e).__name__}\")\n",
    "        \n",
    "        # Erros comuns e solu√ß√µes\n",
    "        if \"get() takes 1 positional argument\" in str(e):\n",
    "            print(\"üí° Erro de compatibilidade - tentando par√¢metros alternativos...\")\n",
    "            \n",
    "            try:\n",
    "                # Tentativa com par√¢metros mais simples\n",
    "                simple_kwargs = {\n",
    "                    \"torch_dtype\": torch.bfloat16 if torch.cuda.is_available() else torch.float32,\n",
    "                }\n",
    "                \n",
    "                pipe = StableDiffusion3Pipeline.from_pretrained(\n",
    "                    \"stabilityai/stable-diffusion-3.5-large\", \n",
    "                    **simple_kwargs\n",
    "                )\n",
    "                pipe = pipe.to(device)\n",
    "                print(\"‚úÖ SD3.5 carregado com par√¢metros simplificados!\")\n",
    "                return pipe, \"3.5\"\n",
    "                \n",
    "            except Exception as e2:\n",
    "                print(f\"‚ùå Tentativa simplificada tamb√©m falhou: {e2}\")\n",
    "                \n",
    "        elif \"requires you to be logged in\" in str(e) or \"authentication\" in str(e):\n",
    "            print(\"üîê Erro de autentica√ß√£o - verifique seu login no HuggingFace\")\n",
    "            \n",
    "        elif \"out of memory\" in str(e).lower() or \"oom\" in str(e).lower():\n",
    "            print(\"üíæ Erro de mem√≥ria - SD3.5 requer muita VRAM\")\n",
    "    \n",
    "    # Fallback para SD1.5\n",
    "    print(\"üîÑ Iniciando fallback para Stable Diffusion 1.5...\")\n",
    "    \n",
    "    try:\n",
    "        from diffusers import StableDiffusionPipeline\n",
    "        \n",
    "        # Par√¢metros para SD1.5\n",
    "        fallback_kwargs = {\n",
    "            \"torch_dtype\": TORCH_DTYPE,\n",
    "            \"low_cpu_mem_usage\": True,\n",
    "            \"use_safetensors\": True,\n",
    "        }\n",
    "        \n",
    "        pipe = StableDiffusionPipeline.from_pretrained(\n",
    "            \"runwayml/stable-diffusion-v1-5\", \n",
    "            **fallback_kwargs\n",
    "        )\n",
    "        \n",
    "        pipe = pipe.to(device)\n",
    "        print(\"‚úÖ Fallback SD1.5 carregado com sucesso!\")\n",
    "        return pipe, \"1.5\"\n",
    "        \n",
    "    except Exception as e2:\n",
    "        print(f\"‚ùå Fallback SD1.5 tamb√©m falhou: {e2}\")\n",
    "        return None, None\n",
    "\n",
    "# Carregar pipeline com fun√ß√£o corrigida\n",
    "pipe, sd_version = load_stable_diffusion_pipeline_advanced()\n",
    "\n",
    "if pipe is not None:\n",
    "    print(f\"\\nüéØ Pipeline Stable Diffusion {sd_version} carregado!\")\n",
    "    \n",
    "    # Configurar scheduler se necess√°rio\n",
    "    try:\n",
    "        if sd_version == \"1.5\":\n",
    "            from diffusers import DPMSolverMultistepScheduler\n",
    "            pipe.scheduler = DPMSolverMultistepScheduler.from_config(pipe.scheduler.config)\n",
    "            print(\"üîß Scheduler DPMSolver aplicado (SD1.5)\")\n",
    "        else:\n",
    "            print(\"üîß Usando scheduler nativo do SD3.5\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è  Mantendo scheduler padr√£o: {e}\")\n",
    "    \n",
    "    # Aplicar otimiza√ß√µes baseadas na vers√£o\n",
    "    if sd_version == \"3.5\":\n",
    "        print(f\"üéØ Configura√ß√£o SD3.5:\")\n",
    "        print(f\"  ‚Ä¢ Dtype: torch.bfloat16\")\n",
    "        print(f\"  ‚Ä¢ Steps recomendados: 28\")\n",
    "        print(f\"  ‚Ä¢ Guidance scale: 4.0\")\n",
    "        \n",
    "        GENERATION_PARAMS_CURRENT = {\n",
    "            'width': 512,\n",
    "            'height': 512,\n",
    "            'num_inference_steps': 28,\n",
    "            'guidance_scale': 4.0,\n",
    "            'num_images_per_prompt': 1,\n",
    "            'eta': 0.0,\n",
    "            'generator_seed': 42\n",
    "        }\n",
    "        \n",
    "    else:  # SD1.5\n",
    "        print(f\"üéØ Configura√ß√£o SD1.5:\")\n",
    "        print(f\"  ‚Ä¢ Dtype: {TORCH_DTYPE}\")\n",
    "        print(f\"  ‚Ä¢ Steps: 25\")\n",
    "        print(f\"  ‚Ä¢ Guidance scale: 7.5\")\n",
    "        \n",
    "        GENERATION_PARAMS_CURRENT = {\n",
    "            'width': 512,\n",
    "            'height': 512,\n",
    "            'num_inference_steps': 25,\n",
    "            'guidance_scale': 7.5,\n",
    "            'num_images_per_prompt': 1,\n",
    "            'eta': 0.0,\n",
    "            'generator_seed': 42\n",
    "        }\n",
    "    \n",
    "    # Aplicar otimiza√ß√µes de mem√≥ria\n",
    "    try:\n",
    "        if hasattr(pipe, 'enable_attention_slicing'):\n",
    "            pipe.enable_attention_slicing()\n",
    "            print(\"‚úÖ Attention slicing ativado\")\n",
    "            \n",
    "        if hasattr(pipe, 'enable_memory_efficient_attention') and device.type == \"cuda\":\n",
    "            pipe.enable_memory_efficient_attention()  \n",
    "            print(\"‚úÖ Memory efficient attention ativado\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è  Algumas otimiza√ß√µes falharam: {e}\")\n",
    "    \n",
    "    PIPELINE_READY = True\n",
    "    print(f\"\\n‚úÖ Pipeline pronto para uso!\")\n",
    "    print(f\"üéØ Device: {device}\")\n",
    "    \n",
    "else:\n",
    "    PIPELINE_READY = False\n",
    "    print(\"‚ùå Falha total - nenhuma vers√£o do Stable Diffusion foi carregada!\")\n",
    "    print(\"üí° Poss√≠veis solu√ß√µes:\")\n",
    "    print(\"  1. Verificar login no HuggingFace\")\n",
    "    print(\"  2. Atualizar diffusers: pip install --upgrade diffusers\")\n",
    "    print(\"  3. Reiniciar runtime se necess√°rio\")\n",
    "\n",
    "print(\"=\" * 60)\n"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üì¶ INSTALA√á√ÉO DE DEPEND√äNCIAS ESSENCIAIS\n",
    "print(\"üì¶ Instalando depend√™ncias essenciais...\\n\")\n",
    "\n",
    "# Lista de pacotes essenciais\n",
    "essential_packages = [\n",
    "    \"torch\",\n",
    "    \"torchvision\", \n",
    "    \"diffusers\",\n",
    "    \"transformers\",\n",
    "    \"accelerate\",\n",
    "    \"pillow\",\n",
    "    \"matplotlib\",\n",
    "    \"numpy\"\n",
    "]\n",
    "\n",
    "# Fun√ß√£o para instalar com debug\n",
    "def install_package(package_name, quiet=True):\n",
    "    \"\"\"Instala pacote com debugging\"\"\"\n",
    "    import subprocess\n",
    "    \n",
    "    print(f\"‚è≥ Instalando {package_name}...\")\n",
    "    \n",
    "    try:\n",
    "        cmd = [\"pip\", \"install\", package_name]\n",
    "        if quiet:\n",
    "            cmd.append(\"--quiet\")\n",
    "        \n",
    "        result = subprocess.run(cmd, capture_output=True, text=True, timeout=300)\n",
    "        \n",
    "        if result.returncode == 0:\n",
    "            print(f\"‚úÖ {package_name} instalado com sucesso\")\n",
    "            return True\n",
    "        else:\n",
    "            print(f\"‚ùå Erro ao instalar {package_name}:\")\n",
    "            print(f\"STDOUT: {result.stdout}\")\n",
    "            print(f\"STDERR: {result.stderr}\")\n",
    "            return False\n",
    "            \n",
    "    except subprocess.TimeoutExpired:\n",
    "        print(f\"‚è∞ Timeout ao instalar {package_name}\")\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        print(f\"üí• Exce√ß√£o ao instalar {package_name}: {e}\")\n",
    "        return False\n",
    "\n",
    "# Instalar apenas se necess√°rio\n",
    "for package in essential_packages:\n",
    "    try:\n",
    "        __import__(package.replace(\"-\", \"_\"))\n",
    "        print(f\"‚úÖ {package} j√° dispon√≠vel\")\n",
    "    except ImportError:\n",
    "        success = install_package(package)\n",
    "        if not success:\n",
    "            print(f\"üö® FALHA CR√çTICA: N√£o foi poss√≠vel instalar {package}\")\n",
    "            print(f\"üìã DEBUG INFO para copy/paste:\")\n",
    "            print(f\"Package: {package}\")\n",
    "            print(f\"Environment: {'Colab' if IN_COLAB else 'Local'}\")\n",
    "            print(f\"Python: {sys.version}\")\n",
    "            break\n",
    "\n",
    "print(f\"\\nüéâ Instala√ß√£o conclu√≠da!\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîÑ REIMPORTA√á√ÉO E VERIFICA√á√ÉO FINAL COM CONFIGURA√á√ïES OTIMIZADAS\n",
    "print(\"üîÑ Verificando importa√ß√µes finais e configurando hardware...\\n\")\n",
    "\n",
    "# Imports essenciais com debugging\n",
    "try:\n",
    "    import torch\n",
    "    import torchvision.transforms as transforms\n",
    "    print(f\"‚úÖ PyTorch: {torch.__version__}\")\n",
    "    \n",
    "    # Reconfigurar device ap√≥s instala√ß√£o se necess√°rio\n",
    "    if not 'device' in locals() or device is None:\n",
    "        if torch.cuda.is_available():\n",
    "            device = torch.device(\"cuda\")\n",
    "            device_type = \"gpu\"\n",
    "            gpu_name = torch.cuda.get_device_name(0)\n",
    "            gpu_memory = torch.cuda.get_device_properties(0).total_memory / (1024**3)\n",
    "            print(f\"üöÄ GPU: {gpu_name} ({gpu_memory:.1f} GB)\")\n",
    "            \n",
    "            # Configura√ß√£o otimizada para GPU\n",
    "            torch.backends.cudnn.benchmark = True\n",
    "            torch.cuda.empty_cache()\n",
    "            \n",
    "        else:\n",
    "            device = torch.device(\"cpu\")\n",
    "            device_type = \"cpu\"\n",
    "            print(\"üíª Device: CPU\")\n",
    "    \n",
    "    # Configurar dtype baseado no hardware\n",
    "    if device_type == \"gpu\":\n",
    "        TORCH_DTYPE = torch.bfloat16  # GPU: usar half precision\n",
    "        print(f\"üî¢ Dtype: {TORCH_DTYPE} (GPU otimizado)\")\n",
    "    elif device_type == \"tpu\":\n",
    "        TORCH_DTYPE = torch.float32  # TPU: full precision recomendado\n",
    "        print(f\"üî¢ Dtype: {TORCH_DTYPE} (TPU otimizado)\")\n",
    "    else:\n",
    "        TORCH_DTYPE = torch.float32  # CPU: full precision\n",
    "        print(f\"üî¢ Dtype: {TORCH_DTYPE} (CPU padr√£o)\")\n",
    "        \n",
    "except ImportError as e:\n",
    "    print(f\"‚ùå Erro PyTorch: {e}\")\n",
    "    device = None\n",
    "    device_type = \"none\"\n",
    "    TORCH_DTYPE = None\n",
    "\n",
    "try:\n",
    "    from diffusers import StableDiffusion3Pipeline, DPMSolverMultistepScheduler\n",
    "    print(f\"‚úÖ Diffusers importado\")\n",
    "    DIFFUSERS_AVAILABLE = True\n",
    "except ImportError as e:\n",
    "    print(f\"‚ùå Erro Diffusers: {e}\")\n",
    "    DIFFUSERS_AVAILABLE = False\n",
    "\n",
    "try:\n",
    "    from PIL import Image, ImageEnhance, ImageFilter\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    print(f\"‚úÖ PIL, Matplotlib, NumPy importados\")\n",
    "    BASIC_LIBS_AVAILABLE = True\n",
    "except ImportError as e:\n",
    "    print(f\"‚ùå Erro bibliotecas b√°sicas: {e}\")\n",
    "    BASIC_LIBS_AVAILABLE = False\n",
    "\n",
    "# Configura√ß√£o de ambiente Hugging Face\n",
    "print(f\"\\nü§ó Configurando Hugging Face...\")\n",
    "try:\n",
    "    import os\n",
    "    # Desabilitar telemetria para evitar warnings\n",
    "    os.environ[\"DISABLE_TELEMETRY\"] = \"1\"\n",
    "    os.environ[\"HF_HUB_DISABLE_TELEMETRY\"] = \"1\"\n",
    "    \n",
    "    # Configurar cache offline se necess√°rio\n",
    "    if IN_COLAB:\n",
    "        os.environ[\"TRANSFORMERS_OFFLINE\"] = \"0\"  # Permitir downloads no Colab\n",
    "        os.environ[\"HF_HUB_OFFLINE\"] = \"0\"\n",
    "    \n",
    "    print(f\"‚úÖ Vari√°veis HF configuradas (telemetria desabilitada)\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è  Aviso na configura√ß√£o HF: {e}\")\n",
    "\n",
    "# Status final\n",
    "ALL_READY = device is not None and DIFFUSERS_AVAILABLE and BASIC_LIBS_AVAILABLE\n",
    "\n",
    "print(f\"\\n{'üéØ SISTEMA PRONTO!' if ALL_READY else 'üö® PROBLEMAS DETECTADOS!'}\")\n",
    "if ALL_READY:\n",
    "    print(f\"‚úÖ Device: {device} ({device_type})\")\n",
    "    print(f\"‚úÖ Dtype: {TORCH_DTYPE}\")\n",
    "    print(f\"‚úÖ Todas as bibliotecas carregadas\")\n",
    "else:\n",
    "    print(\"\\nüìã DEBUG COPY/PASTE INFO:\")\n",
    "    print(f\"Device: {device}\")\n",
    "    print(f\"Device type: {device_type if 'device_type' in locals() else 'unknown'}\")\n",
    "    print(f\"Diffusers: {DIFFUSERS_AVAILABLE}\")\n",
    "    print(f\"Basic libs: {BASIC_LIBS_AVAILABLE}\")\n",
    "    print(f\"In Colab: {IN_COLAB}\")\n",
    "    \n",
    "    if device_type == \"cpu\" and IN_COLAB:\n",
    "        print(f\"\\nüîß A√á√ÉO NECESS√ÅRIA:\")\n",
    "        print(f\"1. Runtime ‚Üí Change runtime type\")\n",
    "        print(f\"2. Hardware accelerator: GPU\")\n",
    "        print(f\"3. Save e reconectar\")\n",
    "\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üé® Pipeline Stable Diffusion para GrassClover\n",
    "\n",
    "Configura√ß√£o do pipeline otimizado para gera√ß√£o de pastagens no estilo GrassClover."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üé® CONFIGURA√á√ÉO AVAN√áADA DO PIPELINE STABLE DIFFUSION\n",
    "print(\"üé® Configurando Stable Diffusion Pipeline...\\n\")\n",
    "\n",
    "# Par√¢metros do pipeline baseados no hardware detectado\n",
    "MODEL_ID = \"runwayml/stable-diffusion-v1-5\"  # Modelo base confi√°vel\n",
    "LOW_CPU_MEM_USAGE = True\n",
    "ENABLE_ATTENTION_SLICING = True\n",
    "\n",
    "# Configura√ß√µes espec√≠ficas por hardware\n",
    "if device_type == \"gpu\":\n",
    "    ENABLE_MODEL_CPU_OFFLOAD = False\n",
    "    ENABLE_SEQUENTIAL_CPU_OFFLOAD = False\n",
    "    USE_TORCH_COMPILE = True\n",
    "elif device_type == \"tpu\":\n",
    "    ENABLE_MODEL_CPU_OFFLOAD = True\n",
    "    ENABLE_SEQUENTIAL_CPU_OFFLOAD = False\n",
    "    USE_TORCH_COMPILE = False  # TPU pode ter problemas com compile\n",
    "else:  # CPU\n",
    "    ENABLE_MODEL_CPU_OFFLOAD = True\n",
    "    ENABLE_SEQUENTIAL_CPU_OFFLOAD = True\n",
    "    USE_TORCH_COMPILE = False\n",
    "\n",
    "print(f\"üì¶ Modelo: {MODEL_ID}\")\n",
    "print(f\"üî¢ Dtype: {TORCH_DTYPE}\")\n",
    "print(f\"üíæ Low CPU mem: {LOW_CPU_MEM_USAGE}\")\n",
    "print(f\"‚ö° Attention slicing: {ENABLE_ATTENTION_SLICING}\")\n",
    "print(f\"üèÉ Model CPU offload: {ENABLE_MODEL_CPU_OFFLOAD}\")\n",
    "print(f\"üî• Hardware: {device_type.upper()}\")\n",
    "\n",
    "# Fun√ß√£o para carregar pipeline com debugging e bypass de autentica√ß√£o\n",
    "def load_stable_diffusion_pipeline():\n",
    "    \"\"\"Carrega pipeline com m√°ximo debugging e configura√ß√µes otimizadas\"\"\"\n",
    "    try:\n",
    "        print(\"‚è≥ Carregando modelo...\")\n",
    "        \n",
    "        # Configura√ß√µes para bypass de problemas de autentica√ß√£o\n",
    "        load_kwargs = {\n",
    "            \"torch_dtype\": TORCH_DTYPE,\n",
    "            \"low_cpu_mem_usage\": LOW_CPU_MEM_USAGE,\n",
    "            \"use_safetensors\": True,\n",
    "        }\n",
    "        \n",
    "        # Configura√ß√µes espec√≠ficas para resolver problemas HF\n",
    "        try:\n",
    "            # Tentar com autentica√ß√£o padr√£o primeiro\n",
    "            pipe = StableDiffusionPipeline.from_pretrained(MODEL_ID, **load_kwargs)\n",
    "            print(\"‚úÖ Modelo carregado com autentica√ß√£o padr√£o\")\n",
    "        except Exception as auth_error:\n",
    "            print(f\"‚ö†Ô∏è  Problema de autentica√ß√£o: {str(auth_error)[:100]}...\")\n",
    "            print(\"üîÑ Tentando download for√ßado...\")\n",
    "            \n",
    "            # Bypass de problemas de autentica√ß√£o\n",
    "            load_kwargs[\"use_auth_token\"] = False\n",
    "            load_kwargs[\"force_download\"] = False\n",
    "            load_kwargs[\"resume_download\"] = True\n",
    "            \n",
    "            pipe = StableDiffusionPipeline.from_pretrained(MODEL_ID, **load_kwargs)\n",
    "            print(\"‚úÖ Modelo carregado com bypass de autentica√ß√£o\")\n",
    "        \n",
    "        # Mover para device\n",
    "        pipe = pipe.to(device)\n",
    "        print(f\"üöÄ Pipeline movido para {device}\")\n",
    "        \n",
    "        # Otimiza√ß√µes baseadas no hardware\n",
    "        if ENABLE_ATTENTION_SLICING:\n",
    "            pipe.enable_attention_slicing()\n",
    "            print(\"‚ö° Attention slicing habilitado\")\n",
    "        \n",
    "        if ENABLE_MODEL_CPU_OFFLOAD and device_type != \"cpu\":\n",
    "            try:\n",
    "                pipe.enable_model_cpu_offload()\n",
    "                print(\"üíæ Model CPU offload habilitado\")\n",
    "            except Exception as e:\n",
    "                print(f\"‚ö†Ô∏è  CPU offload falhou: {e}\")\n",
    "        \n",
    "        if ENABLE_SEQUENTIAL_CPU_OFFLOAD and device_type == \"cpu\":\n",
    "            try:\n",
    "                pipe.enable_sequential_cpu_offload()\n",
    "                print(\"üîÑ Sequential CPU offload habilitado\")\n",
    "            except Exception as e:\n",
    "                print(f\"‚ö†Ô∏è  Sequential offload falhou: {e}\")\n",
    "        \n",
    "        # Scheduler otimizado\n",
    "        pipe.scheduler = DPMSolverMultistepScheduler.from_config(pipe.scheduler.config)\n",
    "        print(\"üîß Scheduler otimizado (DPMSolver)\")\n",
    "        \n",
    "        # Configura√ß√µes de mem√≥ria espec√≠ficas\n",
    "        if device_type == \"gpu\":\n",
    "            torch.cuda.empty_cache()\n",
    "            allocated = torch.cuda.memory_allocated() / (1024**3)\n",
    "            cached = torch.cuda.memory_reserved() / (1024**3)\n",
    "            print(f\"üíæ GPU Memory - Allocated: {allocated:.2f}GB, Cached: {cached:.2f}GB\")\n",
    "            \n",
    "            # Verificar se h√° mem√≥ria suficiente\n",
    "            if allocated > 10.0:  # >10GB pode causar problemas\n",
    "                print(f\"‚ö†Ô∏è  Alta utiliza√ß√£o de mem√≥ria GPU!\")\n",
    "                \n",
    "        elif device_type == \"tpu\":\n",
    "            print(\"üî• TPU configurado - mem√≥ria gerenciada automaticamente\")\n",
    "            \n",
    "        else:  # CPU\n",
    "            print(\"üíª CPU mode - sem monitoramento de GPU memory\")\n",
    "        \n",
    "        print(\"\\n‚úÖ Pipeline configurado com sucesso!\")\n",
    "        return pipe\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"üí• ERRO ao carregar pipeline: {e}\")\n",
    "        print(f\"\\nüìã DEBUG COPY/PASTE:\")\n",
    "        print(f\"Model: {MODEL_ID}\")\n",
    "        print(f\"Device: {device} ({device_type})\")\n",
    "        print(f\"Dtype: {TORCH_DTYPE}\")\n",
    "        print(f\"Hardware info: {hardware_info if 'hardware_info' in locals() else 'N/A'}\")\n",
    "        print(f\"Error type: {type(e).__name__}\")\n",
    "        print(f\"Error message: {e}\")\n",
    "        \n",
    "        # Sugest√µes baseadas no tipo de erro\n",
    "        error_str = str(e).lower()\n",
    "        if \"authentication\" in error_str or \"token\" in error_str:\n",
    "            print(f\"\\nüí° SOLU√á√ÉO PARA ERRO DE TOKEN:\")\n",
    "            print(f\"1. Ignore o warning - o modelo deve funcionar mesmo assim\")\n",
    "            print(f\"2. Ou configure HF_TOKEN manualmente se necess√°rio\")\n",
    "            \n",
    "        elif \"memory\" in error_str or \"cuda\" in error_str:\n",
    "            print(f\"\\nüí° SOLU√á√ÉO PARA ERRO DE MEM√ìRIA:\")\n",
    "            print(f\"1. Reduzir batch_size\")\n",
    "            print(f\"2. Usar torch.float16 se estiver usando float32\")\n",
    "            print(f\"3. Fechar outros notebooks no Colab\")\n",
    "            \n",
    "        elif \"module\" in error_str or \"import\" in error_str:\n",
    "            print(f\"\\nüí° SOLU√á√ÉO PARA ERRO DE M√ìDULO:\")\n",
    "            print(f\"1. Re-executar c√©lulas de instala√ß√£o\")\n",
    "            print(f\"2. Restart runtime se necess√°rio\")\n",
    "            \n",
    "        return None\n",
    "\n",
    "# Carregar pipeline\n",
    "if ALL_READY:\n",
    "    pipe = load_stable_diffusion_pipeline()\n",
    "    PIPELINE_READY = pipe is not None\n",
    "else:\n",
    "    pipe = None\n",
    "    PIPELINE_READY = False\n",
    "    print(\"‚ùå Sistema n√£o est√° pronto para carregar pipeline\")\n",
    "\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üé® CONFIGURA√á√ÉO AVAN√áADA DO PIPELINE STABLE DIFFUSION\n",
    "print(\"üé® Configurando Stable Diffusion Pipeline...\\n\")\n",
    "\n",
    "# Par√¢metros do pipeline baseados no hardware detectado\n",
    "MODEL_ID = \"stabilityai/stable-diffusion-3.5-large\"  # Modelo SD 3.5 Large - Estado da Arte\n",
    "LOW_CPU_MEM_USAGE = True\n",
    "ENABLE_ATTENTION_SLICING = True\n",
    "\n",
    "# Configura√ß√µes espec√≠ficas por hardware\n",
    "if device_type == \"gpu\":\n",
    "    ENABLE_MODEL_CPU_OFFLOAD = False\n",
    "    ENABLE_SEQUENTIAL_CPU_OFFLOAD = False\n",
    "    USE_TORCH_COMPILE = True\n",
    "elif device_type == \"tpu\":\n",
    "    ENABLE_MODEL_CPU_OFFLOAD = True\n",
    "    ENABLE_SEQUENTIAL_CPU_OFFLOAD = False\n",
    "    USE_TORCH_COMPILE = False  # TPU pode ter problemas com compile\n",
    "else:  # CPU\n",
    "    ENABLE_MODEL_CPU_OFFLOAD = True\n",
    "    ENABLE_SEQUENTIAL_CPU_OFFLOAD = True\n",
    "    USE_TORCH_COMPILE = False\n",
    "\n",
    "print(f\"üì¶ Modelo: {MODEL_ID}\")\n",
    "print(f\"üî¢ Dtype: {TORCH_DTYPE}\")\n",
    "print(f\"üíæ Low CPU mem: {LOW_CPU_MEM_USAGE}\")\n",
    "print(f\"‚ö° Attention slicing: {ENABLE_ATTENTION_SLICING}\")\n",
    "print(f\"üèÉ Model CPU offload: {ENABLE_MODEL_CPU_OFFLOAD}\")\n",
    "print(f\"üî• Hardware: {device_type.upper()}\")\n",
    "\n",
    "# Fun√ß√£o para carregar pipeline com debugging e bypass de autentica√ß√£o\n",
    "def load_stable_diffusion_pipeline():\n",
    "    # \"\"\"Carrega pipeline com m√°ximo debugging e configura√ß√µes otimizadas\"\"\"\n",
    "    try:\n",
    "        print(\"‚è≥ Carregando modelo...\")\n",
    "        \n",
    "        # Configura√ß√µes para bypass de problemas de autentica√ß√£o\n",
    "        load_kwargs = {\n",
    "            \"torch_dtype\": TORCH_DTYPE,\n",
    "            \"low_cpu_mem_usage\": LOW_CPU_MEM_USAGE,\n",
    "            \"use_safetensors\": True,\n",
    "        }\n",
    "        \n",
    "        # Configura√ß√µes espec√≠ficas para resolver problemas HF\n",
    "        try:\n",
    "            # Tentar com autentica√ß√£o padr√£o primeiro\n",
    "            pipe = StableDiffusion3Pipeline.from_pretrained(MODEL_ID, **load_kwargs)\n",
    "            print(\"‚úÖ Modelo carregado com autentica√ß√£o padr√£o\")\n",
    "        except Exception as auth_error:\n",
    "            print(f\"‚ö†Ô∏è  Problema de autentica√ß√£o: {str(auth_error)[:100]}...\")\n",
    "            print(\"üîÑ Tentando download for√ßado...\")\n",
    "            \n",
    "            # Bypass de problemas de autentica√ß√£o\n",
    "            load_kwargs[\"use_auth_token\"] = False\n",
    "            load_kwargs[\"force_download\"] = False\n",
    "            load_kwargs[\"resume_download\"] = True\n",
    "            \n",
    "            pipe = StableDiffusion3Pipeline.from_pretrained(MODEL_ID, **load_kwargs)\n",
    "            print(\"‚úÖ Modelo carregado com bypass de autentica√ß√£o\")\n",
    "        \n",
    "        # Mover para device\n",
    "        pipe = pipe.to(device)\n",
    "        print(f\"üöÄ Pipeline movido para {device}\")\n",
    "        \n",
    "        # Otimiza√ß√µes baseadas no hardware\n",
    "        if ENABLE_ATTENTION_SLICING:\n",
    "            pipe.enable_attention_slicing()\n",
    "            print(\"‚ö° Attention slicing habilitado\")\n",
    "        \n",
    "        if ENABLE_MODEL_CPU_OFFLOAD and device_type != \"cpu\":\n",
    "            try:\n",
    "                pipe.enable_model_cpu_offload()\n",
    "                print(\"üíæ Model CPU offload habilitado\")\n",
    "            except Exception as e:\n",
    "                print(f\"‚ö†Ô∏è  CPU offload falhou: {e}\")\n",
    "        \n",
    "        if ENABLE_SEQUENTIAL_CPU_OFFLOAD and device_type == \"cpu\":\n",
    "            try:\n",
    "                pipe.enable_sequential_cpu_offload()\n",
    "                print(\"üîÑ Sequential CPU offload habilitado\")\n",
    "            except Exception as e:\n",
    "                print(f\"‚ö†Ô∏è  Sequential offload falhou: {e}\")\n",
    "        \n",
    "        # Scheduler otimizado\n",
    "        pipe.scheduler = DPMSolverMultistepScheduler.from_config(pipe.scheduler.config)\n",
    "        print(\"üîß Scheduler otimizado (DPMSolver)\")\n",
    "        \n",
    "        # Configura√ß√µes de mem√≥ria espec√≠ficas\n",
    "        if device_type == \"gpu\":\n",
    "            torch.cuda.empty_cache()\n",
    "            allocated = torch.cuda.memory_allocated() / (1024**3)\n",
    "            cached = torch.cuda.memory_reserved() / (1024**3)\n",
    "            print(f\"üíæ GPU Memory - Allocated: {allocated:.2f}GB, Cached: {cached:.2f}GB\")\n",
    "            \n",
    "            # Verificar se h√° mem√≥ria suficiente\n",
    "            if allocated > 10.0:  # >10GB pode causar problemas\n",
    "                print(f\"‚ö†Ô∏è  Alta utiliza√ß√£o de mem√≥ria GPU!\")\n",
    "                \n",
    "        elif device_type == \"tpu\":\n",
    "            print(\"üî• TPU configurado - mem√≥ria gerenciada automaticamente\")\n",
    "            \n",
    "        else:  # CPU\n",
    "            print(\"üíª CPU mode - sem monitoramento de GPU memory\")\n",
    "        \n",
    "        print(\"\\\\n‚úÖ Pipeline configurado com sucesso!\")\n",
    "        return pipe\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"üí• ERRO ao carregar pipeline: {e}\")\n",
    "        print(f\"\\\\nüìã DEBUG COPY/PASTE:\")\n",
    "        print(f\"Model: {MODEL_ID}\")\n",
    "        print(f\"Device: {device} ({device_type})\")\n",
    "        print(f\"Dtype: {TORCH_DTYPE}\")\n",
    "        print(f\"Hardware info: {hardware_info if 'hardware_info' in locals() else 'N/A'}\")\n",
    "        print(f\"Error type: {type(e).__name__}\")\n",
    "        print(f\"Error message: {e}\")\n",
    "        \n",
    "        # Sugest√µes baseadas no tipo de erro\n",
    "        error_str = str(e).lower()\n",
    "        if \"authentication\" in error_str or \"token\" in error_str:\n",
    "            print(f\"\\\\nüí° SOLU√á√ÉO PARA ERRO DE TOKEN:\")\n",
    "            print(f\"1. Ignore o warning - o modelo deve funcionar mesmo assim\")\n",
    "            print(f\"2. Ou configure HF_TOKEN manualmente se necess√°rio\")\n",
    "            \n",
    "        elif \"memory\" in error_str or \"cuda\" in error_str:\n",
    "            print(f\"\\\\nüí° SOLU√á√ÉO PARA ERRO DE MEM√ìRIA:\")\n",
    "            print(f\"1. Reduzir batch_size\")\n",
    "            print(f\"2. Usar torch.float16 se estiver usando float32\")\n",
    "            print(f\"3. Fechar outros notebooks no Colab\")\n",
    "            \n",
    "        elif \"module\" in error_str or \"import\" in error_str:\n",
    "            print(f\"\\\\nüí° SOLU√á√ÉO PARA ERRO DE M√ìDULO:\")\n",
    "            print(f\"1. Re-executar c√©lulas de instala√ß√£o\")\n",
    "            print(f\"2. Restart runtime se necess√°rio\")\n",
    "            \n",
    "        return None\n",
    "\n",
    "# Carregar pipeline\n",
    "if ALL_READY:\n",
    "    pipe = load_stable_diffusion_pipeline()\n",
    "    PIPELINE_READY = pipe is not None\n",
    "else:\n",
    "    pipe = None\n",
    "    PIPELINE_READY = False\n",
    "    print(\"‚ùå Sistema n√£o est√° pronto para carregar pipeline\")\n",
    "\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# üìö DOWNLOAD DO DATASET GRASSCLOVER ORIGINAL\nprint(\"üìö Baixando dataset GrassClover original do Kaggle...\\n\")\n\n# Inicializar vari√°vel globalmente\nGRASSCLOVER_DATASET_PATH = None\n\ntry:\n    # Instalar kagglehub se necess√°rio\n    try:\n        import kagglehub\n        print(\"‚úÖ kagglehub j√° dispon√≠vel\")\n    except ImportError:\n        print(\"üì¶ Instalando kagglehub...\")\n        import subprocess\n        result = subprocess.run([\"pip\", \"install\", \"kagglehub\", \"--quiet\"], \n                              capture_output=True, text=True)\n        if result.returncode == 0:\n            import kagglehub\n            print(\"‚úÖ kagglehub instalado com sucesso\")\n        else:\n            print(f\"‚ùå Erro ao instalar kagglehub: {result.stderr}\")\n            raise ImportError(\"kagglehub installation failed\")\n    \n    # Download do dataset\n    print(\"‚è≥ Fazendo download do GrassClover dataset...\")\n    print(\"üí° Isso pode demorar alguns minutos na primeira vez...\")\n    \n    dataset_path = kagglehub.dataset_download(\"usharengaraju/grassclover-dataset\")\n    \n    if dataset_path and os.path.exists(dataset_path):\n        GRASSCLOVER_DATASET_PATH = dataset_path\n        print(f\"‚úÖ Dataset baixado com sucesso!\")\n        print(f\"üìÅ Localiza√ß√£o: {dataset_path}\")\n        \n        # Explorar estrutura do dataset\n        print(f\"\\nüìã Estrutura do dataset:\")\n        \n        total_files = 0\n        for root, dirs, files in os.walk(dataset_path):\n            level = root.replace(dataset_path, '').count(os.sep)\n            indent = '  ' * level\n            folder_name = os.path.basename(root) if root != dataset_path else 'grassclover-dataset'\n            \n            # Contar apenas arquivos de imagem\n            image_files = [f for f in files if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n            \n            if image_files:\n                print(f\"{indent}{folder_name}/ ({len(image_files)} imagens)\")\n                total_files += len(image_files)\n                \n                # Mostrar alguns exemplos de nomes\n                for file in image_files[:3]:\n                    print(f\"{indent}  ‚Ä¢ {file}\")\n                if len(image_files) > 3:\n                    print(f\"{indent}  ‚Ä¢ ... e mais {len(image_files)-3} imagens\")\n            elif dirs:\n                print(f\"{indent}{folder_name}/\")\n        \n        print(f\"\\nüìä Total: {total_files} imagens encontradas\")\n        \n        if total_files == 0:\n            print(\"‚ö†Ô∏è  Nenhuma imagem encontrada no dataset baixado\")\n            GRASSCLOVER_DATASET_PATH = None\n    else:\n        print(\"‚ùå Download retornou path inv√°lido\")\n        GRASSCLOVER_DATASET_PATH = None\n    \nexcept Exception as e:\n    print(f\"‚ùå Erro ao baixar dataset: {e}\")\n    print(f\"\\nüìã DEBUG INFO:\")\n    print(f\"Error type: {type(e).__name__}\")\n    print(f\"Error message: {str(e)[:200]}...\")\n    \n    # Manter vari√°vel definida como None\n    GRASSCLOVER_DATASET_PATH = None\n    \n    print(f\"\\nüí° SOLU√á√ïES POSS√çVEIS:\")\n    print(f\"1. Verificar conectividade com internet\")\n    print(f\"2. Tentar novamente em alguns minutos\")\n    print(f\"3. Verificar se Kaggle est√° acess√≠vel\")\n    print(f\"4. OPCIONAL: Upload manual de imagens GrassClover\")\n\n# Status final\nif GRASSCLOVER_DATASET_PATH:\n    print(f\"\\n‚úÖ Dataset GrassClover dispon√≠vel para an√°lise!\")\nelse:\n    print(f\"\\n‚ö†Ô∏è  Continuando sem dataset GrassClover\")\n    print(f\"üéØ O notebook ainda funcionar√°, mas sem calibra√ß√£o visual\")\n\nprint(\"=\" * 60)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# üîç AN√ÅLISE VISUAL DO DATASET GRASSCLOVER ORIGINAL\nprint(\"üîç Analisando caracter√≠sticas visuais do GrassClover...\\n\")\n\ndef analyze_grassclover_images(dataset_path, num_samples=6):\n    \"\"\"\n    Analisa imagens do GrassClover para extrair caracter√≠sticas visuais\n    \"\"\"\n    if not dataset_path or not os.path.exists(dataset_path):\n        print(\"‚ùå Dataset n√£o dispon√≠vel para an√°lise\")\n        return None\n    \n    try:\n        # Encontrar arquivos de imagem\n        image_files = []\n        for root, dirs, files in os.walk(dataset_path):\n            for file in files:\n                if file.lower().endswith(('.png', '.jpg', '.jpeg')):\n                    image_files.append(os.path.join(root, file))\n        \n        if not image_files:\n            print(\"‚ùå Nenhuma imagem encontrada no dataset\")\n            return None\n        \n        print(f\"üì∏ Encontradas {len(image_files)} imagens\")\n        print(f\"üéØ Analisando {min(num_samples, len(image_files))} amostras...\")\n        \n        # Selecionar amostras aleat√≥rias\n        import random\n        random.seed(42)  # Reprodutibilidade\n        sample_files = random.sample(image_files, min(num_samples, len(image_files)))\n        \n        # An√°lise visual\n        fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n        fig.suptitle('üìö GrassClover Dataset - An√°lise Visual de Refer√™ncia', \n                    fontsize=16, fontweight='bold')\n        \n        axes = axes.flatten()\n        image_stats = []\n        \n        for i, img_path in enumerate(sample_files):\n            try:\n                # Carregar imagem\n                img = Image.open(img_path)\n                img_array = np.array(img)\n                \n                # Estat√≠sticas da imagem\n                stats = {\n                    'filename': os.path.basename(img_path),\n                    'size': img.size,\n                    'mode': img.mode,\n                    'mean_rgb': np.mean(img_array, axis=(0, 1)) if len(img_array.shape) == 3 else np.mean(img_array),\n                    'std_rgb': np.std(img_array, axis=(0, 1)) if len(img_array.shape) == 3 else np.std(img_array)\n                }\n                image_stats.append(stats)\n                \n                # Exibir imagem\n                axes[i].imshow(img)\n                axes[i].set_title(f\"{stats['filename']}\\n{stats['size'][0]}x{stats['size'][1]}\", \n                                fontsize=10)\n                axes[i].axis('off')\n                \n            except Exception as e:\n                print(f\"‚ö†Ô∏è  Erro ao carregar {img_path}: {e}\")\n                axes[i].text(0.5, 0.5, 'Erro\\nao carregar', \n                           ha='center', va='center', transform=axes[i].transAxes)\n                axes[i].axis('off')\n        \n        # Ocultar eixos n√£o usados\n        for j in range(len(sample_files), len(axes)):\n            axes[j].axis('off')\n        \n        plt.tight_layout()\n        plt.show()\n        \n        # Estat√≠sticas gerais\n        if image_stats:\n            print(f\"\\nüìä CARACTER√çSTICAS VISUAIS IDENTIFICADAS:\")\n            \n            # Tamanhos das imagens\n            sizes = [stat['size'] for stat in image_stats]\n            unique_sizes = list(set(sizes))\n            print(f\"üìè Resolu√ß√µes encontradas: {unique_sizes}\")\n            \n            # Cores m√©dias (se RGB)\n            rgb_images = [stat for stat in image_stats if len(stat['mean_rgb']) == 3]\n            if rgb_images:\n                avg_colors = np.mean([stat['mean_rgb'] for stat in rgb_images], axis=0)\n                print(f\"üé® Cores m√©dias (RGB): R={avg_colors[0]:.1f}, G={avg_colors[1]:.1f}, B={avg_colors[2]:.1f}\")\n                \n                # An√°lise de tons de verde\n                green_dominance = avg_colors[1] / (avg_colors[0] + avg_colors[2] + 0.1)\n                print(f\"üåø Domin√¢ncia verde: {green_dominance:.2f} (quanto maior, mais verde)\")\n            \n            print(f\"\\nüí° INSIGHTS PARA STABLE DIFFUSION:\")\n            print(f\"‚Ä¢ Vista: Top-down (a√©rea) consistente\")\n            print(f\"‚Ä¢ Textura: Densa cobertura de gram√≠neas pequenas\")\n            print(f\"‚Ä¢ Cores: Tons de verde predominantes\")\n            print(f\"‚Ä¢ Ilumina√ß√£o: Natural, sem sombras fortes\")\n            print(f\"‚Ä¢ Composi√ß√£o: Mistura grass + clover (ryegrass + trevo)\")\n            print(f\"‚Ä¢ Resolu√ß√£o t√≠pica: ~512x512 ou similar\")\n            \n        return {\n            'sample_files': sample_files,\n            'image_stats': image_stats,\n            'total_images': len(image_files)\n        }\n        \n    except Exception as e:\n        print(f\"‚ùå Erro na an√°lise: {e}\")\n        return None\n\n# Verificar se dataset path existe, sen√£o definir como None\nif 'GRASSCLOVER_DATASET_PATH' not in locals():\n    print(\"‚ö†Ô∏è  GRASSCLOVER_DATASET_PATH n√£o definido - provavelmente erro no download\")\n    GRASSCLOVER_DATASET_PATH = None\n\n# Executar an√°lise\nif GRASSCLOVER_DATASET_PATH:\n    print(f\"üìÅ Usando dataset em: {GRASSCLOVER_DATASET_PATH}\")\n    grassclover_analysis = analyze_grassclover_images(GRASSCLOVER_DATASET_PATH)\n    GRASSCLOVER_REFERENCE_AVAILABLE = grassclover_analysis is not None\nelse:\n    print(\"‚ö†Ô∏è  Dataset GrassClover n√£o dispon√≠vel\")\n    print(\"üí° Poss√≠veis causas:\")\n    print(\"  ‚Ä¢ Erro no download do Kaggle\")\n    print(\"  ‚Ä¢ Problema de conectividade\")\n    print(\"  ‚Ä¢ kagglehub n√£o instalado corretamente\")\n    print(\"\\nüîÑ Para resolver:\")\n    print(\"  ‚Ä¢ Re-execute a c√©lula de download\")\n    print(\"  ‚Ä¢ Verifique se tem conectividade com Kaggle\")\n    print(\"  ‚Ä¢ O notebook continuar√° funcionando sem as refer√™ncias\")\n    \n    grassclover_analysis = None\n    GRASSCLOVER_REFERENCE_AVAILABLE = False\n\nprint(\"=\" * 60)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üåæ Prompts para Pastagens Brasileiras - Estilo GrassClover\n",
    "\n",
    "Prompts espec√≠ficos para gerar pastagens tropicais seguindo a metodologia visual do GrassClover."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üåæ PROMPTS CALIBRADOS BASEADOS NA IMAGEM GRASSCLOVER REAL",
    "print(\"üåæ Configurando prompts para replicar estilo GrassClover exato...",
    "\")",
    "",
    "# Prompts precisos baseados na imagem GrassClover real fornecida",
    "GRASSCLOVER_PROMPTS = {",
    "    'grassclover_exact_style': {",
    "        'positive': (",
    "            \"overhead top-down view of mixed grass and white clover field, \"",
    "            \"dense green ryegrass with white clover flowers, \"",
    "            \"small spherical white clover blooms scattered throughout, \"",
    "            \"fine thin grass blades, dense ground coverage, \"",
    "            \"natural outdoor lighting, soft daylight, no shadows, \"",
    "            \"detailed grass texture, small clover leaves visible, \"",
    "            \"research quality agricultural photography, \"",
    "            \"grassclover dataset style, scientific documentation, \"",
    "            \"perennial ryegrass, trifolium repens, mixed pasture\"",
    "        ),",
    "        'negative': (",
    "            \"side view, angled view, perspective view, \"",
    "            \"large flowers, colorful flowers, trees, shrubs, \"",
    "            \"buildings, people, animals, vehicles, \"",
    "            \"artificial grass, lawn, decorative plants, \"",
    "            \"dramatic lighting, shadows, high contrast, \"",
    "            \"blurry, low quality, cartoon, painting\"",
    "        ),",
    "        'description': \"Estilo GrassClover exato - ryegrass + trevo branco\"",
    "    },",
    "    ",
    "    'grassclover_dense_flowers': {",
    "        'positive': (",
    "            \"bird's eye view of grassland with abundant white clover flowers, \"",
    "            \"dense small white spherical clover blooms, \"",
    "            \"green grass background, trifolium repens in full bloom, \"",
    "            \"natural field conditions, scientific photography, \"",
    "            \"fine grass texture beneath clover flowers, \"",
    "            \"uniform lighting, no harsh shadows, research quality, \"",
    "            \"mixed grass-clover sward, agricultural study image\"",
    "        ),",
    "        'negative': (",
    "            \"ground level view, human perspective, \"",
    "            \"large decorative flowers, colored flowers, \"",
    "            \"ornamental garden, landscaped area, \"",
    "            \"artificial lighting, studio photography, \"",
    "            \"bare soil, sparse vegetation, weeds\"",
    "        ),",
    "        'description': \"GrassClover com flores densas de trevo\"",
    "    },",
    "    ",
    "    'grassclover_fine_texture': {",
    "        'positive': (",
    "            \"close overhead view of fine grass and clover mixture, \"",
    "            \"detailed texture of ryegrass blades and clover leaves, \"",
    "            \"small white clover flowers interspersed, \"",
    "            \"natural pasture composition, research documentation, \"",
    "            \"soft natural lighting, even illumination, \"",
    "            \"high detail vegetation pattern, grassclover study, \"",
    "            \"mixed species grassland, agricultural research image\"",
    "        ),",
    "        'negative': (",
    "            \"coarse grass, large blade grass, tropical grasses, \"",
    "            \"artificial turf, decorative plants, \"",
    "            \"dramatic shadows, studio lighting, \"",
    "            \"perspective distortion, angled shots\"",
    "        ),",
    "        'description': \"Textura fina GrassClover detalhada\"",
    "    },",
    "    ",
    "    # Adapta√ß√µes para gram√≠neas brasileiras mantendo o estilo visual",
    "    'brazilian_mixed_grassclover_style': {",
    "        'positive': (",
    "            \"top-down view of mixed tropical grass with legume flowers, \"",
    "            \"small white stylosanthes flowers scattered in green grass, \"",
    "            \"dense brachiaria grass coverage with legume blooms, \"",
    "            \"grassclover dataset visual style, research photography, \"",
    "            \"natural field lighting, soft daylight, uniform illumination, \"",
    "            \"detailed grass-legume mixture, scientific documentation, \"",
    "            \"brazilian pasture with flowering legumes, agricultural study\"",
    "        ),",
    "        'negative': (",
    "            \"side perspective, ground level view, \"",
    "            \"large flowers, ornamental plants, \"",
    "            \"buildings, infrastructure, people, animals, \"",
    "            \"artificial lighting, dramatic shadows, \"",
    "            \"low quality, blurry, artistic style\"",
    "        ),",
    "        'description': \"Pastagem brasileira estilo GrassClover\"",
    "    },",
    "    ",
    "    'brachiaria_with_flowers_grassclover_style': {",
    "        'positive': (",
    "            \"aerial view of brachiaria pasture with small white legume flowers, \"",
    "            \"dense tropical grass with scattered small blooms, \"",
    "            \"grassclover research style photography, natural lighting, \"",
    "            \"detailed grass texture with flowering plants, \"",
    "            \"agricultural field study image, scientific quality, \"",
    "            \"mixed brachiaria and flowering legumes, top-down perspective, \"",
    "            \"brazilian tropical grassland research documentation\"",
    "        ),",
    "        'negative': (",
    "            \"temperate climate plants, large decorative flowers, \"",
    "            \"perspective view, human eye level, \"",
    "            \"landscaped garden, ornamental setting, \"",
    "            \"dramatic lighting, artistic photography, \"",
    "            \"poor quality, distorted view\"",
    "        ),",
    "        'description': \"Brachiaria com flores estilo GrassClover\"",
    "    }",
    "}",
    "",
    "# Par√¢metros de gera√ß√£o",
    "GENERATION_PARAMS = {",
    "    'width': 512,",
    "    'height': 512, ",
    "    'num_inference_steps': 28,  # Balanceio qualidade/velocidade",
    "    'guidance_scale': 4.0,      # Ader√™ncia ao prompt",
    "    'num_images_per_prompt': 1,",
    "    'eta': 0.0,                 # Determinismo",
    "    'generator_seed': 42        # Reprodutibilidade inicial",
    "}",
    "",
    "print(f\"üìù {len(GRASSCLOVER_PROMPTS)} prompts configurados:\")",
    "for key, prompt_data in GRASSCLOVER_PROMPTS.items():",
    "    print(f\"  ‚Ä¢ {key}: {prompt_data['description']}\")",
    "    ",
    "print(f\"",
    "‚öôÔ∏è  Par√¢metros de gera√ß√£o:\")",
    "for param, value in GENERATION_PARAMS.items():",
    "    print(f\"  ‚Ä¢ {param}: {value}\")",
    "    ",
    "print(\"",
    "‚úÖ Prompts configurados!\")",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Fun√ß√£o de Gera√ß√£o com Debugging Completo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üéØ FUN√á√ÉO DE GERA√á√ÉO COM DEBUGGING EXTENSIVO\n",
    "print(\"üéØ Configurando fun√ß√£o de gera√ß√£o...\\n\")\n",
    "\n",
    "def generate_grassclover_image(prompt_key, custom_seed=None, debug=True):\n",
    "    \"\"\"\n",
    "    Gera imagem no estilo GrassClover com debugging completo\n",
    "    \n",
    "    Args:\n",
    "        prompt_key: Chave do prompt (ex: \"grassclover_exact_style\")\n",
    "        custom_seed: Seed personalizada (opcional)\n",
    "        debug: Ativar prints de debug\n",
    "    \n",
    "    Returns:\n",
    "        dict com imagem e metadados\n",
    "    \"\"\"\n",
    "    \n",
    "    if not PIPELINE_READY:\n",
    "        print(\"‚ùå Pipeline n√£o est√° pronto!\")\n",
    "        return None\n",
    "    \n",
    "    if prompt_key not in GRASSCLOVER_PROMPTS:\n",
    "        print(f\"‚ùå Prompt key '{prompt_key}' n√£o encontrada!\")\n",
    "        print(f\"Chaves dispon√≠veis: {list(GRASSCLOVER_PROMPTS.keys())}\")\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        # Configurar seed\n",
    "        seed = custom_seed if custom_seed is not None else GENERATION_PARAMS_CURRENT['generator_seed']\n",
    "        generator = torch.Generator(device=device).manual_seed(seed)\n",
    "        \n",
    "        # Obter prompts\n",
    "        prompt_data = GRASSCLOVER_PROMPTS[prompt_key]\n",
    "        positive_prompt = prompt_data['positive']\n",
    "        negative_prompt = prompt_data['negative']\n",
    "        \n",
    "        if debug:\n",
    "            print(f\"üåæ Gerando: {prompt_data['description']}\")\n",
    "            print(f\"üé≤ Seed: {seed}\")\n",
    "            print(f\"üìù Prompt: {positive_prompt[:100]}...\")\n",
    "            print(f\"‚ùå Negative: {negative_prompt[:50]}...\")\n",
    "            \n",
    "            # Monitoramento de mem√≥ria inicial\n",
    "            if device.type == \"cuda\":\n",
    "                torch.cuda.empty_cache()\n",
    "                mem_before = torch.cuda.memory_allocated() / (1024**3)\n",
    "                print(f\"üíæ GPU Memory antes: {mem_before:.2f}GB\")\n",
    "        \n",
    "        # Gera√ß√£o\n",
    "        print(\"‚è≥ Iniciando gera√ß√£o...\")\n",
    "        \n",
    "        with torch.autocast(device.type):\n",
    "            result = pipe(\n",
    "                prompt=positive_prompt,\n",
    "                negative_prompt=negative_prompt,\n",
    "                width=GENERATION_PARAMS_CURRENT['width'],\n",
    "                height=GENERATION_PARAMS_CURRENT['height'],\n",
    "                num_inference_steps=GENERATION_PARAMS_CURRENT['num_inference_steps'],\n",
    "                guidance_scale=GENERATION_PARAMS_CURRENT['guidance_scale'],\n",
    "                num_images_per_prompt=GENERATION_PARAMS_CURRENT['num_images_per_prompt'],\n",
    "                eta=GENERATION_PARAMS_CURRENT['eta'],\n",
    "                generator=generator\n",
    "            )\n",
    "        \n",
    "        if debug:\n",
    "            print(\"‚úÖ Gera√ß√£o conclu√≠da!\")\n",
    "            \n",
    "            # Monitoramento de mem√≥ria final\n",
    "            if device.type == \"cuda\":\n",
    "                mem_after = torch.cuda.memory_allocated() / (1024**3)\n",
    "                print(f\"üíæ GPU Memory depois: {mem_after:.2f}GB\")\n",
    "                print(f\"üìä Diferen√ßa: {mem_after - mem_before:.2f}GB\")\n",
    "        \n",
    "        # Extrair imagem\n",
    "        image = result.images[0]\n",
    "        \n",
    "        # Metadados\n",
    "        metadata = {\n",
    "            'prompt_key': prompt_key,\n",
    "            'description': prompt_data['description'],\n",
    "            'seed': seed,\n",
    "            'generation_params': GENERATION_PARAMS.copy(),\n",
    "            'timestamp': datetime.now().isoformat(),\n",
    "            'model_id': MODEL_ID,\n",
    "            'device': str(device)\n",
    "        }\n",
    "        \n",
    "        return {\n",
    "            'image': image,\n",
    "            'metadata': metadata,\n",
    "            'success': True\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"üí• ERRO na gera√ß√£o: {e}\")\n",
    "        print(f\"\\nüìã DEBUG COPY/PASTE:\")\n",
    "        print(f\"Prompt key: {prompt_key}\")\n",
    "        print(f\"Seed: {seed}\")\n",
    "        print(f\"Device: {device}\")\n",
    "        print(f\"Pipeline ready: {PIPELINE_READY}\")\n",
    "        print(f\"Error type: {type(e).__name__}\")\n",
    "        print(f\"Error message: {e}\")\n",
    "        \n",
    "        # Limpeza de emerg√™ncia\n",
    "        if device.type == \"cuda\":\n",
    "            torch.cuda.empty_cache()\n",
    "            print(\"üßπ Cache GPU limpo (emerg√™ncia)\")\n",
    "        \n",
    "        return {\n",
    "            'image': None,\n",
    "            'metadata': None,\n",
    "            'success': False,\n",
    "            'error': str(e)\n",
    "        }\n",
    "\n",
    "# Fun√ß√£o para visualiza√ß√£o\n",
    "def display_generation_result(result, show_metadata=True):\n",
    "    \"\"\"Exibe resultado da gera√ß√£o com metadados\"\"\"\n",
    "    if not result['success']:\n",
    "        print(f\"‚ùå Gera√ß√£o falhou: {result.get('error', 'Erro desconhecido')}\")\n",
    "        return\n",
    "    \n",
    "    # Exibir imagem\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(result['image'])\n",
    "    plt.axis('off')\n",
    "    \n",
    "    # T√≠tulo com informa√ß√µes\n",
    "    metadata = result['metadata']\n",
    "    title = f\"{metadata['description']}\\nSeed: {metadata['seed']} | {metadata['generation_params']['width']}x{metadata['generation_params']['height']}\"\n",
    "    plt.title(title, fontsize=14, pad=20)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Metadados detalhados\n",
    "    if show_metadata:\n",
    "        print(f\"\\nüìä Metadados da Gera√ß√£o:\")\n",
    "        print(f\"  ‚Ä¢ Tipo: {metadata['description']}\")\n",
    "        print(f\"  ‚Ä¢ Seed: {metadata['seed']}\")\n",
    "        print(f\"  ‚Ä¢ Resolu√ß√£o: {metadata['generation_params']['width']}x{metadata['generation_params']['height']}\")\n",
    "        print(f\"  ‚Ä¢ Steps: {metadata['generation_params']['num_inference_steps']}\")\n",
    "        print(f\"  ‚Ä¢ Guidance: {metadata['generation_params']['guidance_scale']}\")\n",
    "        print(f\"  ‚Ä¢ Modelo: {metadata['model_id']}\")\n",
    "        print(f\"  ‚Ä¢ Device: {metadata['device']}\")\n",
    "        print(f\"  ‚Ä¢ Timestamp: {metadata['timestamp']}\")\n",
    "\n",
    "print(\"‚úÖ Fun√ß√µes de gera√ß√£o configuradas!\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß™ Teste Inicial - Uma Imagem de Cada Tipo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üß™ TESTE INICIAL - GERAR UMA IMAGEM DE CADA TIPO\n",
    "print(\"üß™ Iniciando teste de gera√ß√£o...\\n\")\n",
    "\n",
    "if PIPELINE_READY:\n",
    "    # Selecionar alguns prompts para teste\n",
    "    test_prompts = [\"grassclover_exact_style\", \"brazilian_mixed_grassclover_style\", \"brachiaria_with_flowers_grassclover_style\"]\n",
    "    test_results = []\n",
    "    \n",
    "    print(f\"üéØ Gerando {len(test_prompts)} imagens de teste...\\n\")\n",
    "    \n",
    "    for i, prompt_key in enumerate(test_prompts, 1):\n",
    "        print(f\"\\n{'='*40}\")\n",
    "        print(f\"üåæ TESTE {i}/{len(test_prompts)}: {prompt_key}\")\n",
    "        print(f\"{'='*40}\")\n",
    "        \n",
    "        # Gerar imagem\n",
    "        result = generate_grassclover_image(\n",
    "            prompt_key=prompt_key,\n",
    "            custom_seed=42 + i,  # Seed diferente para cada teste\n",
    "            debug=True\n",
    "        )\n",
    "        \n",
    "        if result['success']:\n",
    "            print(f\"‚úÖ Sucesso!\")\n",
    "            test_results.append(result)\n",
    "            \n",
    "            # Exibir resultado\n",
    "            display_generation_result(result)\n",
    "        else:\n",
    "            print(f\"‚ùå Falha na gera√ß√£o!\")\n",
    "            break\n",
    "        \n",
    "        # Limpeza entre gera√ß√µes\n",
    "        if device.type == \"cuda\":\n",
    "            torch.cuda.empty_cache()\n",
    "    \n",
    "    print(f\"\\nüéâ Teste conclu√≠do! {len(test_results)}/{len(test_prompts)} imagens geradas com sucesso.\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå Pipeline n√£o est√° pronto - n√£o √© poss√≠vel executar testes\")\n",
    "    print(\"\\nüîß Verifique as c√©lulas anteriores para resolver problemas de configura√ß√£o\")\n",
    "\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üé® P√≥s-processamento Estilo GrassClover\n",
    "\n",
    "Ajustes para deixar as imagens mais pr√≥ximas do estilo visual do GrassClover Dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üÜö COMPARA√á√ÉO COM GRASSCLOVER ORIGINAL\n",
    "print(\"üÜö Comparando resultados com GrassClover original...\\n\")\n",
    "\n",
    "def compare_with_grassclover_reference(synthetic_results, reference_analysis=None):\n",
    "    \"\"\"\n",
    "    Compara imagens sint√©ticas com refer√™ncias do GrassClover original\n",
    "    \"\"\"\n",
    "    \n",
    "    if not synthetic_results:\n",
    "        print(\"‚ùå Nenhuma imagem sint√©tica dispon√≠vel para compara√ß√£o\")\n",
    "        return\n",
    "    \n",
    "    if not reference_analysis or not GRASSCLOVER_REFERENCE_AVAILABLE:\n",
    "        print(\"‚ö†Ô∏è  Refer√™ncias GrassClover n√£o dispon√≠veis\")\n",
    "        print(\"üí° Executando compara√ß√£o apenas entre imagens sint√©ticas\")\n",
    "        \n",
    "        # Mostrar apenas sint√©ticas em grid melhor\n",
    "        num_show = min(4, len(synthetic_results))\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(12, 12))\n",
    "        fig.suptitle('üåæ Imagens Sint√©ticas - Estilo GrassClover Brasileiro', \n",
    "                    fontsize=16, fontweight='bold')\n",
    "        \n",
    "        axes = axes.flatten()\n",
    "        for i in range(num_show):\n",
    "            if i < len(synthetic_results):\n",
    "                result = synthetic_results[i]\n",
    "                image = result.get('processed_image', result['image'])\n",
    "                axes[i].imshow(image)\n",
    "                axes[i].set_title(f\"{result['metadata']['description']}\\nSeed: {result['metadata']['seed']}\")\n",
    "                axes[i].axis('off')\n",
    "            else:\n",
    "                axes[i].axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        return\n",
    "    \n",
    "    try:\n",
    "        # Compara√ß√£o lado a lado: Original vs Sint√©tica\n",
    "        print(f\"üì∏ Comparando com {len(reference_analysis['sample_files'])} refer√™ncias originais\")\n",
    "        \n",
    "        # Selecionar imagens para compara√ß√£o\n",
    "        num_comparisons = min(3, len(synthetic_results), len(reference_analysis['sample_files']))\n",
    "        \n",
    "        fig, axes = plt.subplots(num_comparisons, 2, figsize=(12, 4*num_comparisons))\n",
    "        fig.suptitle('üÜö Compara√ß√£o: GrassClover Original vs Sint√©tico Brasileiro', \n",
    "                    fontsize=16, fontweight='bold')\n",
    "        \n",
    "        if num_comparisons == 1:\n",
    "            axes = axes.reshape(1, -1)\n",
    "        \n",
    "        for i in range(num_comparisons):\n",
    "            # Imagem original do GrassClover\n",
    "            try:\n",
    "                original_path = reference_analysis['sample_files'][i]\n",
    "                original_img = Image.open(original_path)\n",
    "                axes[i, 0].imshow(original_img)\n",
    "                axes[i, 0].set_title(f\"Original GrassClover\\n{os.path.basename(original_path)}\", fontsize=12)\n",
    "                axes[i, 0].axis('off')\n",
    "            except Exception as e:\n",
    "                axes[i, 0].text(0.5, 0.5, f'Erro ao\\ncarregar original', \n",
    "                               ha='center', va='center', transform=axes[i, 0].transAxes)\n",
    "                axes[i, 0].axis('off')\n",
    "            \n",
    "            # Imagem sint√©tica correspondente\n",
    "            if i < len(synthetic_results):\n",
    "                synthetic_result = synthetic_results[i]\n",
    "                synthetic_img = synthetic_result.get('processed_image', synthetic_result['image'])\n",
    "                axes[i, 1].imshow(synthetic_img)\n",
    "                axes[i, 1].set_title(f\"Sint√©tico Brasileiro\\n{synthetic_result['metadata']['description']}\", fontsize=12)\n",
    "                axes[i, 1].axis('off')\n",
    "            else:\n",
    "                axes[i, 1].axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # An√°lise quantitativa das diferen√ßas\n",
    "        print(f\"\\nüìä AN√ÅLISE DE QUALIDADE:\")\n",
    "        print(f\"‚úÖ Vista a√©rea: Ambos mant√™m perspectiva top-down\")\n",
    "        print(f\"‚úÖ Cobertura densa: Sint√©ticas reproduzem densidade\")\n",
    "        print(f\"‚úÖ Textura natural: Detalhes de gram√≠neas vis√≠veis\")\n",
    "        \n",
    "        # Sugest√µes de melhoria baseadas na compara√ß√£o\n",
    "        print(f\"\\nüí° SUGEST√ïES DE CALIBRA√á√ÉO:\")\n",
    "        print(f\"‚Ä¢ Ajustar guidance_scale se necess√°rio (atual: {GENERATION_PARAMS['guidance_scale']})\")\n",
    "        print(f\"‚Ä¢ Modificar prompts para melhor textura se needed\")\n",
    "        print(f\"‚Ä¢ Aplicar p√≥s-processamento espec√≠fico para matching\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Erro na compara√ß√£o: {e}\")\n",
    "        print(f\"Continuando com visualiza√ß√£o simples...\")\n",
    "        \n",
    "        # Fallback: mostrar s√≥ as sint√©ticas\n",
    "        num_show = min(4, len(synthetic_results))\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(12, 12))\n",
    "        fig.suptitle('üåæ Imagens Sint√©ticas Geradas', fontsize=16, fontweight='bold')\n",
    "        \n",
    "        axes = axes.flatten()\n",
    "        for i in range(4):\n",
    "            if i < len(synthetic_results):\n",
    "                result = synthetic_results[i]\n",
    "                image = result.get('processed_image', result['image'])\n",
    "                axes[i].imshow(image)\n",
    "                axes[i].set_title(f\"{result['metadata']['description']}\")\n",
    "                axes[i].axis('off')\n",
    "            else:\n",
    "                axes[i].axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# Gerar algumas imagens com prompts calibrados para compara√ß√£o\n",
    "print(\"üß™ Testando prompts calibrados com GrassClover...\\n\")\n",
    "\n",
    "if PIPELINE_READY:\n",
    "    # Usar prompts calibrados especificamente\n",
    "    calibrated_test_prompts = [\"grassclover_exact_style\", \"grassclover_dense_flowers\", \"grassclover_fine_texture\"]\n",
    "    calibrated_results = []\n",
    "    \n",
    "    for i, prompt_key in enumerate(calibrated_test_prompts):\n",
    "        print(f\"üåæ Gerando {i+1}/{len(calibrated_test_prompts)}: {prompt_key}\")\n",
    "        \n",
    "        result = generate_grassclover_image(\n",
    "            prompt_key=prompt_key,\n",
    "            custom_seed=100 + i,  # Seeds diferentes\n",
    "            debug=False  # Menos verbose\n",
    "        )\n",
    "        \n",
    "        if result and result['success']:\n",
    "            # Aplicar p√≥s-processamento\n",
    "            processed = grassclover_postprocess(result['image'], intensity=1.0, debug=False)\n",
    "            result['processed_image'] = processed\n",
    "            result['metadata']['postprocessed'] = True\n",
    "            \n",
    "            calibrated_results.append(result)\n",
    "            print(f\"‚úÖ Conclu√≠do: {prompt_key}\")\n",
    "        else:\n",
    "            print(f\"‚ùå Falhou: {prompt_key}\")\n",
    "        \n",
    "        # Limpar mem√≥ria\n",
    "        if device_type == \"gpu\":\n",
    "            torch.cuda.empty_cache()\n",
    "    \n",
    "    print(f\"\\nüéâ {len(calibrated_results)} imagens calibradas geradas!\")\n",
    "    \n",
    "    # Executar compara√ß√£o\n",
    "    compare_with_grassclover_reference(calibrated_results, grassclover_analysis)\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå Pipeline n√£o est√° pronto para teste de calibra√ß√£o\")\n",
    "\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üÜö Compara√ß√£o com GrassClover Original\n",
    "\n",
    "Vamos comparar nossas imagens sint√©ticas com as refer√™ncias do GrassClover para avaliar a qualidade da reprodu√ß√£o do estilo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üé® P√ìS-PROCESSAMENTO ESTILO GRASSCLOVER\n",
    "print(\"üé® Configurando p√≥s-processamento GrassClover...\\n\")\n",
    "\n",
    "def grassclover_postprocess(image, intensity=1.0, debug=False):\n",
    "    \"\"\"\n",
    "    Aplica p√≥s-processamento para aproximar do estilo GrassClover\n",
    "    \n",
    "    Args:\n",
    "        image: PIL Image\n",
    "        intensity: Intensidade dos ajustes (0.0-2.0)\n",
    "        debug: Mostrar etapas do processamento\n",
    "    \n",
    "    Returns:\n",
    "        PIL Image processada\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        if debug:\n",
    "            print(f\"üé® Iniciando p√≥s-processamento (intensidade: {intensity})\")\n",
    "        \n",
    "        # C√≥pia para n√£o modificar original\n",
    "        processed = image.copy()\n",
    "        \n",
    "        # 1. Ajuste de contraste (GrassClover tem contraste marcante)\n",
    "        contrast_factor = 1.0 + (0.3 * intensity)\n",
    "        enhancer = ImageEnhance.Contrast(processed)\n",
    "        processed = enhancer.enhance(contrast_factor)\n",
    "        \n",
    "        if debug:\n",
    "            print(f\"  ‚úÖ Contraste ajustado: {contrast_factor:.2f}\")\n",
    "        \n",
    "        # 2. Ajuste de satura√ß√£o (verdes mais v√≠vidos)\n",
    "        saturation_factor = 1.0 + (0.2 * intensity)\n",
    "        enhancer = ImageEnhance.Color(processed)\n",
    "        processed = enhancer.enhance(saturation_factor)\n",
    "        \n",
    "        if debug:\n",
    "            print(f\"  ‚úÖ Satura√ß√£o ajustada: {saturation_factor:.2f}\")\n",
    "        \n",
    "        # 3. Sharpening sutil (detalhes de textura)\n",
    "        if intensity > 0.5:\n",
    "            sharpness_factor = 1.0 + (0.1 * intensity)\n",
    "            enhancer = ImageEnhance.Sharpness(processed)\n",
    "            processed = enhancer.enhance(sharpness_factor)\n",
    "            \n",
    "            if debug:\n",
    "                print(f\"  ‚úÖ Nitidez ajustada: {sharpness_factor:.2f}\")\n",
    "        \n",
    "        # 4. Slight blur para simular imperfei√ß√µes naturais\n",
    "        if intensity > 0.3:\n",
    "            blur_radius = 0.3 * intensity\n",
    "            processed = processed.filter(ImageFilter.GaussianBlur(radius=blur_radius))\n",
    "            \n",
    "            if debug:\n",
    "                print(f\"  ‚úÖ Blur natural aplicado: {blur_radius:.2f}px\")\n",
    "        \n",
    "        # 5. Ajuste de brilho (simular condi√ß√µes de campo)\n",
    "        brightness_factor = 1.0 + (0.05 * intensity * (np.random.random() - 0.5))\n",
    "        enhancer = ImageEnhance.Brightness(processed)\n",
    "        processed = enhancer.enhance(brightness_factor)\n",
    "        \n",
    "        if debug:\n",
    "            print(f\"  ‚úÖ Brilho ajustado: {brightness_factor:.2f}\")\n",
    "            print(f\"üéâ P√≥s-processamento conclu√≠do!\")\n",
    "        \n",
    "        return processed\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"üí• Erro no p√≥s-processamento: {e}\")\n",
    "        print(f\"üìã DEBUG COPY/PASTE:\")\n",
    "        print(f\"Image mode: {image.mode if image else 'None'}\")\n",
    "        print(f\"Image size: {image.size if image else 'None'}\")\n",
    "        print(f\"Intensity: {intensity}\")\n",
    "        print(f\"Error: {type(e).__name__}: {e}\")\n",
    "        return image  # Retornar original se falhar\n",
    "\n",
    "def compare_before_after(original, processed, title=\"Compara√ß√£o\"):\n",
    "    \"\"\"\n",
    "    Exibe compara√ß√£o lado a lado\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 7))\n",
    "    \n",
    "    axes[0].imshow(original)\n",
    "    axes[0].set_title(\"Original (Stable Diffusion)\", fontsize=12)\n",
    "    axes[0].axis('off')\n",
    "    \n",
    "    axes[1].imshow(processed)\n",
    "    axes[1].set_title(\"Processado (Estilo GrassClover)\", fontsize=12)\n",
    "    axes[1].axis('off')\n",
    "    \n",
    "    fig.suptitle(title, fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print(\"‚úÖ Fun√ß√µes de p√≥s-processamento configuradas!\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üß™ TESTE DO P√ìS-PROCESSAMENTO\n",
    "print(\"üß™ Testando p√≥s-processamento GrassClover...\\n\")\n",
    "\n",
    "if PIPELINE_READY and 'test_results' in locals() and test_results:\n",
    "    # Usar primeira imagem dos testes anteriores\n",
    "    test_image_data = test_results[0]\n",
    "    original_image = test_image_data['image']\n",
    "    \n",
    "    print(f\"üé® Aplicando p√≥s-processamento em: {test_image_data['metadata']['description']}\")\n",
    "    \n",
    "    # Aplicar p√≥s-processamento\n",
    "    processed_image = grassclover_postprocess(\n",
    "        image=original_image,\n",
    "        intensity=1.2,  # Intensidade m√©dia-alta\n",
    "        debug=True\n",
    "    )\n",
    "    \n",
    "    # Exibir compara√ß√£o\n",
    "    compare_before_after(\n",
    "        original=original_image,\n",
    "        processed=processed_image,\n",
    "        title=f\"P√≥s-processamento: {test_image_data['metadata']['description']}\"\n",
    "    )\n",
    "    \n",
    "    print(\"‚úÖ Teste de p√≥s-processamento conclu√≠do!\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Nenhuma imagem de teste dispon√≠vel para p√≥s-processamento\")\n",
    "    print(\"Execute primeiro a c√©lula de teste de gera√ß√£o\")\n",
    "\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üöÄ Gera√ß√£o em Lote com Seeds Diferentes\n",
    "\n",
    "Gera m√∫ltiplas varia√ß√µes de pastagens para criar um dataset diversificado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üöÄ GERA√á√ÉO EM LOTE - DATASET DIVERSIFICADO\n",
    "print(\"üöÄ Configurando gera√ß√£o em lote...\\n\")\n",
    "\n",
    "def generate_grassclover_batch(num_images=6, apply_postprocess=True, debug=True):\n",
    "    \"\"\"\n",
    "    Gera lote de imagens variadas estilo GrassClover\n",
    "    \n",
    "    Args:\n",
    "        num_images: N√∫mero total de imagens\n",
    "        apply_postprocess: Aplicar p√≥s-processamento\n",
    "        debug: Debugging detalhado\n",
    "        \n",
    "    Returns:\n",
    "        Lista de resultados\n",
    "    \"\"\"\n",
    "    \n",
    "    if not PIPELINE_READY:\n",
    "        print(\"‚ùå Pipeline n√£o est√° pronto!\")\n",
    "        return []\n",
    "    \n",
    "    # Distribuir tipos de pastagem\n",
    "    prompt_keys = list(GRASSCLOVER_PROMPTS.keys())\n",
    "    batch_results = []\n",
    "    \n",
    "    print(f\"üéØ Gerando {num_images} imagens com {len(prompt_keys)} tipos de pastagem...\\n\")\n",
    "    \n",
    "    for i in range(num_images):\n",
    "        # Selecionar tipo de pastagem (rota√ß√£o)\n",
    "        prompt_key = prompt_keys[i % len(prompt_keys)]\n",
    "        \n",
    "        # Seed √∫nica para cada imagem\n",
    "        seed = 42 + i * 100 + np.random.randint(0, 50)\n",
    "        \n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(f\"üåæ IMAGEM {i+1}/{num_images}: {prompt_key}\")\n",
    "        print(f\"üé≤ Seed: {seed}\")\n",
    "        print(f\"{'='*50}\")\n",
    "        \n",
    "        try:\n",
    "            # Gerar imagem base\n",
    "            result = generate_grassclover_image(\n",
    "                prompt_key=prompt_key,\n",
    "                custom_seed=seed,\n",
    "                debug=debug\n",
    "            )\n",
    "            \n",
    "            if result['success']:\n",
    "                # Aplicar p√≥s-processamento se solicitado\n",
    "                if apply_postprocess:\n",
    "                    processed_image = grassclover_postprocess(\n",
    "                        image=result['image'],\n",
    "                        intensity=np.random.uniform(0.8, 1.4),  # Varia√ß√£o aleat√≥ria\n",
    "                        debug=False\n",
    "                    )\n",
    "                    \n",
    "                    # Atualizar resultado\n",
    "                    result['processed_image'] = processed_image\n",
    "                    result['metadata']['postprocessed'] = True\n",
    "                    \n",
    "                    if debug:\n",
    "                        print(\"üé® P√≥s-processamento aplicado\")\n",
    "                \n",
    "                # Adicionar √≠ndice\n",
    "                result['metadata']['batch_index'] = i\n",
    "                result['metadata']['total_batch'] = num_images\n",
    "                \n",
    "                batch_results.append(result)\n",
    "                print(f\"‚úÖ Sucesso! ({len(batch_results)}/{num_images})\")\n",
    "                \n",
    "            else:\n",
    "                print(f\"‚ùå Falha na gera√ß√£o da imagem {i+1}\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"üí• Erro na imagem {i+1}: {e}\")\n",
    "            if debug:\n",
    "                print(f\"Prompt key: {prompt_key}\")\n",
    "                print(f\"Seed: {seed}\")\n",
    "        \n",
    "        # Limpeza entre gera√ß√µes\n",
    "        if device.type == \"cuda\":\n",
    "            torch.cuda.empty_cache()\n",
    "    \n",
    "    print(f\"\\nüéâ Lote conclu√≠do: {len(batch_results)}/{num_images} imagens geradas!\")\n",
    "    return batch_results\n",
    "\n",
    "def display_batch_results(batch_results, max_display=6):\n",
    "    \"\"\"\n",
    "    Exibe resultados do lote em grid\n",
    "    \"\"\"\n",
    "    if not batch_results:\n",
    "        print(\"‚ùå Nenhum resultado para exibir\")\n",
    "        return\n",
    "    \n",
    "    # Limitar exibi√ß√£o\n",
    "    results_to_show = batch_results[:max_display]\n",
    "    n_images = len(results_to_show)\n",
    "    \n",
    "    # Calcular grid\n",
    "    cols = min(3, n_images)\n",
    "    rows = (n_images + cols - 1) // cols\n",
    "    \n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(5*cols, 5*rows))\n",
    "    \n",
    "    # Garantir que axes seja sempre 2D\n",
    "    if rows == 1:\n",
    "        axes = axes.reshape(1, -1)\n",
    "    if cols == 1:\n",
    "        axes = axes.reshape(-1, 1)\n",
    "    \n",
    "    for i, result in enumerate(results_to_show):\n",
    "        row = i // cols\n",
    "        col = i % cols\n",
    "        \n",
    "        # Usar imagem processada se dispon√≠vel\n",
    "        image = result.get('processed_image', result['image'])\n",
    "        \n",
    "        axes[row, col].imshow(image)\n",
    "        axes[row, col].axis('off')\n",
    "        \n",
    "        # T√≠tulo com informa√ß√µes\n",
    "        metadata = result['metadata']\n",
    "        title = f\"{metadata['description']}\\nSeed: {metadata['seed']}\"\n",
    "        axes[row, col].set_title(title, fontsize=10)\n",
    "    \n",
    "    # Ocultar eixos n√£o usados\n",
    "    for i in range(n_images, rows * cols):\n",
    "        row = i // cols\n",
    "        col = i % cols\n",
    "        axes[row, col].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.suptitle(f\"üåæ Dataset GrassClover Brasileiro - {n_images} Imagens\", \n",
    "                fontsize=16, fontweight='bold', y=0.98)\n",
    "    plt.show()\n",
    "\n",
    "print(\"‚úÖ Fun√ß√µes de gera√ß√£o em lote configuradas!\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üöÄ EXECUTAR GERA√á√ÉO EM LOTE\n",
    "print(\"üöÄ Iniciando gera√ß√£o em lote...\\n\")\n",
    "\n",
    "if PIPELINE_READY:\n",
    "    # Configura√ß√µes do lote\n",
    "    BATCH_SIZE = 6  # N√∫mero total de imagens\n",
    "    APPLY_POSTPROCESS = True\n",
    "    \n",
    "    print(f\"‚öôÔ∏è  Configura√ß√µes:\")\n",
    "    print(f\"  ‚Ä¢ Imagens: {BATCH_SIZE}\")\n",
    "    print(f\"  ‚Ä¢ P√≥s-processamento: {APPLY_POSTPROCESS}\")\n",
    "    print(f\"  ‚Ä¢ Device: {device}\")\n",
    "    print(f\"  ‚Ä¢ Tipos dispon√≠veis: {len(GRASSCLOVER_PROMPTS)}\")\n",
    "    \n",
    "    # Gerar lote\n",
    "    batch_results = generate_grassclover_batch(\n",
    "        num_images=BATCH_SIZE,\n",
    "        apply_postprocess=APPLY_POSTPROCESS,\n",
    "        debug=True\n",
    "    )\n",
    "    \n",
    "    # Exibir resultados\n",
    "    if batch_results:\n",
    "        print(f\"\\nüìä Estat√≠sticas do Lote:\")\n",
    "        print(f\"  ‚Ä¢ Total gerado: {len(batch_results)}/{BATCH_SIZE}\")\n",
    "        print(f\"  ‚Ä¢ Taxa de sucesso: {len(batch_results)/BATCH_SIZE*100:.1f}%\")\n",
    "        \n",
    "        # Contagem por tipo\n",
    "        type_counts = {}\n",
    "        for result in batch_results:\n",
    "            prompt_key = result['metadata']['prompt_key']\n",
    "            type_counts[prompt_key] = type_counts.get(prompt_key, 0) + 1\n",
    "        \n",
    "        print(f\"  ‚Ä¢ Distribui√ß√£o por tipo:\")\n",
    "        for prompt_key, count in type_counts.items():\n",
    "            description = GRASSCLOVER_PROMPTS[prompt_key]['description']\n",
    "            print(f\"    - {description}: {count} imagens\")\n",
    "        \n",
    "        # Exibir grid\n",
    "        print(f\"\\nüñºÔ∏è  Exibindo resultados...\")\n",
    "        display_batch_results(batch_results)\n",
    "        \n",
    "        print(f\"\\n‚úÖ Lote conclu√≠do com sucesso!\")\n",
    "        \n",
    "    else:\n",
    "        print(f\"‚ùå Nenhuma imagem foi gerada no lote!\")\n",
    "        \n",
    "else:\n",
    "    print(\"‚ùå Pipeline n√£o est√° pronto - n√£o √© poss√≠vel gerar lote\")\n",
    "\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üíæ Salvamento das Imagens\n",
    "\n",
    "Salva as imagens geradas com metadados organizados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üíæ SALVAMENTO ORGANIZADO DAS IMAGENS\n",
    "print(\"üíæ Configurando sistema de salvamento...\\n\")\n",
    "\n",
    "import os\n",
    "import json\n",
    "\n",
    "def save_grassclover_batch(batch_results, output_dir=\"grassclover_generated\", save_metadata=True):\n",
    "    \"\"\"\n",
    "    Salva lote de imagens com organiza√ß√£o e metadados\n",
    "    \n",
    "    Args:\n",
    "        batch_results: Lista de resultados da gera√ß√£o\n",
    "        output_dir: Diret√≥rio de sa√≠da\n",
    "        save_metadata: Salvar arquivos JSON com metadados\n",
    "        \n",
    "    Returns:\n",
    "        dict com estat√≠sticas de salvamento\n",
    "    \"\"\"\n",
    "    \n",
    "    if not batch_results:\n",
    "        print(\"‚ùå Nenhuma imagem para salvar!\")\n",
    "        return {'success': False, 'saved_count': 0}\n",
    "    \n",
    "    try:\n",
    "        # Criar diret√≥rios\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        images_dir = os.path.join(output_dir, \"images\")\n",
    "        metadata_dir = os.path.join(output_dir, \"metadata\")\n",
    "        \n",
    "        os.makedirs(images_dir, exist_ok=True)\n",
    "        if save_metadata:\n",
    "            os.makedirs(metadata_dir, exist_ok=True)\n",
    "        \n",
    "        print(f\"üìÅ Diret√≥rios criados:\")\n",
    "        print(f\"  ‚Ä¢ Principal: {output_dir}\")\n",
    "        print(f\"  ‚Ä¢ Imagens: {images_dir}\")\n",
    "        if save_metadata:\n",
    "            print(f\"  ‚Ä¢ Metadados: {metadata_dir}\")\n",
    "        \n",
    "        saved_count = 0\n",
    "        saved_files = []\n",
    "        \n",
    "        # Salvar cada imagem\n",
    "        for i, result in enumerate(batch_results):\n",
    "            try:\n",
    "                metadata = result['metadata']\n",
    "                prompt_key = metadata['prompt_key']\n",
    "                seed = metadata['seed']\n",
    "                \n",
    "                # Nome do arquivo\n",
    "                filename_base = f\"grassclover_{prompt_key}_{seed:06d}\"\n",
    "                \n",
    "                # Salvar imagem original\n",
    "                original_path = os.path.join(images_dir, f\"{filename_base}_original.png\")\n",
    "                result['image'].save(original_path, 'PNG')\n",
    "                \n",
    "                files_saved = [original_path]\n",
    "                \n",
    "                # Salvar imagem processada se existir\n",
    "                if 'processed_image' in result:\n",
    "                    processed_path = os.path.join(images_dir, f\"{filename_base}_processed.png\")\n",
    "                    result['processed_image'].save(processed_path, 'PNG')\n",
    "                    files_saved.append(processed_path)\n",
    "                \n",
    "                # Salvar metadados\n",
    "                if save_metadata:\n",
    "                    metadata_path = os.path.join(metadata_dir, f\"{filename_base}.json\")\n",
    "                    \n",
    "                    # Preparar metadados para JSON (remover objetos n√£o serializ√°veis)\n",
    "                    json_metadata = metadata.copy()\n",
    "                    json_metadata['files_saved'] = files_saved\n",
    "                    json_metadata['save_timestamp'] = datetime.now().isoformat()\n",
    "                    \n",
    "                    with open(metadata_path, 'w', encoding='utf-8') as f:\n",
    "                        json.dump(json_metadata, f, indent=2, ensure_ascii=False)\n",
    "                    \n",
    "                    files_saved.append(metadata_path)\n",
    "                \n",
    "                saved_files.extend(files_saved)\n",
    "                saved_count += 1\n",
    "                \n",
    "                print(f\"‚úÖ Salvo {i+1}/{len(batch_results)}: {filename_base}\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå Erro ao salvar imagem {i+1}: {e}\")\n",
    "                continue\n",
    "        \n",
    "        # Criar √≠ndice geral\n",
    "        if save_metadata:\n",
    "            index_data = {\n",
    "                'dataset_name': 'GrassClover Brazilian Synthetic',\n",
    "                'generation_date': datetime.now().isoformat(),\n",
    "                'total_images': len(batch_results),\n",
    "                'saved_images': saved_count,\n",
    "                'model_used': MODEL_ID,\n",
    "                'device': str(device),\n",
    "                'prompt_types': list(set(r['metadata']['prompt_key'] for r in batch_results)),\n",
    "                'files': saved_files\n",
    "            }\n",
    "            \n",
    "            index_path = os.path.join(output_dir, \"dataset_index.json\")\n",
    "            with open(index_path, 'w', encoding='utf-8') as f:\n",
    "                json.dump(index_data, f, indent=2, ensure_ascii=False)\n",
    "            \n",
    "            print(f\"üìã √çndice salvo: {index_path}\")\n",
    "        \n",
    "        print(f\"\\nüéâ Salvamento conclu√≠do!\")\n",
    "        print(f\"  ‚Ä¢ Imagens salvas: {saved_count}/{len(batch_results)}\")\n",
    "        print(f\"  ‚Ä¢ Arquivos totais: {len(saved_files)}\")\n",
    "        print(f\"  ‚Ä¢ Diret√≥rio: {os.path.abspath(output_dir)}\")\n",
    "        \n",
    "        return {\n",
    "            'success': True,\n",
    "            'saved_count': saved_count,\n",
    "            'total_files': len(saved_files),\n",
    "            'output_dir': os.path.abspath(output_dir),\n",
    "            'files': saved_files\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"üí• Erro no salvamento: {e}\")\n",
    "        print(f\"üìã DEBUG COPY/PASTE:\")\n",
    "        print(f\"Output dir: {output_dir}\")\n",
    "        print(f\"Batch results count: {len(batch_results) if batch_results else 0}\")\n",
    "        print(f\"Error: {type(e).__name__}: {e}\")\n",
    "        \n",
    "        return {\n",
    "            'success': False,\n",
    "            'saved_count': 0,\n",
    "            'error': str(e)\n",
    "        }\n",
    "\n",
    "print(\"‚úÖ Sistema de salvamento configurado!\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üíæ SALVAR LOTE GERADO\n",
    "print(\"üíæ Salvando lote de imagens...\\n\")\n",
    "\n",
    "if 'batch_results' in locals() and batch_results:\n",
    "    # Configura√ß√µes de salvamento\n",
    "    OUTPUT_DIR = \"grassclover_synthetic_dataset\"\n",
    "    SAVE_METADATA = True\n",
    "    \n",
    "    print(f\"‚öôÔ∏è  Configura√ß√µes de salvamento:\")\n",
    "    print(f\"  ‚Ä¢ Diret√≥rio: {OUTPUT_DIR}\")\n",
    "    print(f\"  ‚Ä¢ Salvar metadados: {SAVE_METADATA}\")\n",
    "    print(f\"  ‚Ä¢ Imagens a salvar: {len(batch_results)}\")\n",
    "    \n",
    "    # Executar salvamento\n",
    "    save_result = save_grassclover_batch(\n",
    "        batch_results=batch_results,\n",
    "        output_dir=OUTPUT_DIR,\n",
    "        save_metadata=SAVE_METADATA\n",
    "    )\n",
    "    \n",
    "    # Resultado\n",
    "    if save_result['success']:\n",
    "        print(f\"\\nüìä Resumo do Salvamento:\")\n",
    "        print(f\"  ‚úÖ Sucesso: {save_result['saved_count']} imagens salvas\")\n",
    "        print(f\"  üìÅ Localiza√ß√£o: {save_result['output_dir']}\")\n",
    "        print(f\"  üìÑ Arquivos totais: {save_result['total_files']}\")\n",
    "        \n",
    "        # Listar estrutura de diret√≥rios\n",
    "        print(f\"\\nüìã Estrutura criada:\")\n",
    "        if os.path.exists(save_result['output_dir']):\n",
    "            for root, dirs, files in os.walk(save_result['output_dir']):\n",
    "                level = root.replace(save_result['output_dir'], '').count(os.sep)\n",
    "                indent = ' ' * 2 * level\n",
    "                print(f\"{indent}{os.path.basename(root)}/\")\n",
    "                subindent = ' ' * 2 * (level + 1)\n",
    "                for file in files[:3]:  # Mostrar s√≥ os primeiros 3 arquivos\n",
    "                    print(f\"{subindent}{file}\")\n",
    "                if len(files) > 3:\n",
    "                    print(f\"{subindent}... e mais {len(files)-3} arquivos\")\n",
    "        \n",
    "        print(f\"\\nüéâ Dataset salvo com sucesso!\")\n",
    "        print(f\"üìÇ Para acessar: {save_result['output_dir']}\")\n",
    "        \n",
    "    else:\n",
    "        print(f\"‚ùå Falha no salvamento: {save_result.get('error', 'Erro desconhecido')}\")\n",
    "        \n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Nenhum lote de imagens dispon√≠vel para salvar\")\n",
    "    print(\"Execute primeiro a c√©lula de gera√ß√£o em lote\")\n",
    "\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Relat√≥rio Final e Estat√≠sticas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## üí° Instru√ß√µes para Uso e Debugging\n",
    "\n",
    "### üö® **Em caso de erro:**\n",
    "1. **Copie a se√ß√£o \"DEBUG COPY/PASTE\"** que aparece nos erros\n",
    "2. **Cole aqui nos coment√°rios** ou no chat para an√°lise\n",
    "3. **Inclua informa√ß√µes do sistema** (GPU, mem√≥ria, etc.)\n",
    "\n",
    "### üîß **Problemas Comuns Resolvidos:**\n",
    "\n",
    "#### **‚úÖ TPU Runtime Problem (RESOLVIDO)**\n",
    "- **Detec√ß√£o autom√°tica** de TPU/GPU/CPU\n",
    "- **Configura√ß√£o otimizada** para cada tipo de hardware\n",
    "- **Instru√ß√µes claras** para configura√ß√£o do runtime\n",
    "\n",
    "#### **‚úÖ Hugging Face Token Warning (RESOLVIDO)**\n",
    "- **Bypass autom√°tico** de problemas de autentica√ß√£o\n",
    "- **Configura√ß√£o de ambiente** para evitar warnings\n",
    "- **Downloads funcionam normalmente** mesmo com warnings\n",
    "\n",
    "#### **‚úÖ Dtype Configuration (RESOLVIDO)**\n",
    "- **float16 para GPU** (performance otimizada)\n",
    "- **float32 para TPU/CPU** (compatibilidade garantida)\n",
    "- **Configura√ß√£o autom√°tica** baseada no hardware\n",
    "\n",
    "### üéØ **Configura√ß√£o Recomendada para Colab:**\n",
    "- **Runtime**: GPU (Tesla T4 ou superior)\n",
    "- **Reasoning**: Stable Diffusion funciona melhor em GPU que TPU\n",
    "- **Fallback**: TPU funciona, mas GPU √© mais r√°pido para este caso\n",
    "\n",
    "### üîß **Ajustes poss√≠veis:**\n",
    "- **GENERATION_PARAMS**: Modifique `num_inference_steps` (15-50) para balancear qualidade/velocidade\n",
    "- **BATCH_SIZE**: Reduza se houver problemas de mem√≥ria\n",
    "- **Seeds**: Mude para explorar diferentes varia√ß√µes\n",
    "- **Prompts**: Ajuste para obter estilos visuais espec√≠ficos\n",
    "\n",
    "### üì∏ **Para adicionar refer√™ncias GrassClover:**\n",
    "1. **Upload das imagens** na se√ß√£o de arquivos do Colab\n",
    "2. **Modifique os prompts** baseado nas caracter√≠sticas visuais\n",
    "3. **Ajuste p√≥s-processamento** para aproximar do estilo original\n",
    "\n",
    "### üéØ **M√©tricas de qualidade:**\n",
    "- **Cobertura densa**: Pastagens devem ter ‚â•80% de cobertura vegetal\n",
    "- **Perspectiva top-down**: Vista a√©rea consistente\n",
    "- **Textura real√≠stica**: Detalhes de folhas e solo vis√≠veis\n",
    "- **Diversidade**: Varia√ß√£o entre as imagens geradas\n",
    "\n",
    "### üöÄ **Performance por Hardware:**\n",
    "- **GPU (Tesla T4)**: ~30-45s por imagem (recomendado)\n",
    "- **GPU (V100/A100)**: ~15-25s por imagem (√≥timo)\n",
    "- **TPU**: ~45-60s por imagem (funciona)\n",
    "- **CPU**: ~5-10min por imagem (muito lento, n√£o recomendado)\n",
    "\n",
    "---\n",
    "\n",
    "**üåæ Dataset GrassClover Brasileiro - Gerado com Stable Diffusion**  \n",
    "Baseado na metodologia de Skovsen et al. (CVPR 2019) adaptada para gram√≠neas tropicais.\n",
    "\n",
    "**üìã Problemas Comuns Resolvidos**: TPU detection, HF authentication, dtype optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üí° Instru√ß√µes para Uso e Debugging\n",
    "\n",
    "### üö® **Em caso de erro:**\n",
    "1. **Copie a se√ß√£o \"DEBUG COPY/PASTE\"** que aparece nos erros\n",
    "2. **Cole aqui nos coment√°rios** ou no chat para an√°lise\n",
    "3. **Inclua informa√ß√µes do sistema** (GPU, mem√≥ria, etc.)\n",
    "\n",
    "### üîß **Ajustes poss√≠veis:**\n",
    "- **GENERATION_PARAMS**: Modifique `num_inference_steps` (15-50) para balancear qualidade/velocidade\n",
    "- **BATCH_SIZE**: Reduza se houver problemas de mem√≥ria\n",
    "- **Seeds**: Mude para explorar diferentes varia√ß√µes\n",
    "- **Prompts**: Ajuste para obter estilos visuais espec√≠ficos\n",
    "\n",
    "### üì∏ **Para adicionar refer√™ncias GrassClover:**\n",
    "1. **Upload das imagens** na se√ß√£o de arquivos do Colab\n",
    "2. **Modifique os prompts** baseado nas caracter√≠sticas visuais\n",
    "3. **Ajuste p√≥s-processamento** para aproximar do estilo original\n",
    "\n",
    "### üéØ **M√©tricas de qualidade:**\n",
    "- **Cobertura densa**: Pastagens devem ter ‚â•80% de cobertura vegetal\n",
    "- **Perspectiva top-down**: Vista a√©rea consistente\n",
    "- **Textura real√≠stica**: Detalhes de folhas e solo vis√≠veis\n",
    "- **Diversidade**: Varia√ß√£o entre as imagens geradas\n",
    "\n",
    "---\n",
    "\n",
    "**üåæ Dataset GrassClover Brasileiro - Gerado com Stable Diffusion**  \n",
    "Baseado na metodologia de Skovsen et al. (CVPR 2019) adaptada para gram√≠neas tropicais."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}