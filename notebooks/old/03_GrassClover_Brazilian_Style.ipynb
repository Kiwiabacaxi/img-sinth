{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# üåæ Brazilian GrassClover: Synthetic Dataset Generation\n",
    "\n",
    "Este notebook implementa a metodologia do **GrassClover Dataset** adaptada para gram√≠neas forrageiras brasileiras.\n",
    "\n",
    "**Baseado em:** Skovsen et al. \"The GrassClover Image Dataset for Semantic and Hierarchical Species Understanding in Agriculture\" (CVPR Workshops, 2019)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "## üì¶ Instala√ß√£o e Configura√ß√£o\n",
    "\n",
    "Instala√ß√£o das depend√™ncias necess√°rias seguindo a metodologia GrassClover."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": "# üö® VERS√ÉO ULTRA-COMPAT√çVEL COLAB - APENAS BIBLIOTECAS B√ÅSICAS\n# Evita TODOS os conflitos de depend√™ncias\n!pip install \"opencv-python-headless\" \"pillow\" \"matplotlib\" --quiet\n\n# IMPORTA√á√ïES M√çNIMAS - SEM CONFLITOS\nimport numpy as np\nimport cv2\nfrom PIL import Image, ImageDraw, ImageFilter, ImageEnhance\nimport matplotlib.pyplot as plt\nfrom matplotlib.colors import ListedColormap\nimport os\nimport json\nimport random\nimport math\nfrom datetime import datetime\nfrom pathlib import Path\nfrom collections import defaultdict, Counter\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Seeds para reprodutibilidade\nnp.random.seed(42)\nrandom.seed(42)\n\nprint(f\"‚úÖ NumPy: {np.__version__}\")\nprint(f\"‚úÖ OpenCV: {cv2.__version__}\")\nprint(f\"üöÄ Modo Ultra-Compat√≠vel: Apenas bibliotecas essenciais\")\nprint(f\"‚úÖ Pronto para Colab!\")"
  },
  {
   "cell_type": "markdown",
   "id": "cell-3",
   "metadata": {},
   "source": [
    "## üîß Importa√ß√µes e Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": "# IMPORTA√á√ïES ULTRA-M√çNIMAS - SEM SCIKIT-IMAGE\nimport numpy as np\nimport cv2\nfrom PIL import Image, ImageDraw, ImageFilter, ImageEnhance\nimport matplotlib.pyplot as plt\nfrom matplotlib.colors import ListedColormap\nimport os\nimport json\nimport random\nimport math\nfrom datetime import datetime\nfrom pathlib import Path\nfrom collections import defaultdict, Counter\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Fun√ß√£o para simular filtro gaussiano (substituir scikit-image)\ndef simple_gaussian_blur(image, sigma=2):\n    \"\"\"Substituto simples para filtro gaussiano\"\"\"\n    kernel_size = int(6 * sigma + 1)\n    if kernel_size % 2 == 0:\n        kernel_size += 1\n    return cv2.GaussianBlur(image, (kernel_size, kernel_size), sigma)\n\nprint(\"üîß Modo Ultra-Compat√≠vel configurado (sem scikit-image)\")\nprint(\"‚úÖ Usando apenas: NumPy, OpenCV, PIL, Matplotlib\")\n\n# Configurar matplotlib\nplt.rcParams['figure.dpi'] = 100\nplt.rcParams['savefig.dpi'] = 150\nplt.rcParams['font.size'] = 10\n\n# Seeds\nnp.random.seed(42)\nrandom.seed(42)\n\nprint(\"‚úÖ Configura√ß√£o ultra-compat√≠vel conclu√≠da!\")"
  },
  {
   "cell_type": "markdown",
   "id": "cell-5",
   "metadata": {},
   "source": [
    "## üå± Defini√ß√£o das Classes - Estilo GrassClover Brasileiro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classes hier√°rquicas seguindo metodologia GrassClover para pastagens brasileiras\n",
    "GRASS_CLOVER_CLASSES = {\n",
    "    'background': {\n",
    "        'id': 0,\n",
    "        'color': (0, 0, 0),  # Preto\n",
    "        'name': 'Background',\n",
    "        'description': 'Fundo da imagem'\n",
    "    },\n",
    "    'soil': {\n",
    "        'id': 1,\n",
    "        'color': (139, 69, 19),  # Marrom\n",
    "        'name': 'Solo',\n",
    "        'description': 'Solo exposto ou entre plantas'\n",
    "    },\n",
    "    'brachiaria': {\n",
    "        'id': 2,\n",
    "        'color': (34, 139, 34),  # Verde floresta\n",
    "        'name': 'Brachiaria',\n",
    "        'description': 'Brachiaria spp. - Principal gram√≠nea forrageira'\n",
    "    },\n",
    "    'panicum': {\n",
    "        'id': 3,\n",
    "        'color': (50, 205, 50),  # Verde lima\n",
    "        'name': 'Panicum',\n",
    "        'description': 'Panicum spp. - Gram√≠nea de alto valor nutritivo'\n",
    "    },\n",
    "    'cynodon': {\n",
    "        'id': 4,\n",
    "        'color': (0, 255, 127),  # Verde primavera\n",
    "        'name': 'Cynodon', \n",
    "        'description': 'Cynodon spp. - Gram√≠nea resistente'\n",
    "    },\n",
    "    'leguminous': {\n",
    "        'id': 5,\n",
    "        'color': (255, 20, 147),  # Rosa profundo\n",
    "        'name': 'Leguminosas',\n",
    "        'description': 'Plantas fixadoras de nitrog√™nio (equivalente ao clover)'\n",
    "    },\n",
    "    'weeds': {\n",
    "        'id': 6,\n",
    "        'color': (255, 165, 0),  # Laranja\n",
    "        'name': 'Ervas Daninhas',\n",
    "        'description': 'Plantas invasoras e indesej√°veis'\n",
    "    }\n",
    "}\n",
    "\n",
    "# Paleta de cores para visualiza√ß√£o\n",
    "CLASS_COLORS = [cls['color'] for cls in GRASS_CLOVER_CLASSES.values()]\n",
    "CLASS_NAMES = [cls['name'] for cls in GRASS_CLOVER_CLASSES.values()]\n",
    "NUM_CLASSES = len(GRASS_CLOVER_CLASSES)\n",
    "\n",
    "# Criar colormap personalizado\n",
    "cmap_grass = ListedColormap([np.array(color)/255.0 for color in CLASS_COLORS])\n",
    "\n",
    "print(f\"üìä {NUM_CLASSES} classes definidas:\")\n",
    "for name, info in GRASS_CLOVER_CLASSES.items():\n",
    "    print(f\"  {info['id']}: {info['name']} - {info['description']}\")\n",
    "\n",
    "# Visualizar paleta de cores\n",
    "fig, ax = plt.subplots(1, 1, figsize=(12, 2))\n",
    "colors_array = np.array(CLASS_COLORS).reshape(1, -1, 3) / 255.0\n",
    "ax.imshow(colors_array, aspect='auto')\n",
    "ax.set_xticks(range(len(CLASS_NAMES)))\n",
    "ax.set_xticklabels(CLASS_NAMES, rotation=45, ha='right')\n",
    "ax.set_yticks([])\n",
    "ax.set_title('üé® Paleta de Classes - GrassClover Brasileiro')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-7",
   "metadata": {},
   "source": [
    "## üé® Gerador de Imagens Sint√©ticas - Metodologia GrassClover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": "class BrazilianGrassCloverGenerator:\n    \"\"\"\n    Gerador ULTRA-COMPAT√çVEL baseado na metodologia GrassClover\n    üö® VERS√ÉO COLAB - SEM DEPEND√äNCIAS PROBLEM√ÅTICAS\n    \"\"\"\n    \n    def __init__(self, image_size=(512, 512), ground_sampling_distance=6):\n        self.image_size = image_size\n        self.gsd = ground_sampling_distance\n        print(\"üé® Gerador ultra-compat√≠vel inicializado!\")\n    \n    def generate_soil_texture(self, soil_type=\"tropical\"):\n        \"\"\"Gera textura de solo usando apenas NumPy e OpenCV\"\"\"\n        h, w = self.image_size\n        \n        # Cores do solo brasileiro\n        soil_colors = {\n            'tropical': [(139, 69, 19), (160, 82, 45), (205, 133, 63)],\n            'cerrado': [(139, 90, 43), (165, 108, 64), (188, 143, 107)],\n            'clay': [(139, 54, 38), (160, 65, 47), (181, 83, 65)]\n        }\n        \n        colors = soil_colors.get(soil_type, soil_colors['tropical'])\n        \n        # Criar textura com ru√≠do (substituindo scikit-image)\n        noise = np.random.random((h, w)).astype(np.float32)\n        \n        # Aplicar blur gaussiano usando OpenCV\n        noise_smooth = simple_gaussian_blur(noise, sigma=2)\n        \n        # Imagem colorida\n        soil_img = np.zeros((h, w, 3), dtype=np.uint8)\n        \n        # Aplicar cores baseadas no ru√≠do\n        for i, color in enumerate(colors):\n            threshold_low = i / len(colors)\n            threshold_high = (i + 1) / len(colors)\n            mask = (noise_smooth >= threshold_low) & (noise_smooth < threshold_high)\n            soil_img[mask] = color\n        \n        # Varia√ß√£o de brilho\n        brightness_var = (np.random.random((h, w, 1)) - 0.5) * 30\n        soil_img = np.clip(soil_img + brightness_var, 0, 255).astype(np.uint8)\n        \n        return Image.fromarray(soil_img)\n    \n    def generate_grass_blade(self, grass_type=\"brachiaria\", size=(64, 64)):\n        \"\"\"Gera folha de grama individual usando PIL\"\"\"\n        h, w = size\n        \n        # Par√¢metros por tipo\n        grass_params = {\n            'brachiaria': {'color': (34, 139, 34), 'width': 0.6, 'curve': 0.3},\n            'panicum': {'color': (50, 205, 50), 'width': 0.8, 'curve': 0.5},\n            'cynodon': {'color': (0, 255, 127), 'width': 0.4, 'curve': 0.2},\n            'leguminous': {'color': (255, 20, 147), 'width': 0.9, 'curve': 0.1},\n            'weeds': {'color': (255, 165, 0), 'width': 0.5, 'curve': 0.7}\n        }\n        \n        params = grass_params.get(grass_type, grass_params['brachiaria'])\n        \n        # Criar imagem transparente\n        img = Image.new('RGBA', (w, h), (0, 0, 0, 0))\n        draw = ImageDraw.Draw(img)\n        \n        # Desenhar folha de grama\n        blade_width = int(w * params['width'])\n        center_x = w // 2\n        \n        points = []\n        for y in range(h):\n            progress = y / h\n            current_width = blade_width * (0.1 + 0.9 * progress)\n            curve_offset = int(params['curve'] * w * math.sin(progress * math.pi))\n            \n            left_x = center_x - current_width // 2 + curve_offset\n            right_x = center_x + current_width // 2 + curve_offset\n            points.append((left_x, y))\n        \n        # Lado direito da folha\n        for y in range(h-1, -1, -1):\n            progress = y / h\n            current_width = blade_width * (0.1 + 0.9 * progress)\n            curve_offset = int(params['curve'] * w * math.sin(progress * math.pi))\n            right_x = center_x + current_width // 2 + curve_offset\n            points.append((right_x, y))\n        \n        # Cor da folha com varia√ß√£o\n        base_color = params['color']\n        color_var = [random.randint(-20, 20) for _ in range(3)]\n        final_color = tuple(max(0, min(255, base_color[i] + color_var[i])) for i in range(3))\n        \n        # Desenhar pol√≠gono da folha\n        draw.polygon(points, fill=final_color + (255,))\n        \n        # Nervura central\n        nervure_color = tuple(max(0, c - 30) for c in final_color)\n        for y in range(h):\n            progress = y / h\n            curve_offset = int(params['curve'] * w * math.sin(progress * math.pi))\n            x = center_x + curve_offset\n            if 0 <= x < w:  # Verificar limites\n                draw.point((x, y), fill=nervure_color + (255,))\n        \n        return img\n    \n    def create_plant_cluster(self, plant_type=\"brachiaria\", num_blades=5):\n        \"\"\"Cria agrupamento de folhas\"\"\"\n        cluster_size = (128, 128)\n        cluster = Image.new('RGBA', cluster_size, (0, 0, 0, 0))\n        \n        for _ in range(num_blades):\n            # Gerar folha individual\n            blade_size = (random.randint(40, 80), random.randint(60, 100))\n            blade = self.generate_grass_blade(plant_type, blade_size)\n            \n            # Rota√ß√£o aleat√≥ria\n            angle = random.randint(-30, 30)\n            blade = blade.rotate(angle, expand=True)\n            \n            # Posi√ß√£o aleat√≥ria no cluster\n            max_x = max(0, cluster_size[0] - blade.size[0])\n            max_y = max(0, cluster_size[1] - blade.size[1])\n            \n            if max_x >= 0 and max_y >= 0:\n                pos_x = random.randint(0, max_x) if max_x > 0 else 0\n                pos_y = random.randint(0, max_y) if max_y > 0 else 0\n                \n                try:\n                    cluster.alpha_composite(blade, (pos_x, pos_y))\n                except:\n                    pass  # Ignorar erros de composi√ß√£o\n        \n        return cluster\n    \n    def generate_synthetic_scene(self, target_lai=2.0, composition=None):\n        \"\"\"Gera cena sint√©tica completa\"\"\"\n        if composition is None:\n            composition = {\n                'brachiaria': 0.4, 'panicum': 0.3, 'cynodon': 0.15,\n                'leguminous': 0.1, 'weeds': 0.05\n            }\n        \n        print(f\"üå± Gerando cena ultra-compat√≠vel (LAI: {target_lai:.1f})...\")\n        \n        # Solo base\n        soil_types = ['tropical', 'cerrado', 'clay']\n        soil_type = random.choice(soil_types)\n        scene_img = self.generate_soil_texture(soil_type)\n        \n        # M√°scara de segmenta√ß√£o (iniciar com solo = id 1)\n        segmentation_mask = np.ones(self.image_size, dtype=np.uint8)\n        \n        # N√∫mero de plantas baseado no LAI\n        base_plants = int(target_lai * 15)\n        plant_positions = []\n        \n        # Adicionar plantas por tipo\n        for plant_type, proportion in composition.items():\n            num_plants = int(base_plants * proportion)\n            class_id = GRASS_CLOVER_CLASSES[plant_type]['id']\n            \n            for _ in range(num_plants):\n                try:\n                    # Criar cluster de plantas\n                    num_blades = random.randint(3, 8)\n                    plant_cluster = self.create_plant_cluster(plant_type, num_blades)\n                    \n                    # Escala aleat√≥ria\n                    scale = random.uniform(0.5, 1.5)\n                    new_size = (int(plant_cluster.size[0] * scale), int(plant_cluster.size[1] * scale))\n                    plant_cluster = plant_cluster.resize(new_size, Image.Resampling.LANCZOS)\n                    \n                    # Posi√ß√£o aleat√≥ria (com margem de seguran√ßa)\n                    margin = 50\n                    max_x = max(0, self.image_size[0] - plant_cluster.size[0] - margin)\n                    max_y = max(0, self.image_size[1] - plant_cluster.size[1] - margin)\n                    \n                    if max_x > margin and max_y > margin:\n                        pos_x = random.randint(margin, max_x)\n                        pos_y = random.randint(margin, max_y)\n                        \n                        # Adicionar planta √† cena\n                        scene_img.paste(plant_cluster, (pos_x, pos_y), plant_cluster)\n                        \n                        # Atualizar m√°scara de segmenta√ß√£o\n                        plant_array = np.array(plant_cluster)\n                        if plant_array.shape[2] >= 4:  # Verificar canal alfa\n                            alpha_mask = plant_array[:, :, 3] > 0\n                            \n                            end_x = min(pos_x + plant_cluster.size[0], self.image_size[0])\n                            end_y = min(pos_y + plant_cluster.size[1], self.image_size[1])\n                            \n                            mask_h = end_y - pos_y\n                            mask_w = end_x - pos_x\n                            \n                            if mask_h > 0 and mask_w > 0:\n                                mask_region = alpha_mask[:mask_h, :mask_w]\n                                segmentation_mask[pos_y:end_y, pos_x:end_x][mask_region] = class_id\n                        \n                        plant_positions.append({\n                            'type': plant_type,\n                            'position': (pos_x, pos_y),\n                            'size': plant_cluster.size,\n                            'scale': scale,\n                            'class_id': class_id\n                        })\n                \n                except Exception as e:\n                    # Ignorar erros individuais de plantas\n                    continue\n        \n        # Aplicar efeitos naturais\n        scene_img = self._apply_natural_effects(scene_img)\n        \n        return {\n            'image': scene_img,\n            'segmentation_mask': segmentation_mask,\n            'plant_positions': plant_positions,\n            'composition': composition,\n            'lai': target_lai,\n            'soil_type': soil_type,\n            'metadata': {\n                'gsd': self.gsd,\n                'image_size': self.image_size,\n                'num_plants': len(plant_positions),\n                'generation_method': 'ultra_compatible_colab',\n                'timestamp': datetime.now().isoformat()\n            }\n        }\n    \n    def _apply_natural_effects(self, image):\n        \"\"\"Aplicar efeitos naturais usando PIL\"\"\"\n        try:\n            # Varia√ß√£o de brilho\n            enhancer = ImageEnhance.Brightness(image)\n            brightness_factor = random.uniform(0.8, 1.2)\n            image = enhancer.enhance(brightness_factor)\n            \n            # Varia√ß√£o de contraste\n            enhancer = ImageEnhance.Contrast(image)\n            contrast_factor = random.uniform(0.9, 1.1)\n            image = enhancer.enhance(contrast_factor)\n            \n            # Desfoque ocasional (simular vento)\n            if random.random() < 0.3:\n                blur_radius = random.uniform(0.5, 1.0)\n                image = image.filter(ImageFilter.GaussianBlur(radius=blur_radius))\n        \n        except Exception:\n            pass  # Ignorar erros de efeitos\n        \n        return image\n\nprint(\"‚úÖ Gerador BrazilianGrassClover ULTRA-COMPAT√çVEL criado!\")"
  },
  {
   "cell_type": "markdown",
   "id": "cell-9",
   "metadata": {},
   "source": [
    "## üöÄ Gera√ß√£o de Dataset Sint√©tico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializar gerador\n",
    "generator = BrazilianGrassCloverGenerator(image_size=(512, 512))\n",
    "\n",
    "# Configura√ß√µes do dataset\n",
    "num_synthetic_images = 8  # Come√ßar com poucas para teste\n",
    "lai_range = (1.0, 3.5)  # Leaf Area Index vari√°vel\n",
    "\n",
    "# Composi√ß√µes vari√°veis para simular diferentes pastagens\n",
    "composition_variants = [\n",
    "    {'brachiaria': 0.6, 'panicum': 0.2, 'cynodon': 0.1, 'leguminous': 0.08, 'weeds': 0.02},  # Brachiaria dominante\n",
    "    {'brachiaria': 0.3, 'panicum': 0.5, 'cynodon': 0.1, 'leguminous': 0.07, 'weeds': 0.03},  # Panicum dominante\n",
    "    {'brachiaria': 0.2, 'panicum': 0.2, 'cynodon': 0.4, 'leguminous': 0.15, 'weeds': 0.05}, # Cynodon com leguminosas\n",
    "    {'brachiaria': 0.4, 'panicum': 0.3, 'cynodon': 0.2, 'leguminous': 0.05, 'weeds': 0.05}, # Misto equilibrado\n",
    "    {'brachiaria': 0.5, 'panicum': 0.15, 'cynodon': 0.15, 'leguminous': 0.1, 'weeds': 0.1}, # Com mais ervas daninhas\n",
    "]\n",
    "\n",
    "print(f\"üåæ Gerando {num_synthetic_images} imagens sint√©ticas...\")\n",
    "\n",
    "synthetic_dataset = []\n",
    "\n",
    "for i in range(num_synthetic_images):\n",
    "    print(f\"\\nüì∏ Gerando imagem {i+1}/{num_synthetic_images}...\")\n",
    "    \n",
    "    # Par√¢metros vari√°veis\n",
    "    target_lai = random.uniform(*lai_range)\n",
    "    composition = random.choice(composition_variants)\n",
    "    \n",
    "    print(f\"  LAI alvo: {target_lai:.2f}\")\n",
    "    print(f\"  Composi√ß√£o: {composition}\")\n",
    "    \n",
    "    try:\n",
    "        # Gerar cena sint√©tica\n",
    "        scene_data = generator.generate_synthetic_scene(\n",
    "            target_lai=target_lai,\n",
    "            composition=composition\n",
    "        )\n",
    "        \n",
    "        scene_data['scene_id'] = i\n",
    "        synthetic_dataset.append(scene_data)\n",
    "        \n",
    "        print(f\"  ‚úÖ Cena {i+1} gerada com {len(scene_data['plant_positions'])} plantas\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  ‚ùå Erro ao gerar cena {i+1}: {e}\")\n",
    "        continue\n",
    "\n",
    "print(f\"\\nüéâ Dataset sint√©tico criado com {len(synthetic_dataset)} imagens!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-11",
   "metadata": {},
   "source": [
    "## üìä Visualiza√ß√£o do Dataset Sint√©tico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar algumas imagens do dataset\n",
    "if synthetic_dataset:\n",
    "    print(\"üìä Visualizando dataset sint√©tico...\")\n",
    "    \n",
    "    # Mostrar primeiras 4 imagens\n",
    "    num_show = min(4, len(synthetic_dataset))\n",
    "    \n",
    "    fig, axes = plt.subplots(num_show, 3, figsize=(15, 5 * num_show))\n",
    "    fig.suptitle('üåæ Dataset Sint√©tico - Estilo GrassClover Brasileiro', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    if num_show == 1:\n",
    "        axes = axes.reshape(1, -1)\n",
    "    \n",
    "    for i in range(num_show):\n",
    "        scene = synthetic_dataset[i]\n",
    "        \n",
    "        # 1. Imagem RGB\n",
    "        axes[i, 0].imshow(scene['image'])\n",
    "        axes[i, 0].set_title(f\"Cena {i+1}\\nLAI: {scene['lai']:.2f}\")\n",
    "        axes[i, 0].axis('off')\n",
    "        \n",
    "        # 2. M√°scara de segmenta√ß√£o\n",
    "        seg_colored = cmap_grass(scene['segmentation_mask'] / (NUM_CLASSES - 1))\n",
    "        axes[i, 1].imshow(seg_colored)\n",
    "        axes[i, 1].set_title(f\"Segmenta√ß√£o\\n{len(scene['plant_positions'])} plantas\")\n",
    "        axes[i, 1].axis('off')\n",
    "        \n",
    "        # 3. Overlay\n",
    "        img_array = np.array(scene['image'])\n",
    "        overlay = img_array * 0.7 + (seg_colored[:, :, :3] * 255) * 0.3\n",
    "        axes[i, 2].imshow(overlay.astype(np.uint8))\n",
    "        axes[i, 2].set_title('Overlay RGB + Segmenta√ß√£o')\n",
    "        axes[i, 2].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Estat√≠sticas do dataset\n",
    "    print(\"\\nüìà Estat√≠sticas do Dataset:\")\n",
    "    \n",
    "    total_plants = sum(len(scene['plant_positions']) for scene in synthetic_dataset)\n",
    "    avg_lai = np.mean([scene['lai'] for scene in synthetic_dataset])\n",
    "    \n",
    "    print(f\"Total de imagens: {len(synthetic_dataset)}\")\n",
    "    print(f\"Total de plantas: {total_plants}\")\n",
    "    print(f\"Plantas por imagem: {total_plants/len(synthetic_dataset):.1f}\")\n",
    "    print(f\"LAI m√©dio: {avg_lai:.2f}\")\n",
    "    \n",
    "    # Contagem por classe\n",
    "    class_counts = Counter()\n",
    "    for scene in synthetic_dataset:\n",
    "        for plant in scene['plant_positions']:\n",
    "            class_counts[plant['type']] += 1\n",
    "    \n",
    "    print(\"\\nDistribui√ß√£o por classe:\")\n",
    "    for plant_type, count in class_counts.most_common():\n",
    "        percentage = (count / total_plants) * 100\n",
    "        print(f\"  {plant_type}: {count} plantas ({percentage:.1f}%)\")\n",
    "    \n",
    "    # Gr√°fico de distribui√ß√£o\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    \n",
    "    # Distribui√ß√£o LAI\n",
    "    lais = [scene['lai'] for scene in synthetic_dataset]\n",
    "    ax1.hist(lais, bins=10, alpha=0.7, color='green', edgecolor='black')\n",
    "    ax1.set_xlabel('Leaf Area Index (LAI)')\n",
    "    ax1.set_ylabel('Frequ√™ncia')\n",
    "    ax1.set_title('Distribui√ß√£o do LAI')\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Distribui√ß√£o por classe\n",
    "    if class_counts:\n",
    "        classes = list(class_counts.keys())\n",
    "        counts = list(class_counts.values())\n",
    "        colors = [np.array(GRASS_CLOVER_CLASSES[cls]['color'])/255.0 for cls in classes]\n",
    "        \n",
    "        ax2.bar(classes, counts, color=colors)\n",
    "        ax2.set_xlabel('Tipo de Planta')\n",
    "        ax2.set_ylabel('N√∫mero de Plantas')\n",
    "        ax2.set_title('Distribui√ß√£o por Classe')\n",
    "        ax2.tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "else:\n",
    "    print(\"‚ùå Nenhuma imagem sint√©tica foi gerada\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-13",
   "metadata": {},
   "source": [
    "## üîç An√°lise de Composi√ß√£o - Estilo GrassClover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_scene_composition(scene_data):\n",
    "    \"\"\"\n",
    "    An√°lise detalhada da composi√ß√£o da cena seguindo metodologia GrassClover\n",
    "    \"\"\"\n",
    "    seg_mask = scene_data['segmentation_mask']\n",
    "    total_pixels = seg_mask.shape[0] * seg_mask.shape[1]\n",
    "    \n",
    "    # Contagem por classe\n",
    "    class_pixels = {}\n",
    "    class_percentages = {}\n",
    "    \n",
    "    for class_name, class_info in GRASS_CLOVER_CLASSES.items():\n",
    "        class_id = class_info['id']\n",
    "        pixels = np.sum(seg_mask == class_id)\n",
    "        percentage = (pixels / total_pixels) * 100\n",
    "        \n",
    "        class_pixels[class_name] = pixels\n",
    "        class_percentages[class_name] = percentage\n",
    "    \n",
    "    # An√°lise de biomassa (similar ao GrassClover)\n",
    "    vegetation_pixels = total_pixels - class_pixels['background'] - class_pixels['soil']\n",
    "    vegetation_coverage = (vegetation_pixels / total_pixels) * 100\n",
    "    \n",
    "    # Densidade de plantas\n",
    "    plant_density = len(scene_data['plant_positions']) / (total_pixels / (1000 * 1000))  # plantas por m¬≤\n",
    "    \n",
    "    return {\n",
    "        'scene_id': scene_data['scene_id'],\n",
    "        'total_pixels': total_pixels,\n",
    "        'class_pixels': class_pixels,\n",
    "        'class_percentages': class_percentages,\n",
    "        'vegetation_coverage': vegetation_coverage,\n",
    "        'plant_density': plant_density,\n",
    "        'lai': scene_data['lai'],\n",
    "        'num_plants': len(scene_data['plant_positions'])\n",
    "    }\n",
    "\n",
    "# Analisar todas as cenas\n",
    "if synthetic_dataset:\n",
    "    print(\"üîç Analisando composi√ß√£o das cenas...\")\n",
    "    \n",
    "    composition_analyses = []\n",
    "    for scene in synthetic_dataset:\n",
    "        analysis = analyze_scene_composition(scene)\n",
    "        composition_analyses.append(analysis)\n",
    "    \n",
    "    # Visualizar an√°lises\n",
    "    num_analyses = len(composition_analyses)\n",
    "    \n",
    "    # Gr√°fico de cobertura por classe para cada cena\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    fig.suptitle('üìä An√°lise de Composi√ß√£o - Metodologia GrassClover', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # 1. Cobertura vegetacional por cena\n",
    "    scene_ids = [a['scene_id'] for a in composition_analyses]\n",
    "    vegetation_coverages = [a['vegetation_coverage'] for a in composition_analyses]\n",
    "    \n",
    "    axes[0, 0].bar(scene_ids, vegetation_coverages, color='green', alpha=0.7)\n",
    "    axes[0, 0].set_xlabel('ID da Cena')\n",
    "    axes[0, 0].set_ylabel('Cobertura Vegetacional (%)')\n",
    "    axes[0, 0].set_title('Cobertura Vegetacional por Cena')\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 2. LAI vs Cobertura\n",
    "    lais = [a['lai'] for a in composition_analyses]\n",
    "    \n",
    "    axes[0, 1].scatter(lais, vegetation_coverages, c=scene_ids, cmap='viridis', s=100)\n",
    "    axes[0, 1].set_xlabel('Leaf Area Index (LAI)')\n",
    "    axes[0, 1].set_ylabel('Cobertura Vegetacional (%)')\n",
    "    axes[0, 1].set_title('Rela√ß√£o LAI vs Cobertura')\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 3. Composi√ß√£o m√©dia por classe\n",
    "    avg_percentages = {}\n",
    "    for class_name in GRASS_CLOVER_CLASSES.keys():\n",
    "        percentages = [a['class_percentages'][class_name] for a in composition_analyses]\n",
    "        avg_percentages[class_name] = np.mean(percentages)\n",
    "    \n",
    "    # Filtrar classes com cobertura significativa (> 0.1%)\n",
    "    significant_classes = {k: v for k, v in avg_percentages.items() if v > 0.1}\n",
    "    \n",
    "    if significant_classes:\n",
    "        class_names = list(significant_classes.keys())\n",
    "        percentages = list(significant_classes.values())\n",
    "        colors = [np.array(GRASS_CLOVER_CLASSES[cls]['color'])/255.0 for cls in class_names]\n",
    "        \n",
    "        axes[1, 0].pie(percentages, labels=class_names, colors=colors, autopct='%1.1f%%')\n",
    "        axes[1, 0].set_title('Composi√ß√£o M√©dia por Classe')\n",
    "    \n",
    "    # 4. Densidade de plantas vs LAI\n",
    "    plant_densities = [a['plant_density'] for a in composition_analyses]\n",
    "    \n",
    "    axes[1, 1].scatter(lais, plant_densities, c=vegetation_coverages, cmap='Greens', s=100)\n",
    "    axes[1, 1].set_xlabel('Leaf Area Index (LAI)')\n",
    "    axes[1, 1].set_ylabel('Densidade de Plantas (plantas/m¬≤)')\n",
    "    axes[1, 1].set_title('Densidade vs LAI')\n",
    "    axes[1, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.colorbar(axes[1, 1].collections[0], ax=axes[1, 1], label='Cobertura (%)')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Relat√≥rio estat√≠stico\n",
    "    print(\"\\nüìà Relat√≥rio Estat√≠stico da Composi√ß√£o:\")\n",
    "    print(f\"Cobertura vegetacional m√©dia: {np.mean(vegetation_coverages):.1f}%\")\n",
    "    print(f\"LAI m√©dio: {np.mean(lais):.2f}\")\n",
    "    print(f\"Densidade m√©dia: {np.mean(plant_densities):.1f} plantas/m¬≤\")\n",
    "    \n",
    "    print(\"\\nComposi√ß√£o m√©dia por classe:\")\n",
    "    for class_name, avg_pct in avg_percentages.items():\n",
    "        if avg_pct > 0.1:  # Mostrar apenas classes significativas\n",
    "            print(f\"  {GRASS_CLOVER_CLASSES[class_name]['name']}: {avg_pct:.1f}%\")\n",
    "\n",
    "else:\n",
    "    print(\"‚ùå Nenhum dado dispon√≠vel para an√°lise\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-15",
   "metadata": {},
   "source": [
    "## üß† Modelo de Segmenta√ß√£o - DeepLabV3+ (Estilo GrassClover)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-16",
   "metadata": {},
   "outputs": [],
   "source": "# üß† Modelo de Segmenta√ß√£o - DeepLabV3+ (Estilo GrassClover)\n# ‚ö†Ô∏è VERS√ÉO COLAB COM GPU HABILITADA\n\n# PRIMEIRO: Verificar se o Colab tem GPU habilitada\nimport torch\nprint(\"üîç Verificando configura√ß√£o do Colab...\")\nprint(f\"CUDA dispon√≠vel: {torch.cuda.is_available()}\")\n\nif torch.cuda.is_available():\n    print(f\"N√∫mero de GPUs: {torch.cuda.device_count()}\")\n    for i in range(torch.cuda.device_count()):\n        print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")\n        print(f\"Mem√≥ria GPU {i}: {torch.cuda.get_device_properties(i).total_memory / 1e9:.1f} GB\")\n    device = \"cuda\"\n    print(\"‚úÖ Usando GPU!\")\nelse:\n    device = \"cpu\"\n    print(\"‚ö†Ô∏è GPU n√£o detectada. Instru√ß√µes para habilitar:\")\n    print(\"1. No Colab: Runtime > Change runtime type\")\n    print(\"2. Hardware accelerator: GPU (T4, V100, ou A100)\")\n    print(\"3. Save > Restart runtime\")\n\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torchvision import models\n\n# Implementa√ß√£o DeepLabV3+ otimizada para Colab\nclass SimpleDeepLabV3Plus(nn.Module):\n    \"\"\"DeepLabV3+ otimizado para Colab GPU\"\"\"\n    \n    def __init__(self, num_classes=NUM_CLASSES, backbone='resnet50'):\n        super().__init__()\n        \n        # Backbone (encoder) - ResNet-50\n        if backbone == 'resnet50':\n            backbone_model = models.resnet50(weights='IMAGENET1K_V1')  # Nova sintaxe\n            self.backbone = nn.Sequential(*list(backbone_model.children())[:-2])\n            backbone_channels = 2048\n        \n        # ASPP (Atrous Spatial Pyramid Pooling)\n        self.aspp = ASPP(backbone_channels, 256)\n        \n        # Decoder\n        self.decoder = Decoder(num_classes)\n        \n        # Low-level features projection\n        self.low_level_conv = nn.Conv2d(256, 48, 1, bias=False)\n        self.low_level_bn = nn.BatchNorm2d(48)\n        self.low_level_relu = nn.ReLU(inplace=True)\n    \n    def forward(self, x):\n        input_size = x.shape[-2:]\n        \n        # Extrair features\n        features = self.extract_features(x)\n        \n        # ASPP\n        aspp_out = self.aspp(features['high_level'])\n        \n        # Upsample ASPP\n        aspp_upsampled = F.interpolate(\n            aspp_out, \n            size=features['low_level'].shape[-2:], \n            mode='bilinear', \n            align_corners=False\n        )\n        \n        # Low-level features\n        low_level = self.low_level_conv(features['low_level'])\n        low_level = self.low_level_bn(low_level)\n        low_level = self.low_level_relu(low_level)\n        \n        # Concatenate\n        concat_features = torch.cat([assp_upsampled, low_level], dim=1)\n        \n        # Decoder\n        output = self.decoder(concat_features)\n        \n        # Final upsample\n        output = F.interpolate(output, size=input_size, mode='bilinear', align_corners=False)\n        \n        return output\n    \n    def extract_features(self, x):\n        \"\"\"Extrai features do ResNet-50\"\"\"\n        features = {}\n        \n        # Conv1 + BN + ReLU + MaxPool\n        x = self.backbone[0](x)  # conv1\n        x = self.backbone[1](x)  # bn1\n        x = self.backbone[2](x)  # relu\n        x = self.backbone[3](x)  # maxpool\n        \n        # ResNet blocks\n        x = self.backbone[4](x)  # layer1 (64 -> 256 channels)\n        features['low_level'] = x  # Para skip connection\n        \n        x = self.backbone[5](x)  # layer2 (256 -> 512)\n        x = self.backbone[6](x)  # layer3 (512 -> 1024)  \n        x = self.backbone[7](x)  # layer4 (1024 -> 2048)\n        \n        features['high_level'] = x\n        \n        return features\n\n\nclass ASPP(nn.Module):\n    \"\"\"Atrous Spatial Pyramid Pooling - Otimizado para GPU\"\"\"\n    \n    def __init__(self, in_channels, out_channels):\n        super().__init__()\n        \n        # Diferentes taxas de dilata√ß√£o\n        self.conv1 = nn.Conv2d(in_channels, out_channels, 1, bias=False)\n        self.conv6 = nn.Conv2d(in_channels, out_channels, 3, padding=6, dilation=6, bias=False)\n        self.conv12 = nn.Conv2d(in_channels, out_channels, 3, padding=12, dilation=12, bias=False)\n        self.conv18 = nn.Conv2d(in_channels, out_channels, 3, padding=18, dilation=18, bias=False)\n        \n        # Global pooling\n        self.global_pool = nn.AdaptiveAvgPool2d(1)\n        self.global_conv = nn.Conv2d(in_channels, out_channels, 1, bias=False)\n        \n        # Batch normalization\n        self.bn1 = nn.BatchNorm2d(out_channels)\n        self.bn6 = nn.BatchNorm2d(out_channels)\n        self.bn12 = nn.BatchNorm2d(out_channels)\n        self.bn18 = nn.BatchNorm2d(out_channels)\n        self.bn_global = nn.BatchNorm2d(out_channels)\n        \n        self.relu = nn.ReLU(inplace=True)\n        \n        # Proje√ß√£o final\n        self.project = nn.Conv2d(out_channels * 5, out_channels, 1, bias=False)\n        self.project_bn = nn.BatchNorm2d(out_channels)\n        self.dropout = nn.Dropout(0.1)\n    \n    def forward(self, x):\n        size = x.shape[-2:]\n        \n        # Convolu√ß√µes com diferentes dilata√ß√µes\n        x1 = self.relu(self.bn1(self.conv1(x)))\n        x6 = self.relu(self.bn6(self.conv6(x)))\n        x12 = self.relu(self.bn12(self.conv12(x)))\n        x18 = self.relu(self.bn18(self.conv18(x)))\n        \n        # Branch de pooling global\n        x_global = self.global_pool(x)\n        x_global = self.relu(self.bn_global(self.global_conv(x_global)))\n        x_global = F.interpolate(x_global, size=size, mode='bilinear', align_corners=False)\n        \n        # Concatenar todos os branches\n        x_concat = torch.cat([x1, x6, x12, x18, x_global], dim=1)\n        \n        # Proje√ß√£o final\n        output = self.project(x_concat)\n        output = self.project_bn(output)\n        output = self.relu(output)\n        output = self.dropout(output)\n        \n        return output\n\n\nclass Decoder(nn.Module):\n    \"\"\"Decoder otimizado para GPU\"\"\"\n    \n    def __init__(self, num_classes):\n        super().__init__()\n        \n        # Primeiro bloco\n        self.conv1 = nn.Conv2d(256 + 48, 256, 3, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(256)\n        self.relu1 = nn.ReLU(inplace=True)\n        \n        self.conv2 = nn.Conv2d(256, 256, 3, padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(256)\n        self.relu2 = nn.ReLU(inplace=True)\n        \n        # Classificador final\n        self.classifier = nn.Conv2d(256, num_classes, 1)\n        self.dropout = nn.Dropout(0.1)\n    \n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.bn1(x)\n        x = self.relu1(x)\n        x = self.dropout(x)\n        \n        x = self.conv2(x)\n        x = self.bn2(x)\n        x = self.relu2(x)\n        x = self.dropout(x)\n        \n        x = self.classifier(x)\n        \n        return x\n\n\n# Criar e testar modelo\nprint(f\"\\nüß† Criando modelo DeepLabV3+ para GPU...\")\n\ntry:\n    # Criar modelo\n    model = SimpleDeepLabV3Plus(num_classes=NUM_CLASSES)\n    \n    # Mover para dispositivo\n    model = model.to(device)\n    print(f\"‚úÖ Modelo movido para: {device}\")\n    \n    # Contar par√¢metros\n    total_params = sum(p.numel() for p in model.parameters())\n    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n    \n    print(f\"üìä Par√¢metros: {total_params:,} total ({trainable_params:,} trein√°veis)\")\n    \n    # Teste com entrada dummy\n    print(f\"\\nüß™ Testando modelo...\")\n    \n    # Definir modelo em modo eval para teste\n    model.eval()\n    \n    with torch.no_grad():\n        # Criar entrada dummy\n        batch_size = 2 if device == \"cuda\" else 1  # Usar batch maior na GPU\n        dummy_input = torch.randn(batch_size, 3, 512, 512).to(device)\n        \n        print(f\"Input shape: {dummy_input.shape}\")\n        print(f\"Input device: {dummy_input.device}\")\n        \n        # Forward pass\n        output = model(dummy_input)\n        \n        print(f\"‚úÖ Output shape: {output.shape}\")\n        print(f\"‚úÖ Output device: {output.device}\")\n        \n        if device == \"cuda\":\n            memory_used = torch.cuda.memory_allocated() / 1e9\n            memory_cached = torch.cuda.memory_reserved() / 1e9\n            print(f\"üíæ Mem√≥ria GPU: {memory_used:.2f} GB usada, {memory_cached:.2f} GB reservada\")\n        \n        print(\"üéâ Modelo funcionando perfeitamente!\")\n\nexcept Exception as e:\n    print(f\"‚ùå Erro: {e}\")\n    print(\"\\nüí° Solu√ß√µes:\")\n    print(\"1. Verificar se GPU est√° habilitada no Colab\")\n    print(\"2. Runtime > Restart runtime se necess√°rio\")\n    print(\"3. Reduzir batch_size se falta mem√≥ria\")\n    \n    # Tentar vers√£o mais simples\n    try:\n        print(\"\\nüîÑ Tentando vers√£o simplificada...\")\n        device = \"cpu\"\n        model = SimpleDeepLabV3Plus(num_classes=NUM_CLASSES).to(device)\n        with torch.no_grad():\n            dummy_input = torch.randn(1, 3, 256, 256).to(device)  # Menor\n            output = model(dummy_input)\n            print(f\"‚úÖ Vers√£o CPU funcionando: {output.shape}\")\n    except Exception as e2:\n        print(f\"‚ùå Erro tamb√©m na CPU: {e2}\")\n        model = None\n\nprint(f\"\\nüìã Resumo:\")\nprint(f\"Device final: {device}\")\nprint(f\"Modelo criado: {'‚úÖ' if 'model' in locals() and model is not None else '‚ùå'}\")\n\n# Instru√ß√µes para o usu√°rio do Colab\nif device == \"cpu\":\n    print(f\"\\nüö® IMPORTANTE - Para usar GPU no Colab:\")\n    print(f\"1. Menu: Runtime ‚Üí Change runtime type\")\n    print(f\"2. Hardware accelerator: GPU\")  \n    print(f\"3. Runtime ‚Üí Restart runtime\")\n    print(f\"4. Execute novamente esta c√©lula\")"
  },
  {
   "cell_type": "markdown",
   "id": "cell-17",
   "metadata": {},
   "source": [
    "## üéØ Avalia√ß√£o e M√©tricas - Metodologia GrassClover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_miou(pred_mask, true_mask, num_classes=NUM_CLASSES, ignore_index=0):\n",
    "    \"\"\"\n",
    "    Calcula mean Intersection over Union (mIoU)\n",
    "    M√©trica principal usada no paper GrassClover\n",
    "    \"\"\"\n",
    "    iou_per_class = []\n",
    "    \n",
    "    for class_id in range(num_classes):\n",
    "        if class_id == ignore_index:\n",
    "            continue\n",
    "            \n",
    "        pred_class = (pred_mask == class_id)\n",
    "        true_class = (true_mask == class_id)\n",
    "        \n",
    "        intersection = np.logical_and(pred_class, true_class).sum()\n",
    "        union = np.logical_or(pred_class, true_class).sum()\n",
    "        \n",
    "        if union == 0:\n",
    "            iou = 0.0  # Classe n√£o presente\n",
    "        else:\n",
    "            iou = intersection / union\n",
    "        \n",
    "        iou_per_class.append(iou)\n",
    "    \n",
    "    miou = np.mean(iou_per_class)\n",
    "    return miou, iou_per_class\n",
    "\n",
    "\n",
    "def calculate_pixel_accuracy(pred_mask, true_mask):\n",
    "    \"\"\"Calcula acur√°cia pixel a pixel\"\"\"\n",
    "    correct = np.sum(pred_mask == true_mask)\n",
    "    total = pred_mask.size\n",
    "    return correct / total\n",
    "\n",
    "\n",
    "def evaluate_biomass_composition(pred_mask, true_mask):\n",
    "    \"\"\"\n",
    "    Avalia predi√ß√£o da composi√ß√£o de biomassa\n",
    "    Seguindo metodologia do GrassClover para agricultura\n",
    "    \"\"\"\n",
    "    pred_composition = {}\n",
    "    true_composition = {}\n",
    "    \n",
    "    total_pixels = pred_mask.size\n",
    "    \n",
    "    for class_name, class_info in GRASS_CLOVER_CLASSES.items():\n",
    "        class_id = class_info['id']\n",
    "        \n",
    "        pred_pixels = np.sum(pred_mask == class_id)\n",
    "        true_pixels = np.sum(true_mask == class_id)\n",
    "        \n",
    "        pred_composition[class_name] = (pred_pixels / total_pixels) * 100\n",
    "        true_composition[class_name] = (true_pixels / total_pixels) * 100\n",
    "    \n",
    "    # Calcular erro absoluto m√©dio na composi√ß√£o\n",
    "    mae_composition = np.mean([\n",
    "        abs(pred_composition[class_name] - true_composition[class_name])\n",
    "        for class_name in GRASS_CLOVER_CLASSES.keys()\n",
    "    ])\n",
    "    \n",
    "    return pred_composition, true_composition, mae_composition\n",
    "\n",
    "\n",
    "# Fun√ß√£o para criar m√°scara de predi√ß√£o simulada (para demonstra√ß√£o)\n",
    "def create_simulated_prediction(true_mask, noise_level=0.1):\n",
    "    \"\"\"\n",
    "    Cria uma predi√ß√£o simulada baseada na m√°scara verdadeira\n",
    "    Para demonstrar as m√©tricas de avalia√ß√£o\n",
    "    \"\"\"\n",
    "    pred_mask = true_mask.copy()\n",
    "    \n",
    "    # Adicionar ru√≠do aleat√≥rio\n",
    "    h, w = pred_mask.shape\n",
    "    noise_pixels = int(h * w * noise_level)\n",
    "    \n",
    "    for _ in range(noise_pixels):\n",
    "        y = random.randint(0, h-1)\n",
    "        x = random.randint(0, w-1)\n",
    "        \n",
    "        # Trocar para classe aleat√≥ria\n",
    "        available_classes = list(range(NUM_CLASSES))\n",
    "        available_classes.remove(pred_mask[y, x])  # Remover classe atual\n",
    "        if available_classes:\n",
    "            pred_mask[y, x] = random.choice(available_classes)\n",
    "    \n",
    "    return pred_mask\n",
    "\n",
    "\n",
    "# Avaliar dataset sint√©tico\n",
    "if synthetic_dataset:\n",
    "    print(\"üéØ Avaliando dataset com m√©tricas do GrassClover...\")\n",
    "    \n",
    "    evaluation_results = []\n",
    "    \n",
    "    # Avaliar primeiras 3 imagens como exemplo\n",
    "    num_eval = min(3, len(synthetic_dataset))\n",
    "    \n",
    "    for i in range(num_eval):\n",
    "        scene = synthetic_dataset[i]\n",
    "        true_mask = scene['segmentation_mask']\n",
    "        \n",
    "        # Criar predi√ß√£o simulada\n",
    "        pred_mask = create_simulated_prediction(true_mask, noise_level=0.15)\n",
    "        \n",
    "        # Calcular m√©tricas\n",
    "        miou, iou_per_class = calculate_miou(pred_mask, true_mask)\n",
    "        pixel_acc = calculate_pixel_accuracy(pred_mask, true_mask)\n",
    "        pred_comp, true_comp, mae_comp = evaluate_biomass_composition(pred_mask, true_mask)\n",
    "        \n",
    "        evaluation_results.append({\n",
    "            'scene_id': i,\n",
    "            'miou': miou,\n",
    "            'iou_per_class': iou_per_class,\n",
    "            'pixel_accuracy': pixel_acc,\n",
    "            'mae_composition': mae_comp,\n",
    "            'pred_composition': pred_comp,\n",
    "            'true_composition': true_comp\n",
    "        })\n",
    "        \n",
    "        print(f\"Cena {i+1}: mIoU = {miou:.3f}, Pixel Acc = {pixel_acc:.3f}, MAE Comp = {mae_comp:.2f}%\")\n",
    "    \n",
    "    # Visualizar resultados da avalia√ß√£o\n",
    "    fig, axes = plt.subplots(num_eval, 4, figsize=(20, 5 * num_eval))\n",
    "    fig.suptitle('üéØ Avalia√ß√£o de Segmenta√ß√£o - Metodologia GrassClover', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    if num_eval == 1:\n",
    "        axes = axes.reshape(1, -1)\n",
    "    \n",
    "    for i in range(num_eval):\n",
    "        scene = synthetic_dataset[i]\n",
    "        result = evaluation_results[i]\n",
    "        \n",
    "        true_mask = scene['segmentation_mask']\n",
    "        pred_mask = create_simulated_prediction(true_mask, noise_level=0.15)\n",
    "        \n",
    "        # 1. Imagem original\n",
    "        axes[i, 0].imshow(scene['image'])\n",
    "        axes[i, 0].set_title(f\"Cena {i+1} - Original\")\n",
    "        axes[i, 0].axis('off')\n",
    "        \n",
    "        # 2. Ground truth\n",
    "        gt_colored = cmap_grass(true_mask / (NUM_CLASSES - 1))\n",
    "        axes[i, 1].imshow(gt_colored)\n",
    "        axes[i, 1].set_title('Ground Truth')\n",
    "        axes[i, 1].axis('off')\n",
    "        \n",
    "        # 3. Predi√ß√£o simulada\n",
    "        pred_colored = cmap_grass(pred_mask / (NUM_CLASSES - 1))\n",
    "        axes[i, 2].imshow(pred_colored)\n",
    "        axes[i, 2].set_title(f\"Predi√ß√£o\\nmIoU: {result['miou']:.3f}\")\n",
    "        axes[i, 2].axis('off')\n",
    "        \n",
    "        # 4. Mapa de erro\n",
    "        error_map = (pred_mask != true_mask).astype(np.uint8)\n",
    "        axes[i, 3].imshow(error_map, cmap='Reds')\n",
    "        axes[i, 3].set_title(f\"Erros\\nPixel Acc: {result['pixel_accuracy']:.3f}\")\n",
    "        axes[i, 3].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Estat√≠sticas gerais\n",
    "    print(\"\\nüìä Estat√≠sticas de Avalia√ß√£o:\")\n",
    "    avg_miou = np.mean([r['miou'] for r in evaluation_results])\n",
    "    avg_pixel_acc = np.mean([r['pixel_accuracy'] for r in evaluation_results])\n",
    "    avg_mae_comp = np.mean([r['mae_composition'] for r in evaluation_results])\n",
    "    \n",
    "    print(f\"mIoU m√©dio: {avg_miou:.3f}\")\n",
    "    print(f\"Acur√°cia pixel m√©dia: {avg_pixel_acc:.3f}\")\n",
    "    print(f\"MAE composi√ß√£o m√©dia: {avg_mae_comp:.2f}%\")\n",
    "    \n",
    "    # IoU por classe\n",
    "    class_names_filtered = [name for name in CLASS_NAMES if name != 'Background']\n",
    "    avg_iou_per_class = np.mean([r['iou_per_class'] for r in evaluation_results], axis=0)\n",
    "    \n",
    "    print(\"\\nIoU por classe:\")\n",
    "    for i, (class_name, iou) in enumerate(zip(class_names_filtered, avg_iou_per_class)):\n",
    "        print(f\"  {class_name}: {iou:.3f}\")\n",
    "    \n",
    "    print(f\"\\nüìù Nota: O paper original GrassClover reportou mIoU de 0.55 com FCN-8s\")\n",
    "    print(f\"    Nosso resultado simulado: {avg_miou:.3f}\")\n",
    "\n",
    "else:\n",
    "    print(\"‚ùå Nenhum dado dispon√≠vel para avalia√ß√£o\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-19",
   "metadata": {},
   "source": [
    "## üíæ Exporta√ß√£o do Dataset - Formato GrassClover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exportar dataset no formato compat√≠vel com metodologia GrassClover\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "def export_grassclover_dataset(dataset, output_dir=\"grassclover_brazilian_dataset\"):\n",
    "    \"\"\"\n",
    "    Exporta dataset no formato GrassClover\n",
    "    \"\"\"\n",
    "    output_path = Path(output_dir)\n",
    "    output_path.mkdir(exist_ok=True)\n",
    "    \n",
    "    # Estrutura de diret√≥rios\n",
    "    (output_path / \"images\").mkdir(exist_ok=True)\n",
    "    (output_path / \"masks\").mkdir(exist_ok=True)\n",
    "    (output_path / \"metadata\").mkdir(exist_ok=True)\n",
    "    \n",
    "    dataset_info = {\n",
    "        'name': 'Brazilian GrassClover Dataset',\n",
    "        'description': 'Synthetic dataset of Brazilian forage grasses following GrassClover methodology',\n",
    "        'created': datetime.now().isoformat(),\n",
    "        'num_images': len(dataset),\n",
    "        'image_size': dataset[0]['image'].size if dataset else [512, 512],\n",
    "        'classes': GRASS_CLOVER_CLASSES,\n",
    "        'methodology': 'Based on Skovsen et al. GrassClover Dataset (CVPR 2019)',\n",
    "        'ground_sampling_distance': '4-8 px/mm',\n",
    "        'scene_parameters': {\n",
    "            'lai_range': [1.0, 3.5],\n",
    "            'composition_variants': 5,\n",
    "            'plant_density_range': 'Variable based on LAI'\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    exported_scenes = []\n",
    "    \n",
    "    print(f\"üíæ Exportando {len(dataset)} cenas para {output_path}...\")\n",
    "    \n",
    "    for i, scene in enumerate(dataset):\n",
    "        scene_id = f\"scene_{i:04d}\"\n",
    "        \n",
    "        # Salvar imagem RGB\n",
    "        image_path = output_path / \"images\" / f\"{scene_id}.png\"\n",
    "        scene['image'].save(image_path)\n",
    "        \n",
    "        # Salvar m√°scara de segmenta√ß√£o\n",
    "        mask_path = output_path / \"masks\" / f\"{scene_id}_mask.png\"\n",
    "        mask_image = Image.fromarray(scene['segmentation_mask'].astype(np.uint8))\n",
    "        mask_image.save(mask_path)\n",
    "        \n",
    "        # Salvar m√°scara colorida para visualiza√ß√£o\n",
    "        mask_colored_path = output_path / \"masks\" / f\"{scene_id}_colored.png\"\n",
    "        mask_colored = cmap_grass(scene['segmentation_mask'] / (NUM_CLASSES - 1))\n",
    "        mask_colored_image = Image.fromarray((mask_colored * 255).astype(np.uint8))\n",
    "        mask_colored_image.save(mask_colored_path)\n",
    "        \n",
    "        # Metadata da cena\n",
    "        scene_metadata = {\n",
    "            'scene_id': scene_id,\n",
    "            'lai': float(scene['lai']),\n",
    "            'composition': scene['composition'],\n",
    "            'num_plants': len(scene['plant_positions']),\n",
    "            'plant_positions': scene['plant_positions'],\n",
    "            'image_path': str(image_path.name),\n",
    "            'mask_path': str(mask_path.name),\n",
    "            'colored_mask_path': str(mask_colored_path.name),\n",
    "            'metadata': scene['metadata']\n",
    "        }\n",
    "        \n",
    "        # Salvar metadata individual\n",
    "        metadata_path = output_path / \"metadata\" / f\"{scene_id}.json\"\n",
    "        with open(metadata_path, 'w') as f:\n",
    "            json.dump(scene_metadata, f, indent=2)\n",
    "        \n",
    "        exported_scenes.append(scene_metadata)\n",
    "        \n",
    "        if (i + 1) % 2 == 0:\n",
    "            print(f\"  ‚úÖ {i+1} cenas exportadas\")\n",
    "    \n",
    "    # Salvar informa√ß√µes gerais do dataset\n",
    "    dataset_info['scenes'] = exported_scenes\n",
    "    \n",
    "    with open(output_path / \"dataset_info.json\", 'w') as f:\n",
    "        json.dump(dataset_info, f, indent=2)\n",
    "    \n",
    "    # Criar arquivo README\n",
    "    readme_content = f\"\"\"# Brazilian GrassClover Dataset\n",
    "\n",
    "## Descri√ß√£o\n",
    "Dataset sint√©tico de gram√≠neas forrageiras brasileiras seguindo a metodologia do GrassClover Dataset.\n",
    "\n",
    "## Refer√™ncia\n",
    "Baseado em: Skovsen et al. \"The GrassClover Image Dataset for Semantic and Hierarchical Species Understanding in Agriculture\" (CVPR Workshops, 2019)\n",
    "\n",
    "## Estrutura\n",
    "- `images/`: Imagens RGB sint√©ticas ({len(dataset)} imagens)\n",
    "- `masks/`: M√°scaras de segmenta√ß√£o pixel-perfect\n",
    "- `metadata/`: Metadados detalhados de cada cena\n",
    "- `dataset_info.json`: Informa√ß√µes gerais do dataset\n",
    "\n",
    "## Classes\n",
    "{chr(10).join([f\"- {info['id']}: {info['name']} - {info['description']}\" for info in GRASS_CLOVER_CLASSES.values()])}\n",
    "\n",
    "## Par√¢metros\n",
    "- Resolu√ß√£o: {dataset[0]['image'].size if dataset else '512x512'}\n",
    "- Ground Sampling Distance: 4-8 px/mm\n",
    "- LAI Range: 1.0-3.5\n",
    "- Total de cenas: {len(dataset)}\n",
    "\n",
    "## Uso\n",
    "Este dataset pode ser usado para:\n",
    "- Treinamento de modelos de segmenta√ß√£o sem√¢ntica\n",
    "- An√°lise de composi√ß√£o de biomassa\n",
    "- Estudos de pastagens brasileiras\n",
    "- Desenvolvimento de algoritmos de agricultura de precis√£o\n",
    "\n",
    "Gerado em: {datetime.now().strftime('%d/%m/%Y %H:%M:%S')}\n",
    "\"\"\"\n",
    "    \n",
    "    with open(output_path / \"README.md\", 'w', encoding='utf-8') as f:\n",
    "        f.write(readme_content)\n",
    "    \n",
    "    print(f\"\\nüéâ Dataset exportado com sucesso para {output_path}!\")\n",
    "    print(f\"üìä Total: {len(dataset)} cenas com m√°scaras pixel-perfect\")\n",
    "    return output_path\n",
    "\n",
    "\n",
    "# Exportar dataset\n",
    "if synthetic_dataset:\n",
    "    dataset_path = export_grassclover_dataset(synthetic_dataset)\n",
    "    \n",
    "    # Mostrar estat√≠sticas finais\n",
    "    print(\"\\nüìà Estat√≠sticas Finais do Dataset:\")\n",
    "    \n",
    "    total_plants = sum(len(scene['plant_positions']) for scene in synthetic_dataset)\n",
    "    avg_lai = np.mean([scene['lai'] for scene in synthetic_dataset])\n",
    "    \n",
    "    print(f\"Total de imagens: {len(synthetic_dataset)}\")\n",
    "    print(f\"Total de plantas sint√©ticas: {total_plants}\")\n",
    "    print(f\"LAI m√©dio: {avg_lai:.2f}\")\n",
    "    \n",
    "    # An√°lise de composi√ß√£o final\n",
    "    all_compositions = []\n",
    "    for scene in synthetic_dataset:\n",
    "        for plant_type, proportion in scene['composition'].items():\n",
    "            all_compositions.append(plant_type)\n",
    "    \n",
    "    composition_counts = Counter(all_compositions)\n",
    "    print(\"\\nDistribui√ß√£o de tipos de pastagem:\")\n",
    "    for plant_type, count in composition_counts.most_common():\n",
    "        print(f\"  {GRASS_CLOVER_CLASSES[plant_type]['name']}: presente em {count} cenas\")\n",
    "    \n",
    "    print(f\"\\n‚úÖ Dataset Brazilian GrassClover pronto para uso!\")\n",
    "    print(f\"üìÅ Localiza√ß√£o: {dataset_path.absolute()}\")\n",
    "\n",
    "else:\n",
    "    print(\"‚ùå Nenhum dataset dispon√≠vel para exporta√ß√£o\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-21",
   "metadata": {},
   "source": [
    "## üìù Relat√≥rio Final e Conclus√µes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gerar relat√≥rio final seguindo padr√µes cient√≠ficos\n",
    "print(\"üìù RELAT√ìRIO FINAL - Brazilian GrassClover Dataset\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "if synthetic_dataset:\n",
    "    print(f\"\\nüåæ DATASET GERADO:\")\n",
    "    print(f\"Metodologia: Baseada em Skovsen et al. (CVPR 2019)\")\n",
    "    print(f\"Total de imagens sint√©ticas: {len(synthetic_dataset)}\")\n",
    "    print(f\"Resolu√ß√£o: {synthetic_dataset[0]['image'].size}\")\n",
    "    print(f\"Classes: {NUM_CLASSES} (solo, gram√≠neas brasileiras, leguminosas, ervas)\")\n",
    "    \n",
    "    total_plants = sum(len(scene['plant_positions']) for scene in synthetic_dataset)\n",
    "    avg_plants_per_scene = total_plants / len(synthetic_dataset)\n",
    "    avg_lai = np.mean([scene['lai'] for scene in synthetic_dataset])\n",
    "    \n",
    "    print(f\"\\nüìä ESTAT√çSTICAS:\")\n",
    "    print(f\"Total de plantas sint√©ticas: {total_plants}\")\n",
    "    print(f\"Plantas por cena (m√©dia): {avg_plants_per_scene:.1f}\")\n",
    "    print(f\"Leaf Area Index m√©dio: {avg_lai:.2f}\")\n",
    "    print(f\"Ground Sampling Distance: 4-8 px/mm\")\n",
    "    \n",
    "    # An√°lise de composi√ß√£o\n",
    "    class_distribution = Counter()\n",
    "    for scene in synthetic_dataset:\n",
    "        for plant in scene['plant_positions']:\n",
    "            class_distribution[plant['type']] += 1\n",
    "    \n",
    "    print(f\"\\nüå± DISTRIBUI√á√ÉO POR CLASSE:\")\n",
    "    for plant_type, count in class_distribution.most_common():\n",
    "        percentage = (count / total_plants) * 100\n",
    "        class_name = GRASS_CLOVER_CLASSES[plant_type]['name']\n",
    "        print(f\"  {class_name}: {count} plantas ({percentage:.1f}%)\")\n",
    "    \n",
    "    # Avalia√ß√£o simulada\n",
    "    if 'evaluation_results' in locals() and evaluation_results:\n",
    "        avg_miou = np.mean([r['miou'] for r in evaluation_results])\n",
    "        avg_pixel_acc = np.mean([r['pixel_accuracy'] for r in evaluation_results])\n",
    "        \n",
    "        print(f\"\\nüéØ M√âTRICAS DE AVALIA√á√ÉO (Simuladas):\")\n",
    "        print(f\"mIoU m√©dio: {avg_miou:.3f}\")\n",
    "        print(f\"Acur√°cia pixel m√©dia: {avg_pixel_acc:.3f}\")\n",
    "        print(f\"Compara√ß√£o: GrassClover original reportou mIoU=0.55\")\n",
    "\n",
    "print(f\"\\nüî¨ METODOLOGIA APLICADA:\")\n",
    "print(f\"‚úì Gera√ß√£o sint√©tica de plantas individuais\")\n",
    "print(f\"‚úì Composi√ß√£o sobre bases de solo realistas\")\n",
    "print(f\"‚úì Controle de Leaf Area Index (LAI)\")\n",
    "print(f\"‚úì M√°scaras de segmenta√ß√£o pixel-perfect\")\n",
    "print(f\"‚úì Varia√ß√µes de composi√ß√£o de esp√©cies\")\n",
    "print(f\"‚úì Simula√ß√£o de oclus√µes pesadas\")\n",
    "print(f\"‚úì Popula√ß√µes densas de gram√≠neas\")\n",
    "\n",
    "print(f\"\\nüåæ ADAPTA√á√ïES PARA PASTAGENS BRASILEIRAS:\")\n",
    "print(f\"‚úì Brachiaria spp. (brizantha, decumbens, humidicola)\")\n",
    "print(f\"‚úì Panicum spp. (momba√ßa, tanz√¢nia, massai)\")\n",
    "print(f\"‚úì Cynodon spp. (tifton, coast-cross)\")\n",
    "print(f\"‚úì Leguminosas fixadoras de nitrog√™nio\")\n",
    "print(f\"‚úì Ervas daninhas caracter√≠sticas\")\n",
    "\n",
    "print(f\"\\nüéØ APLICA√á√ïES POTENCIAIS:\")\n",
    "print(f\"‚Ä¢ Treinamento de modelos DeepLabV3+ para segmenta√ß√£o\")\n",
    "print(f\"‚Ä¢ An√°lise de composi√ß√£o de biomassa em pastagens\")\n",
    "print(f\"‚Ä¢ Monitoramento de qualidade de pastagens\")\n",
    "print(f\"‚Ä¢ Detec√ß√£o e quantifica√ß√£o de ervas daninhas\")\n",
    "print(f\"‚Ä¢ Agricultura de precis√£o para pecu√°ria\")\n",
    "print(f\"‚Ä¢ Estudos de biodiversidade em pastagens\")\n",
    "\n",
    "print(f\"\\nüìö REFER√äNCIAS E INSPIRA√á√ÉO:\")\n",
    "print(f\"[1] Skovsen et al. 'The GrassClover Image Dataset for Semantic\")\n",
    "print(f\"    and Hierarchical Species Understanding in Agriculture'\")\n",
    "print(f\"    IEEE/CVF CVPR Workshops, 2019\")\n",
    "print(f\"[2] Metodologia adaptada para gram√≠neas tropicais brasileiras\")\n",
    "print(f\"[3] Foco em esp√©cies forrageiras de import√¢ncia econ√¥mica\")\n",
    "\n",
    "print(f\"\\nüîÆ TRABALHOS FUTUROS:\")\n",
    "print(f\"‚Ä¢ Expans√£o para mais esp√©cies de gram√≠neas\")\n",
    "print(f\"‚Ä¢ Simula√ß√£o de condi√ß√µes clim√°ticas vari√°veis\")\n",
    "print(f\"‚Ä¢ Integra√ß√£o com dados de sensoriamento remoto\")\n",
    "print(f\"‚Ä¢ Valida√ß√£o com imagens reais de campo\")\n",
    "print(f\"‚Ä¢ Desenvolvimento de m√©tricas espec√≠ficas para pastagens\")\n",
    "\n",
    "print(f\"\\n‚ö° INFORMA√á√ïES T√âCNICAS:\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU utilizada: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Mem√≥ria GPU m√°xima: {torch.cuda.max_memory_allocated() / 1e9:.2f} GB\")\n",
    "print(f\"Framework: PyTorch {torch.__version__}\")\n",
    "print(f\"Modelo de gera√ß√£o: Stable Diffusion v1.5\")\n",
    "print(f\"Tempo de processamento: Vari√°vel por imagem\")\n",
    "\n",
    "print(f\"\\nüèÅ CONCLUS√ÉO:\")\n",
    "print(f\"Dataset sint√©tico brasileiro criado com sucesso seguindo a metodologia\")\n",
    "print(f\"consolidada do GrassClover. O dataset captura a diversidade das\")\n",
    "print(f\"gram√≠neas forrageiras brasileiras e pode servir como base s√≥lida\")\n",
    "print(f\"para desenvolvimento de sistemas de vis√£o computacional aplicados\")\n",
    "print(f\"√† agricultura e pecu√°ria sustent√°vel no Brasil.\")\n",
    "\n",
    "print(f\"\\n‚úÖ Notebook executado com sucesso!\")\n",
    "print(f\"üìÖ Data de conclus√£o: {datetime.now().strftime('%d/%m/%Y %H:%M:%S')}\")\n",
    "print(f\"\\nüåæüáßüá∑ Brazilian GrassClover Dataset - Ready for Agriculture! üáßüá∑üåæ\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}