{
 "cells":[
  {
   "cell_type":"markdown",
   "metadata":{},
   "source":[
    "# GrassClover-Style Generation with Stable Diffusion\n",
    "Este notebook implementa gera√ß√£o de imagens sint√©ticas de pastagens brasileiras usando **Stable Diffusion**, seguindo o estilo visual do **GrassClover Dataset** (Skovsen et al., CVPR 2019).\n",
    "## Objetivos:\n",
    "- Gerar imagens **top-down** de pastagens com Stable Diffusion\n",
    "- Adaptar para **gram√≠neas brasileiras** (Brachiaria, Panicum, Cynodon)\n",
    "- Seguir **metodologia GrassClover** (densidade, perspectiva, resolu√ß√£o)\n",
    "- **Ultra-compat√≠vel** com Google Colab (debugging extensivo)\n",
    "## Refer√™ncia:\n",
    "- **Paper**: Skovsen et al. \"The GrassClover Image Dataset for Semantic and Hierarchical Species Understanding in Agriculture\" (CVPR Workshops, 2019)\n",
    "- **Adapta√ß√£o**: Esp√©cies temperadas ‚Üí Tropicais brasileiras\n"
   ],
   "outputs":[],
   "execution_count":null
  },
  {
   "cell_type":"markdown",
   "metadata":{},
   "source":[
    "## Setup Ultra-Compat√≠vel para Colab\n",
    "**IMPORTANTE**: Este notebook foi desenvolvido para m√°xima compatibilidade com Google Colab Free/Pro."
   ],
   "outputs":[],
   "execution_count":null
  },
  {
   "cell_type":"code",
   "execution_count":null,
   "metadata":{},
   "outputs":[],
   "source":[
    "import sys\n",
    "import platform\n",
    "from datetime import datetime\n",
    "try:\n",
    "    import google.colab\n",
    "    in_colab = True\n",
    "except ImportError:\n",
    "    in_colab = False\n"
   ]
  },
  {
   "cell_type":"code",
   "execution_count":null,
   "metadata":{},
   "outputs":[],
   "source":[
    "device = None\n",
    "dev_type = \"unknown\"\n",
    "hw_info = {}\n",
    "# Tentar importar torch primeiro\n",
    "try:\n",
    "    import torch\n",
    "    torch_ok = True\n",
    "    hw_info['pytorch_version'] = torch.__version__\n",
    "except ImportError:\n",
    "    torch_ok = False\n",
    "if torch_ok:\n",
    "    try:\n",
    "        import torch_xla\n",
    "        import torch_xla.core.xla_model as xm\n",
    "        if xm.xrt_world_size() > 1:\n",
    "            device = xm.xla_device()\n",
    "            dev_type = \"tpu\"\n",
    "            hw_info.update({\n",
    "                'dev_type': 'tpu',\n",
    "                'tpu_cores': xm.xrt_world_size(),\n",
    "                'device': str(device)\n",
    "            })\n",
    "        else:\n",
    "    except ImportError:\n",
    "    except Exception as e:\n",
    "        print(\"‚ö†Ô∏è  Erro ao verificar TPU: {e}\")\n",
    "    if device is None:\n",
    "        cuda_available = torch.cuda.is_available()\n",
    "        if cuda_available:\n",
    "            gpu_count = torch.cuda.device_count()\n",
    "            for i in range(gpu_count):\n",
    "                gpu_name = torch.cuda.get_device_name(i)\n",
    "                gpu_memory = torch.cuda.get_device_properties(i).total_memory\n",
    "                gpu_memory_gb = gpu_memory / (1024**3)\n",
    "            device = torch.device(\"cuda\")\n",
    "            dev_type = \"gpu\"\n",
    "            hw_info.update({\n",
    "                'dev_type': 'gpu',\n",
    "                'gpu_count': gpu_count,\n",
    "                'gpu_name': torch.cuda.get_device_name(0),\n",
    "                'gpu_memory_gb': torch.cuda.get_device_properties(0).total_memory / (1024**3),\n",
    "                'device': str(device)\n",
    "            })\n",
    "            torch.cuda.empty_cache()\n",
    "        else:\n",
    "    if device is None:\n",
    "        device = torch.device(\"cpu\")\n",
    "        dev_type = \"cpu\"\n",
    "        hw_info.update({\n",
    "            'dev_type': 'cpu',\n",
    "            'device': str(device)\n",
    "        })\n",
    "    if dev_type == \"cpu\" and in_colab:\n",
    "    elif dev_type == \"tpu\":\n",
    "    elif dev_type == \"gpu\":\n",
    "else:\n",
    "    device = None\n",
    "    dev_type = \"none\"\n"
   ]
  },
  {
   "cell_type":"code",
   "source":"# üîê AUTENTICA√á√ÉO HUGGINGFACE \nprint(\"üîê Configurando autentica√ß√£o HuggingFace...\\n\")\n\ntry:\n    from huggingface_hub import notebook_login\n    \n    print(\"üìã Para usar Stable Diffusion 3.5 Large, voc√™ precisa fazer login no HuggingFace\")\n    print(\"üí° Aceite os termos em: https://huggingface.co/stabilityai/stable-diffusion-3.5-large\")\n    print(\"‚è≥ Executando login...\")\n    \n    # Login interativo no notebook\n    notebook_login()\n    \n    print(\"‚úÖ Login realizado com sucesso!\")\n    HUGGINGFACE_LOGGED_IN = True\n    \nexcept Exception as e:\n    print(f\"‚ö†Ô∏è  Erro no login: {e}\")\n    print(\"üîÑ Continuando sem autentica√ß√£o (fallback para SD1.5)\")\n    HUGGINGFACE_LOGGED_IN = False\n\nprint(\"=\" * 60)",
   "metadata":{},
   "execution_count":null,
   "outputs":[]
  },
  {
   "cell_type":"code",
   "source":[
    "# üöÄ STABLE DIFFUSION 3.5 LARGE - CONFIGURA√á√ÉO CORRIGIDA\n",
    "def load_stable_diffusion_pipeline_advanced():\n",
    "    \"\"\"\n",
    "    Carrega SD3.5 Large com fallback autom√°tico e tratamento de erros robusto\n",
    "    \"\"\"\n",
    "    if not HUGGINGFACE_LOGGED_IN:\n",
    "    try:\n",
    "        # Imports espec√≠ficos para SD3.5\n",
    "        from diffusers import StableDiffusion3Pipeline\n",
    "        import torch\n",
    "        # Configura√ß√µes mais conservadoras para SD3.5\n",
    "        load_kwargs = {\n",
    "            \"torch_dtype\": torch.bfloat16 if torch.cuda.is_available() else torch.float32,\n",
    "            \"device_map\": \"auto\" if torch.cuda.is_available() else None,\n",
    "            \"low_cpu_mem_usage\": True,\n",
    "        }\n",
    "        pipe = StableDiffusion3Pipeline.from_pretrained(\n",
    "            \"stabilityai/stable-diffusion-3.5-large\", \n",
    "            **load_kwargs\n",
    "        )\n",
    "        if not torch.cuda.is_available() or load_kwargs.get(\"device_map\") is None:\n",
    "            pipe = pipe.to(device)\n",
    "        return pipe, \"3.5\"\n",
    "    except ImportError as e:\n",
    "        print(\"‚ùå Erro de import SD3.5: {e}\")\n",
    "    except Exception as e:\n",
    "        print(\"üîç Tipo do erro: {type(e).__name__}\")\n",
    "        if \"get() takes 1 positional argument\" in str(e):\n",
    "            print(\"üí° Erro de compatibilidade - tentando par√¢metros alternativos...\")\n",
    "            try:\n",
    "                simple_kwargs = {\n",
    "                    \"torch_dtype\": torch.bfloat16 if torch.cuda.is_available() else torch.float32,\n",
    "                }\n",
    "                pipe = StableDiffusion3Pipeline.from_pretrained(\n",
    "                    \"stabilityai/stable-diffusion-3.5-large\", \n",
    "                    **simple_kwargs\n",
    "                )\n",
    "                pipe = pipe.to(device)\n",
    "                return pipe, \"3.5\"\n",
    "            except Exception as e2:\n",
    "        elif \"requires you to be logged in\" in str(e) or \"authentication\" in str(e):\n",
    "            print(\"üîê Erro de autentica√ß√£o - verifique seu login no HuggingFace\")\n",
    "        elif \"out of memory\" in str(e).lower() or \"oom\" in str(e).lower():\n",
    "            print(\"üíæ Erro de mem√≥ria - SD3.5 requer muita VRAM\")\n",
    "    try:\n",
    "        from diffusers import StableDiffusionPipeline\n",
    "        fallback_kwargs = {\n",
    "            \"torch_dtype\": TORCH_DTYPE,\n",
    "            \"low_cpu_mem_usage\": True,\n",
    "            \"use_safetensors\": True,\n",
    "        }\n",
    "        pipe = StableDiffusionPipeline.from_pretrained(\n",
    "            \"runwayml/stable-diffusion-v1-5\", \n",
    "            **fallback_kwargs\n",
    "        )\n",
    "        pipe = pipe.to(device)\n",
    "        return pipe, \"1.5\"\n",
    "    except Exception as e2:\n",
    "        return None, None\n",
    "# Carregar pipeline com fun√ß√£o corrigida\n",
    "pipe, sd_version = load_stable_diffusion_pipeline_advanced()\n",
    "if pipe is not None:\n",
    "    # Configurar scheduler se necess√°rio\n",
    "    try:\n",
    "        if sd_version == \"1.5\":\n",
    "            from diffusers import DPMSolverMultistepScheduler\n",
    "            pipe.scheduler = DPMSolverMultistepScheduler.from_config(pipe.scheduler.config)\n",
    "        else:\n",
    "    except Exception as e:\n",
    "    if sd_version == \"3.5\":\n",
    "        GENERATION_PARAMS_CURRENT = {\n",
    "            'width': 512,\n",
    "            'height': 512,\n",
    "            'num_inference_steps': 28,\n",
    "            'guidance_scale': 4.0,\n",
    "            'num_images_per_prompt': 1,\n",
    "            'eta': 0.0,\n",
    "            'generator_seed': 42\n",
    "        }\n",
    "    else:  # SD1.5\n",
    "        GENERATION_PARAMS_CURRENT = {\n",
    "            'width': 512,\n",
    "            'height': 512,\n",
    "            'num_inference_steps': 25,\n",
    "            'guidance_scale': 7.5,\n",
    "            'num_images_per_prompt': 1,\n",
    "            'eta': 0.0,\n",
    "            'generator_seed': 42\n",
    "        }\n",
    "    try:\n",
    "        if hasattr(pipe, 'enable_attention_slicing'):\n",
    "            pipe.enable_attention_slicing()\n",
    "        if hasattr(pipe, 'enable_memory_efficient_attention') and device.type == \"cuda\":\n",
    "            pipe.enable_memory_efficient_attention()  \n",
    "    except Exception as e:\n",
    "    PIPELINE_READY = True\n",
    "else:\n",
    "    PIPELINE_READY = False\n"
   ],
   "metadata":{},
   "execution_count":null,
   "outputs":[]
  },
  {
   "cell_type":"code",
   "execution_count":null,
   "metadata":{},
   "outputs":[],
   "source":[
    "essential_packages = [\n",
    "    \"torch\",\n",
    "    \"torchvision\", \n",
    "    \"diffusers\",\n",
    "    \"transformers\",\n",
    "    \"accelerate\",\n",
    "    \"pillow\",\n",
    "    \"matplotlib\",\n",
    "    \"numpy\"\n",
    "]\n",
    "def install_package(package_name, quiet=True):\n",
    "    \"\"\"Instala pacote com debugging\"\"\"\n",
    "    import subprocess\n",
    "    try:\n",
    "        cmd = [\"pip\", \"install\", package_name]\n",
    "        if quiet:\n",
    "            cmd.append(\"--quiet\")\n",
    "        result = subprocess.run(cmd, capture_output=True, text=True, timeout=300)\n",
    "        if result.returncode == 0:\n",
    "            return True\n",
    "        else:\n",
    "            print(\"‚ùå Erro ao instalar {package_name}:\")\n",
    "            return False\n",
    "    except subprocess.TimeoutExpired:\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        return False\n",
    "for package in essential_packages:\n",
    "    try:\n",
    "        __import__(package.replace(\"-\", \"_\"))\n",
    "    except ImportError:\n",
    "        success = install_package(package)\n",
    "        if not success:\n",
    "            break\n"
   ]
  },
  {
   "cell_type":"code",
   "execution_count":null,
   "metadata":{},
   "outputs":[],
   "source":[
    "# üîÑ REIMPORTA√á√ÉO E VERIFICA√á√ÉO FINAL COM CONFIGURA√á√ïES OTIMIZADAS\n",
    "# Imports essenciais com debugging\n",
    "try:\n",
    "    import torch\n",
    "    import torchvision.transforms as transforms\n",
    "    # Reconfigurar device ap√≥s instala√ß√£o se necess√°rio\n",
    "    if not 'device' in locals() or device is None:\n",
    "        if torch.cuda.is_available():\n",
    "            device = torch.device(\"cuda\")\n",
    "            dev_type = \"gpu\"\n",
    "            gpu_name = torch.cuda.get_device_name(0)\n",
    "            gpu_memory = torch.cuda.get_device_properties(0).total_memory / (1024**3)\n",
    "            # Configura√ß√£o otimizada para GPU\n",
    "            torch.backends.cudnn.benchmark = True\n",
    "            torch.cuda.empty_cache()\n",
    "        else:\n",
    "            device = torch.device(\"cpu\")\n",
    "            dev_type = \"cpu\"\n",
    "    # Configurar dtype baseado no hardware\n",
    "    if dev_type == \"gpu\":\n",
    "        TORCH_DTYPE = torch.bfloat16  # GPU: usar half precision\n",
    "    elif dev_type == \"tpu\":\n",
    "        TORCH_DTYPE = torch.float32  # TPU: full precision recomendado\n",
    "    else:\n",
    "        TORCH_DTYPE = torch.float32  # CPU: full precision\n",
    "except ImportError as e:\n",
    "    print(\"‚ùå Erro PyTorch: {e}\")\n",
    "    device = None\n",
    "    dev_type = \"none\"\n",
    "    TORCH_DTYPE = None\n",
    "try:\n",
    "    from diffusers import StableDiffusion3Pipeline, DPMSolverMultistepScheduler\n",
    "    diffusers_ok = True\n",
    "except ImportError as e:\n",
    "    print(\"‚ùå Erro Diffusers: {e}\")\n",
    "    diffusers_ok = False\n",
    "try:\n",
    "    from PIL import Image, ImageEnhance, ImageFilter\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    libs_ok = True\n",
    "except ImportError as e:\n",
    "    print(\"‚ùå Erro bibliotecas b√°sicas: {e}\")\n",
    "    libs_ok = False\n",
    "# Configura√ß√£o de ambiente Hugging Face\n",
    "try:\n",
    "    import os\n",
    "    os.environ[\"DISABLE_TELEMETRY\"] = \"1\"\n",
    "    os.environ[\"HF_HUB_DISABLE_TELEMETRY\"] = \"1\"\n",
    "    # Configurar cache offline se necess√°rio\n",
    "    if in_colab:\n",
    "        os.environ[\"TRANSFORMERS_OFFLINE\"] = \"0\"  # Permitir downloads no Colab\n",
    "        os.environ[\"HF_HUB_OFFLINE\"] = \"0\"\n",
    "except Exception as e:\n",
    "    print(\"‚ö†Ô∏è  Aviso na configura√ß√£o HF: {e}\")\n",
    "ALL_READY = device is not None and diffusers_ok and libs_ok\n",
    "if ALL_READY:\n",
    "else:\n",
    "    if dev_type == \"cpu\" and in_colab:\n"
   ]
  },
  {
   "cell_type":"markdown",
   "metadata":{},
   "source":[
    "## Pipeline Stable Diffusion para GrassClover\n",
    "Configura√ß√£o do pipeline otimizado para gera√ß√£o de pastagens no estilo GrassClover."
   ],
   "outputs":[],
   "execution_count":null
  },
  {
   "cell_type":"markdown",
   "metadata":{},
   "source":[
    "# CONFIGURA√á√ÉO AVAN√áADA DO PIPELINE STABLE DIFFUSION\n",
    "print(\"üé® Configurando Stable Diffusion Pipeline...\\n\")\n",
    "# Par√¢metros do pipeline baseados no hardware detectado\n",
    "MODEL_ID = \"runwayml/stable-diffusion-v1-5\"  # Modelo base confi√°vel\n",
    "LOW_CPU_MEM_USAGE = True\n",
    "ENABLE_ATTENTION_SLICING = True\n",
    "# Configura√ß√µes espec√≠ficas por hardware\n",
    "if device_type == \"gpu\":\n",
    "    ENABLE_MODEL_CPU_OFFLOAD = False\n",
    "    ENABLE_SEQUENTIAL_CPU_OFFLOAD = False\n",
    "    USE_TORCH_COMPILE = True\n",
    "elif device_type == \"tpu\":\n",
    "    ENABLE_MODEL_CPU_OFFLOAD = True\n",
    "    ENABLE_SEQUENTIAL_CPU_OFFLOAD = False\n",
    "    USE_TORCH_COMPILE = False  # TPU pode ter problemas com compile\n",
    "else:  # CPU\n",
    "    ENABLE_MODEL_CPU_OFFLOAD = True\n",
    "    ENABLE_SEQUENTIAL_CPU_OFFLOAD = True\n",
    "    USE_TORCH_COMPILE = False\n",
    "print(f\"üì¶ Modelo: {MODEL_ID}\")\n",
    "print(f\"üî¢ Dtype: {TORCH_DTYPE}\")\n",
    "print(f\"üíæ Low CPU mem: {LOW_CPU_MEM_USAGE}\")\n",
    "print(f\"‚ö° Attention slicing: {ENABLE_ATTENTION_SLICING}\")\n",
    "print(f\"üèÉ Model CPU offload: {ENABLE_MODEL_CPU_OFFLOAD}\")\n",
    "print(f\"üî• Hardware: {device_type.upper()}\")\n",
    "# Fun√ß√£o para carregar pipeline com debugging e bypass de autentica√ß√£o\n",
    "def load_stable_diffusion_pipeline():\n",
    "    \"\"\"Carrega pipeline com m√°ximo debugging e configura√ß√µes otimizadas\"\"\"\n",
    "    try:\n",
    "        print(\"‚è≥ Carregando modelo...\")\n",
    "        # Configura√ß√µes para bypass de problemas de autentica√ß√£o\n",
    "        load_kwargs = {\n",
    "            \"torch_dtype\": TORCH_DTYPE,\n",
    "            \"low_cpu_mem_usage\": LOW_CPU_MEM_USAGE,\n",
    "            \"use_safetensors\": True,\n",
    "        }\n",
    "        # Configura√ß√µes espec√≠ficas para resolver problemas HF\n",
    "        try:\n",
    "            # Tentar com autentica√ß√£o padr√£o primeiro\n",
    "            pipe = StableDiffusionPipeline.from_pretrained(MODEL_ID, **load_kwargs)\n",
    "            print(\"‚úÖ Modelo carregado com autentica√ß√£o padr√£o\")\n",
    "        except Exception as auth_error:\n",
    "            print(f\"‚ö†Ô∏è  Problema de autentica√ß√£o: {str(auth_error)[:100]}...\")\n",
    "            print(\"üîÑ Tentando download for√ßado...\")\n",
    "            # Bypass de problemas de autentica√ß√£o\n",
    "            load_kwargs[\"use_auth_token\"] = False\n",
    "            load_kwargs[\"force_download\"] = False\n",
    "            load_kwargs[\"resume_download\"] = True\n",
    "            pipe = StableDiffusionPipeline.from_pretrained(MODEL_ID, **load_kwargs)\n",
    "            print(\"‚úÖ Modelo carregado com bypass de autentica√ß√£o\")\n",
    "        # Mover para device\n",
    "        pipe = pipe.to(device)\n",
    "        print(f\"üöÄ Pipeline movido para {device}\")\n",
    "        # Otimiza√ß√µes baseadas no hardware\n",
    "        if ENABLE_ATTENTION_SLICING:\n",
    "            pipe.enable_attention_slicing()\n",
    "            print(\"‚ö° Attention slicing habilitado\")\n",
    "        if ENABLE_MODEL_CPU_OFFLOAD and device_type != \"cpu\":\n",
    "            try:\n",
    "                pipe.enable_model_cpu_offload()\n",
    "                print(\"üíæ Model CPU offload habilitado\")\n",
    "            except Exception as e:\n",
    "                print(f\"‚ö†Ô∏è  CPU offload falhou: {e}\")\n",
    "        if ENABLE_SEQUENTIAL_CPU_OFFLOAD and device_type == \"cpu\":\n",
    "            try:\n",
    "                pipe.enable_sequential_cpu_offload()\n",
    "                print(\"üîÑ Sequential CPU offload habilitado\")\n",
    "            except Exception as e:\n",
    "                print(f\"‚ö†Ô∏è  Sequential offload falhou: {e}\")\n",
    "        # Scheduler otimizado\n",
    "        pipe.scheduler = DPMSolverMultistepScheduler.from_config(pipe.scheduler.config)\n",
    "        print(\"üîß Scheduler otimizado (DPMSolver)\")\n",
    "        # Configura√ß√µes de mem√≥ria espec√≠ficas\n",
    "        if device_type == \"gpu\":\n",
    "            torch.cuda.empty_cache()\n",
    "            allocated = torch.cuda.memory_allocated() / (1024**3)\n",
    "            cached = torch.cuda.memory_reserved() / (1024**3)\n",
    "            print(f\"üíæ GPU Memory - Allocated: {allocated:.2f}GB, Cached: {cached:.2f}GB\")\n",
    "            # Verificar se h√° mem√≥ria suficiente\n",
    "            if allocated > 10.0:  # >10GB pode causar problemas\n",
    "                print(f\"‚ö†Ô∏è  Alta utiliza√ß√£o de mem√≥ria GPU!\")\n",
    "        elif device_type == \"tpu\":\n",
    "            print(\"üî• TPU configurado - mem√≥ria gerenciada automaticamente\")\n",
    "        else:  # CPU\n",
    "            print(\"üíª CPU mode - sem monitoramento de GPU memory\")\n",
    "        print(\"\\n‚úÖ Pipeline configurado com sucesso!\")\n",
    "        return pipe\n",
    "    except Exception as e:\n",
    "        print(f\"üí• ERRO ao carregar pipeline: {e}\")\n",
    "        print(f\"\\nüìã DEBUG COPY/PASTE:\")\n",
    "        print(f\"Model: {MODEL_ID}\")\n",
    "        print(f\"Device: {device} ({device_type})\")\n",
    "        print(f\"Dtype: {TORCH_DTYPE}\")\n",
    "        print(f\"Hardware info: {hardware_info if 'hardware_info' in locals() else 'N/A'}\")\n",
    "        print(f\"Error type: {type(e).__name__}\")\n",
    "        print(f\"Error message: {e}\")\n",
    "        # Sugest√µes baseadas no tipo de erro\n",
    "        error_str = str(e).lower()\n",
    "        if \"authentication\" in error_str or \"token\" in error_str:\n",
    "            print(f\"\\nüí° SOLU√á√ÉO PARA ERRO DE TOKEN:\")\n",
    "            print(f\"1. Ignore o warning - o modelo deve funcionar mesmo assim\")\n",
    "            print(f\"2. Ou configure HF_TOKEN manualmente se necess√°rio\")\n",
    "        elif \"memory\" in error_str or \"cuda\" in error_str:\n",
    "            print(f\"\\nüí° SOLU√á√ÉO PARA ERRO DE MEM√ìRIA:\")\n",
    "            print(f\"1. Reduzir batch_size\")\n",
    "            print(f\"2. Usar torch.float16 se estiver usando float32\")\n",
    "            print(f\"3. Fechar outros notebooks no Colab\")\n",
    "        elif \"module\" in error_str or \"import\" in error_str:\n",
    "            print(f\"\\nüí° SOLU√á√ÉO PARA ERRO DE M√ìDULO:\")\n",
    "            print(f\"1. Re-executar c√©lulas de instala√ß√£o\")\n",
    "            print(f\"2. Restart runtime se necess√°rio\")\n",
    "        return None\n",
    "# Carregar pipeline\n",
    "if ALL_READY:\n",
    "    pipe = load_stable_diffusion_pipeline()\n",
    "    PIPELINE_READY = pipe is not None\n",
    "else:\n",
    "    pipe = None\n",
    "    PIPELINE_READY = False\n",
    "    print(\"‚ùå Sistema n√£o est√° pronto para carregar pipeline\")\n",
    "print(\"=\" * 60)"
   ],
   "outputs":[],
   "execution_count":null
  },
  {
   "cell_type":"code",
   "execution_count":null,
   "metadata":{},
   "outputs":[],
   "source":[
    "# üé® CONFIGURA√á√ÉO AVAN√áADA DO PIPELINE STABLE DIFFUSION\n",
    "# Par√¢metros do pipeline baseados no hardware detectado\n",
    "MODEL_ID = \"stabilityai/stable-diffusion-3.5-large\"  # Modelo SD 3.5 Large - Estado da Arte\n",
    "low_mem = True\n",
    "attn_slice = True\n",
    "# Configura√ß√µes espec√≠ficas por hardware\n",
    "if dev_type == \"gpu\":\n",
    "    cpu_offload = False\n",
    "    seq_offload = False\n",
    "    use_compile = True\n",
    "elif dev_type == \"tpu\":\n",
    "    cpu_offload = True\n",
    "    seq_offload = False\n",
    "    use_compile = False  # TPU pode ter problemas com compile\n",
    "else:  # CPU\n",
    "    cpu_offload = True\n",
    "    seq_offload = True\n",
    "    use_compile = False\n",
    "# Fun√ß√£o para carregar pipeline com debugging e bypass de autentica√ß√£o\n",
    "def load_stable_diffusion_pipeline():\n",
    "    # \"\"\"Carrega pipeline com m√°ximo debugging e configura√ß√µes otimizadas\"\"\"\n",
    "    try:\n",
    "        # Configura√ß√µes para bypass de problemas de autentica√ß√£o\n",
    "        load_kwargs = {\n",
    "            \"torch_dtype\": TORCH_DTYPE,\n",
    "            \"low_cpu_mem_usage\": low_mem,\n",
    "            \"use_safetensors\": True,\n",
    "        }\n",
    "        # Configura√ß√µes espec√≠ficas para resolver problemas HF\n",
    "        try:\n",
    "            pipe = StableDiffusion3Pipeline.from_pretrained(MODEL_ID, **load_kwargs)\n",
    "        except Exception as auth_error:\n",
    "            print(\"‚ö†Ô∏è  Problema de autentica√ß√£o: {str(auth_error)[:100]}...\")\n",
    "            load_kwargs[\"use_auth_token\"] = False\n",
    "            load_kwargs[\"force_download\"] = False\n",
    "            load_kwargs[\"resume_download\"] = True\n",
    "            pipe = StableDiffusion3Pipeline.from_pretrained(MODEL_ID, **load_kwargs)\n",
    "        pipe = pipe.to(device)\n",
    "        if attn_slice:\n",
    "            pipe.enable_attention_slicing()\n",
    "        if cpu_offload and dev_type != \"cpu\":\n",
    "            try:\n",
    "                pipe.enable_model_cpu_offload()\n",
    "            except Exception as e:\n",
    "        if seq_offload and dev_type == \"cpu\":\n",
    "            try:\n",
    "                pipe.enable_sequential_cpu_offload()\n",
    "            except Exception as e:\n",
    "        pipe.scheduler = DPMSolverMultistepScheduler.from_config(pipe.scheduler.config)\n",
    "        # Configura√ß√µes de mem√≥ria espec√≠ficas\n",
    "        if dev_type == \"gpu\":\n",
    "            torch.cuda.empty_cache()\n",
    "            allocated = torch.cuda.memory_allocated() / (1024**3)\n",
    "            cached = torch.cuda.memory_reserved() / (1024**3)\n",
    "            if allocated > 10.0:  # >10GB pode causar problemas\n",
    "        elif dev_type == \"tpu\":\n",
    "        else:  # CPU\n",
    "        return pipe\n",
    "    except Exception as e:\n",
    "        print(\"üí• ERRO ao carregar pipeline: {e}\")\n",
    "        print(\"Error type: {type(e).__name__}\")\n",
    "        print(\"Error message: {e}\")\n",
    "        error_str = str(e).lower()\n",
    "        if \"authentication\" in error_str or \"token\" in error_str:\n",
    "            print(\"\\\\nüí° SOLU√á√ÉO PARA ERRO DE TOKEN:\")\n",
    "            print(\"1. Ignore o warning - o modelo deve funcionar mesmo assim\")\n",
    "        elif \"memory\" in error_str or \"cuda\" in error_str:\n",
    "            print(\"\\\\nüí° SOLU√á√ÉO PARA ERRO DE MEM√ìRIA:\")\n",
    "        elif \"module\" in error_str or \"import\" in error_str:\n",
    "            print(\"\\\\nüí° SOLU√á√ÉO PARA ERRO DE M√ìDULO:\")\n",
    "        return None\n",
    "# Carregar pipeline\n",
    "if ALL_READY:\n",
    "    pipe = load_stable_diffusion_pipeline()\n",
    "    PIPELINE_READY = pipe is not None\n",
    "else:\n",
    "    pipe = None\n",
    "    PIPELINE_READY = False\n"
   ]
  },
  {
   "cell_type":"code",
   "execution_count":null,
   "metadata":{},
   "outputs":[],
   "source":"# üìö DOWNLOAD DO DATASET GRASSCLOVER ORIGINAL\nprint(\"üìö Baixando dataset GrassClover original do Kaggle...\\n\")\n\n# Inicializar vari√°vel globalmente\nGRASSCLOVER_DATASET_PATH = None\n\ntry:\n    # Instalar kagglehub se necess√°rio\n    try:\n        import kagglehub\n        print(\"‚úÖ kagglehub j√° dispon√≠vel\")\n    except ImportError:\n        print(\"üì¶ Instalando kagglehub...\")\n        import subprocess\n        result = subprocess.run([\"pip\", \"install\", \"kagglehub\", \"--quiet\"], \n                              capture_output=True, text=True)\n        if result.returncode == 0:\n            import kagglehub\n            print(\"‚úÖ kagglehub instalado com sucesso\")\n        else:\n            print(f\"‚ùå Erro ao instalar kagglehub: {result.stderr}\")\n            raise ImportError(\"kagglehub installation failed\")\n    \n    # Download do dataset\n    print(\"‚è≥ Fazendo download do GrassClover dataset...\")\n    print(\"üí° Isso pode demorar alguns minutos na primeira vez...\")\n    \n    dataset_path = kagglehub.dataset_download(\"usharengaraju/grassclover-dataset\")\n    \n    if dataset_path and os.path.exists(dataset_path):\n        GRASSCLOVER_DATASET_PATH = dataset_path\n        print(f\"‚úÖ Dataset baixado com sucesso!\")\n        print(f\"üìÅ Localiza√ß√£o: {dataset_path}\")\n        \n        # Explorar estrutura do dataset\n        print(f\"\\nüìã Estrutura do dataset:\")\n        \n        total_files = 0\n        for root, dirs, files in os.walk(dataset_path):\n            level = root.replace(dataset_path, '').count(os.sep)\n            indent = '  ' * level\n            folder_name = os.path.basename(root) if root != dataset_path else 'grassclover-dataset'\n            \n            # Contar apenas arquivos de imagem\n            image_files = [f for f in files if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n            \n            if image_files:\n                print(f\"{indent}{folder_name}/ ({len(image_files)} imagens)\")\n                total_files += len(image_files)\n                \n                # Mostrar alguns exemplos de nomes\n                for file in image_files[:3]:\n                    print(f\"{indent}  ‚Ä¢ {file}\")\n                if len(image_files) > 3:\n                    print(f\"{indent}  ‚Ä¢ ... e mais {len(image_files)-3} imagens\")\n            elif dirs:\n                print(f\"{indent}{folder_name}/\")\n        \n        print(f\"\\nüìä Total: {total_files} imagens encontradas\")\n        \n        if total_files == 0:\n            print(\"‚ö†Ô∏è  Nenhuma imagem encontrada no dataset baixado\")\n            GRASSCLOVER_DATASET_PATH = None\n    else:\n        print(\"‚ùå Download retornou path inv√°lido\")\n        GRASSCLOVER_DATASET_PATH = None\n    \nexcept Exception as e:\n    print(f\"‚ùå Erro ao baixar dataset: {e}\")\n    print(f\"\\nüìã DEBUG INFO:\")\n    print(f\"Error type: {type(e).__name__}\")\n    print(f\"Error message: {str(e)[:200]}...\")\n    \n    # Manter vari√°vel definida como None\n    GRASSCLOVER_DATASET_PATH = None\n    \n    print(f\"\\nüí° SOLU√á√ïES POSS√çVEIS:\")\n    print(f\"1. Verificar conectividade com internet\")\n    print(f\"2. Tentar novamente em alguns minutos\")\n    print(f\"3. Verificar se Kaggle est√° acess√≠vel\")\n    print(f\"4. OPCIONAL: Upload manual de imagens GrassClover\")\n\n# Status final\nif GRASSCLOVER_DATASET_PATH:\n    print(f\"\\n‚úÖ Dataset GrassClover dispon√≠vel para an√°lise!\")\nelse:\n    print(f\"\\n‚ö†Ô∏è  Continuando sem dataset GrassClover\")\n    print(f\"üéØ O notebook ainda funcionar√°, mas sem calibra√ß√£o visual\")\n\nprint(\"=\" * 60)"
  },
  {
   "cell_type":"code",
   "execution_count":null,
   "metadata":{},
   "outputs":[],
   "source":"# üîç AN√ÅLISE VISUAL DO DATASET GRASSCLOVER ORIGINAL\nprint(\"üîç Analisando caracter√≠sticas visuais do GrassClover...\\n\")\n\ndef analyze_grassclover_images(dataset_path, num_samples=6):\n    \"\"\"\n    Analisa imagens do GrassClover para extrair caracter√≠sticas visuais\n    \"\"\"\n    if not dataset_path or not os.path.exists(dataset_path):\n        print(\"‚ùå Dataset n√£o dispon√≠vel para an√°lise\")\n        return None\n    \n    try:\n        # Encontrar arquivos de imagem\n        image_files = []\n        for root, dirs, files in os.walk(dataset_path):\n            for file in files:\n                if file.lower().endswith(('.png', '.jpg', '.jpeg')):\n                    image_files.append(os.path.join(root, file))\n        \n        if not image_files:\n            print(\"‚ùå Nenhuma imagem encontrada no dataset\")\n            return None\n        \n        print(f\"üì∏ Encontradas {len(image_files)} imagens\")\n        print(f\"üéØ Analisando {min(num_samples, len(image_files))} amostras...\")\n        \n        # Selecionar amostras aleat√≥rias\n        import random\n        random.seed(42)  # Reprodutibilidade\n        sample_files = random.sample(image_files, min(num_samples, len(image_files)))\n        \n        # An√°lise visual\n        fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n        fig.suptitle('üìö GrassClover Dataset - An√°lise Visual de Refer√™ncia', \n                    fontsize=16, fontweight='bold')\n        \n        axes = axes.flatten()\n        image_stats = []\n        \n        for i, img_path in enumerate(sample_files):\n            try:\n                # Carregar imagem\n                img = Image.open(img_path)\n                img_array = np.array(img)\n                \n                # Estat√≠sticas da imagem\n                stats = {\n                    'filename': os.path.basename(img_path),\n                    'size': img.size,\n                    'mode': img.mode,\n                    'mean_rgb': np.mean(img_array, axis=(0, 1)) if len(img_array.shape) == 3 else np.mean(img_array),\n                    'std_rgb': np.std(img_array, axis=(0, 1)) if len(img_array.shape) == 3 else np.std(img_array)\n                }\n                image_stats.append(stats)\n                \n                # Exibir imagem\n                axes[i].imshow(img)\n                axes[i].set_title(f\"{stats['filename']}\\n{stats['size'][0]}x{stats['size'][1]}\", \n                                fontsize=10)\n                axes[i].axis('off')\n                \n            except Exception as e:\n                print(f\"‚ö†Ô∏è  Erro ao carregar {img_path}: {e}\")\n                axes[i].text(0.5, 0.5, 'Erro\\nao carregar', \n                           ha='center', va='center', transform=axes[i].transAxes)\n                axes[i].axis('off')\n        \n        # Ocultar eixos n√£o usados\n        for j in range(len(sample_files), len(axes)):\n            axes[j].axis('off')\n        \n        plt.tight_layout()\n        plt.show()\n        \n        # Estat√≠sticas gerais\n        if image_stats:\n            print(f\"\\nüìä CARACTER√çSTICAS VISUAIS IDENTIFICADAS:\")\n            \n            # Tamanhos das imagens\n            sizes = [stat['size'] for stat in image_stats]\n            unique_sizes = list(set(sizes))\n            print(f\"üìè Resolu√ß√µes encontradas: {unique_sizes}\")\n            \n            # Cores m√©dias (se RGB)\n            rgb_images = [stat for stat in image_stats if len(stat['mean_rgb']) == 3]\n            if rgb_images:\n                avg_colors = np.mean([stat['mean_rgb'] for stat in rgb_images], axis=0)\n                print(f\"üé® Cores m√©dias (RGB): R={avg_colors[0]:.1f}, G={avg_colors[1]:.1f}, B={avg_colors[2]:.1f}\")\n                \n                # An√°lise de tons de verde\n                green_dominance = avg_colors[1] / (avg_colors[0] + avg_colors[2] + 0.1)\n                print(f\"üåø Domin√¢ncia verde: {green_dominance:.2f} (quanto maior, mais verde)\")\n            \n            print(f\"\\nüí° INSIGHTS PARA STABLE DIFFUSION:\")\n            print(f\"‚Ä¢ Vista: Top-down (a√©rea) consistente\")\n            print(f\"‚Ä¢ Textura: Densa cobertura de gram√≠neas pequenas\")\n            print(f\"‚Ä¢ Cores: Tons de verde predominantes\")\n            print(f\"‚Ä¢ Ilumina√ß√£o: Natural, sem sombras fortes\")\n            print(f\"‚Ä¢ Composi√ß√£o: Mistura grass + clover (ryegrass + trevo)\")\n            print(f\"‚Ä¢ Resolu√ß√£o t√≠pica: ~512x512 ou similar\")\n            \n        return {\n            'sample_files': sample_files,\n            'image_stats': image_stats,\n            'total_images': len(image_files)\n        }\n        \n    except Exception as e:\n        print(f\"‚ùå Erro na an√°lise: {e}\")\n        return None\n\n# Verificar se dataset path existe, sen√£o definir como None\nif 'GRASSCLOVER_DATASET_PATH' not in locals():\n    print(\"‚ö†Ô∏è  GRASSCLOVER_DATASET_PATH n√£o definido - provavelmente erro no download\")\n    GRASSCLOVER_DATASET_PATH = None\n\n# Executar an√°lise\nif GRASSCLOVER_DATASET_PATH:\n    print(f\"üìÅ Usando dataset em: {GRASSCLOVER_DATASET_PATH}\")\n    grassclover_analysis = analyze_grassclover_images(GRASSCLOVER_DATASET_PATH)\n    GRASSCLOVER_REFERENCE_AVAILABLE = grassclover_analysis is not None\nelse:\n    print(\"‚ö†Ô∏è  Dataset GrassClover n√£o dispon√≠vel\")\n    print(\"üí° Poss√≠veis causas:\")\n    print(\"  ‚Ä¢ Erro no download do Kaggle\")\n    print(\"  ‚Ä¢ Problema de conectividade\")\n    print(\"  ‚Ä¢ kagglehub n√£o instalado corretamente\")\n    print(\"\\nüîÑ Para resolver:\")\n    print(\"  ‚Ä¢ Re-execute a c√©lula de download\")\n    print(\"  ‚Ä¢ Verifique se tem conectividade com Kaggle\")\n    print(\"  ‚Ä¢ O notebook continuar√° funcionando sem as refer√™ncias\")\n    \n    grassclover_analysis = None\n    GRASSCLOVER_REFERENCE_AVAILABLE = False\n\nprint(\"=\" * 60)"
  },
  {
   "cell_type":"markdown",
   "metadata":{},
   "source":[
    "## Prompts para Pastagens Brasileiras - Estilo GrassClover\n",
    "Prompts espec√≠ficos para gerar pastagens tropicais seguindo a metodologia visual do GrassClover."
   ],
   "outputs":[],
   "execution_count":null
  },
  {
   "cell_type":"code",
   "execution_count":null,
   "metadata":{},
   "outputs":[],
   "source":[
    "\")",
    "GRASSCLOVER_PROMPTS = {",
    "    'grassclover_exact_style': {",
    "        'positive': (",
    "            \"overhead top-down view of mixed grass and white clover field, \"",
    "            \"dense green ryegrass with white clover flowers, \"",
    "            \"small spherical white clover blooms scattered throughout, \"",
    "            \"fine thin grass blades, dense ground coverage, \"",
    "            \"natural outdoor lighting, soft daylight, no shadows, \"",
    "            \"detailed grass texture, small clover leaves visible, \"",
    "            \"research quality agricultural photography, \"",
    "            \"grassclover dataset style, scientific documentation, \"",
    "            \"perennial ryegrass, trifolium repens, mixed pasture\"",
    "        ),",
    "        'negative': (",
    "            \"side view, angled view, perspective view, \"",
    "            \"large flowers, colorful flowers, trees, shrubs, \"",
    "            \"buildings, people, animals, vehicles, \"",
    "            \"artificial grass, lawn, decorative plants, \"",
    "            \"dramatic lighting, shadows, high contrast, \"",
    "            \"blurry, low quality, cartoon, painting\"",
    "        ),",
    "        'description': \"Estilo GrassClover exato - ryegrass + trevo branco\"",
    "    },",
    "    'grassclover_dense_flowers': {",
    "        'positive': (",
    "            \"bird's eye view of grassland with abundant white clover flowers, \"",
    "            \"dense small white spherical clover blooms, \"",
    "            \"green grass background, trifolium repens in full bloom, \"",
    "            \"natural field conditions, scientific photography, \"",
    "            \"fine grass texture beneath clover flowers, \"",
    "            \"uniform lighting, no harsh shadows, research quality, \"",
    "            \"mixed grass-clover sward, agricultural study image\"",
    "        ),",
    "        'negative': (",
    "            \"ground level view, human perspective, \"",
    "            \"large decorative flowers, colored flowers, \"",
    "            \"ornamental garden, landscaped area, \"",
    "            \"artificial lighting, studio photography, \"",
    "            \"bare soil, sparse vegetation, weeds\"",
    "        ),",
    "        'description': \"GrassClover com flores densas de trevo\"",
    "    },",
    "    'grassclover_fine_texture': {",
    "        'positive': (",
    "            \"close overhead view of fine grass and clover mixture, \"",
    "            \"detailed texture of ryegrass blades and clover leaves, \"",
    "            \"small white clover flowers interspersed, \"",
    "            \"natural pasture composition, research documentation, \"",
    "            \"soft natural lighting, even illumination, \"",
    "            \"high detail vegetation pattern, grassclover study, \"",
    "            \"mixed species grassland, agricultural research image\"",
    "        ),",
    "        'negative': (",
    "            \"coarse grass, large blade grass, tropical grasses, \"",
    "            \"artificial turf, decorative plants, \"",
    "            \"dramatic shadows, studio lighting, \"",
    "            \"perspective distortion, angled shots\"",
    "        ),",
    "        'description': \"Textura fina GrassClover detalhada\"",
    "    },",
    "    'brazilian_mixed_grassclover_style': {",
    "        'positive': (",
    "            \"top-down view of mixed tropical grass with legume flowers, \"",
    "            \"small white stylosanthes flowers scattered in green grass, \"",
    "            \"dense brachiaria grass coverage with legume blooms, \"",
    "            \"grassclover dataset visual style, research photography, \"",
    "            \"natural field lighting, soft daylight, uniform illumination, \"",
    "            \"detailed grass-legume mixture, scientific documentation, \"",
    "            \"brazilian pasture with flowering legumes, agricultural study\"",
    "        ),",
    "        'negative': (",
    "            \"side perspective, ground level view, \"",
    "            \"large flowers, ornamental plants, \"",
    "            \"buildings, infrastructure, people, animals, \"",
    "            \"artificial lighting, dramatic shadows, \"",
    "            \"low quality, blurry, artistic style\"",
    "        ),",
    "        'description': \"Pastagem brasileira estilo GrassClover\"",
    "    },",
    "    'brachiaria_with_flowers_grassclover_style': {",
    "        'positive': (",
    "            \"aerial view of brachiaria pasture with small white legume flowers, \"",
    "            \"dense tropical grass with scattered small blooms, \"",
    "            \"grassclover research style photography, natural lighting, \"",
    "            \"detailed grass texture with flowering plants, \"",
    "            \"agricultural field study image, scientific quality, \"",
    "            \"mixed brachiaria and flowering legumes, top-down perspective, \"",
    "            \"brazilian tropical grassland research documentation\"",
    "        ),",
    "        'negative': (",
    "            \"temperate climate plants, large decorative flowers, \"",
    "            \"perspective view, human eye level, \"",
    "            \"landscaped garden, ornamental setting, \"",
    "            \"dramatic lighting, artistic photography, \"",
    "            \"poor quality, distorted view\"",
    "        ),",
    "        'description': \"Brachiaria com flores estilo GrassClover\"",
    "    }",
    "}",
    "GENERATION_PARAMS = {",
    "    'width': 512,",
    "    'height': 512, ",
    "    'num_inference_steps': 28,  # Balanceio qualidade/velocidade",
    "    'guidance_scale': 4.0,      # Ader√™ncia ao prompt",
    "    'num_images_per_prompt': 1,",
    "    'eta': 0.0,                 # Determinismo",
    "    'generator_seed': 42        # Reprodutibilidade inicial",
    "}",
    "for key, prompt_data in GRASSCLOVER_PROMPTS.items():",
    "‚öôÔ∏è  Par√¢metros de gera√ß√£o:\")",
    "for param, value in GENERATION_PARAMS.items():",
    "‚úÖ Prompts configurados!\")"
   ]
  },
  {
   "cell_type":"markdown",
   "metadata":{},
   "source":[
    "## Fun√ß√£o de Gera√ß√£o com Debugging Completo"
   ],
   "outputs":[],
   "execution_count":null
  },
  {
   "cell_type":"code",
   "execution_count":null,
   "metadata":{},
   "outputs":[],
   "source":[
    "def generate_grassclover_image(prompt_key, custom_seed=None, debug=True):\n",
    "    \"\"\"\n",
    "    Gera imagem no estilo GrassClover com debugging completo\n",
    "    Args:\n",
    "        prompt_key: Chave do prompt (ex: \"grassclover_exact_style\")\n",
    "        custom_seed: Seed personalizada (opcional)\n",
    "        debug: Ativar prints de debug\n",
    "    Returns:\n",
    "        dict com imagem e metadados\n",
    "    \"\"\"\n",
    "    if not PIPELINE_READY:\n",
    "        return None\n",
    "    if prompt_key not in GRASSCLOVER_PROMPTS:\n",
    "        return None\n",
    "    try:\n",
    "        # Configurar seed\n",
    "        seed = custom_seed if custom_seed is not None else GENERATION_PARAMS_CURRENT['generator_seed']\n",
    "        generator = torch.Generator(device=device).manual_seed(seed)\n",
    "        prompt_data = GRASSCLOVER_PROMPTS[prompt_key]\n",
    "        positive_prompt = prompt_data['positive']\n",
    "        negative_prompt = prompt_data['negative']\n",
    "        if debug:\n",
    "            if device.type == \"cuda\":\n",
    "                torch.cuda.empty_cache()\n",
    "                mem_before = torch.cuda.memory_allocated() / (1024**3)\n",
    "        with torch.autocast(device.type):\n",
    "            result = pipe(\n",
    "                prompt=positive_prompt,\n",
    "                negative_prompt=negative_prompt,\n",
    "                width=GENERATION_PARAMS_CURRENT['width'],\n",
    "                height=GENERATION_PARAMS_CURRENT['height'],\n",
    "                num_inference_steps=GENERATION_PARAMS_CURRENT['num_inference_steps'],\n",
    "                guidance_scale=GENERATION_PARAMS_CURRENT['guidance_scale'],\n",
    "                num_images_per_prompt=GENERATION_PARAMS_CURRENT['num_images_per_prompt'],\n",
    "                eta=GENERATION_PARAMS_CURRENT['eta'],\n",
    "                generator=generator\n",
    "            )\n",
    "        if debug:\n",
    "            if device.type == \"cuda\":\n",
    "                mem_after = torch.cuda.memory_allocated() / (1024**3)\n",
    "        image = result.images[0]\n",
    "        metadata = {\n",
    "            'prompt_key': prompt_key,\n",
    "            'description': prompt_data['description'],\n",
    "            'seed': seed,\n",
    "            'generation_params': GENERATION_PARAMS.copy(),\n",
    "            'timestamp': datetime.now().isoformat(),\n",
    "            'model_id': MODEL_ID,\n",
    "            'device': str(device)\n",
    "        }\n",
    "        return {\n",
    "            'image': image,\n",
    "            'metadata': metadata,\n",
    "            'success': True\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(\"üí• ERRO na gera√ß√£o: {e}\")\n",
    "        print(\"Error type: {type(e).__name__}\")\n",
    "        print(\"Error message: {e}\")\n",
    "        if device.type == \"cuda\":\n",
    "            torch.cuda.empty_cache()\n",
    "        return {\n",
    "            'image': None,\n",
    "            'metadata': None,\n",
    "            'success': False,\n",
    "            'error': str(e)\n",
    "        }\n",
    "def display_generation_result(result, show_metadata=True):\n",
    "    \"\"\"Exibe resultado da gera√ß√£o com metadados\"\"\"\n",
    "    if not result['success']:\n",
    "        print(\"error\")}\")\n",
    "        return\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(result['image'])\n",
    "    plt.axis('off')\n",
    "    metadata = result['metadata']\n",
    "    title = f\"{metadata['description']}\\nSeed: {metadata['seed']} | {metadata['generation_params']['width']}x{metadata['generation_params']['height']}\"\n",
    "    plt.title(title, fontsize=14, pad=20)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    if show_metadata:\n"
   ]
  },
  {
   "cell_type":"markdown",
   "metadata":{},
   "source":[
    "## üß™ Teste Inicial - Uma Imagem de Cada Tipo"
   ],
   "outputs":[],
   "execution_count":null
  },
  {
   "cell_type":"code",
   "execution_count":null,
   "metadata":{},
   "outputs":[],
   "source":[
    "if PIPELINE_READY:\n",
    "    test_prompts = [\"grassclover_exact_style\", \"brazilian_mixed_grassclover_style\", \"brachiaria_with_flowers_grassclover_style\"]\n",
    "    test_results = []\n",
    "    for i, prompt_key in enumerate(test_prompts, 1):\n",
    "        result = generate_grassclover_image(\n",
    "            prompt_key=prompt_key,\n",
    "            custom_seed=42 + i,  # Seed diferente para cada teste\n",
    "            debug=True\n",
    "        )\n",
    "        if result['success']:\n",
    "            test_results.append(result)\n",
    "            display_generation_result(result)\n",
    "        else:\n",
    "            break\n",
    "        if device.type == \"cuda\":\n",
    "            torch.cuda.empty_cache()\n",
    "else:\n"
   ]
  },
  {
   "cell_type":"markdown",
   "metadata":{},
   "source":[
    "## P√≥s-processamento Estilo GrassClover\n",
    "Ajustes para deixar as imagens mais pr√≥ximas do estilo visual do GrassClover Dataset."
   ],
   "outputs":[],
   "execution_count":null
  },
  {
   "cell_type":"code",
   "execution_count":null,
   "metadata":{},
   "outputs":[],
   "source":[
    "def compare_with_grassclover_reference(synthetic_results, reference_analysis=None):\n",
    "    \"\"\"\n",
    "    Compara imagens sint√©ticas com refer√™ncias do GrassClover original\n",
    "    \"\"\"\n",
    "    if not synthetic_results:\n",
    "        return\n",
    "    if not reference_analysis or not GRASSCLOVER_REFERENCE_AVAILABLE:\n",
    "        num_show = min(4, len(synthetic_results))\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(12, 12))\n",
    "        fig.suptitle('üåæ Imagens Sint√©ticas - Estilo GrassClover Brasileiro', \n",
    "                    fontsize=16, fontweight='bold')\n",
    "        axes = axes.flatten()\n",
    "        for i in range(num_show):\n",
    "            if i < len(synthetic_results):\n",
    "                result = synthetic_results[i]\n",
    "                image = result.get('processed_image', result['image'])\n",
    "                axes[i].imshow(image)\n",
    "                axes[i].set_title(f\"{result['metadata']['description']}\\nSeed: {result['metadata']['seed']}\")\n",
    "                axes[i].axis('off')\n",
    "            else:\n",
    "                axes[i].axis('off')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        return\n",
    "    try:\n",
    "        num_comparisons = min(3, len(synthetic_results), len(reference_analysis['sample_files']))\n",
    "        fig, axes = plt.subplots(num_comparisons, 2, figsize=(12, 4*num_comparisons))\n",
    "        fig.suptitle('üÜö Compara√ß√£o: GrassClover Original vs Sint√©tico Brasileiro', \n",
    "                    fontsize=16, fontweight='bold')\n",
    "        if num_comparisons == 1:\n",
    "            axes = axes.reshape(1, -1)\n",
    "        for i in range(num_comparisons):\n",
    "            try:\n",
    "                original_path = reference_analysis['sample_files'][i]\n",
    "                original_img = Image.open(original_path)\n",
    "                axes[i, 0].imshow(original_img)\n",
    "                axes[i, 0].set_title(f\"Original GrassClover\\n{os.path.basename(original_path)}\", fontsize=12)\n",
    "                axes[i, 0].axis('off')\n",
    "            except Exception as e:\n",
    "                axes[i, 0].text(0.5, 0.5, f'Erro ao\\ncarregar original', \n",
    "                               ha='center', va='center', transform=axes[i, 0].transAxes)\n",
    "                axes[i, 0].axis('off')\n",
    "            if i < len(synthetic_results):\n",
    "                synthetic_result = synthetic_results[i]\n",
    "                synthetic_img = synthetic_result.get('processed_image', synthetic_result['image'])\n",
    "                axes[i, 1].imshow(synthetic_img)\n",
    "                axes[i, 1].set_title(f\"Sint√©tico Brasileiro\\n{synthetic_result['metadata']['description']}\", fontsize=12)\n",
    "                axes[i, 1].axis('off')\n",
    "            else:\n",
    "                axes[i, 1].axis('off')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    except Exception as e:\n",
    "        print(\"‚ùå Erro na compara√ß√£o: {e}\")\n",
    "        num_show = min(4, len(synthetic_results))\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(12, 12))\n",
    "        fig.suptitle('üåæ Imagens Sint√©ticas Geradas', fontsize=16, fontweight='bold')\n",
    "        axes = axes.flatten()\n",
    "        for i in range(4):\n",
    "            if i < len(synthetic_results):\n",
    "                result = synthetic_results[i]\n",
    "                image = result.get('processed_image', result['image'])\n",
    "                axes[i].imshow(image)\n",
    "                axes[i].set_title(f\"{result['metadata']['description']}\")\n",
    "                axes[i].axis('off')\n",
    "            else:\n",
    "                axes[i].axis('off')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "if PIPELINE_READY:\n",
    "    calibrated_test_prompts = [\"grassclover_exact_style\", \"grassclover_dense_flowers\", \"grassclover_fine_texture\"]\n",
    "    calibrated_results = []\n",
    "    for i, prompt_key in enumerate(calibrated_test_prompts):\n",
    "        result = generate_grassclover_image(\n",
    "            prompt_key=prompt_key,\n",
    "            custom_seed=100 + i,  # Seeds diferentes\n",
    "            debug=False  # Menos verbose\n",
    "        )\n",
    "        if result and result['success']:\n",
    "            processed = grassclover_postprocess(result['image'], intensity=1.0, debug=False)\n",
    "            result['processed_image'] = processed\n",
    "            result['metadata']['postprocessed'] = True\n",
    "            calibrated_results.append(result)\n",
    "        else:\n",
    "        if dev_type == \"gpu\":\n",
    "            torch.cuda.empty_cache()\n",
    "    compare_with_grassclover_reference(calibrated_results, grassclover_analysis)\n",
    "else:\n"
   ]
  },
  {
   "cell_type":"markdown",
   "metadata":{},
   "source":[
    "## üÜö Compara√ß√£o com GrassClover Original\n",
    "Vamos comparar nossas imagens sint√©ticas com as refer√™ncias do GrassClover para avaliar a qualidade da reprodu√ß√£o do estilo."
   ],
   "outputs":[],
   "execution_count":null
  },
  {
   "cell_type":"code",
   "execution_count":null,
   "metadata":{},
   "outputs":[],
   "source":[
    "def grassclover_postprocess(image, intensity=1.0, debug=False):\n",
    "    \"\"\"\n",
    "    Aplica p√≥s-processamento para aproximar do estilo GrassClover\n",
    "    Args:\n",
    "        image: PIL Image\n",
    "        intensity: Intensidade dos ajustes (0.0-2.0)\n",
    "        debug: Mostrar etapas do processamento\n",
    "    Returns:\n",
    "        PIL Image processada\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if debug:\n",
    "        processed = image.copy()\n",
    "        contrast_factor = 1.0 + (0.3 * intensity)\n",
    "        enhancer = ImageEnhance.Contrast(processed)\n",
    "        processed = enhancer.enhance(contrast_factor)\n",
    "        if debug:\n",
    "        saturation_factor = 1.0 + (0.2 * intensity)\n",
    "        enhancer = ImageEnhance.Color(processed)\n",
    "        processed = enhancer.enhance(saturation_factor)\n",
    "        if debug:\n",
    "        if intensity > 0.5:\n",
    "            sharpness_factor = 1.0 + (0.1 * intensity)\n",
    "            enhancer = ImageEnhance.Sharpness(processed)\n",
    "            processed = enhancer.enhance(sharpness_factor)\n",
    "            if debug:\n",
    "        if intensity > 0.3:\n",
    "            blur_radius = 0.3 * intensity\n",
    "            processed = processed.filter(ImageFilter.GaussianBlur(radius=blur_radius))\n",
    "            if debug:\n",
    "        brightness_factor = 1.0 + (0.05 * intensity * (np.random.random() - 0.5))\n",
    "        enhancer = ImageEnhance.Brightness(processed)\n",
    "        processed = enhancer.enhance(brightness_factor)\n",
    "        if debug:\n",
    "        return processed\n",
    "    except Exception as e:\n",
    "        print(\"üí• Erro no p√≥s-processamento: {e}\")\n",
    "        print(\"Error: {type(e).__name__}: {e}\")\n",
    "        return image  # Retornar original se falhar\n",
    "def compare_before_after(original, processed, title=\"Compara√ß√£o\"):\n",
    "    \"\"\"\n",
    "    Exibe compara√ß√£o lado a lado\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 7))\n",
    "    axes[0].imshow(original)\n",
    "    axes[0].set_title(\"Original (Stable Diffusion)\", fontsize=12)\n",
    "    axes[0].axis('off')\n",
    "    axes[1].imshow(processed)\n",
    "    axes[1].set_title(\"Processado (Estilo GrassClover)\", fontsize=12)\n",
    "    axes[1].axis('off')\n",
    "    fig.suptitle(title, fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type":"code",
   "execution_count":null,
   "metadata":{},
   "outputs":[],
   "source":[
    "if PIPELINE_READY and 'test_results' in locals() and test_results:\n",
    "    test_image_data = test_results[0]\n",
    "    original_image = test_image_data['image']\n",
    "    processed_image = grassclover_postprocess(\n",
    "        image=original_image,\n",
    "        intensity=1.2,  # Intensidade m√©dia-alta\n",
    "        debug=True\n",
    "    )\n",
    "    compare_before_after(\n",
    "        original=original_image,\n",
    "        processed=processed_image,\n",
    "        title=f\"P√≥s-processamento: {test_image_data['metadata']['description']}\"\n",
    "    )\n",
    "else:\n"
   ]
  },
  {
   "cell_type":"markdown",
   "metadata":{},
   "source":[
    "## Gera√ß√£o em Lote com Seeds Diferentes\n",
    "Gera m√∫ltiplas varia√ß√µes de pastagens para criar um dataset diversificado."
   ],
   "outputs":[],
   "execution_count":null
  },
  {
   "cell_type":"code",
   "execution_count":null,
   "metadata":{},
   "outputs":[],
   "source":[
    "def generate_grassclover_batch(num_images=6, apply_postprocess=True, debug=True):\n",
    "    \"\"\"\n",
    "    Gera lote de imagens variadas estilo GrassClover\n",
    "    Args:\n",
    "        num_images: N√∫mero total de imagens\n",
    "        apply_postprocess: Aplicar p√≥s-processamento\n",
    "        debug: Debugging detalhado\n",
    "    Returns:\n",
    "        Lista de resultados\n",
    "    \"\"\"\n",
    "    if not PIPELINE_READY:\n",
    "        return []\n",
    "    prompt_keys = list(GRASSCLOVER_PROMPTS.keys())\n",
    "    batch_results = []\n",
    "    for i in range(num_images):\n",
    "        prompt_key = prompt_keys[i % len(prompt_keys)]\n",
    "        seed = 42 + i * 100 + np.random.randint(0, 50)\n",
    "        try:\n",
    "            result = generate_grassclover_image(\n",
    "                prompt_key=prompt_key,\n",
    "                custom_seed=seed,\n",
    "                debug=debug\n",
    "            )\n",
    "            if result['success']:\n",
    "                if apply_postprocess:\n",
    "                    processed_image = grassclover_postprocess(\n",
    "                        image=result['image'],\n",
    "                        intensity=np.random.uniform(0.8, 1.4),  # Varia√ß√£o aleat√≥ria\n",
    "                        debug=False\n",
    "                    )\n",
    "                    result['processed_image'] = processed_image\n",
    "                    result['metadata']['postprocessed'] = True\n",
    "                    if debug:\n",
    "                result['metadata']['batch_index'] = i\n",
    "                result['metadata']['total_batch'] = num_images\n",
    "                batch_results.append(result)\n",
    "            else:\n",
    "        except Exception as e:\n",
    "            print(\"üí• Erro na imagem {i+1}: {e}\")\n",
    "            if debug:\n",
    "        if device.type == \"cuda\":\n",
    "            torch.cuda.empty_cache()\n",
    "    return batch_results\n",
    "def display_batch_results(batch_results, max_display=6):\n",
    "    \"\"\"\n",
    "    Exibe resultados do lote em grid\n",
    "    \"\"\"\n",
    "    if not batch_results:\n",
    "        return\n",
    "    results_to_show = batch_results[:max_display]\n",
    "    n_images = len(results_to_show)\n",
    "    cols = min(3, n_images)\n",
    "    rows = (n_images + cols - 1) // cols\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(5*cols, 5*rows))\n",
    "    if rows == 1:\n",
    "        axes = axes.reshape(1, -1)\n",
    "    if cols == 1:\n",
    "        axes = axes.reshape(-1, 1)\n",
    "    for i, result in enumerate(results_to_show):\n",
    "        row = i // cols\n",
    "        col = i % cols\n",
    "        image = result.get('processed_image', result['image'])\n",
    "        axes[row, col].imshow(image)\n",
    "        axes[row, col].axis('off')\n",
    "        metadata = result['metadata']\n",
    "        title = f\"{metadata['description']}\\nSeed: {metadata['seed']}\"\n",
    "        axes[row, col].set_title(title, fontsize=10)\n",
    "    for i in range(n_images, rows * cols):\n",
    "        row = i // cols\n",
    "        col = i % cols\n",
    "        axes[row, col].axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.suptitle(f\"üåæ Dataset GrassClover Brasileiro - {n_images} Imagens\", \n",
    "                fontsize=16, fontweight='bold', y=0.98)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type":"code",
   "execution_count":null,
   "metadata":{},
   "outputs":[],
   "source":[
    "if PIPELINE_READY:\n",
    "    # Configura√ß√µes do lote\n",
    "    BATCH_SIZE = 6  # N√∫mero total de imagens\n",
    "    APPLY_POSTPROCESS = True\n",
    "    batch_results = generate_grassclover_batch(\n",
    "        num_images=BATCH_SIZE,\n",
    "        apply_postprocess=APPLY_POSTPROCESS,\n",
    "        debug=True\n",
    "    )\n",
    "    if batch_results:\n",
    "        type_counts = {}\n",
    "        for result in batch_results:\n",
    "            prompt_key = result['metadata']['prompt_key']\n",
    "            type_counts[prompt_key] = type_counts.get(prompt_key, 0) + 1\n",
    "        for prompt_key, count in type_counts.items():\n",
    "            description = GRASSCLOVER_PROMPTS[prompt_key]['description']\n",
    "        display_batch_results(batch_results)\n",
    "    else:\n",
    "else:\n"
   ]
  },
  {
   "cell_type":"markdown",
   "metadata":{},
   "source":[
    "## Salvamento das Imagens\n",
    "Salva as imagens geradas com metadados organizados."
   ],
   "outputs":[],
   "execution_count":null
  },
  {
   "cell_type":"code",
   "execution_count":null,
   "metadata":{},
   "outputs":[],
   "source":[
    "import os\n",
    "import json\n",
    "def save_grassclover_batch(batch_results, output_dir=\"grassclover_generated\", save_metadata=True):\n",
    "    \"\"\"\n",
    "    Salva lote de imagens com organiza√ß√£o e metadados\n",
    "    Args:\n",
    "        batch_results: Lista de resultados da gera√ß√£o\n",
    "        output_dir: Diret√≥rio de sa√≠da\n",
    "        save_metadata: Salvar arquivos JSON com metadados\n",
    "    Returns:\n",
    "        dict com estat√≠sticas de salvamento\n",
    "    \"\"\"\n",
    "    if not batch_results:\n",
    "        return {'success': False, 'saved_count': 0}\n",
    "    try:\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        images_dir = os.path.join(output_dir, \"images\")\n",
    "        metadata_dir = os.path.join(output_dir, \"metadata\")\n",
    "        os.makedirs(images_dir, exist_ok=True)\n",
    "        if save_metadata:\n",
    "            os.makedirs(metadata_dir, exist_ok=True)\n",
    "        if save_metadata:\n",
    "        saved_count = 0\n",
    "        saved_files = []\n",
    "        for i, result in enumerate(batch_results):\n",
    "            try:\n",
    "                metadata = result['metadata']\n",
    "                prompt_key = metadata['prompt_key']\n",
    "                seed = metadata['seed']\n",
    "                filename_base = f\"grassclover_{prompt_key}_{seed:06d}\"\n",
    "                original_path = os.path.join(images_dir, f\"{filename_base}_original.png\")\n",
    "                result['image'].save(original_path, 'PNG')\n",
    "                files_saved = [original_path]\n",
    "                if 'processed_image' in result:\n",
    "                    processed_path = os.path.join(images_dir, f\"{filename_base}_processed.png\")\n",
    "                    result['processed_image'].save(processed_path, 'PNG')\n",
    "                    files_saved.append(processed_path)\n",
    "                if save_metadata:\n",
    "                    metadata_path = os.path.join(metadata_dir, f\"{filename_base}.json\")\n",
    "                    json_metadata = metadata.copy()\n",
    "                    json_metadata['files_saved'] = files_saved\n",
    "                    json_metadata['save_timestamp'] = datetime.now().isoformat()\n",
    "                    with open(metadata_path, 'w', encoding='utf-8') as f:\n",
    "                        json.dump(json_metadata, f, indent=2, ensure_ascii=False)\n",
    "                    files_saved.append(metadata_path)\n",
    "                saved_files.extend(files_saved)\n",
    "                saved_count += 1\n",
    "            except Exception as e:\n",
    "                print(\"‚ùå Erro ao salvar imagem {i+1}: {e}\")\n",
    "                continue\n",
    "        if save_metadata:\n",
    "            index_data = {\n",
    "                'dataset_name': 'GrassClover Brazilian Synthetic',\n",
    "                'generation_date': datetime.now().isoformat(),\n",
    "                'total_images': len(batch_results),\n",
    "                'saved_images': saved_count,\n",
    "                'model_used': MODEL_ID,\n",
    "                'device': str(device),\n",
    "                'prompt_types': list(set(r['metadata']['prompt_key'] for r in batch_results)),\n",
    "                'files': saved_files\n",
    "            }\n",
    "            index_path = os.path.join(output_dir, \"dataset_index.json\")\n",
    "            with open(index_path, 'w', encoding='utf-8') as f:\n",
    "                json.dump(index_data, f, indent=2, ensure_ascii=False)\n",
    "        return {\n",
    "            'success': True,\n",
    "            'saved_count': saved_count,\n",
    "            'total_files': len(saved_files),\n",
    "            'output_dir': os.path.abspath(output_dir),\n",
    "            'files': saved_files\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(\"üí• Erro no salvamento: {e}\")\n",
    "        print(\"Error: {type(e).__name__}: {e}\")\n",
    "        return {\n",
    "            'success': False,\n",
    "            'saved_count': 0,\n",
    "            'error': str(e)\n",
    "        }\n"
   ]
  },
  {
   "cell_type":"code",
   "execution_count":null,
   "metadata":{},
   "outputs":[],
   "source":[
    "if 'batch_results' in locals() and batch_results:\n",
    "    # Configura√ß√µes de salvamento\n",
    "    OUTPUT_DIR = \"grassclover_synthetic_dataset\"\n",
    "    SAVE_METADATA = True\n",
    "    save_result = save_grassclover_batch(\n",
    "        batch_results=batch_results,\n",
    "        output_dir=OUTPUT_DIR,\n",
    "        save_metadata=SAVE_METADATA\n",
    "    )\n",
    "    if save_result['success']:\n",
    "        if os.path.exists(save_result['output_dir']):\n",
    "            for root, dirs, files in os.walk(save_result['output_dir']):\n",
    "                level = root.replace(save_result['output_dir'], '').count(os.sep)\n",
    "                indent = ' ' * 2 * level\n",
    "                subindent = ' ' * 2 * (level + 1)\n",
    "                for file in files[:3]:  # Mostrar s√≥ os primeiros 3 arquivos\n",
    "                if len(files) > 3:\n",
    "    else:\n",
    "        print(\"error\")}\")\n",
    "else:\n"
   ]
  },
  {
   "cell_type":"markdown",
   "metadata":{},
   "source":[
    "## üìä Relat√≥rio Final e Estat√≠sticas"
   ],
   "outputs":[],
   "execution_count":null
  },
  {
   "cell_type":"code",
   "execution_count":null,
   "metadata":{},
   "outputs":[],
   "source":[
    "1. **Copie a se√ß√£o \"DEBUG COPY/PASTE\"** que aparece nos erros\n",
    "2. **Cole aqui nos coment√°rios** ou no chat para an√°lise\n",
    "3. **Inclua informa√ß√µes do sistema** (GPU, mem√≥ria, etc.)\n",
    "- **Detec√ß√£o autom√°tica** de TPU/GPU/CPU\n",
    "- **Configura√ß√£o otimizada** para cada tipo de hardware\n",
    "- **Instru√ß√µes claras** para configura√ß√£o do runtime\n",
    "- **Bypass autom√°tico** de problemas de autentica√ß√£o\n",
    "- **Configura√ß√£o de ambiente** para evitar warnings\n",
    "- **Downloads funcionam normalmente** mesmo com warnings\n",
    "#### **‚úÖ Dtype Configuration (RESOLVIDO)**\n",
    "- **float16 para GPU** (performance otimizada)\n",
    "- **float32 para TPU/CPU** (compatibilidade garantida)\n",
    "- **Configura√ß√£o autom√°tica** baseada no hardware\n",
    "### üéØ **Configura√ß√£o Recomendada para Colab:**\n",
    "- **Runtime**: GPU (Tesla T4 ou superior)\n",
    "- **Reasoning**: Stable Diffusion funciona melhor em GPU que TPU\n",
    "- **Fallback**: TPU funciona, mas GPU √© mais r√°pido para este caso\n",
    "- **GENERATION_PARAMS**: Modifique `num_inference_steps` (15-50) para balancear qualidade/velocidade\n",
    "- **BATCH_SIZE**: Reduza se houver problemas de mem√≥ria\n",
    "- **Seeds**: Mude para explorar diferentes varia√ß√µes\n",
    "- **Prompts**: Ajuste para obter estilos visuais espec√≠ficos\n",
    "1. **Upload das imagens** na se√ß√£o de arquivos do Colab\n",
    "2. **Modifique os prompts** baseado nas caracter√≠sticas visuais\n",
    "3. **Ajuste p√≥s-processamento** para aproximar do estilo original\n",
    "- **Cobertura densa**: Pastagens devem ter ‚â•80% de cobertura vegetal\n",
    "- **Perspectiva top-down**: Vista a√©rea consistente\n",
    "- **Textura real√≠stica**: Detalhes de folhas e solo vis√≠veis\n",
    "- **Diversidade**: Varia√ß√£o entre as imagens geradas\n",
    "- **GPU (Tesla T4)**: ~30-45s por imagem (recomendado)\n",
    "- **GPU (V100/A100)**: ~15-25s por imagem (√≥timo)\n",
    "- **TPU**: ~45-60s por imagem (funciona)\n",
    "- **CPU**: ~5-10min por imagem (muito lento, n√£o recomendado)\n",
    "---\n",
    "**üåæ Dataset GrassClover Brasileiro - Gerado com Stable Diffusion**  \n",
    "Baseado na metodologia de Skovsen et al. (CVPR 2019) adaptada para gram√≠neas tropicais.\n",
    "**üìã Problemas Comuns Resolvidos**: TPU detection, HF authentication, dtype optimization"
   ]
  },
  {
   "cell_type":"markdown",
   "metadata":{},
   "source":[
    "## üí° Instru√ß√µes para Uso e Debugging\n",
    "### üö® **Em caso de erro:**\n",
    "1. **Copie a se√ß√£o \"DEBUG COPY/PASTE\"** que aparece nos erros\n",
    "2. **Cole aqui nos coment√°rios** ou no chat para an√°lise\n",
    "3. **Inclua informa√ß√µes do sistema** (GPU, mem√≥ria, etc.)\n",
    "### üîß **Ajustes poss√≠veis:**\n",
    "- **GENERATION_PARAMS**: Modifique `num_inference_steps` (15-50) para balancear qualidade/velocidade\n",
    "- **BATCH_SIZE**: Reduza se houver problemas de mem√≥ria\n",
    "- **Seeds**: Mude para explorar diferentes varia√ß√µes\n",
    "- **Prompts**: Ajuste para obter estilos visuais espec√≠ficos\n",
    "### üì∏ **Para adicionar refer√™ncias GrassClover:**\n",
    "1. **Upload das imagens** na se√ß√£o de arquivos do Colab\n",
    "2. **Modifique os prompts** baseado nas caracter√≠sticas visuais\n",
    "3. **Ajuste p√≥s-processamento** para aproximar do estilo original\n",
    "### **M√©tricas de qualidade:**\n",
    "- **Cobertura densa**: Pastagens devem ter ‚â•80% de cobertura vegetal\n",
    "- **Perspectiva top-down**: Vista a√©rea consistente\n",
    "- **Textura real√≠stica**: Detalhes de folhas e solo vis√≠veis\n",
    "- **Diversidade**: Varia√ß√£o entre as imagens geradas\n",
    "**üåæ Dataset GrassClover Brasileiro - Gerado com Stable Diffusion**  \n",
    "Baseado na metodologia de Skovsen et al. (CVPR 2019) adaptada para gram√≠neas tropicais."
   ],
   "outputs":[],
   "execution_count":null
  }
 ],
 "metadata":{
  "kernelspec":{
   "display_name":"Python 3",
   "language":"python",
   "name":"python3"
  },
  "language_info":{
   "codemirror_mode":{
    "name":"ipython",
    "version":3
   },
   "file_extension":".py",
   "mimetype":"text/x-python",
   "name":"python",
   "nbconvert_exporter":"python",
   "pygments_lexer":"ipython3",
   "version":"3.8.10"
  }
 },
 "nbformat":4,
 "nbformat_minor":4
}