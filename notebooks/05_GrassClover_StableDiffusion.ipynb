{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GrassClover-Style Generation with Stable Diffusion\n",
    "Este notebook implementa gera√ß√£o de imagens sint√©ticas de pastagens brasileiras usando **Stable Diffusion**, seguindo o estilo visual do **GrassClover Dataset** (Skovsen et al., CVPR 2019).\n",
    "## Objetivos:\n",
    "- Gerar imagens **top-down** de pastagens com Stable Diffusion\n",
    "- Adaptar para **gram√≠neas brasileiras** (Brachiaria, Panicum, Cynodon)\n",
    "- Seguir **metodologia GrassClover** (densidade, perspectiva, resolu√ß√£o)\n",
    "- **Ultra-compat√≠vel** com Google Colab (debugging extensivo)\n",
    "## Refer√™ncia:\n",
    "- **Paper**: Skovsen et al. \"The GrassClover Image Dataset for Semantic and Hierarchical Species Understanding in Agriculture\" (CVPR Workshops, 2019)\n",
    "- **Adapta√ß√£o**: Esp√©cies temperadas ‚Üí Tropicais brasileiras\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Ultra-Compat√≠vel para Colab\n",
    "**IMPORTANTE**: Este notebook foi desenvolvido para m√°xima compatibilidade com Google Colab Free/Pro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import platform\n",
    "from datetime import datetime\n",
    "try:\n",
    "    import google.colab\n",
    "    in_colab = True\n",
    "except ImportError:\n",
    "    in_colab = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = None\n",
    "dev_type = \"unknown\"\n",
    "hw_info = {}\n",
    "\n",
    "# Tentar importar torch primeiro\n",
    "try:\n",
    "    import torch\n",
    "    torch_ok = True\n",
    "    hw_info['pytorch_version'] = torch.__version__\n",
    "except ImportError:\n",
    "    torch_ok = False\n",
    "\n",
    "if torch_ok:\n",
    "    # Verificar TPU primeiro\n",
    "    try:\n",
    "        import torch_xla\n",
    "        import torch_xla.core.xla_model as xm\n",
    "        if xm.xrt_world_size() > 1:\n",
    "            device = xm.xla_device()\n",
    "            dev_type = \"tpu\"\n",
    "            hw_info.update({\n",
    "                'dev_type': 'tpu',\n",
    "                'tpu_cores': xm.xrt_world_size(),\n",
    "                'device': str(device)\n",
    "            })\n",
    "        else:\n",
    "            # TPU dispon√≠vel mas n√£o configurado\n",
    "            device = torch.device(\"cpu\")\n",
    "            dev_type = \"cpu\"\n",
    "    except ImportError:\n",
    "        # TPU n√£o dispon√≠vel, tentar GPU\n",
    "        pass\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è  Erro ao verificar TPU: {e}\")\n",
    "    \n",
    "    # Se n√£o conseguiu TPU, tentar GPU\n",
    "    if device is None:\n",
    "        cuda_available = torch.cuda.is_available()\n",
    "        if cuda_available:\n",
    "            gpu_count = torch.cuda.device_count()\n",
    "            for i in range(gpu_count):\n",
    "                gpu_name = torch.cuda.get_device_name(i)\n",
    "                gpu_memory = torch.cuda.get_device_properties(i).total_memory\n",
    "                gpu_memory_gb = gpu_memory / (1024**3)\n",
    "            \n",
    "            device = torch.device(\"cuda\")\n",
    "            dev_type = \"gpu\"\n",
    "            hw_info.update({\n",
    "                'dev_type': 'gpu',\n",
    "                'gpu_count': gpu_count,\n",
    "                'gpu_name': torch.cuda.get_device_name(0),\n",
    "                'gpu_memory_gb': torch.cuda.get_device_properties(0).total_memory / (1024**3),\n",
    "                'device': str(device)\n",
    "            })\n",
    "            torch.cuda.empty_cache()\n",
    "        else:\n",
    "            # Fallback para CPU\n",
    "            device = torch.device(\"cpu\")\n",
    "            dev_type = \"cpu\"\n",
    "    \n",
    "    # Se ainda n√£o definiu device, usar CPU\n",
    "    if device is None:\n",
    "        device = torch.device(\"cpu\")\n",
    "        dev_type = \"cpu\"\n",
    "        hw_info.update({\n",
    "            'dev_type': 'cpu',\n",
    "            'device': str(device)\n",
    "        })\n",
    "\n",
    "    # Print do status do hardware\n",
    "    if dev_type == \"cpu\" and in_colab:\n",
    "        print(\"‚ö†Ô∏è CPU detectado - Considere ativar GPU no Colab\")\n",
    "    elif dev_type == \"tpu\":\n",
    "        print(\"üî• TPU detectado\")\n",
    "    elif dev_type == \"gpu\":\n",
    "        print(f\"üöÄ GPU detectado: {hw_info.get('gpu_name', 'Unknown')}\")\n",
    "        \n",
    "else:\n",
    "    device = None\n",
    "    dev_type = \"none\"\n",
    "\n",
    "print(f\"üîß Hardware configurado: {dev_type.upper()}\")\n",
    "print(f\"üì± Device: {device}\")\n",
    "if hw_info:\n",
    "    print(f\"‚ÑπÔ∏è  Info: {hw_info}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# üîê AUTENTICA√á√ÉO HUGGINGFACE OBRIGAT√ìRIA\nprint(\"üîê AUTENTICA√á√ÉO HUGGINGFACE OBRIGAT√ìRIA\")\nprint(\"=\" * 60)\nprint(\"‚ö†Ô∏è  IMPORTANTE: Este notebook REQUER login no HuggingFace para funcionar!\")\nprint(\"üìã Voc√™ DEVE aceitar os termos em: https://huggingface.co/stabilityai/stable-diffusion-3.5-large\")\nprint(\"üîë Voc√™ DEVE ter um token HuggingFace v√°lido\")\nprint(\"=\" * 60)\n\ntry:\n    from huggingface_hub import notebook_login, whoami\n    \n    print(\"‚è≥ Iniciando processo de login...\")\n    \n    # For√ßar login interativo - isso vai parar e pedir o token\n    notebook_login()\n    \n    # Verificar se o login foi bem-sucedido\n    try:\n        user_info = whoami()\n        print(f\"‚úÖ Login realizado com sucesso!\")\n        print(f\"üë§ Usu√°rio logado: {user_info.get('name', 'N/A')}\")\n        HUGGINGFACE_LOGGED_IN = True\n    except Exception as e:\n        print(f\"‚ùå Falha na verifica√ß√£o do login: {e}\")\n        print(\"üö´ PARANDO EXECU√á√ÉO - LOGIN NECESS√ÅRIO\")\n        raise SystemExit(\"Login no HuggingFace √© obrigat√≥rio para continuar\")\n    \nexcept ImportError as e:\n    print(f\"‚ùå Erro ao importar huggingface_hub: {e}\")\n    print(\"üì¶ Instalando huggingface_hub...\")\n    import subprocess\n    result = subprocess.run([\"pip\", \"install\", \"huggingface_hub\", \"--upgrade\", \"--quiet\"], \n                          capture_output=True, text=True)\n    if result.returncode == 0:\n        from huggingface_hub import notebook_login, whoami\n        print(\"‚úÖ huggingface_hub instalado\")\n        \n        # Tentar login novamente ap√≥s instala√ß√£o\n        notebook_login()\n        try:\n            user_info = whoami()\n            print(f\"‚úÖ Login realizado com sucesso ap√≥s instala√ß√£o!\")\n            print(f\"üë§ Usu√°rio logado: {user_info.get('name', 'N/A')}\")\n            HUGGINGFACE_LOGGED_IN = True\n        except:\n            print(\"üö´ PARANDO EXECU√á√ÉO - LOGIN NECESS√ÅRIO\")\n            raise SystemExit(\"Login no HuggingFace √© obrigat√≥rio para continuar\")\n    else:\n        print(\"‚ùå Falha ao instalar huggingface_hub\")\n        raise SystemExit(\"N√£o foi poss√≠vel instalar huggingface_hub\")\n\nexcept Exception as e:\n    print(f\"‚ùå Erro durante o login: {e}\")\n    print(\"üö´ PARANDO EXECU√á√ÉO - LOGIN NECESS√ÅRIO\")\n    print(\"\\nüí° SOLU√á√ïES:\")\n    print(\"1. Certifique-se de que tem um token HuggingFace v√°lido\")\n    print(\"2. Acesse: https://huggingface.co/settings/tokens\")\n    print(\"3. Aceite os termos do modelo: https://huggingface.co/stabilityai/stable-diffusion-3.5-large\")\n    print(\"4. Execute esta c√©lula novamente\")\n    raise SystemExit(\"Login no HuggingFace √© obrigat√≥rio para continuar\")\n\nprint(\"=\" * 60)\nprint(\"üéâ AUTENTICA√á√ÉO CONCLU√çDA - NOTEBOOK PODE CONTINUAR\")\nprint(\"=\" * 60)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# üöÄ STABLE DIFFUSION 3.5 LARGE - CONFIGURA√á√ÉO EXCLUSIVA\nprint(\"üöÄ Carregando Stable Diffusion 3.5 Large...\")\nprint(\"‚ö†Ô∏è  APENAS SD3.5 SER√Å USADO - SEM FALLBACK PARA VERS√ïES ANTIGAS\")\n\ndef load_stable_diffusion_35_only():\n    \"\"\"\n    Carrega APENAS SD3.5 Large - sem fallback para outras vers√µes\n    \"\"\"\n    # Verificar se o login foi feito\n    if not HUGGINGFACE_LOGGED_IN:\n        print(\"üö´ ERRO: Login no HuggingFace √© obrigat√≥rio!\")\n        print(\"üìã Execute a c√©lula anterior para fazer login\")\n        raise SystemExit(\"Login necess√°rio para continuar\")\n    \n    try:\n        # Imports espec√≠ficos para SD3.5\n        from diffusers import StableDiffusion3Pipeline\n        import torch\n        \n        print(\"‚è≥ Carregando SD3.5 Large (pode demorar alguns minutos)...\")\n        \n        # Determinar device_map baseado no hardware\n        if torch.cuda.is_available():\n            # Para GPU, usar device espec√≠fico ao inv√©s de \"auto\"\n            device_map_strategy = None  # Usar .to(device) depois\n            torch_dtype = torch.bfloat16\n            print(\"üöÄ Usando GPU com bfloat16\")\n        else:\n            device_map_strategy = None\n            torch_dtype = torch.float32\n            print(\"üíª Usando CPU com float32\")\n        \n        # Configura√ß√µes otimizadas para SD3.5\n        load_kwargs = {\n            \"torch_dtype\": torch_dtype,\n            \"low_cpu_mem_usage\": True,\n        }\n        \n        # Adicionar device_map apenas se necess√°rio\n        if device_map_strategy:\n            load_kwargs[\"device_map\"] = device_map_strategy\n        \n        print(\"üì¶ Fazendo download/carregamento do modelo...\")\n        pipe = StableDiffusion3Pipeline.from_pretrained(\n            \"stabilityai/stable-diffusion-3.5-large\", \n            **load_kwargs\n        )\n        \n        # Mover para device manualmente se n√£o usou device_map\n        if not device_map_strategy:\n            print(f\"üì± Movendo modelo para {device}...\")\n            pipe = pipe.to(device)\n            \n        print(\"‚úÖ SD3.5 Large carregado com sucesso!\")\n        return pipe, \"3.5\"\n        \n    except Exception as e:\n        print(f\"‚ùå ERRO ao carregar SD3.5: {e}\")\n        print(f\"üîç Tipo do erro: {type(e).__name__}\")\n        \n        # An√°lise espec√≠fica de erros\n        error_str = str(e).lower()\n        \n        if \"auto not supported\" in error_str:\n            print(\"üí° DIAGN√ìSTICO: Problema com device_map='auto'\")\n            print(\"üîß CORRE√á√ÉO: Removendo device_map e usando .to(device)\")\n            \n        elif \"requires you to be logged in\" in error_str or \"authentication\" in error_str:\n            print(\"üí° DIAGN√ìSTICO: Problema de autentica√ß√£o\")\n            print(\"üîß CORRE√á√ÉO: Verifique se fez login correto na c√©lula anterior\")\n            \n        elif \"out of memory\" in error_str or \"oom\" in error_str:\n            print(\"üí° DIAGN√ìSTICO: Problema de mem√≥ria\")\n            print(\"üîß CORRE√á√ÉO: SD3.5 Large requer ~12GB+ VRAM\")\n            \n        elif \"connection\" in error_str or \"network\" in error_str:\n            print(\"üí° DIAGN√ìSTICO: Problema de conex√£o\")\n            print(\"üîß CORRE√á√ÉO: Verifique sua conex√£o com internet\")\n            \n        # N√ÉO FAZER FALLBACK - PARAR AQUI\n        print(\"\\nüö´ PARANDO EXECU√á√ÉO - SD3.5 √â OBRIGAT√ìRIO\")\n        print(\"üí≠ Este notebook foi projetado especificamente para SD3.5\")\n        print(\"üîÑ SOLU√á√ïES:\")\n        print(\"  1. Verifique seu login HuggingFace\")\n        print(\"  2. Aceite os termos do modelo\")\n        print(\"  3. Certifique-se de ter GPU com VRAM suficiente\")\n        print(\"  4. Tente reiniciar o runtime se necess√°rio\")\n        \n        raise SystemExit(f\"SD3.5 √© obrigat√≥rio. Erro: {e}\")\n\n# Definir TORCH_DTYPE se n√£o existir\nif 'TORCH_DTYPE' not in locals():\n    if device.type == \"cuda\":\n        TORCH_DTYPE = torch.bfloat16\n        print(f\"üî¢ TORCH_DTYPE configurado: {TORCH_DTYPE} (GPU)\")\n    else:\n        TORCH_DTYPE = torch.float32\n        print(f\"üî¢ TORCH_DTYPE configurado: {TORCH_DTYPE} (CPU)\")\n\n# Carregar pipeline - APENAS SD3.5\npipe, sd_version = load_stable_diffusion_35_only()\n\nif pipe is not None:\n    print(f\"\\nüéâ Pipeline SD{sd_version} carregado com sucesso!\")\n    \n    # Configurar scheduler espec√≠fico para SD3.5\n    print(\"üîß Configurando scheduler otimizado...\")\n    # SD3.5 j√° vem com scheduler adequado, n√£o precisamos trocar\n    print(\"‚úÖ Scheduler SD3.5 mantido (nativo do modelo)\")\n\n    # Configura√ß√µes espec√≠ficas para SD3.5\n    GENERATION_PARAMS_CURRENT = {\n        'width': 1024,           # SD3.5 funciona melhor em resolu√ß√£o maior\n        'height': 1024,\n        'num_inference_steps': 28,  # Padr√£o SD3.5\n        'guidance_scale': 4.5,      # Ajustado para SD3.5\n        'num_images_per_prompt': 1,\n        'eta': 0.0,\n        'generator_seed': 42\n    }\n    \n    print(\"‚öôÔ∏è Par√¢metros SD3.5 configurados:\")\n    for param, value in GENERATION_PARAMS_CURRENT.items():\n        print(f\"  ‚Ä¢ {param}: {value}\")\n    \n    # Otimiza√ß√µes de mem√≥ria espec√≠ficas\n    try:\n        if hasattr(pipe, 'enable_attention_slicing'):\n            pipe.enable_attention_slicing()\n            print(\"‚ö° Attention slicing ativado\")\n            \n        if hasattr(pipe, 'enable_memory_efficient_attention') and device.type == \"cuda\":\n            pipe.enable_memory_efficient_attention()  \n            print(\"üíæ Memory efficient attention ativado\")\n            \n    except Exception as e:\n        print(f\"‚ö†Ô∏è Aviso nas otimiza√ß√µes: {e}\")\n    \n    print(f\"\\nüéâ SD3.5 PRONTO PARA GERA√á√ÉO!\")\n    PIPELINE_READY = True\n    \nelse:\n    print(\"üö´ SISTEMA PARADO - SD3.5 N√ÉO FOI CARREGADO\")\n    PIPELINE_READY = False"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "essential_packages = [\n",
    "    \"torch\",\n",
    "    \"torchvision\", \n",
    "    \"diffusers\",\n",
    "    \"transformers\",\n",
    "    \"accelerate\",\n",
    "    \"pillow\",\n",
    "    \"matplotlib\",\n",
    "    \"numpy\"\n",
    "]\n",
    "\n",
    "def install_package(package_name, quiet=True):\n",
    "    \"\"\"Instala pacote com debugging\"\"\"\n",
    "    import subprocess\n",
    "    try:\n",
    "        cmd = [\"pip\", \"install\", package_name]\n",
    "        if quiet:\n",
    "            cmd.append(\"--quiet\")\n",
    "        result = subprocess.run(cmd, capture_output=True, text=True, timeout=300)\n",
    "        if result.returncode == 0:\n",
    "            return True\n",
    "        else:\n",
    "            print(f\"‚ùå Erro ao instalar {package_name}:\")\n",
    "            print(result.stderr[:200])\n",
    "            return False\n",
    "    except subprocess.TimeoutExpired:\n",
    "        print(f\"‚è±Ô∏è Timeout ao instalar {package_name}\")\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        print(f\"üí• Erro inesperado ao instalar {package_name}: {e}\")\n",
    "        return False\n",
    "\n",
    "print(\"üì¶ Verificando e instalando pacotes essenciais...\")\n",
    "\n",
    "for package in essential_packages:\n",
    "    try:\n",
    "        __import__(package.replace(\"-\", \"_\"))\n",
    "        print(f\"‚úÖ {package} j√° instalado\")\n",
    "    except ImportError:\n",
    "        print(f\"üì¶ Instalando {package}...\")\n",
    "        success = install_package(package)\n",
    "        if not success:\n",
    "            print(f\"‚ùå Falhou ao instalar {package} - continuando mesmo assim\")\n",
    "            break\n",
    "\n",
    "print(\"‚úÖ Verifica√ß√£o de pacotes conclu√≠da!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîÑ REIMPORTA√á√ÉO E VERIFICA√á√ÉO FINAL COM CONFIGURA√á√ïES OTIMIZADAS\n",
    "print(\"üîÑ Verifica√ß√£o final do sistema...\")\n",
    "\n",
    "# Imports essenciais com debugging\n",
    "try:\n",
    "    import torch\n",
    "    import torchvision.transforms as transforms\n",
    "    print(\"‚úÖ PyTorch importado\")\n",
    "    \n",
    "    # Reconfigurar device ap√≥s instala√ß√£o se necess√°rio\n",
    "    if not 'device' in locals() or device is None:\n",
    "        if torch.cuda.is_available():\n",
    "            device = torch.device(\"cuda\")\n",
    "            dev_type = \"gpu\"\n",
    "            gpu_name = torch.cuda.get_device_name(0)\n",
    "            gpu_memory = torch.cuda.get_device_properties(0).total_memory / (1024**3)\n",
    "            print(f\"üöÄ GPU detectada: {gpu_name} ({gpu_memory:.1f}GB)\")\n",
    "            \n",
    "            # Configura√ß√£o otimizada para GPU\n",
    "            torch.backends.cudnn.benchmark = True\n",
    "            torch.cuda.empty_cache()\n",
    "        else:\n",
    "            device = torch.device(\"cpu\")\n",
    "            dev_type = \"cpu\"\n",
    "            print(\"üíª Usando CPU\")\n",
    "    \n",
    "    # Configurar dtype baseado no hardware\n",
    "    if dev_type == \"gpu\":\n",
    "        TORCH_DTYPE = torch.bfloat16  # GPU: usar half precision\n",
    "    elif dev_type == \"tpu\":\n",
    "        TORCH_DTYPE = torch.float32  # TPU: full precision recomendado\n",
    "    else:\n",
    "        TORCH_DTYPE = torch.float32  # CPU: full precision\n",
    "        \n",
    "    print(f\"üî¢ Dtype configurado: {TORCH_DTYPE}\")\n",
    "    \n",
    "except ImportError as e:\n",
    "    print(f\"‚ùå Erro PyTorch: {e}\")\n",
    "    device = None\n",
    "    dev_type = \"none\"\n",
    "    TORCH_DTYPE = None\n",
    "\n",
    "try:\n",
    "    from diffusers import StableDiffusion3Pipeline, DPMSolverMultistepScheduler\n",
    "    print(\"‚úÖ Diffusers importado\")\n",
    "    diffusers_ok = True\n",
    "except ImportError as e:\n",
    "    print(f\"‚ùå Erro Diffusers: {e}\")\n",
    "    diffusers_ok = False\n",
    "\n",
    "try:\n",
    "    from PIL import Image, ImageEnhance, ImageFilter\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    print(\"‚úÖ Bibliotecas de imagem importadas\")\n",
    "    libs_ok = True\n",
    "except ImportError as e:\n",
    "    print(f\"‚ùå Erro bibliotecas b√°sicas: {e}\")\n",
    "    libs_ok = False\n",
    "\n",
    "# Configura√ß√£o de ambiente Hugging Face\n",
    "try:\n",
    "    import os\n",
    "    os.environ[\"DISABLE_TELEMETRY\"] = \"1\"\n",
    "    os.environ[\"HF_HUB_DISABLE_TELEMETRY\"] = \"1\"\n",
    "    \n",
    "    # Configurar cache offline se necess√°rio\n",
    "    if in_colab:\n",
    "        os.environ[\"TRANSFORMERS_OFFLINE\"] = \"0\"  # Permitir downloads no Colab\n",
    "        os.environ[\"HF_HUB_OFFLINE\"] = \"0\"\n",
    "    print(\"‚úÖ Configura√ß√£o HF aplicada\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Aviso na configura√ß√£o HF: {e}\")\n",
    "\n",
    "ALL_READY = device is not None and diffusers_ok and libs_ok\n",
    "\n",
    "if ALL_READY:\n",
    "    print(\"‚úÖ Sistema totalmente configurado e pronto!\")\n",
    "    print(f\"üì± Device: {device}\")\n",
    "    print(f\"üîß Tipo: {dev_type}\")\n",
    "else:\n",
    "    print(\"‚ùå Sistema n√£o est√° completamente configurado\")\n",
    "    if device is None:\n",
    "        print(\"  - Device n√£o configurado\")\n",
    "    if not diffusers_ok:\n",
    "        print(\"  - Diffusers n√£o dispon√≠vel\")\n",
    "    if not libs_ok:\n",
    "        print(\"  - Bibliotecas b√°sicas com problema\")\n",
    "    \n",
    "    if dev_type == \"cpu\" and in_colab:\n",
    "        print(\"‚ö†Ô∏è Executando em CPU - Performance limitada\")\n",
    "        print(\"üí° Considere ativar GPU no Runtime do Colab\")\n",
    "\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline Stable Diffusion para GrassClover\n",
    "Configura√ß√£o do pipeline otimizado para gera√ß√£o de pastagens no estilo GrassClover."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CONFIGURA√á√ÉO AVAN√áADA DO PIPELINE STABLE DIFFUSION\n",
    "print(\"üé® Configurando Stable Diffusion Pipeline...\\n\")\n",
    "# Par√¢metros do pipeline baseados no hardware detectado\n",
    "MODEL_ID = \"runwayml/stable-diffusion-v1-5\"  # Modelo base confi√°vel\n",
    "LOW_CPU_MEM_USAGE = True\n",
    "ENABLE_ATTENTION_SLICING = True\n",
    "# Configura√ß√µes espec√≠ficas por hardware\n",
    "if device_type == \"gpu\":\n",
    "    ENABLE_MODEL_CPU_OFFLOAD = False\n",
    "    ENABLE_SEQUENTIAL_CPU_OFFLOAD = False\n",
    "    USE_TORCH_COMPILE = True\n",
    "elif device_type == \"tpu\":\n",
    "    ENABLE_MODEL_CPU_OFFLOAD = True\n",
    "    ENABLE_SEQUENTIAL_CPU_OFFLOAD = False\n",
    "    USE_TORCH_COMPILE = False  # TPU pode ter problemas com compile\n",
    "else:  # CPU\n",
    "    ENABLE_MODEL_CPU_OFFLOAD = True\n",
    "    ENABLE_SEQUENTIAL_CPU_OFFLOAD = True\n",
    "    USE_TORCH_COMPILE = False\n",
    "print(f\"üì¶ Modelo: {MODEL_ID}\")\n",
    "print(f\"üî¢ Dtype: {TORCH_DTYPE}\")\n",
    "print(f\"üíæ Low CPU mem: {LOW_CPU_MEM_USAGE}\")\n",
    "print(f\"‚ö° Attention slicing: {ENABLE_ATTENTION_SLICING}\")\n",
    "print(f\"üèÉ Model CPU offload: {ENABLE_MODEL_CPU_OFFLOAD}\")\n",
    "print(f\"üî• Hardware: {device_type.upper()}\")\n",
    "# Fun√ß√£o para carregar pipeline com debugging e bypass de autentica√ß√£o\n",
    "def load_stable_diffusion_pipeline():\n",
    "    \"\"\"Carrega pipeline com m√°ximo debugging e configura√ß√µes otimizadas\"\"\"\n",
    "    try:\n",
    "        print(\"‚è≥ Carregando modelo...\")\n",
    "        # Configura√ß√µes para bypass de problemas de autentica√ß√£o\n",
    "        load_kwargs = {\n",
    "            \"torch_dtype\": TORCH_DTYPE,\n",
    "            \"low_cpu_mem_usage\": LOW_CPU_MEM_USAGE,\n",
    "            \"use_safetensors\": True,\n",
    "        }\n",
    "        # Configura√ß√µes espec√≠ficas para resolver problemas HF\n",
    "        try:\n",
    "            # Tentar com autentica√ß√£o padr√£o primeiro\n",
    "            pipe = StableDiffusionPipeline.from_pretrained(MODEL_ID, **load_kwargs)\n",
    "            print(\"‚úÖ Modelo carregado com autentica√ß√£o padr√£o\")\n",
    "        except Exception as auth_error:\n",
    "            print(f\"‚ö†Ô∏è  Problema de autentica√ß√£o: {str(auth_error)[:100]}...\")\n",
    "            print(\"üîÑ Tentando download for√ßado...\")\n",
    "            # Bypass de problemas de autentica√ß√£o\n",
    "            load_kwargs[\"use_auth_token\"] = False\n",
    "            load_kwargs[\"force_download\"] = False\n",
    "            load_kwargs[\"resume_download\"] = True\n",
    "            pipe = StableDiffusionPipeline.from_pretrained(MODEL_ID, **load_kwargs)\n",
    "            print(\"‚úÖ Modelo carregado com bypass de autentica√ß√£o\")\n",
    "        # Mover para device\n",
    "        pipe = pipe.to(device)\n",
    "        print(f\"üöÄ Pipeline movido para {device}\")\n",
    "        # Otimiza√ß√µes baseadas no hardware\n",
    "        if ENABLE_ATTENTION_SLICING:\n",
    "            pipe.enable_attention_slicing()\n",
    "            print(\"‚ö° Attention slicing habilitado\")\n",
    "        if ENABLE_MODEL_CPU_OFFLOAD and device_type != \"cpu\":\n",
    "            try:\n",
    "                pipe.enable_model_cpu_offload()\n",
    "                print(\"üíæ Model CPU offload habilitado\")\n",
    "            except Exception as e:\n",
    "                print(f\"‚ö†Ô∏è  CPU offload falhou: {e}\")\n",
    "        if ENABLE_SEQUENTIAL_CPU_OFFLOAD and device_type == \"cpu\":\n",
    "            try:\n",
    "                pipe.enable_sequential_cpu_offload()\n",
    "                print(\"üîÑ Sequential CPU offload habilitado\")\n",
    "            except Exception as e:\n",
    "                print(f\"‚ö†Ô∏è  Sequential offload falhou: {e}\")\n",
    "        # Scheduler otimizado\n",
    "        pipe.scheduler = DPMSolverMultistepScheduler.from_config(pipe.scheduler.config)\n",
    "        print(\"üîß Scheduler otimizado (DPMSolver)\")\n",
    "        # Configura√ß√µes de mem√≥ria espec√≠ficas\n",
    "        if device_type == \"gpu\":\n",
    "            torch.cuda.empty_cache()\n",
    "            allocated = torch.cuda.memory_allocated() / (1024**3)\n",
    "            cached = torch.cuda.memory_reserved() / (1024**3)\n",
    "            print(f\"üíæ GPU Memory - Allocated: {allocated:.2f}GB, Cached: {cached:.2f}GB\")\n",
    "            # Verificar se h√° mem√≥ria suficiente\n",
    "            if allocated > 10.0:  # >10GB pode causar problemas\n",
    "                print(f\"‚ö†Ô∏è  Alta utiliza√ß√£o de mem√≥ria GPU!\")\n",
    "        elif device_type == \"tpu\":\n",
    "            print(\"üî• TPU configurado - mem√≥ria gerenciada automaticamente\")\n",
    "        else:  # CPU\n",
    "            print(\"üíª CPU mode - sem monitoramento de GPU memory\")\n",
    "        print(\"\\n‚úÖ Pipeline configurado com sucesso!\")\n",
    "        return pipe\n",
    "    except Exception as e:\n",
    "        print(f\"üí• ERRO ao carregar pipeline: {e}\")\n",
    "        print(f\"\\nüìã DEBUG COPY/PASTE:\")\n",
    "        print(f\"Model: {MODEL_ID}\")\n",
    "        print(f\"Device: {device} ({device_type})\")\n",
    "        print(f\"Dtype: {TORCH_DTYPE}\")\n",
    "        print(f\"Hardware info: {hardware_info if 'hardware_info' in locals() else 'N/A'}\")\n",
    "        print(f\"Error type: {type(e).__name__}\")\n",
    "        print(f\"Error message: {e}\")\n",
    "        # Sugest√µes baseadas no tipo de erro\n",
    "        error_str = str(e).lower()\n",
    "        if \"authentication\" in error_str or \"token\" in error_str:\n",
    "            print(f\"\\nüí° SOLU√á√ÉO PARA ERRO DE TOKEN:\")\n",
    "            print(f\"1. Ignore o warning - o modelo deve funcionar mesmo assim\")\n",
    "            print(f\"2. Ou configure HF_TOKEN manualmente se necess√°rio\")\n",
    "        elif \"memory\" in error_str or \"cuda\" in error_str:\n",
    "            print(f\"\\nüí° SOLU√á√ÉO PARA ERRO DE MEM√ìRIA:\")\n",
    "            print(f\"1. Reduzir batch_size\")\n",
    "            print(f\"2. Usar torch.float16 se estiver usando float32\")\n",
    "            print(f\"3. Fechar outros notebooks no Colab\")\n",
    "        elif \"module\" in error_str or \"import\" in error_str:\n",
    "            print(f\"\\nüí° SOLU√á√ÉO PARA ERRO DE M√ìDULO:\")\n",
    "            print(f\"1. Re-executar c√©lulas de instala√ß√£o\")\n",
    "            print(f\"2. Restart runtime se necess√°rio\")\n",
    "        return None\n",
    "# Carregar pipeline\n",
    "if ALL_READY:\n",
    "    pipe = load_stable_diffusion_pipeline()\n",
    "    PIPELINE_READY = pipe is not None\n",
    "else:\n",
    "    pipe = None\n",
    "    PIPELINE_READY = False\n",
    "    print(\"‚ùå Sistema n√£o est√° pronto para carregar pipeline\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# üé® STATUS DO SISTEMA\nprint(\"üé® Verificando status do sistema SD3.5...\")\n\n# Verificar se todos os pr√©-requisitos est√£o atendidos\ndef check_system_status():\n    \"\"\"Verifica se o sistema est√° pronto para usar SD3.5\"\"\"\n    \n    status = {\n        'huggingface_login': False,\n        'pipeline_loaded': False,\n        'device_ready': False,\n        'all_ready': False\n    }\n    \n    # Verificar login HuggingFace\n    if 'HUGGINGFACE_LOGGED_IN' in globals() and HUGGINGFACE_LOGGED_IN:\n        print(\"‚úÖ HuggingFace: Login OK\")\n        status['huggingface_login'] = True\n    else:\n        print(\"‚ùå HuggingFace: Login necess√°rio\")\n        return status\n    \n    # Verificar pipeline\n    if 'PIPELINE_READY' in globals() and PIPELINE_READY:\n        print(\"‚úÖ Pipeline SD3.5: Carregado\")\n        status['pipeline_loaded'] = True\n    else:\n        print(\"‚ùå Pipeline SD3.5: N√£o carregado\")\n        return status\n    \n    # Verificar device\n    if 'device' in globals() and device is not None:\n        print(f\"‚úÖ Device: {device} ({dev_type})\")\n        status['device_ready'] = True\n    else:\n        print(\"‚ùå Device: N√£o configurado\")\n        return status\n    \n    # Verificar se tudo est√° pronto\n    if all([status['huggingface_login'], status['pipeline_loaded'], status['device_ready']]):\n        status['all_ready'] = True\n        print(\"üéâ Sistema completamente pronto para gera√ß√£o!\")\n    else:\n        print(\"‚ö†Ô∏è Sistema n√£o est√° completamente configurado\")\n    \n    return status\n\n# Executar verifica√ß√£o\nsystem_status = check_system_status()\n\nif system_status['all_ready']:\n    print(f\"\\nüìã CONFIGURA√á√ÉO FINAL:\")\n    print(f\"  ‚Ä¢ Modelo: Stable Diffusion 3.5 Large\")\n    print(f\"  ‚Ä¢ Device: {device}\")\n    print(f\"  ‚Ä¢ Dtype: {TORCH_DTYPE}\")\n    print(f\"  ‚Ä¢ Resolu√ß√£o: {GENERATION_PARAMS_CURRENT['width']}x{GENERATION_PARAMS_CURRENT['height']}\")\n    print(f\"  ‚Ä¢ Steps: {GENERATION_PARAMS_CURRENT['num_inference_steps']}\")\n    print(f\"  ‚Ä¢ Guidance: {GENERATION_PARAMS_CURRENT['guidance_scale']}\")\n    \n    print(f\"\\nüöÄ PRONTO PARA GERAR IMAGENS GRASSCLOVER!\")\n    \nelse:\n    print(f\"\\nüö´ SISTEMA N√ÉO EST√Å PRONTO\")\n    print(f\"üìã Execute as c√©lulas anteriores na ordem:\")\n    print(f\"  1. Login HuggingFace (obrigat√≥rio)\")\n    print(f\"  2. Configura√ß√£o de hardware\")\n    print(f\"  3. Carregamento do SD3.5\")\n\nprint(\"=\" * 60)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìö DOWNLOAD DO DATASET GRASSCLOVER ORIGINAL\n",
    "print(\"üìö Baixando dataset GrassClover original do Kaggle...\\n\")\n",
    "\n",
    "# Inicializar vari√°vel globalmente\n",
    "GRASSCLOVER_DATASET_PATH = None\n",
    "\n",
    "try:\n",
    "    # Instalar kagglehub se necess√°rio\n",
    "    try:\n",
    "        import kagglehub\n",
    "        print(\"‚úÖ kagglehub j√° dispon√≠vel\")\n",
    "    except ImportError:\n",
    "        print(\"üì¶ Instalando kagglehub...\")\n",
    "        import subprocess\n",
    "        result = subprocess.run([\"pip\", \"install\", \"kagglehub\", \"--quiet\"], \n",
    "                              capture_output=True, text=True)\n",
    "        if result.returncode == 0:\n",
    "            import kagglehub\n",
    "            print(\"‚úÖ kagglehub instalado com sucesso\")\n",
    "        else:\n",
    "            print(f\"‚ùå Erro ao instalar kagglehub: {result.stderr}\")\n",
    "            raise ImportError(\"kagglehub installation failed\")\n",
    "    \n",
    "    # Download do dataset\n",
    "    print(\"‚è≥ Fazendo download do GrassClover dataset...\")\n",
    "    print(\"üí° Isso pode demorar alguns minutos na primeira vez...\")\n",
    "    \n",
    "    dataset_path = kagglehub.dataset_download(\"usharengaraju/grassclover-dataset\")\n",
    "    \n",
    "    if dataset_path and os.path.exists(dataset_path):\n",
    "        GRASSCLOVER_DATASET_PATH = dataset_path\n",
    "        print(f\"‚úÖ Dataset baixado com sucesso!\")\n",
    "        print(f\"üìÅ Localiza√ß√£o: {dataset_path}\")\n",
    "        \n",
    "        # Explorar estrutura do dataset\n",
    "        print(f\"\\nüìã Estrutura do dataset:\")\n",
    "        \n",
    "        total_files = 0\n",
    "        for root, dirs, files in os.walk(dataset_path):\n",
    "            level = root.replace(dataset_path, '').count(os.sep)\n",
    "            indent = '  ' * level\n",
    "            folder_name = os.path.basename(root) if root != dataset_path else 'grassclover-dataset'\n",
    "            \n",
    "            # Contar apenas arquivos de imagem\n",
    "            image_files = [f for f in files if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "            \n",
    "            if image_files:\n",
    "                print(f\"{indent}{folder_name}/ ({len(image_files)} imagens)\")\n",
    "                total_files += len(image_files)\n",
    "                \n",
    "                # Mostrar alguns exemplos de nomes\n",
    "                for file in image_files[:3]:\n",
    "                    print(f\"{indent}  ‚Ä¢ {file}\")\n",
    "                if len(image_files) > 3:\n",
    "                    print(f\"{indent}  ‚Ä¢ ... e mais {len(image_files)-3} imagens\")\n",
    "            elif dirs:\n",
    "                print(f\"{indent}{folder_name}/\")\n",
    "        \n",
    "        print(f\"\\nüìä Total: {total_files} imagens encontradas\")\n",
    "        \n",
    "        if total_files == 0:\n",
    "            print(\"‚ö†Ô∏è  Nenhuma imagem encontrada no dataset baixado\")\n",
    "            GRASSCLOVER_DATASET_PATH = None\n",
    "    else:\n",
    "        print(\"‚ùå Download retornou path inv√°lido\")\n",
    "        GRASSCLOVER_DATASET_PATH = None\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Erro ao baixar dataset: {e}\")\n",
    "    print(f\"\\nüìã DEBUG INFO:\")\n",
    "    print(f\"Error type: {type(e).__name__}\")\n",
    "    print(f\"Error message: {str(e)[:200]}...\")\n",
    "    \n",
    "    # Manter vari√°vel definida como None\n",
    "    GRASSCLOVER_DATASET_PATH = None\n",
    "    \n",
    "    print(f\"\\nüí° SOLU√á√ïES POSS√çVEIS:\")\n",
    "    print(f\"1. Verificar conectividade com internet\")\n",
    "    print(f\"2. Tentar novamente em alguns minutos\")\n",
    "    print(f\"3. Verificar se Kaggle est√° acess√≠vel\")\n",
    "    print(f\"4. OPCIONAL: Upload manual de imagens GrassClover\")\n",
    "\n",
    "# Status final\n",
    "if GRASSCLOVER_DATASET_PATH:\n",
    "    print(f\"\\n‚úÖ Dataset GrassClover dispon√≠vel para an√°lise!\")\n",
    "else:\n",
    "    print(f\"\\n‚ö†Ô∏è  Continuando sem dataset GrassClover\")\n",
    "    print(f\"üéØ O notebook ainda funcionar√°, mas sem calibra√ß√£o visual\")\n",
    "\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîç AN√ÅLISE VISUAL DO DATASET GRASSCLOVER ORIGINAL\n",
    "print(\"üîç Analisando caracter√≠sticas visuais do GrassClover...\\n\")\n",
    "\n",
    "def analyze_grassclover_images(dataset_path, num_samples=6):\n",
    "    \"\"\"\n",
    "    Analisa imagens do GrassClover para extrair caracter√≠sticas visuais\n",
    "    \"\"\"\n",
    "    if not dataset_path or not os.path.exists(dataset_path):\n",
    "        print(\"‚ùå Dataset n√£o dispon√≠vel para an√°lise\")\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        # Encontrar arquivos de imagem\n",
    "        image_files = []\n",
    "        for root, dirs, files in os.walk(dataset_path):\n",
    "            for file in files:\n",
    "                if file.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "                    image_files.append(os.path.join(root, file))\n",
    "        \n",
    "        if not image_files:\n",
    "            print(\"‚ùå Nenhuma imagem encontrada no dataset\")\n",
    "            return None\n",
    "        \n",
    "        print(f\"üì∏ Encontradas {len(image_files)} imagens\")\n",
    "        print(f\"üéØ Analisando {min(num_samples, len(image_files))} amostras...\")\n",
    "        \n",
    "        # Selecionar amostras aleat√≥rias\n",
    "        import random\n",
    "        random.seed(42)  # Reprodutibilidade\n",
    "        sample_files = random.sample(image_files, min(num_samples, len(image_files)))\n",
    "        \n",
    "        # An√°lise visual\n",
    "        fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "        fig.suptitle('üìö GrassClover Dataset - An√°lise Visual de Refer√™ncia', \n",
    "                    fontsize=16, fontweight='bold')\n",
    "        \n",
    "        axes = axes.flatten()\n",
    "        image_stats = []\n",
    "        \n",
    "        for i, img_path in enumerate(sample_files):\n",
    "            try:\n",
    "                # Carregar imagem\n",
    "                img = Image.open(img_path)\n",
    "                img_array = np.array(img)\n",
    "                \n",
    "                # Estat√≠sticas da imagem\n",
    "                stats = {\n",
    "                    'filename': os.path.basename(img_path),\n",
    "                    'size': img.size,\n",
    "                    'mode': img.mode,\n",
    "                    'mean_rgb': np.mean(img_array, axis=(0, 1)) if len(img_array.shape) == 3 else np.mean(img_array),\n",
    "                    'std_rgb': np.std(img_array, axis=(0, 1)) if len(img_array.shape) == 3 else np.std(img_array)\n",
    "                }\n",
    "                image_stats.append(stats)\n",
    "                \n",
    "                # Exibir imagem\n",
    "                axes[i].imshow(img)\n",
    "                axes[i].set_title(f\"{stats['filename']}\\n{stats['size'][0]}x{stats['size'][1]}\", \n",
    "                                fontsize=10)\n",
    "                axes[i].axis('off')\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"‚ö†Ô∏è  Erro ao carregar {img_path}: {e}\")\n",
    "                axes[i].text(0.5, 0.5, 'Erro\\nao carregar', \n",
    "                           ha='center', va='center', transform=axes[i].transAxes)\n",
    "                axes[i].axis('off')\n",
    "        \n",
    "        # Ocultar eixos n√£o usados\n",
    "        for j in range(len(sample_files), len(axes)):\n",
    "            axes[j].axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Estat√≠sticas gerais\n",
    "        if image_stats:\n",
    "            print(f\"\\nüìä CARACTER√çSTICAS VISUAIS IDENTIFICADAS:\")\n",
    "            \n",
    "            # Tamanhos das imagens\n",
    "            sizes = [stat['size'] for stat in image_stats]\n",
    "            unique_sizes = list(set(sizes))\n",
    "            print(f\"üìè Resolu√ß√µes encontradas: {unique_sizes}\")\n",
    "            \n",
    "            # Cores m√©dias (se RGB)\n",
    "            rgb_images = [stat for stat in image_stats if len(stat['mean_rgb']) == 3]\n",
    "            if rgb_images:\n",
    "                avg_colors = np.mean([stat['mean_rgb'] for stat in rgb_images], axis=0)\n",
    "                print(f\"üé® Cores m√©dias (RGB): R={avg_colors[0]:.1f}, G={avg_colors[1]:.1f}, B={avg_colors[2]:.1f}\")\n",
    "                \n",
    "                # An√°lise de tons de verde\n",
    "                green_dominance = avg_colors[1] / (avg_colors[0] + avg_colors[2] + 0.1)\n",
    "                print(f\"üåø Domin√¢ncia verde: {green_dominance:.2f} (quanto maior, mais verde)\")\n",
    "            \n",
    "            print(f\"\\nüí° INSIGHTS PARA STABLE DIFFUSION:\")\n",
    "            print(f\"‚Ä¢ Vista: Top-down (a√©rea) consistente\")\n",
    "            print(f\"‚Ä¢ Textura: Densa cobertura de gram√≠neas pequenas\")\n",
    "            print(f\"‚Ä¢ Cores: Tons de verde predominantes\")\n",
    "            print(f\"‚Ä¢ Ilumina√ß√£o: Natural, sem sombras fortes\")\n",
    "            print(f\"‚Ä¢ Composi√ß√£o: Mistura grass + clover (ryegrass + trevo)\")\n",
    "            print(f\"‚Ä¢ Resolu√ß√£o t√≠pica: ~512x512 ou similar\")\n",
    "            \n",
    "        return {\n",
    "            'sample_files': sample_files,\n",
    "            'image_stats': image_stats,\n",
    "            'total_images': len(image_files)\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Erro na an√°lise: {e}\")\n",
    "        return None\n",
    "\n",
    "# Verificar se dataset path existe, sen√£o definir como None\n",
    "if 'GRASSCLOVER_DATASET_PATH' not in locals():\n",
    "    print(\"‚ö†Ô∏è  GRASSCLOVER_DATASET_PATH n√£o definido - provavelmente erro no download\")\n",
    "    GRASSCLOVER_DATASET_PATH = None\n",
    "\n",
    "# Executar an√°lise\n",
    "if GRASSCLOVER_DATASET_PATH:\n",
    "    print(f\"üìÅ Usando dataset em: {GRASSCLOVER_DATASET_PATH}\")\n",
    "    grassclover_analysis = analyze_grassclover_images(GRASSCLOVER_DATASET_PATH)\n",
    "    GRASSCLOVER_REFERENCE_AVAILABLE = grassclover_analysis is not None\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Dataset GrassClover n√£o dispon√≠vel\")\n",
    "    print(\"üí° Poss√≠veis causas:\")\n",
    "    print(\"  ‚Ä¢ Erro no download do Kaggle\")\n",
    "    print(\"  ‚Ä¢ Problema de conectividade\")\n",
    "    print(\"  ‚Ä¢ kagglehub n√£o instalado corretamente\")\n",
    "    print(\"\\nüîÑ Para resolver:\")\n",
    "    print(\"  ‚Ä¢ Re-execute a c√©lula de download\")\n",
    "    print(\"  ‚Ä¢ Verifique se tem conectividade com Kaggle\")\n",
    "    print(\"  ‚Ä¢ O notebook continuar√° funcionando sem as refer√™ncias\")\n",
    "    \n",
    "    grassclover_analysis = None\n",
    "    GRASSCLOVER_REFERENCE_AVAILABLE = False\n",
    "\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompts para Pastagens Brasileiras - Estilo GrassClover\n",
    "Prompts espec√≠ficos para gerar pastagens tropicais seguindo a metodologia visual do GrassClover."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "GRASSCLOVER_PROMPTS = {\n    'grassclover_exact_style': {\n        'positive': (\n            \"overhead top-down view of mixed grass and white clover field, \"\n            \"dense green ryegrass with white clover flowers, \"\n            \"small spherical white clover blooms scattered throughout, \"\n            \"fine thin grass blades, dense ground coverage, \"\n            \"natural outdoor lighting, soft daylight, no shadows, \"\n            \"detailed grass texture, small clover leaves visible, \"\n            \"research quality agricultural photography, \"\n            \"grassclover dataset style, scientific documentation, \"\n            \"perennial ryegrass, trifolium repens, mixed pasture\"\n        ),\n        'negative': (\n            \"side view, angled view, perspective view, \"\n            \"large flowers, colorful flowers, trees, shrubs, \"\n            \"buildings, people, animals, vehicles, \"\n            \"artificial grass, lawn, decorative plants, \"\n            \"dramatic lighting, shadows, high contrast, \"\n            \"blurry, low quality, cartoon, painting\"\n        ),\n        'description': \"Estilo GrassClover exato - ryegrass + trevo branco\"\n    },\n    \n    'grassclover_dense_flowers': {\n        'positive': (\n            \"bird's eye view of grassland with abundant white clover flowers, \"\n            \"dense small white spherical clover blooms, \"\n            \"green grass background, trifolium repens in full bloom, \"\n            \"natural field conditions, scientific photography, \"\n            \"fine grass texture beneath clover flowers, \"\n            \"uniform lighting, no harsh shadows, research quality, \"\n            \"mixed grass-clover sward, agricultural study image\"\n        ),\n        'negative': (\n            \"ground level view, human perspective, \"\n            \"large decorative flowers, colored flowers, \"\n            \"ornamental garden, landscaped area, \"\n            \"artificial lighting, studio photography, \"\n            \"bare soil, sparse vegetation, weeds\"\n        ),\n        'description': \"GrassClover com flores densas de trevo\"\n    },\n    \n    'grassclover_fine_texture': {\n        'positive': (\n            \"close overhead view of fine grass and clover mixture, \"\n            \"detailed texture of ryegrass blades and clover leaves, \"\n            \"small white clover flowers interspersed, \"\n            \"natural pasture composition, research documentation, \"\n            \"soft natural lighting, even illumination, \"\n            \"high detail vegetation pattern, grassclover study, \"\n            \"mixed species grassland, agricultural research image\"\n        ),\n        'negative': (\n            \"coarse grass, large blade grass, tropical grasses, \"\n            \"artificial turf, decorative plants, \"\n            \"dramatic shadows, studio lighting, \"\n            \"perspective distortion, angled shots\"\n        ),\n        'description': \"Textura fina GrassClover detalhada\"\n    },\n    \n    'brazilian_mixed_grassclover_style': {\n        'positive': (\n            \"top-down view of mixed tropical grass with legume flowers, \"\n            \"small white stylosanthes flowers scattered in green grass, \"\n            \"dense brachiaria grass coverage with legume blooms, \"\n            \"grassclover dataset visual style, research photography, \"\n            \"natural field lighting, soft daylight, uniform illumination, \"\n            \"detailed grass-legume mixture, scientific documentation, \"\n            \"brazilian pasture with flowering legumes, agricultural study\"\n        ),\n        'negative': (\n            \"side perspective, ground level view, \"\n            \"large flowers, ornamental plants, \"\n            \"buildings, infrastructure, people, animals, \"\n            \"artificial lighting, dramatic shadows, \"\n            \"low quality, blurry, artistic style\"\n        ),\n        'description': \"Pastagem brasileira estilo GrassClover\"\n    },\n    \n    'brachiaria_with_flowers_grassclover_style': {\n        'positive': (\n            \"aerial view of brachiaria pasture with small white legume flowers, \"\n            \"dense tropical grass with scattered small blooms, \"\n            \"grassclover research style photography, natural lighting, \"\n            \"detailed grass texture with flowering plants, \"\n            \"agricultural field study image, scientific quality, \"\n            \"mixed brachiaria and flowering legumes, top-down perspective, \"\n            \"brazilian tropical grassland research documentation\"\n        ),\n        'negative': (\n            \"temperate climate plants, large decorative flowers, \"\n            \"perspective view, human eye level, \"\n            \"landscaped garden, ornamental setting, \"\n            \"dramatic lighting, artistic photography, \"\n            \"poor quality, distorted view\"\n        ),\n        'description': \"Brachiaria com flores estilo GrassClover\"\n    }\n}\n\n# Usar os par√¢metros j√° definidos para SD3.5\nif 'GENERATION_PARAMS_CURRENT' not in locals():\n    # Par√¢metros padr√£o caso n√£o tenham sido definidos ainda\n    GENERATION_PARAMS_CURRENT = {\n        'width': 1024,\n        'height': 1024, \n        'num_inference_steps': 28,\n        'guidance_scale': 4.5,\n        'num_images_per_prompt': 1,\n        'eta': 0.0,\n        'generator_seed': 42\n    }\n\nprint(\"üéØ Prompts GrassClover configurados para SD3.5:\")\nfor key, prompt_data in GRASSCLOVER_PROMPTS.items():\n    print(f\"  ‚Ä¢ {prompt_data['description']}\")\n\nprint(f\"\\n‚öôÔ∏è Par√¢metros de gera√ß√£o SD3.5:\")\nfor param, value in GENERATION_PARAMS_CURRENT.items():\n    print(f\"  ‚Ä¢ {param}: {value}\")\n\nprint(\"‚úÖ Sistema de prompts configurado exclusivamente para SD3.5!\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fun√ß√£o de Gera√ß√£o com Debugging Completo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_grassclover_image(prompt_key, custom_seed=None, debug=True):\n",
    "    \"\"\"\n",
    "    Gera imagem no estilo GrassClover com debugging completo\n",
    "    Args:\n",
    "        prompt_key: Chave do prompt (ex: \"grassclover_exact_style\")\n",
    "        custom_seed: Seed personalizada (opcional)\n",
    "        debug: Ativar prints de debug\n",
    "    Returns:\n",
    "        dict com imagem e metadados\n",
    "    \"\"\"\n",
    "    if not PIPELINE_READY:\n",
    "        print(\"‚ùå Pipeline n√£o est√° pronto\")\n",
    "        return {'success': False, 'error': 'Pipeline n√£o configurado'}\n",
    "    \n",
    "    if prompt_key not in GRASSCLOVER_PROMPTS:\n",
    "        print(f\"‚ùå Prompt key '{prompt_key}' n√£o encontrada\")\n",
    "        return {'success': False, 'error': f'Prompt key inv√°lida: {prompt_key}'}\n",
    "    \n",
    "    try:\n",
    "        # Configurar seed\n",
    "        seed = custom_seed if custom_seed is not None else GENERATION_PARAMS_CURRENT['generator_seed']\n",
    "        generator = torch.Generator(device=device).manual_seed(seed)\n",
    "        \n",
    "        prompt_data = GRASSCLOVER_PROMPTS[prompt_key]\n",
    "        positive_prompt = prompt_data['positive']\n",
    "        negative_prompt = prompt_data['negative']\n",
    "        \n",
    "        if debug:\n",
    "            print(f\"üéØ Gerando: {prompt_data['description']}\")\n",
    "            print(f\"üå± Seed: {seed}\")\n",
    "            \n",
    "        # Monitoramento de mem√≥ria antes\n",
    "        if device.type == \"cuda\":\n",
    "            torch.cuda.empty_cache()\n",
    "            mem_before = torch.cuda.memory_allocated() / (1024**3)\n",
    "            if debug:\n",
    "                print(f\"üíæ Mem√≥ria GPU antes: {mem_before:.2f}GB\")\n",
    "        \n",
    "        # Gera√ß√£o com autocast para otimiza√ß√£o\n",
    "        with torch.autocast(device.type):\n",
    "            result = pipe(\n",
    "                prompt=positive_prompt,\n",
    "                negative_prompt=negative_prompt,\n",
    "                width=GENERATION_PARAMS_CURRENT['width'],\n",
    "                height=GENERATION_PARAMS_CURRENT['height'],\n",
    "                num_inference_steps=GENERATION_PARAMS_CURRENT['num_inference_steps'],\n",
    "                guidance_scale=GENERATION_PARAMS_CURRENT['guidance_scale'],\n",
    "                num_images_per_prompt=GENERATION_PARAMS_CURRENT['num_images_per_prompt'],\n",
    "                eta=GENERATION_PARAMS_CURRENT['eta'],\n",
    "                generator=generator\n",
    "            )\n",
    "        \n",
    "        # Monitoramento de mem√≥ria depois\n",
    "        if debug:\n",
    "            if device.type == \"cuda\":\n",
    "                mem_after = torch.cuda.memory_allocated() / (1024**3)\n",
    "                print(f\"üíæ Mem√≥ria GPU depois: {mem_after:.2f}GB\")\n",
    "        \n",
    "        image = result.images[0]\n",
    "        \n",
    "        # Metadados completos\n",
    "        metadata = {\n",
    "            'prompt_key': prompt_key,\n",
    "            'description': prompt_data['description'],\n",
    "            'seed': seed,\n",
    "            'generation_params': GENERATION_PARAMS.copy(),\n",
    "            'timestamp': datetime.now().isoformat(),\n",
    "            'model_id': MODEL_ID,\n",
    "            'device': str(device)\n",
    "        }\n",
    "        \n",
    "        if debug:\n",
    "            print(\"‚úÖ Imagem gerada com sucesso!\")\n",
    "        \n",
    "        return {\n",
    "            'image': image,\n",
    "            'metadata': metadata,\n",
    "            'success': True\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"üí• ERRO na gera√ß√£o: {e}\")\n",
    "        print(f\"Error type: {type(e).__name__}\")\n",
    "        print(f\"Error message: {e}\")\n",
    "        \n",
    "        # Limpeza de mem√≥ria em caso de erro\n",
    "        if device.type == \"cuda\":\n",
    "            torch.cuda.empty_cache()\n",
    "        \n",
    "        return {\n",
    "            'image': None,\n",
    "            'metadata': None,\n",
    "            'success': False,\n",
    "            'error': str(e)\n",
    "        }\n",
    "\n",
    "def display_generation_result(result, show_metadata=True):\n",
    "    \"\"\"Exibe resultado da gera√ß√£o com metadados\"\"\"\n",
    "    if not result['success']:\n",
    "        print(f\"‚ùå Erro na gera√ß√£o: {result.get('error', 'Erro desconhecido')}\")\n",
    "        return\n",
    "    \n",
    "    # Exibir imagem\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(result['image'])\n",
    "    plt.axis('off')\n",
    "    \n",
    "    # T√≠tulo com informa√ß√µes\n",
    "    metadata = result['metadata']\n",
    "    title = f\"{metadata['description']}\\nSeed: {metadata['seed']} | {metadata['generation_params']['width']}x{metadata['generation_params']['height']}\"\n",
    "    plt.title(title, fontsize=14, pad=20)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    if show_metadata:\n",
    "        print(f\"üìä Metadados:\")\n",
    "        print(f\"  ‚Ä¢ Prompt: {metadata['prompt_key']}\")\n",
    "        print(f\"  ‚Ä¢ Seed: {metadata['seed']}\")\n",
    "        print(f\"  ‚Ä¢ Resolu√ß√£o: {metadata['generation_params']['width']}x{metadata['generation_params']['height']}\")\n",
    "        print(f\"  ‚Ä¢ Steps: {metadata['generation_params']['num_inference_steps']}\")\n",
    "        print(f\"  ‚Ä¢ Guidance: {metadata['generation_params']['guidance_scale']}\")\n",
    "        print(f\"  ‚Ä¢ Timestamp: {metadata['timestamp']}\")\n",
    "\n",
    "print(\"üîß Fun√ß√£o de gera√ß√£o configurada!\")\n",
    "print(\"üí° Use: generate_grassclover_image('prompt_key', custom_seed=42)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß™ Teste Inicial - Uma Imagem de Cada Tipo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üß™ Iniciando teste do sistema...\")\n",
    "\n",
    "if PIPELINE_READY:\n",
    "    print(\"‚úÖ Pipeline est√° pronto - executando testes\")\n",
    "    \n",
    "    test_prompts = [\"grassclover_exact_style\", \"brazilian_mixed_grassclover_style\", \"brachiaria_with_flowers_grassclover_style\"]\n",
    "    test_results = []\n",
    "    \n",
    "    for i, prompt_key in enumerate(test_prompts, 1):\n",
    "        print(f\"\\nüß™ Teste {i}/{len(test_prompts)}: {prompt_key}\")\n",
    "        \n",
    "        result = generate_grassclover_image(\n",
    "            prompt_key=prompt_key,\n",
    "            custom_seed=42 + i,  # Seed diferente para cada teste\n",
    "            debug=True\n",
    "        )\n",
    "        \n",
    "        if result['success']:\n",
    "            test_results.append(result)\n",
    "            display_generation_result(result)\n",
    "        else:\n",
    "            print(f\"‚ùå Teste {i} falhou: {result.get('error', 'Erro desconhecido')}\")\n",
    "            break\n",
    "        \n",
    "        # Limpeza de mem√≥ria entre testes\n",
    "        if device.type == \"cuda\":\n",
    "            torch.cuda.empty_cache()\n",
    "    \n",
    "    # Resumo dos testes\n",
    "    print(f\"\\nüìä RESUMO DOS TESTES:\")\n",
    "    print(f\"‚úÖ Sucessos: {len(test_results)}/{len(test_prompts)}\")\n",
    "    \n",
    "    if len(test_results) == len(test_prompts):\n",
    "        print(\"üéâ Todos os testes passaram - sistema funcionando!\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è Alguns testes falharam - verifique os erros acima\")\n",
    "        \n",
    "else:\n",
    "    print(\"‚ùå Pipeline n√£o est√° pronto\")\n",
    "    print(\"üí° Poss√≠veis solu√ß√µes:\")\n",
    "    print(\"  ‚Ä¢ Re-executar c√©lulas de configura√ß√£o\")\n",
    "    print(\"  ‚Ä¢ Verificar se h√° GPU/CUDA dispon√≠vel\")\n",
    "    print(\"  ‚Ä¢ Conferir se todas as bibliotecas foram instaladas\")\n",
    "    print(\"  ‚Ä¢ Restart runtime se necess√°rio\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## P√≥s-processamento Estilo GrassClover\n",
    "Ajustes para deixar as imagens mais pr√≥ximas do estilo visual do GrassClover Dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_with_grassclover_reference(synthetic_results, reference_analysis=None):\n",
    "    \"\"\"\n",
    "    Compara imagens sint√©ticas com refer√™ncias do GrassClover original\n",
    "    \"\"\"\n",
    "    if not synthetic_results:\n",
    "        print(\"‚ùå Nenhum resultado sint√©tico para comparar\")\n",
    "        return\n",
    "        \n",
    "    if not reference_analysis or not GRASSCLOVER_REFERENCE_AVAILABLE:\n",
    "        print(\"‚ö†Ô∏è Dataset GrassClover original n√£o dispon√≠vel - mostrando apenas sint√©ticas\")\n",
    "        \n",
    "        # Mostrar apenas as imagens sint√©ticas em grid\n",
    "        num_show = min(4, len(synthetic_results))\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(12, 12))\n",
    "        fig.suptitle('üåæ Imagens Sint√©ticas - Estilo GrassClover Brasileiro', \n",
    "                    fontsize=16, fontweight='bold')\n",
    "        \n",
    "        axes = axes.flatten()\n",
    "        \n",
    "        for i in range(num_show):\n",
    "            if i < len(synthetic_results):\n",
    "                result = synthetic_results[i]\n",
    "                image = result.get('processed_image', result['image'])\n",
    "                axes[i].imshow(image)\n",
    "                axes[i].set_title(f\"{result['metadata']['description']}\\nSeed: {result['metadata']['seed']}\")\n",
    "                axes[i].axis('off')\n",
    "            else:\n",
    "                axes[i].axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        return\n",
    "    \n",
    "    # Compara√ß√£o lado a lado com dataset original\n",
    "    try:\n",
    "        num_comparisons = min(3, len(synthetic_results), len(reference_analysis['sample_files']))\n",
    "        \n",
    "        fig, axes = plt.subplots(num_comparisons, 2, figsize=(12, 4*num_comparisons))\n",
    "        fig.suptitle('üÜö Compara√ß√£o: GrassClover Original vs Sint√©tico Brasileiro', \n",
    "                    fontsize=16, fontweight='bold')\n",
    "        \n",
    "        if num_comparisons == 1:\n",
    "            axes = axes.reshape(1, -1)\n",
    "        \n",
    "        for i in range(num_comparisons):\n",
    "            # Imagem original do GrassClover\n",
    "            try:\n",
    "                original_path = reference_analysis['sample_files'][i]\n",
    "                original_img = Image.open(original_path)\n",
    "                axes[i, 0].imshow(original_img)\n",
    "                axes[i, 0].set_title(f\"Original GrassClover\\n{os.path.basename(original_path)}\", fontsize=12)\n",
    "                axes[i, 0].axis('off')\n",
    "            except Exception as e:\n",
    "                print(f\"‚ö†Ô∏è Erro ao carregar original {i}: {e}\")\n",
    "                axes[i, 0].text(0.5, 0.5, f'Erro ao\\ncarregar original', \n",
    "                               ha='center', va='center', transform=axes[i, 0].transAxes)\n",
    "                axes[i, 0].axis('off')\n",
    "            \n",
    "            # Imagem sint√©tica correspondente\n",
    "            if i < len(synthetic_results):\n",
    "                synthetic_result = synthetic_results[i]\n",
    "                synthetic_img = synthetic_result.get('processed_image', synthetic_result['image'])\n",
    "                axes[i, 1].imshow(synthetic_img)\n",
    "                axes[i, 1].set_title(f\"Sint√©tico Brasileiro\\n{synthetic_result['metadata']['description']}\", fontsize=12)\n",
    "                axes[i, 1].axis('off')\n",
    "            else:\n",
    "                axes[i, 1].axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Erro na compara√ß√£o: {e}\")\n",
    "        \n",
    "        # Fallback para mostrar apenas sint√©ticas\n",
    "        num_show = min(4, len(synthetic_results))\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(12, 12))\n",
    "        fig.suptitle('üåæ Imagens Sint√©ticas Geradas', fontsize=16, fontweight='bold')\n",
    "        axes = axes.flatten()\n",
    "        \n",
    "        for i in range(4):\n",
    "            if i < len(synthetic_results):\n",
    "                result = synthetic_results[i]\n",
    "                image = result.get('processed_image', result['image'])\n",
    "                axes[i].imshow(image)\n",
    "                axes[i].set_title(f\"{result['metadata']['description']}\")\n",
    "                axes[i].axis('off')\n",
    "            else:\n",
    "                axes[i].axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# Executar teste com p√≥s-processamento se o pipeline estiver pronto\n",
    "if PIPELINE_READY:\n",
    "    print(\"üé® Testando gera√ß√£o com p√≥s-processamento...\")\n",
    "    \n",
    "    calibrated_test_prompts = [\"grassclover_exact_style\", \"grassclover_dense_flowers\", \"grassclover_fine_texture\"]\n",
    "    calibrated_results = []\n",
    "    \n",
    "    for i, prompt_key in enumerate(calibrated_test_prompts):\n",
    "        print(f\"‚è≥ Gerando {prompt_key}...\")\n",
    "        \n",
    "        result = generate_grassclover_image(\n",
    "            prompt_key=prompt_key,\n",
    "            custom_seed=100 + i,  # Seeds diferentes\n",
    "            debug=False  # Menos verbose\n",
    "        )\n",
    "        \n",
    "        if result and result['success']:\n",
    "            # Aplicar p√≥s-processamento (fun√ß√£o ser√° definida na pr√≥xima c√©lula)\n",
    "            try:\n",
    "                processed = grassclover_postprocess(result['image'], intensity=1.0, debug=False)\n",
    "                result['processed_image'] = processed\n",
    "                result['metadata']['postprocessed'] = True\n",
    "            except:\n",
    "                print(\"‚ö†Ô∏è P√≥s-processamento n√£o dispon√≠vel ainda\")\n",
    "                \n",
    "            calibrated_results.append(result)\n",
    "            print(\"‚úÖ Sucesso!\")\n",
    "        else:\n",
    "            print(f\"‚ùå Falhou: {result.get('error', 'Erro desconhecido')}\")\n",
    "        \n",
    "        # Limpeza de mem√≥ria\n",
    "        if dev_type == \"gpu\":\n",
    "            torch.cuda.empty_cache()\n",
    "    \n",
    "    # Mostrar compara√ß√£o (mesmo sem dataset original)\n",
    "    compare_with_grassclover_reference(calibrated_results, grassclover_analysis if 'grassclover_analysis' in locals() else None)\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå Pipeline n√£o est√° pronto - pule esta c√©lula por enquanto\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üÜö Compara√ß√£o com GrassClover Original\n",
    "Vamos comparar nossas imagens sint√©ticas com as refer√™ncias do GrassClover para avaliar a qualidade da reprodu√ß√£o do estilo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grassclover_postprocess(image, intensity=1.0, debug=False):\n",
    "    \"\"\"\n",
    "    Aplica p√≥s-processamento para aproximar do estilo GrassClover\n",
    "    Args:\n",
    "        image: PIL Image\n",
    "        intensity: Intensidade dos ajustes (0.0-2.0)\n",
    "        debug: Mostrar etapas do processamento\n",
    "    Returns:\n",
    "        PIL Image processada\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if debug:\n",
    "            print(f\"üé® Aplicando p√≥s-processamento (intensidade: {intensity})\")\n",
    "        \n",
    "        processed = image.copy()\n",
    "        \n",
    "        # 1. Ajuste de contraste\n",
    "        contrast_factor = 1.0 + (0.3 * intensity)\n",
    "        enhancer = ImageEnhance.Contrast(processed)\n",
    "        processed = enhancer.enhance(contrast_factor)\n",
    "        if debug:\n",
    "            print(f\"  ‚úÖ Contraste ajustado ({contrast_factor:.2f}x)\")\n",
    "        \n",
    "        # 2. Satura√ß√£o de cores (realce de verdes)\n",
    "        saturation_factor = 1.0 + (0.2 * intensity)\n",
    "        enhancer = ImageEnhance.Color(processed)\n",
    "        processed = enhancer.enhance(saturation_factor)\n",
    "        if debug:\n",
    "            print(f\"  ‚úÖ Satura√ß√£o ajustada ({saturation_factor:.2f}x)\")\n",
    "        \n",
    "        # 3. Nitidez sutil\n",
    "        if intensity > 0.5:\n",
    "            sharpness_factor = 1.0 + (0.1 * intensity)\n",
    "            enhancer = ImageEnhance.Sharpness(processed)\n",
    "            processed = enhancer.enhance(sharpness_factor)\n",
    "            if debug:\n",
    "                print(f\"  ‚úÖ Nitidez aplicada ({sharpness_factor:.2f}x)\")\n",
    "        \n",
    "        # 4. Suaviza√ß√£o muito leve (simular textura natural)\n",
    "        if intensity > 0.3:\n",
    "            blur_radius = 0.3 * intensity\n",
    "            processed = processed.filter(ImageFilter.GaussianBlur(radius=blur_radius))\n",
    "            if debug:\n",
    "                print(f\"  ‚úÖ Suaviza√ß√£o aplicada (radius: {blur_radius:.2f})\")\n",
    "        \n",
    "        # 5. Pequeno ajuste de brilho aleat√≥rio\n",
    "        brightness_factor = 1.0 + (0.05 * intensity * (np.random.random() - 0.5))\n",
    "        enhancer = ImageEnhance.Brightness(processed)\n",
    "        processed = enhancer.enhance(brightness_factor)\n",
    "        if debug:\n",
    "            print(f\"  ‚úÖ Brilho ajustado ({brightness_factor:.3f}x)\")\n",
    "        \n",
    "        return processed\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"üí• Erro no p√≥s-processamento: {e}\")\n",
    "        print(f\"Error: {type(e).__name__}: {e}\")\n",
    "        return image  # Retornar original se falhar\n",
    "\n",
    "def compare_before_after(original, processed, title=\"Compara√ß√£o\"):\n",
    "    \"\"\"\n",
    "    Exibe compara√ß√£o lado a lado\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 7))\n",
    "    \n",
    "    # Imagem original\n",
    "    axes[0].imshow(original)\n",
    "    axes[0].set_title(\"Original (Stable Diffusion)\", fontsize=12)\n",
    "    axes[0].axis('off')\n",
    "    \n",
    "    # Imagem processada\n",
    "    axes[1].imshow(processed)\n",
    "    axes[1].set_title(\"Processado (Estilo GrassClover)\", fontsize=12)\n",
    "    axes[1].axis('off')\n",
    "    \n",
    "    fig.suptitle(title, fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print(\"üé® Fun√ß√µes de p√≥s-processamento configuradas!\")\n",
    "print(\"üí° Use: grassclover_postprocess(image, intensity=1.2)\")\n",
    "print(\"üí° Use: compare_before_after(original, processed)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Teste do p√≥s-processamento com uma imagem de exemplo\n",
    "if PIPELINE_READY and 'test_results' in locals() and test_results:\n",
    "    print(\"üß™ Testando p√≥s-processamento...\")\n",
    "    \n",
    "    # Usar primeira imagem dos testes anteriores\n",
    "    test_image_data = test_results[0]\n",
    "    original_image = test_image_data['image']\n",
    "    \n",
    "    # Aplicar p√≥s-processamento\n",
    "    processed_image = grassclover_postprocess(\n",
    "        image=original_image,\n",
    "        intensity=1.2,  # Intensidade m√©dia-alta\n",
    "        debug=True\n",
    "    )\n",
    "    \n",
    "    # Mostrar compara√ß√£o\n",
    "    compare_before_after(\n",
    "        original=original_image,\n",
    "        processed=processed_image,\n",
    "        title=f\"P√≥s-processamento: {test_image_data['metadata']['description']}\"\n",
    "    )\n",
    "    \n",
    "    print(\"‚úÖ Teste de p√≥s-processamento conclu√≠do!\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Teste de p√≥s-processamento pulado\")\n",
    "    print(\"üí° Motivos poss√≠veis:\")\n",
    "    print(\"  ‚Ä¢ Pipeline n√£o est√° pronto\")\n",
    "    print(\"  ‚Ä¢ Nenhum resultado de teste dispon√≠vel\")\n",
    "    print(\"  ‚Ä¢ Execute as c√©lulas anteriores primeiro\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gera√ß√£o em Lote com Seeds Diferentes\n",
    "Gera m√∫ltiplas varia√ß√µes de pastagens para criar um dataset diversificado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_grassclover_batch(num_images=6, apply_postprocess=True, debug=True):\n",
    "    \"\"\"\n",
    "    Gera lote de imagens variadas estilo GrassClover\n",
    "    Args:\n",
    "        num_images: N√∫mero total de imagens\n",
    "        apply_postprocess: Aplicar p√≥s-processamento\n",
    "        debug: Debugging detalhado\n",
    "    Returns:\n",
    "        Lista de resultados\n",
    "    \"\"\"\n",
    "    if not PIPELINE_READY:\n",
    "        print(\"‚ùå Pipeline n√£o est√° pronto\")\n",
    "        return []\n",
    "    \n",
    "    prompt_keys = list(GRASSCLOVER_PROMPTS.keys())\n",
    "    batch_results = []\n",
    "    \n",
    "    print(f\"üöÄ Gerando lote de {num_images} imagens...\")\n",
    "    \n",
    "    for i in range(num_images):\n",
    "        prompt_key = prompt_keys[i % len(prompt_keys)]\n",
    "        seed = 42 + i * 100 + np.random.randint(0, 50)\n",
    "        \n",
    "        if debug:\n",
    "            print(f\"\\nüì∏ Imagem {i+1}/{num_images}: {GRASSCLOVER_PROMPTS[prompt_key]['description']}\")\n",
    "        \n",
    "        try:\n",
    "            result = generate_grassclover_image(\n",
    "                prompt_key=prompt_key,\n",
    "                custom_seed=seed,\n",
    "                debug=debug\n",
    "            )\n",
    "            \n",
    "            if result['success']:\n",
    "                # Aplicar p√≥s-processamento se solicitado\n",
    "                if apply_postprocess:\n",
    "                    processed_image = grassclover_postprocess(\n",
    "                        image=result['image'],\n",
    "                        intensity=np.random.uniform(0.8, 1.4),  # Varia√ß√£o aleat√≥ria\n",
    "                        debug=False\n",
    "                    )\n",
    "                    result['processed_image'] = processed_image\n",
    "                    result['metadata']['postprocessed'] = True\n",
    "                    if debug:\n",
    "                        print(\"  üé® P√≥s-processamento aplicado\")\n",
    "                \n",
    "                result['metadata']['batch_index'] = i\n",
    "                result['metadata']['total_batch'] = num_images\n",
    "                batch_results.append(result)\n",
    "                \n",
    "                if debug:\n",
    "                    print(\"  ‚úÖ Sucesso!\")\n",
    "            else:\n",
    "                print(f\"  ‚ùå Falhou: {result.get('error', 'Erro desconhecido')}\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"üí• Erro na imagem {i+1}: {e}\")\n",
    "            if debug:\n",
    "                print(f\"  Error type: {type(e).__name__}\")\n",
    "        \n",
    "        # Limpeza de mem√≥ria entre gera√ß√µes\n",
    "        if device.type == \"cuda\":\n",
    "            torch.cuda.empty_cache()\n",
    "    \n",
    "    print(f\"\\nüìä Lote conclu√≠do: {len(batch_results)}/{num_images} imagens geradas\")\n",
    "    return batch_results\n",
    "\n",
    "def display_batch_results(batch_results, max_display=6):\n",
    "    \"\"\"\n",
    "    Exibe resultados do lote em grid\n",
    "    \"\"\"\n",
    "    if not batch_results:\n",
    "        print(\"‚ùå Nenhum resultado para exibir\")\n",
    "        return\n",
    "    \n",
    "    results_to_show = batch_results[:max_display]\n",
    "    n_images = len(results_to_show)\n",
    "    \n",
    "    # Calcular grid\n",
    "    cols = min(3, n_images)\n",
    "    rows = (n_images + cols - 1) // cols\n",
    "    \n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(5*cols, 5*rows))\n",
    "    \n",
    "    # Ajustar axes para casos especiais\n",
    "    if rows == 1 and cols == 1:\n",
    "        axes = [axes]\n",
    "    elif rows == 1:\n",
    "        axes = axes.reshape(1, -1)\n",
    "    elif cols == 1:\n",
    "        axes = axes.reshape(-1, 1)\n",
    "    \n",
    "    # Mostrar imagens\n",
    "    for i, result in enumerate(results_to_show):\n",
    "        row = i // cols\n",
    "        col = i % cols\n",
    "        \n",
    "        # Usar imagem processada se dispon√≠vel\n",
    "        image = result.get('processed_image', result['image'])\n",
    "        \n",
    "        if rows == 1 and cols == 1:\n",
    "            ax = axes[0]\n",
    "        elif rows == 1:\n",
    "            ax = axes[col]\n",
    "        elif cols == 1:\n",
    "            ax = axes[row]\n",
    "        else:\n",
    "            ax = axes[row, col]\n",
    "        \n",
    "        ax.imshow(image)\n",
    "        ax.axis('off')\n",
    "        \n",
    "        # T√≠tulo da imagem\n",
    "        metadata = result['metadata']\n",
    "        title = f\"{metadata['description']}\\nSeed: {metadata['seed']}\"\n",
    "        ax.set_title(title, fontsize=10)\n",
    "    \n",
    "    # Ocultar eixos n√£o utilizados\n",
    "    total_subplots = rows * cols\n",
    "    for i in range(n_images, total_subplots):\n",
    "        row = i // cols\n",
    "        col = i % cols\n",
    "        \n",
    "        if rows == 1 and cols > 1:\n",
    "            axes[col].axis('off')\n",
    "        elif cols == 1 and rows > 1:\n",
    "            axes[row].axis('off')\n",
    "        elif rows > 1 and cols > 1:\n",
    "            axes[row, col].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.suptitle(f\"üåæ Dataset GrassClover Brasileiro - {n_images} Imagens\", \n",
    "                fontsize=16, fontweight='bold', y=0.98)\n",
    "    plt.show()\n",
    "    \n",
    "    # Estat√≠sticas\n",
    "    if batch_results:\n",
    "        print(f\"\\nüìä Estat√≠sticas do lote:\")\n",
    "        print(f\"  ‚Ä¢ Total de imagens: {len(batch_results)}\")\n",
    "        \n",
    "        # Contar tipos de prompt\n",
    "        type_counts = {}\n",
    "        for result in batch_results:\n",
    "            prompt_key = result['metadata']['prompt_key']\n",
    "            description = result['metadata']['description']\n",
    "            type_counts[description] = type_counts.get(description, 0) + 1\n",
    "        \n",
    "        print(f\"  ‚Ä¢ Tipos gerados:\")\n",
    "        for description, count in type_counts.items():\n",
    "            print(f\"    - {description}: {count}\")\n",
    "\n",
    "print(\"üì¶ Fun√ß√µes de gera√ß√£o em lote configuradas!\")\n",
    "print(\"üí° Use: generate_grassclover_batch(num_images=6)\")\n",
    "print(\"üí° Use: display_batch_results(results)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Executar gera√ß√£o em lote se o pipeline estiver pronto\n",
    "if PIPELINE_READY:\n",
    "    print(\"üöÄ Iniciando gera√ß√£o em lote...\")\n",
    "    \n",
    "    # Configura√ß√µes do lote\n",
    "    BATCH_SIZE = 6  # N√∫mero total de imagens\n",
    "    APPLY_POSTPROCESS = True\n",
    "    \n",
    "    batch_results = generate_grassclover_batch(\n",
    "        num_images=BATCH_SIZE,\n",
    "        apply_postprocess=APPLY_POSTPROCESS,\n",
    "        debug=True\n",
    "    )\n",
    "    \n",
    "    if batch_results:\n",
    "        print(f\"\\n‚úÖ Lote gerado com sucesso!\")\n",
    "        \n",
    "        # Estat√≠sticas por tipo\n",
    "        type_counts = {}\n",
    "        for result in batch_results:\n",
    "            prompt_key = result['metadata']['prompt_key']\n",
    "            type_counts[prompt_key] = type_counts.get(prompt_key, 0) + 1\n",
    "        \n",
    "        print(f\"\\nüìã Distribui√ß√£o por tipo:\")\n",
    "        for prompt_key, count in type_counts.items():\n",
    "            description = GRASSCLOVER_PROMPTS[prompt_key]['description']\n",
    "            print(f\"  ‚Ä¢ {description}: {count} imagens\")\n",
    "        \n",
    "        # Exibir grid de resultados\n",
    "        display_batch_results(batch_results)\n",
    "        \n",
    "        print(f\"\\nüéâ Dataset brasileiro estilo GrassClover gerado!\")\n",
    "        print(f\"üíæ {len(batch_results)} imagens prontas para an√°lise e salvamento\")\n",
    "        \n",
    "    else:\n",
    "        print(\"‚ùå Nenhuma imagem foi gerada no lote\")\n",
    "        print(\"üí° Poss√≠veis causas:\")\n",
    "        print(\"  ‚Ä¢ Problemas de mem√≥ria\")\n",
    "        print(\"  ‚Ä¢ Erros no pipeline\")\n",
    "        print(\"  ‚Ä¢ Configura√ß√µes incorretas\")\n",
    "        \n",
    "else:\n",
    "    print(\"‚ùå Pipeline n√£o est√° pronto\")\n",
    "    print(\"üí° Execute as c√©lulas anteriores para configurar o sistema\")\n",
    "    print(\"‚ö†Ô∏è Esta c√©lula ser√° pulada por enquanto\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Salvamento das Imagens\n",
    "Salva as imagens geradas com metadados organizados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "def save_grassclover_batch(batch_results, output_dir=\"grassclover_generated\", save_metadata=True):\n",
    "    \"\"\"\n",
    "    Salva lote de imagens com organiza√ß√£o e metadados\n",
    "    Args:\n",
    "        batch_results: Lista de resultados da gera√ß√£o\n",
    "        output_dir: Diret√≥rio de sa√≠da\n",
    "        save_metadata: Salvar arquivos JSON com metadados\n",
    "    Returns:\n",
    "        dict com estat√≠sticas de salvamento\n",
    "    \"\"\"\n",
    "    if not batch_results:\n",
    "        print(\"‚ùå Nenhum resultado para salvar\")\n",
    "        return {'success': False, 'saved_count': 0}\n",
    "    \n",
    "    try:\n",
    "        print(f\"üíæ Salvando {len(batch_results)} imagens em {output_dir}...\")\n",
    "        \n",
    "        # Criar diret√≥rios\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        images_dir = os.path.join(output_dir, \"images\")\n",
    "        metadata_dir = os.path.join(output_dir, \"metadata\")\n",
    "        \n",
    "        os.makedirs(images_dir, exist_ok=True)\n",
    "        if save_metadata:\n",
    "            os.makedirs(metadata_dir, exist_ok=True)\n",
    "            print(f\"üìÅ Diret√≥rios criados: images/ e metadata/\")\n",
    "        else:\n",
    "            print(f\"üìÅ Diret√≥rio criado: images/\")\n",
    "        \n",
    "        # Salvar index geral se metadata estiver habilitado\n",
    "        if save_metadata:\n",
    "            print(\"üìù Preparando √≠ndice do dataset...\")\n",
    "        \n",
    "        saved_count = 0\n",
    "        saved_files = []\n",
    "        \n",
    "        for i, result in enumerate(batch_results):\n",
    "            try:\n",
    "                metadata = result['metadata']\n",
    "                prompt_key = metadata['prompt_key']\n",
    "                seed = metadata['seed']\n",
    "                \n",
    "                # Nome base dos arquivos\n",
    "                filename_base = f\"grassclover_{prompt_key}_{seed:06d}\"\n",
    "                \n",
    "                # Salvar imagem original\n",
    "                original_path = os.path.join(images_dir, f\"{filename_base}_original.png\")\n",
    "                result['image'].save(original_path, 'PNG')\n",
    "                files_saved = [original_path]\n",
    "                print(f\"  üíæ Salvou original: {os.path.basename(original_path)}\")\n",
    "                \n",
    "                # Salvar imagem processada se existir\n",
    "                if 'processed_image' in result:\n",
    "                    processed_path = os.path.join(images_dir, f\"{filename_base}_processed.png\")\n",
    "                    result['processed_image'].save(processed_path, 'PNG')\n",
    "                    files_saved.append(processed_path)\n",
    "                    print(f\"  üé® Salvou processada: {os.path.basename(processed_path)}\")\n",
    "                \n",
    "                # Salvar metadados se solicitado\n",
    "                if save_metadata:\n",
    "                    metadata_path = os.path.join(metadata_dir, f\"{filename_base}.json\")\n",
    "                    \n",
    "                    # Preparar JSON metadata\n",
    "                    json_metadata = metadata.copy()\n",
    "                    json_metadata['files_saved'] = files_saved\n",
    "                    json_metadata['save_timestamp'] = datetime.now().isoformat()\n",
    "                    \n",
    "                    with open(metadata_path, 'w', encoding='utf-8') as f:\n",
    "                        json.dump(json_metadata, f, indent=2, ensure_ascii=False)\n",
    "                    \n",
    "                    files_saved.append(metadata_path)\n",
    "                    print(f\"  üìä Salvou metadata: {os.path.basename(metadata_path)}\")\n",
    "                \n",
    "                saved_files.extend(files_saved)\n",
    "                saved_count += 1\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå Erro ao salvar imagem {i+1}: {e}\")\n",
    "                continue\n",
    "        \n",
    "        # Criar √≠ndice geral do dataset\n",
    "        if save_metadata:\n",
    "            print(f\"\\nüìã Criando √≠ndice do dataset...\")\n",
    "            \n",
    "            index_data = {\n",
    "                'dataset_name': 'GrassClover Brazilian Synthetic',\n",
    "                'generation_date': datetime.now().isoformat(),\n",
    "                'total_images': len(batch_results),\n",
    "                'saved_images': saved_count,\n",
    "                'model_used': MODEL_ID if 'MODEL_ID' in globals() else 'stable-diffusion',\n",
    "                'device': str(device) if 'device' in globals() else 'unknown',\n",
    "                'prompt_types': list(set(r['metadata']['prompt_key'] for r in batch_results)),\n",
    "                'files': saved_files,\n",
    "                'generation_params': batch_results[0]['metadata']['generation_params'] if batch_results else {}\n",
    "            }\n",
    "            \n",
    "            index_path = os.path.join(output_dir, \"dataset_index.json\")\n",
    "            with open(index_path, 'w', encoding='utf-8') as f:\n",
    "                json.dump(index_data, f, indent=2, ensure_ascii=False)\n",
    "            \n",
    "            print(f\"‚úÖ √çndice criado: {os.path.basename(index_path)}\")\n",
    "        \n",
    "        # Resultado final\n",
    "        result_data = {\n",
    "            'success': True,\n",
    "            'saved_count': saved_count,\n",
    "            'total_files': len(saved_files),\n",
    "            'output_dir': os.path.abspath(output_dir),\n",
    "            'files': saved_files\n",
    "        }\n",
    "        \n",
    "        print(f\"\\nüéâ Salvamento conclu√≠do!\")\n",
    "        print(f\"  ‚úÖ Imagens salvas: {saved_count}\")\n",
    "        print(f\"  üìÅ Arquivos totais: {len(saved_files)}\")\n",
    "        print(f\"  üìÇ Localiza√ß√£o: {result_data['output_dir']}\")\n",
    "        \n",
    "        return result_data\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"üí• Erro no salvamento: {e}\")\n",
    "        print(f\"Error: {type(e).__name__}: {e}\")\n",
    "        return {\n",
    "            'success': False,\n",
    "            'saved_count': 0,\n",
    "            'error': str(e)\n",
    "        }\n",
    "\n",
    "print(\"üíæ Fun√ß√£o de salvamento configurada!\")\n",
    "print(\"üí° Use: save_grassclover_batch(batch_results, 'meu_dataset')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvar resultados do lote se existir\n",
    "if 'batch_results' in locals() and batch_results:\n",
    "    print(\"üíæ Salvando dataset gerado...\")\n",
    "    \n",
    "    # Configura√ß√µes de salvamento\n",
    "    OUTPUT_DIR = \"grassclover_synthetic_dataset\"\n",
    "    SAVE_METADATA = True\n",
    "    \n",
    "    save_result = save_grassclover_batch(\n",
    "        batch_results=batch_results,\n",
    "        output_dir=OUTPUT_DIR,\n",
    "        save_metadata=SAVE_METADATA\n",
    "    )\n",
    "    \n",
    "    if save_result['success']:\n",
    "        print(f\"\\nüéâ Dataset salvo com sucesso!\")\n",
    "        print(f\"\\nüìä Resumo:\")\n",
    "        print(f\"  ‚Ä¢ Imagens salvas: {save_result['saved_count']}\")\n",
    "        print(f\"  ‚Ä¢ Arquivos totais: {save_result['total_files']}\")\n",
    "        \n",
    "        # Mostrar estrutura do diret√≥rio\n",
    "        if os.path.exists(save_result['output_dir']):\n",
    "            print(f\"\\nüìÅ Estrutura do dataset:\")\n",
    "            for root, dirs, files in os.walk(save_result['output_dir']):\n",
    "                level = root.replace(save_result['output_dir'], '').count(os.sep)\n",
    "                indent = ' ' * 2 * level\n",
    "                folder_name = os.path.basename(root) if root != save_result['output_dir'] else OUTPUT_DIR\n",
    "                print(f\"{indent}{folder_name}/\")\n",
    "                \n",
    "                subindent = ' ' * 2 * (level + 1)\n",
    "                # Mostrar s√≥ os primeiros 3 arquivos por diret√≥rio\n",
    "                for file in files[:3]:\n",
    "                    print(f\"{subindent}{file}\")\n",
    "                if len(files) > 3:\n",
    "                    print(f\"{subindent}... e mais {len(files)-3} arquivos\")\n",
    "        \n",
    "        print(f\"\\nüí° Para usar o dataset:\")\n",
    "        print(f\"  ‚Ä¢ Imagens: {os.path.join(save_result['output_dir'], 'images')}\")\n",
    "        print(f\"  ‚Ä¢ Metadados: {os.path.join(save_result['output_dir'], 'metadata')}\")\n",
    "        print(f\"  ‚Ä¢ √çndice: {os.path.join(save_result['output_dir'], 'dataset_index.json')}\")\n",
    "        \n",
    "    else:\n",
    "        print(f\"‚ùå Erro ao salvar dataset:\")\n",
    "        print(f\"  Error: {save_result.get('error', 'Erro desconhecido')}\")\n",
    "        \n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Salvamento pulado\")\n",
    "    print(\"üí° Motivos poss√≠veis:\")\n",
    "    print(\"  ‚Ä¢ Nenhum lote foi gerado ainda\")\n",
    "    print(\"  ‚Ä¢ Vari√°vel 'batch_results' n√£o existe\")\n",
    "    print(\"  ‚Ä¢ Execute as c√©lulas anteriores primeiro\")\n",
    "    print(\"\\nüîÑ Para gerar e salvar:\")\n",
    "    print(\"  1. Execute a c√©lula de gera√ß√£o em lote\")\n",
    "    print(\"  2. Execute esta c√©lula novamente\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Relat√≥rio Final e Estat√≠sticas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Copie a se√ß√£o \"DEBUG COPY/PASTE\"** que aparece nos erros\n",
    "2. **Cole aqui nos coment√°rios** ou no chat para an√°lise\n",
    "3. **Inclua informa√ß√µes do sistema** (GPU, mem√≥ria, etc.)\n",
    "- **Detec√ß√£o autom√°tica** de TPU/GPU/CPU\n",
    "- **Configura√ß√£o otimizada** para cada tipo de hardware\n",
    "- **Instru√ß√µes claras** para configura√ß√£o do runtime\n",
    "- **Bypass autom√°tico** de problemas de autentica√ß√£o\n",
    "- **Configura√ß√£o de ambiente** para evitar warnings\n",
    "- **Downloads funcionam normalmente** mesmo com warnings\n",
    "#### **‚úÖ Dtype Configuration (RESOLVIDO)**\n",
    "- **float16 para GPU** (performance otimizada)\n",
    "- **float32 para TPU/CPU** (compatibilidade garantida)\n",
    "- **Configura√ß√£o autom√°tica** baseada no hardware\n",
    "### üéØ **Configura√ß√£o Recomendada para Colab:**\n",
    "- **Runtime**: GPU (Tesla T4 ou superior)\n",
    "- **Reasoning**: Stable Diffusion funciona melhor em GPU que TPU\n",
    "- **Fallback**: TPU funciona, mas GPU √© mais r√°pido para este caso\n",
    "- **GENERATION_PARAMS**: Modifique `num_inference_steps` (15-50) para balancear qualidade/velocidade\n",
    "- **BATCH_SIZE**: Reduza se houver problemas de mem√≥ria\n",
    "- **Seeds**: Mude para explorar diferentes varia√ß√µes\n",
    "- **Prompts**: Ajuste para obter estilos visuais espec√≠ficos\n",
    "1. **Upload das imagens** na se√ß√£o de arquivos do Colab\n",
    "2. **Modifique os prompts** baseado nas caracter√≠sticas visuais\n",
    "3. **Ajuste p√≥s-processamento** para aproximar do estilo original\n",
    "- **Cobertura densa**: Pastagens devem ter ‚â•80% de cobertura vegetal\n",
    "- **Perspectiva top-down**: Vista a√©rea consistente\n",
    "- **Textura real√≠stica**: Detalhes de folhas e solo vis√≠veis\n",
    "- **Diversidade**: Varia√ß√£o entre as imagens geradas\n",
    "- **GPU (Tesla T4)**: ~30-45s por imagem (recomendado)\n",
    "- **GPU (V100/A100)**: ~15-25s por imagem (√≥timo)\n",
    "- **TPU**: ~45-60s por imagem (funciona)\n",
    "- **CPU**: ~5-10min por imagem (muito lento, n√£o recomendado)\n",
    "---\n",
    "**üåæ Dataset GrassClover Brasileiro - Gerado com Stable Diffusion**  \n",
    "Baseado na metodologia de Skovsen et al. (CVPR 2019) adaptada para gram√≠neas tropicais.\n",
    "**üìã Problemas Comuns Resolvidos**: TPU detection, HF authentication, dtype optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üí° Instru√ß√µes para Uso e Debugging\n",
    "### üö® **Em caso de erro:**\n",
    "1. **Copie a se√ß√£o \"DEBUG COPY/PASTE\"** que aparece nos erros\n",
    "2. **Cole aqui nos coment√°rios** ou no chat para an√°lise\n",
    "3. **Inclua informa√ß√µes do sistema** (GPU, mem√≥ria, etc.)\n",
    "### üîß **Ajustes poss√≠veis:**\n",
    "- **GENERATION_PARAMS**: Modifique `num_inference_steps` (15-50) para balancear qualidade/velocidade\n",
    "- **BATCH_SIZE**: Reduza se houver problemas de mem√≥ria\n",
    "- **Seeds**: Mude para explorar diferentes varia√ß√µes\n",
    "- **Prompts**: Ajuste para obter estilos visuais espec√≠ficos\n",
    "### üì∏ **Para adicionar refer√™ncias GrassClover:**\n",
    "1. **Upload das imagens** na se√ß√£o de arquivos do Colab\n",
    "2. **Modifique os prompts** baseado nas caracter√≠sticas visuais\n",
    "3. **Ajuste p√≥s-processamento** para aproximar do estilo original\n",
    "### **M√©tricas de qualidade:**\n",
    "- **Cobertura densa**: Pastagens devem ter ‚â•80% de cobertura vegetal\n",
    "- **Perspectiva top-down**: Vista a√©rea consistente\n",
    "- **Textura real√≠stica**: Detalhes de folhas e solo vis√≠veis\n",
    "- **Diversidade**: Varia√ß√£o entre as imagens geradas\n",
    "**üåæ Dataset GrassClover Brasileiro - Gerado com Stable Diffusion**  \n",
    "Baseado na metodologia de Skovsen et al. (CVPR 2019) adaptada para gram√≠neas tropicais."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}