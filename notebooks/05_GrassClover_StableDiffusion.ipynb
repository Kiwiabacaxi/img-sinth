{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \ud83c\udf3e GrassClover-Style Generation with Stable Diffusion\n",
    "\n",
    "Este notebook implementa gera\u00e7\u00e3o de imagens sint\u00e9ticas de pastagens brasileiras usando **Stable Diffusion**, seguindo o estilo visual do **GrassClover Dataset** (Skovsen et al., CVPR 2019).\n",
    "\n",
    "## \ud83c\udfaf Objetivos:\n",
    "- Gerar imagens **top-down** de pastagens com Stable Diffusion\n",
    "- Adaptar para **gram\u00edneas brasileiras** (Brachiaria, Panicum, Cynodon)\n",
    "- Seguir **metodologia GrassClover** (densidade, perspectiva, resolu\u00e7\u00e3o)\n",
    "- **Ultra-compat\u00edvel** com Google Colab (debugging extensivo)\n",
    "\n",
    "## \ud83d\udcda Refer\u00eancia:\n",
    "- **Paper**: Skovsen et al. \"The GrassClover Image Dataset for Semantic and Hierarchical Species Understanding in Agriculture\" (CVPR Workshops, 2019)\n",
    "- **Adapta\u00e7\u00e3o**: Esp\u00e9cies temperadas \u2192 Tropicais brasileiras\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83d\ude80 Setup Ultra-Compat\u00edvel para Colab\n",
    "\n",
    "**IMPORTANTE**: Este notebook foi desenvolvido para m\u00e1xima compatibilidade com Google Colab Free/Pro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \ud83d\udd0d VERIFICA\u00c7\u00c3O INICIAL DO AMBIENTE\n",
    "print(\"=\" * 60)\n",
    "print(\"\ud83c\udf3e GRASSCLOVER STABLE DIFFUSION GENERATOR\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "import sys\n",
    "import platform\n",
    "from datetime import datetime\n",
    "\n",
    "print(f\"\ud83d\udcc5 Timestamp: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"\ud83d\udc0d Python: {sys.version.split()[0]}\")\n",
    "print(f\"\ud83d\udcbb Platform: {platform.system()} {platform.release()}\")\n",
    "print(f\"\ud83d\udccd Working Directory: {sys.path[0] if sys.path else 'Unknown'}\")\n",
    "\n",
    "# Detectar se estamos no Colab\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "    print(\"\ud83d\udd25 Ambiente: Google Colab (DETECTADO)\")\n",
    "except ImportError:\n",
    "    IN_COLAB = False\n",
    "    print(\"\ud83d\udcbb Ambiente: Local/Jupyter (DETECTADO)\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \ud83e\udde0 VERIFICA\u00c7\u00c3O AVAN\u00c7ADA DE HARDWARE (GPU/TPU/CPU)\n",
    "print(\"\ud83d\udd0d Verificando hardware dispon\u00edvel...\\n\")\n",
    "\n",
    "# Vari\u00e1veis de estado\n",
    "device = None\n",
    "device_type = \"unknown\"\n",
    "hardware_info = {}\n",
    "\n",
    "# Tentar importar torch primeiro\n",
    "try:\n",
    "    import torch\n",
    "    TORCH_AVAILABLE = True\n",
    "    print(f\"\u2705 PyTorch: {torch.__version__}\")\n",
    "    hardware_info['pytorch_version'] = torch.__version__\n",
    "except ImportError:\n",
    "    TORCH_AVAILABLE = False\n",
    "    print(\"\u274c PyTorch n\u00e3o encontrado - ser\u00e1 instalado\")\n",
    "\n",
    "if TORCH_AVAILABLE:\n",
    "    # 1. VERIFICAR TPU (prioridade alta no Colab)\n",
    "    try:\n",
    "        import torch_xla\n",
    "        import torch_xla.core.xla_model as xm\n",
    "        \n",
    "        # Detectar TPU\n",
    "        if xm.xrt_world_size() > 1:\n",
    "            device = xm.xla_device()\n",
    "            device_type = \"tpu\"\n",
    "            print(f\"\ud83d\udd25 TPU DETECTADO: {device}\")\n",
    "            print(f\"\ud83d\ude80 TPU cores: {xm.xrt_world_size()}\")\n",
    "            hardware_info.update({\n",
    "                'device_type': 'tpu',\n",
    "                'tpu_cores': xm.xrt_world_size(),\n",
    "                'device': str(device)\n",
    "            })\n",
    "        else:\n",
    "            print(\"\u26a0\ufe0f  TPU configurado mas n\u00e3o dispon\u00edvel\")\n",
    "            \n",
    "    except ImportError:\n",
    "        print(\"\ud83d\udcdd torch_xla n\u00e3o encontrado (normal se n\u00e3o usar TPU)\")\n",
    "    except Exception as e:\n",
    "        print(f\"\u26a0\ufe0f  Erro ao verificar TPU: {e}\")\n",
    "    \n",
    "    # 2. VERIFICAR CUDA/GPU (se TPU n\u00e3o dispon\u00edvel)\n",
    "    if device is None:\n",
    "        cuda_available = torch.cuda.is_available()\n",
    "        print(f\"\ud83d\udd25 CUDA dispon\u00edvel: {cuda_available}\")\n",
    "        \n",
    "        if cuda_available:\n",
    "            gpu_count = torch.cuda.device_count()\n",
    "            print(f\"\ud83d\ude80 N\u00famero de GPUs: {gpu_count}\")\n",
    "            \n",
    "            for i in range(gpu_count):\n",
    "                gpu_name = torch.cuda.get_device_name(i)\n",
    "                gpu_memory = torch.cuda.get_device_properties(i).total_memory\n",
    "                gpu_memory_gb = gpu_memory / (1024**3)\n",
    "                print(f\"  GPU {i}: {gpu_name}\")\n",
    "                print(f\"  Mem\u00f3ria: {gpu_memory_gb:.1f} GB\")\n",
    "            \n",
    "            device = torch.device(\"cuda\")\n",
    "            device_type = \"gpu\"\n",
    "            hardware_info.update({\n",
    "                'device_type': 'gpu',\n",
    "                'gpu_count': gpu_count,\n",
    "                'gpu_name': torch.cuda.get_device_name(0),\n",
    "                'gpu_memory_gb': torch.cuda.get_device_properties(0).total_memory / (1024**3),\n",
    "                'device': str(device)\n",
    "            })\n",
    "            \n",
    "            # Limpeza inicial de mem\u00f3ria GPU\n",
    "            torch.cuda.empty_cache()\n",
    "            print(\"\ud83e\uddf9 Cache GPU limpo\")\n",
    "            \n",
    "        else:\n",
    "            print(\"\u26a0\ufe0f  CUDA n\u00e3o dispon\u00edvel\")\n",
    "    \n",
    "    # 3. FALLBACK PARA CPU\n",
    "    if device is None:\n",
    "        device = torch.device(\"cpu\")\n",
    "        device_type = \"cpu\"\n",
    "        hardware_info.update({\n",
    "            'device_type': 'cpu',\n",
    "            'device': str(device)\n",
    "        })\n",
    "        print(\"\ud83d\udcbb Usando CPU (fallback)\")\n",
    "\n",
    "    # Status final do hardware\n",
    "    print(f\"\\n\ud83c\udfaf DEVICE CONFIGURADO: {device} ({device_type.upper()})\")\n",
    "    \n",
    "    # Instru\u00e7\u00f5es espec\u00edficas para problemas\n",
    "    if device_type == \"cpu\" and IN_COLAB:\n",
    "        print(f\"\\n\ud83d\udea8 IMPORTANTE: Voc\u00ea est\u00e1 usando CPU no Colab!\")\n",
    "        print(f\"Para ativar acelera\u00e7\u00e3o de hardware:\")\n",
    "        print(f\"1. Runtime \u2192 Change runtime type\")\n",
    "        print(f\"2. Hardware accelerator: GPU ou TPU\") \n",
    "        print(f\"3. Save \u2192 Connect (reconectar)\")\n",
    "        print(f\"4. Re-executar este notebook\")\n",
    "        \n",
    "    elif device_type == \"tpu\":\n",
    "        print(f\"\u2705 TPU configurado! Otimizado para treinamento paralelo.\")\n",
    "        \n",
    "    elif device_type == \"gpu\":\n",
    "        print(f\"\u2705 GPU configurado! Otimizado para infer\u00eancia r\u00e1pida.\")\n",
    "\n",
    "else:\n",
    "    device = None\n",
    "    device_type = \"none\"\n",
    "    print(\"\\n\u23f3 PyTorch ser\u00e1 instalado na pr\u00f3xima c\u00e9lula\")\n",
    "\n",
    "print(f\"\\n\ud83d\udcca Hardware Info: {hardware_info}\")\n",
    "print(\"\\n\" + \"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "source": "# \ud83d\udd10 AUTENTICA\u00c7\u00c3O HUGGINGFACE \nprint(\"\ud83d\udd10 Configurando autentica\u00e7\u00e3o HuggingFace...\\n\")\n\ntry:\n    from huggingface_hub import notebook_login\n    \n    print(\"\ud83d\udccb Para usar Stable Diffusion 3.5 Large, voc\u00ea precisa fazer login no HuggingFace\")\n    print(\"\ud83d\udca1 Aceite os termos em: https://huggingface.co/stabilityai/stable-diffusion-3.5-large\")\n    print(\"\u23f3 Executando login...\")\n    \n    # Login interativo no notebook\n    notebook_login()\n    \n    print(\"\u2705 Login realizado com sucesso!\")\n    HUGGINGFACE_LOGGED_IN = True\n    \nexcept Exception as e:\n    print(f\"\u26a0\ufe0f  Erro no login: {e}\")\n    print(\"\ud83d\udd04 Continuando sem autentica\u00e7\u00e3o (fallback para SD1.5)\")\n    HUGGINGFACE_LOGGED_IN = False\n\nprint(\"=\" * 60)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# \ud83d\ude80 STABLE DIFFUSION 3.5 LARGE - CONFIGURA\u00c7\u00c3O CORRIGIDA\n",
    "print(\"\ud83d\ude80 Configurando Stable Diffusion 3.5 Large...\\n\")\n",
    "\n",
    "# \ud83c\udfaf VERS\u00c3O CORRIGIDA: SD3.5 com fallback robusto\n",
    "def load_stable_diffusion_pipeline_advanced():\n",
    "    \"\"\"\n",
    "    Carrega SD3.5 Large com fallback autom\u00e1tico e tratamento de erros robusto\n",
    "    \"\"\"\n",
    "    print(\"\ud83d\udd04 Tentando carregar Stable Diffusion 3.5 Large...\")\n",
    "    \n",
    "    # Verificar se temos login do HuggingFace\n",
    "    if not HUGGINGFACE_LOGGED_IN:\n",
    "        print(\"\u26a0\ufe0f  HuggingFace login n\u00e3o realizado, tentando mesmo assim...\")\n",
    "    \n",
    "    try:\n",
    "        # Imports espec\u00edficos para SD3.5\n",
    "        from diffusers import StableDiffusion3Pipeline\n",
    "        import torch\n",
    "        \n",
    "        print(\"\ud83d\udce6 Imports SD3.5 bem-sucedidos\")\n",
    "        \n",
    "        # Configura\u00e7\u00f5es mais conservadoras para SD3.5\n",
    "        load_kwargs = {\n",
    "            \"torch_dtype\": torch.bfloat16 if torch.cuda.is_available() else torch.float32,\n",
    "            \"device_map\": \"auto\" if torch.cuda.is_available() else None,\n",
    "            \"low_cpu_mem_usage\": True,\n",
    "        }\n",
    "        \n",
    "        print(f\"\ud83d\udd27 Tentando carregar com par\u00e2metros: {load_kwargs}\")\n",
    "        \n",
    "        # Tentar carregar SD3.5 com tratamento mais robusto\n",
    "        pipe = StableDiffusion3Pipeline.from_pretrained(\n",
    "            \"stabilityai/stable-diffusion-3.5-large\", \n",
    "            **load_kwargs\n",
    "        )\n",
    "        \n",
    "        print(\"\u2705 Stable Diffusion 3.5 Large carregado com sucesso!\")\n",
    "        \n",
    "        # Mover para device se necess\u00e1rio (j\u00e1 pode estar no device certo com device_map)\n",
    "        if not torch.cuda.is_available() or load_kwargs.get(\"device_map\") is None:\n",
    "            pipe = pipe.to(device)\n",
    "        \n",
    "        return pipe, \"3.5\"\n",
    "        \n",
    "    except ImportError as e:\n",
    "        print(f\"\u274c Erro de import SD3.5: {e}\")\n",
    "        print(\"\ud83d\udca1 Pode ser necess\u00e1rio atualizar diffusers: pip install --upgrade diffusers\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\u26a0\ufe0f  SD3.5 falhou: {str(e)[:200]}...\")\n",
    "        print(f\"\ud83d\udd0d Tipo do erro: {type(e).__name__}\")\n",
    "        \n",
    "        # Erros comuns e solu\u00e7\u00f5es\n",
    "        if \"get() takes 1 positional argument\" in str(e):\n",
    "            print(\"\ud83d\udca1 Erro de compatibilidade - tentando par\u00e2metros alternativos...\")\n",
    "            \n",
    "            try:\n",
    "                # Tentativa com par\u00e2metros mais simples\n",
    "                simple_kwargs = {\n",
    "                    \"torch_dtype\": torch.bfloat16 if torch.cuda.is_available() else torch.float32,\n",
    "                }\n",
    "                \n",
    "                pipe = StableDiffusion3Pipeline.from_pretrained(\n",
    "                    \"stabilityai/stable-diffusion-3.5-large\", \n",
    "                    **simple_kwargs\n",
    "                )\n",
    "                pipe = pipe.to(device)\n",
    "                print(\"\u2705 SD3.5 carregado com par\u00e2metros simplificados!\")\n",
    "                return pipe, \"3.5\"\n",
    "                \n",
    "            except Exception as e2:\n",
    "                print(f\"\u274c Tentativa simplificada tamb\u00e9m falhou: {e2}\")\n",
    "                \n",
    "        elif \"requires you to be logged in\" in str(e) or \"authentication\" in str(e):\n",
    "            print(\"\ud83d\udd10 Erro de autentica\u00e7\u00e3o - verifique seu login no HuggingFace\")\n",
    "            \n",
    "        elif \"out of memory\" in str(e).lower() or \"oom\" in str(e).lower():\n",
    "            print(\"\ud83d\udcbe Erro de mem\u00f3ria - SD3.5 requer muita VRAM\")\n",
    "    \n",
    "    # Fallback para SD1.5\n",
    "    print(\"\ud83d\udd04 Iniciando fallback para Stable Diffusion 1.5...\")\n",
    "    \n",
    "    try:\n",
    "        from diffusers import StableDiffusionPipeline\n",
    "        \n",
    "        # Par\u00e2metros para SD1.5\n",
    "        fallback_kwargs = {\n",
    "            \"torch_dtype\": TORCH_DTYPE,\n",
    "            \"low_cpu_mem_usage\": True,\n",
    "            \"use_safetensors\": True,\n",
    "        }\n",
    "        \n",
    "        pipe = StableDiffusionPipeline.from_pretrained(\n",
    "            \"runwayml/stable-diffusion-v1-5\", \n",
    "            **fallback_kwargs\n",
    "        )\n",
    "        \n",
    "        pipe = pipe.to(device)\n",
    "        print(\"\u2705 Fallback SD1.5 carregado com sucesso!\")\n",
    "        return pipe, \"1.5\"\n",
    "        \n",
    "    except Exception as e2:\n",
    "        print(f\"\u274c Fallback SD1.5 tamb\u00e9m falhou: {e2}\")\n",
    "        return None, None\n",
    "\n",
    "# Carregar pipeline com fun\u00e7\u00e3o corrigida\n",
    "pipe, sd_version = load_stable_diffusion_pipeline_advanced()\n",
    "\n",
    "if pipe is not None:\n",
    "    print(f\"\\n\ud83c\udfaf Pipeline Stable Diffusion {sd_version} carregado!\")\n",
    "    \n",
    "    # Configurar scheduler se necess\u00e1rio\n",
    "    try:\n",
    "        if sd_version == \"1.5\":\n",
    "            from diffusers import DPMSolverMultistepScheduler\n",
    "            pipe.scheduler = DPMSolverMultistepScheduler.from_config(pipe.scheduler.config)\n",
    "            print(\"\ud83d\udd27 Scheduler DPMSolver aplicado (SD1.5)\")\n",
    "        else:\n",
    "            print(\"\ud83d\udd27 Usando scheduler nativo do SD3.5\")\n",
    "    except Exception as e:\n",
    "        print(f\"\u26a0\ufe0f  Mantendo scheduler padr\u00e3o: {e}\")\n",
    "    \n",
    "    # Aplicar otimiza\u00e7\u00f5es baseadas na vers\u00e3o\n",
    "    if sd_version == \"3.5\":\n",
    "        print(f\"\ud83c\udfaf Configura\u00e7\u00e3o SD3.5:\")\n",
    "        print(f\"  \u2022 Dtype: torch.bfloat16\")\n",
    "        print(f\"  \u2022 Steps recomendados: 28\")\n",
    "        print(f\"  \u2022 Guidance scale: 4.0\")\n",
    "        \n",
    "        GENERATION_PARAMS_CURRENT = {\n",
    "            \\'width\\': 512,\n",
    "            \\'height\\': 512,\n",
    "            \\'num_inference_steps\\': 28,\n",
    "            \\'guidance_scale\\': 4.0,\n",
    "            \\'num_images_per_prompt\\': 1,\n",
    "            \\'eta\\': 0.0,\n",
    "            \\'generator_seed\\': 42\n",
    "        }\n",
    "        \n",
    "    else:  # SD1.5\n",
    "        print(f\"\ud83c\udfaf Configura\u00e7\u00e3o SD1.5:\")\n",
    "        print(f\"  \u2022 Dtype: {TORCH_DTYPE}\")\n",
    "        print(f\"  \u2022 Steps: 25\")\n",
    "        print(f\"  \u2022 Guidance scale: 7.5\")\n",
    "        \n",
    "        GENERATION_PARAMS_CURRENT = {\n",
    "            \\'width\\': 512,\n",
    "            \\'height\\': 512,\n",
    "            \\'num_inference_steps\\': 25,\n",
    "            \\'guidance_scale\\': 7.5,\n",
    "            \\'num_images_per_prompt\\': 1,\n",
    "            \\'eta\\': 0.0,\n",
    "            \\'generator_seed\\': 42\n",
    "        }\n",
    "    \n",
    "    # Aplicar otimiza\u00e7\u00f5es de mem\u00f3ria\n",
    "    try:\n",
    "        if hasattr(pipe, \\'enable_attention_slicing\\'):\n",
    "            pipe.enable_attention_slicing()\n",
    "            print(\"\u2705 Attention slicing ativado\")\n",
    "            \n",
    "        if hasattr(pipe, \\'enable_memory_efficient_attention\\') and device.type == \"cuda\":\n",
    "            pipe.enable_memory_efficient_attention()  \n",
    "            print(\"\u2705 Memory efficient attention ativado\")\n",
    "    except Exception as e:\n",
    "        print(f\"\u26a0\ufe0f  Algumas otimiza\u00e7\u00f5es falharam: {e}\")\n",
    "    \n",
    "    PIPELINE_READY = True\n",
    "    print(f\"\\n\u2705 Pipeline pronto para uso!\")\n",
    "    print(f\"\ud83c\udfaf Device: {device}\")\n",
    "    \n",
    "else:\n",
    "    PIPELINE_READY = False\n",
    "    print(\"\u274c Falha total - nenhuma vers\u00e3o do Stable Diffusion foi carregada!\")\n",
    "    print(\"\ud83d\udca1 Poss\u00edveis solu\u00e7\u00f5es:\")\n",
    "    print(\"  1. Verificar login no HuggingFace\")\n",
    "    print(\"  2. Atualizar diffusers: pip install --upgrade diffusers\")\n",
    "    print(\"  3. Reiniciar runtime se necess\u00e1rio\")\n",
    "\n",
    "print(\"=\" * 60)\n"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \ud83d\udce6 INSTALA\u00c7\u00c3O DE DEPEND\u00caNCIAS ESSENCIAIS\n",
    "print(\"\ud83d\udce6 Instalando depend\u00eancias essenciais...\\n\")\n",
    "\n",
    "# Lista de pacotes essenciais\n",
    "essential_packages = [\n",
    "    \"torch\",\n",
    "    \"torchvision\", \n",
    "    \"diffusers\",\n",
    "    \"transformers\",\n",
    "    \"accelerate\",\n",
    "    \"pillow\",\n",
    "    \"matplotlib\",\n",
    "    \"numpy\"\n",
    "]\n",
    "\n",
    "# Fun\u00e7\u00e3o para instalar com debug\n",
    "def install_package(package_name, quiet=True):\n",
    "    \"\"\"Instala pacote com debugging\"\"\"\n",
    "    import subprocess\n",
    "    \n",
    "    print(f\"\u23f3 Instalando {package_name}...\")\n",
    "    \n",
    "    try:\n",
    "        cmd = [\"pip\", \"install\", package_name]\n",
    "        if quiet:\n",
    "            cmd.append(\"--quiet\")\n",
    "        \n",
    "        result = subprocess.run(cmd, capture_output=True, text=True, timeout=300)\n",
    "        \n",
    "        if result.returncode == 0:\n",
    "            print(f\"\u2705 {package_name} instalado com sucesso\")\n",
    "            return True\n",
    "        else:\n",
    "            print(f\"\u274c Erro ao instalar {package_name}:\")\n",
    "            print(f\"STDOUT: {result.stdout}\")\n",
    "            print(f\"STDERR: {result.stderr}\")\n",
    "            return False\n",
    "            \n",
    "    except subprocess.TimeoutExpired:\n",
    "        print(f\"\u23f0 Timeout ao instalar {package_name}\")\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        print(f\"\ud83d\udca5 Exce\u00e7\u00e3o ao instalar {package_name}: {e}\")\n",
    "        return False\n",
    "\n",
    "# Instalar apenas se necess\u00e1rio\n",
    "for package in essential_packages:\n",
    "    try:\n",
    "        __import__(package.replace(\"-\", \"_\"))\n",
    "        print(f\"\u2705 {package} j\u00e1 dispon\u00edvel\")\n",
    "    except ImportError:\n",
    "        success = install_package(package)\n",
    "        if not success:\n",
    "            print(f\"\ud83d\udea8 FALHA CR\u00cdTICA: N\u00e3o foi poss\u00edvel instalar {package}\")\n",
    "            print(f\"\ud83d\udccb DEBUG INFO para copy/paste:\")\n",
    "            print(f\"Package: {package}\")\n",
    "            print(f\"Environment: {'Colab' if IN_COLAB else 'Local'}\")\n",
    "            print(f\"Python: {sys.version}\")\n",
    "            break\n",
    "\n",
    "print(f\"\\n\ud83c\udf89 Instala\u00e7\u00e3o conclu\u00edda!\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \ud83d\udd04 REIMPORTA\u00c7\u00c3O E VERIFICA\u00c7\u00c3O FINAL COM CONFIGURA\u00c7\u00d5ES OTIMIZADAS\n",
    "print(\"\ud83d\udd04 Verificando importa\u00e7\u00f5es finais e configurando hardware...\\n\")\n",
    "\n",
    "# Imports essenciais com debugging\n",
    "try:\n",
    "    import torch\n",
    "    import torchvision.transforms as transforms\n",
    "    print(f\"\u2705 PyTorch: {torch.__version__}\")\n",
    "    \n",
    "    # Reconfigurar device ap\u00f3s instala\u00e7\u00e3o se necess\u00e1rio\n",
    "    if not 'device' in locals() or device is None:\n",
    "        if torch.cuda.is_available():\n",
    "            device = torch.device(\"cuda\")\n",
    "            device_type = \"gpu\"\n",
    "            gpu_name = torch.cuda.get_device_name(0)\n",
    "            gpu_memory = torch.cuda.get_device_properties(0).total_memory / (1024**3)\n",
    "            print(f\"\ud83d\ude80 GPU: {gpu_name} ({gpu_memory:.1f} GB)\")\n",
    "            \n",
    "            # Configura\u00e7\u00e3o otimizada para GPU\n",
    "            torch.backends.cudnn.benchmark = True\n",
    "            torch.cuda.empty_cache()\n",
    "            \n",
    "        else:\n",
    "            device = torch.device(\"cpu\")\n",
    "            device_type = \"cpu\"\n",
    "            print(\"\ud83d\udcbb Device: CPU\")\n",
    "    \n",
    "    # Configurar dtype baseado no hardware\n",
    "    if device_type == \"gpu\":\n",
    "        TORCH_DTYPE = torch.bfloat16  # GPU: usar half precision\n",
    "        print(f\"\ud83d\udd22 Dtype: {TORCH_DTYPE} (GPU otimizado)\")\n",
    "    elif device_type == \"tpu\":\n",
    "        TORCH_DTYPE = torch.float32  # TPU: full precision recomendado\n",
    "        print(f\"\ud83d\udd22 Dtype: {TORCH_DTYPE} (TPU otimizado)\")\n",
    "    else:\n",
    "        TORCH_DTYPE = torch.float32  # CPU: full precision\n",
    "        print(f\"\ud83d\udd22 Dtype: {TORCH_DTYPE} (CPU padr\u00e3o)\")\n",
    "        \n",
    "except ImportError as e:\n",
    "    print(f\"\u274c Erro PyTorch: {e}\")\n",
    "    device = None\n",
    "    device_type = \"none\"\n",
    "    TORCH_DTYPE = None\n",
    "\n",
    "try:\n",
    "    from diffusers import StableDiffusion3Pipeline, DPMSolverMultistepScheduler\n",
    "    print(f\"\u2705 Diffusers importado\")\n",
    "    DIFFUSERS_AVAILABLE = True\n",
    "except ImportError as e:\n",
    "    print(f\"\u274c Erro Diffusers: {e}\")\n",
    "    DIFFUSERS_AVAILABLE = False\n",
    "\n",
    "try:\n",
    "    from PIL import Image, ImageEnhance, ImageFilter\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    print(f\"\u2705 PIL, Matplotlib, NumPy importados\")\n",
    "    BASIC_LIBS_AVAILABLE = True\n",
    "except ImportError as e:\n",
    "    print(f\"\u274c Erro bibliotecas b\u00e1sicas: {e}\")\n",
    "    BASIC_LIBS_AVAILABLE = False\n",
    "\n",
    "# Configura\u00e7\u00e3o de ambiente Hugging Face\n",
    "print(f\"\\n\ud83e\udd17 Configurando Hugging Face...\")\n",
    "try:\n",
    "    import os\n",
    "    # Desabilitar telemetria para evitar warnings\n",
    "    os.environ[\"DISABLE_TELEMETRY\"] = \"1\"\n",
    "    os.environ[\"HF_HUB_DISABLE_TELEMETRY\"] = \"1\"\n",
    "    \n",
    "    # Configurar cache offline se necess\u00e1rio\n",
    "    if IN_COLAB:\n",
    "        os.environ[\"TRANSFORMERS_OFFLINE\"] = \"0\"  # Permitir downloads no Colab\n",
    "        os.environ[\"HF_HUB_OFFLINE\"] = \"0\"\n",
    "    \n",
    "    print(f\"\u2705 Vari\u00e1veis HF configuradas (telemetria desabilitada)\")\n",
    "except Exception as e:\n",
    "    print(f\"\u26a0\ufe0f  Aviso na configura\u00e7\u00e3o HF: {e}\")\n",
    "\n",
    "# Status final\n",
    "ALL_READY = device is not None and DIFFUSERS_AVAILABLE and BASIC_LIBS_AVAILABLE\n",
    "\n",
    "print(f\"\\n{'\ud83c\udfaf SISTEMA PRONTO!' if ALL_READY else '\ud83d\udea8 PROBLEMAS DETECTADOS!'}\")\n",
    "if ALL_READY:\n",
    "    print(f\"\u2705 Device: {device} ({device_type})\")\n",
    "    print(f\"\u2705 Dtype: {TORCH_DTYPE}\")\n",
    "    print(f\"\u2705 Todas as bibliotecas carregadas\")\n",
    "else:\n",
    "    print(\"\\n\ud83d\udccb DEBUG COPY/PASTE INFO:\")\n",
    "    print(f\"Device: {device}\")\n",
    "    print(f\"Device type: {device_type if 'device_type' in locals() else 'unknown'}\")\n",
    "    print(f\"Diffusers: {DIFFUSERS_AVAILABLE}\")\n",
    "    print(f\"Basic libs: {BASIC_LIBS_AVAILABLE}\")\n",
    "    print(f\"In Colab: {IN_COLAB}\")\n",
    "    \n",
    "    if device_type == \"cpu\" and IN_COLAB:\n",
    "        print(f\"\\n\ud83d\udd27 A\u00c7\u00c3O NECESS\u00c1RIA:\")\n",
    "        print(f\"1. Runtime \u2192 Change runtime type\")\n",
    "        print(f\"2. Hardware accelerator: GPU\")\n",
    "        print(f\"3. Save e reconectar\")\n",
    "\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83c\udfa8 Pipeline Stable Diffusion para GrassClover\n",
    "\n",
    "Configura\u00e7\u00e3o do pipeline otimizado para gera\u00e7\u00e3o de pastagens no estilo GrassClover."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \ud83c\udfa8 CONFIGURA\u00c7\u00c3O AVAN\u00c7ADA DO PIPELINE STABLE DIFFUSION\n",
    "print(\"\ud83c\udfa8 Configurando Stable Diffusion Pipeline...\\n\")\n",
    "\n",
    "# Par\u00e2metros do pipeline baseados no hardware detectado\n",
    "MODEL_ID = \"runwayml/stable-diffusion-v1-5\"  # Modelo base confi\u00e1vel\n",
    "LOW_CPU_MEM_USAGE = True\n",
    "ENABLE_ATTENTION_SLICING = True\n",
    "\n",
    "# Configura\u00e7\u00f5es espec\u00edficas por hardware\n",
    "if device_type == \"gpu\":\n",
    "    ENABLE_MODEL_CPU_OFFLOAD = False\n",
    "    ENABLE_SEQUENTIAL_CPU_OFFLOAD = False\n",
    "    USE_TORCH_COMPILE = True\n",
    "elif device_type == \"tpu\":\n",
    "    ENABLE_MODEL_CPU_OFFLOAD = True\n",
    "    ENABLE_SEQUENTIAL_CPU_OFFLOAD = False\n",
    "    USE_TORCH_COMPILE = False  # TPU pode ter problemas com compile\n",
    "else:  # CPU\n",
    "    ENABLE_MODEL_CPU_OFFLOAD = True\n",
    "    ENABLE_SEQUENTIAL_CPU_OFFLOAD = True\n",
    "    USE_TORCH_COMPILE = False\n",
    "\n",
    "print(f\"\ud83d\udce6 Modelo: {MODEL_ID}\")\n",
    "print(f\"\ud83d\udd22 Dtype: {TORCH_DTYPE}\")\n",
    "print(f\"\ud83d\udcbe Low CPU mem: {LOW_CPU_MEM_USAGE}\")\n",
    "print(f\"\u26a1 Attention slicing: {ENABLE_ATTENTION_SLICING}\")\n",
    "print(f\"\ud83c\udfc3 Model CPU offload: {ENABLE_MODEL_CPU_OFFLOAD}\")\n",
    "print(f\"\ud83d\udd25 Hardware: {device_type.upper()}\")\n",
    "\n",
    "# Fun\u00e7\u00e3o para carregar pipeline com debugging e bypass de autentica\u00e7\u00e3o\n",
    "def load_stable_diffusion_pipeline():\n",
    "    \"\"\"Carrega pipeline com m\u00e1ximo debugging e configura\u00e7\u00f5es otimizadas\"\"\"\n",
    "    try:\n",
    "        print(\"\u23f3 Carregando modelo...\")\n",
    "        \n",
    "        # Configura\u00e7\u00f5es para bypass de problemas de autentica\u00e7\u00e3o\n",
    "        load_kwargs = {\n",
    "            \"torch_dtype\": TORCH_DTYPE,\n",
    "            \"low_cpu_mem_usage\": LOW_CPU_MEM_USAGE,\n",
    "            \"use_safetensors\": True,\n",
    "        }\n",
    "        \n",
    "        # Configura\u00e7\u00f5es espec\u00edficas para resolver problemas HF\n",
    "        try:\n",
    "            # Tentar com autentica\u00e7\u00e3o padr\u00e3o primeiro\n",
    "            pipe = StableDiffusionPipeline.from_pretrained(MODEL_ID, **load_kwargs)\n",
    "            print(\"\u2705 Modelo carregado com autentica\u00e7\u00e3o padr\u00e3o\")\n",
    "        except Exception as auth_error:\n",
    "            print(f\"\u26a0\ufe0f  Problema de autentica\u00e7\u00e3o: {str(auth_error)[:100]}...\")\n",
    "            print(\"\ud83d\udd04 Tentando download for\u00e7ado...\")\n",
    "            \n",
    "            # Bypass de problemas de autentica\u00e7\u00e3o\n",
    "            load_kwargs[\"use_auth_token\"] = False\n",
    "            load_kwargs[\"force_download\"] = False\n",
    "            load_kwargs[\"resume_download\"] = True\n",
    "            \n",
    "            pipe = StableDiffusionPipeline.from_pretrained(MODEL_ID, **load_kwargs)\n",
    "            print(\"\u2705 Modelo carregado com bypass de autentica\u00e7\u00e3o\")\n",
    "        \n",
    "        # Mover para device\n",
    "        pipe = pipe.to(device)\n",
    "        print(f\"\ud83d\ude80 Pipeline movido para {device}\")\n",
    "        \n",
    "        # Otimiza\u00e7\u00f5es baseadas no hardware\n",
    "        if ENABLE_ATTENTION_SLICING:\n",
    "            pipe.enable_attention_slicing()\n",
    "            print(\"\u26a1 Attention slicing habilitado\")\n",
    "        \n",
    "        if ENABLE_MODEL_CPU_OFFLOAD and device_type != \"cpu\":\n",
    "            try:\n",
    "                pipe.enable_model_cpu_offload()\n",
    "                print(\"\ud83d\udcbe Model CPU offload habilitado\")\n",
    "            except Exception as e:\n",
    "                print(f\"\u26a0\ufe0f  CPU offload falhou: {e}\")\n",
    "        \n",
    "        if ENABLE_SEQUENTIAL_CPU_OFFLOAD and device_type == \"cpu\":\n",
    "            try:\n",
    "                pipe.enable_sequential_cpu_offload()\n",
    "                print(\"\ud83d\udd04 Sequential CPU offload habilitado\")\n",
    "            except Exception as e:\n",
    "                print(f\"\u26a0\ufe0f  Sequential offload falhou: {e}\")\n",
    "        \n",
    "        # Scheduler otimizado\n",
    "        pipe.scheduler = DPMSolverMultistepScheduler.from_config(pipe.scheduler.config)\n",
    "        print(\"\ud83d\udd27 Scheduler otimizado (DPMSolver)\")\n",
    "        \n",
    "        # Configura\u00e7\u00f5es de mem\u00f3ria espec\u00edficas\n",
    "        if device_type == \"gpu\":\n",
    "            torch.cuda.empty_cache()\n",
    "            allocated = torch.cuda.memory_allocated() / (1024**3)\n",
    "            cached = torch.cuda.memory_reserved() / (1024**3)\n",
    "            print(f\"\ud83d\udcbe GPU Memory - Allocated: {allocated:.2f}GB, Cached: {cached:.2f}GB\")\n",
    "            \n",
    "            # Verificar se h\u00e1 mem\u00f3ria suficiente\n",
    "            if allocated > 10.0:  # >10GB pode causar problemas\n",
    "                print(f\"\u26a0\ufe0f  Alta utiliza\u00e7\u00e3o de mem\u00f3ria GPU!\")\n",
    "                \n",
    "        elif device_type == \"tpu\":\n",
    "            print(\"\ud83d\udd25 TPU configurado - mem\u00f3ria gerenciada automaticamente\")\n",
    "            \n",
    "        else:  # CPU\n",
    "            print(\"\ud83d\udcbb CPU mode - sem monitoramento de GPU memory\")\n",
    "        \n",
    "        print(\"\\n\u2705 Pipeline configurado com sucesso!\")\n",
    "        return pipe\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\ud83d\udca5 ERRO ao carregar pipeline: {e}\")\n",
    "        print(f\"\\n\ud83d\udccb DEBUG COPY/PASTE:\")\n",
    "        print(f\"Model: {MODEL_ID}\")\n",
    "        print(f\"Device: {device} ({device_type})\")\n",
    "        print(f\"Dtype: {TORCH_DTYPE}\")\n",
    "        print(f\"Hardware info: {hardware_info if 'hardware_info' in locals() else 'N/A'}\")\n",
    "        print(f\"Error type: {type(e).__name__}\")\n",
    "        print(f\"Error message: {e}\")\n",
    "        \n",
    "        # Sugest\u00f5es baseadas no tipo de erro\n",
    "        error_str = str(e).lower()\n",
    "        if \"authentication\" in error_str or \"token\" in error_str:\n",
    "            print(f\"\\n\ud83d\udca1 SOLU\u00c7\u00c3O PARA ERRO DE TOKEN:\")\n",
    "            print(f\"1. Ignore o warning - o modelo deve funcionar mesmo assim\")\n",
    "            print(f\"2. Ou configure HF_TOKEN manualmente se necess\u00e1rio\")\n",
    "            \n",
    "        elif \"memory\" in error_str or \"cuda\" in error_str:\n",
    "            print(f\"\\n\ud83d\udca1 SOLU\u00c7\u00c3O PARA ERRO DE MEM\u00d3RIA:\")\n",
    "            print(f\"1. Reduzir batch_size\")\n",
    "            print(f\"2. Usar torch.float16 se estiver usando float32\")\n",
    "            print(f\"3. Fechar outros notebooks no Colab\")\n",
    "            \n",
    "        elif \"module\" in error_str or \"import\" in error_str:\n",
    "            print(f\"\\n\ud83d\udca1 SOLU\u00c7\u00c3O PARA ERRO DE M\u00d3DULO:\")\n",
    "            print(f\"1. Re-executar c\u00e9lulas de instala\u00e7\u00e3o\")\n",
    "            print(f\"2. Restart runtime se necess\u00e1rio\")\n",
    "            \n",
    "        return None\n",
    "\n",
    "# Carregar pipeline\n",
    "if ALL_READY:\n",
    "    pipe = load_stable_diffusion_pipeline()\n",
    "    PIPELINE_READY = pipe is not None\n",
    "else:\n",
    "    pipe = None\n",
    "    PIPELINE_READY = False\n",
    "    print(\"\u274c Sistema n\u00e3o est\u00e1 pronto para carregar pipeline\")\n",
    "\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \ud83c\udfa8 CONFIGURA\u00c7\u00c3O AVAN\u00c7ADA DO PIPELINE STABLE DIFFUSION\n",
    "print(\"\ud83c\udfa8 Configurando Stable Diffusion Pipeline...\\n\")\n",
    "\n",
    "# Par\u00e2metros do pipeline baseados no hardware detectado\n",
    "MODEL_ID = \"stabilityai/stable-diffusion-3.5-large\"  # Modelo SD 3.5 Large - Estado da Arte\n",
    "LOW_CPU_MEM_USAGE = True\n",
    "ENABLE_ATTENTION_SLICING = True\n",
    "\n",
    "# Configura\u00e7\u00f5es espec\u00edficas por hardware\n",
    "if device_type == \"gpu\":\n",
    "    ENABLE_MODEL_CPU_OFFLOAD = False\n",
    "    ENABLE_SEQUENTIAL_CPU_OFFLOAD = False\n",
    "    USE_TORCH_COMPILE = True\n",
    "elif device_type == \"tpu\":\n",
    "    ENABLE_MODEL_CPU_OFFLOAD = True\n",
    "    ENABLE_SEQUENTIAL_CPU_OFFLOAD = False\n",
    "    USE_TORCH_COMPILE = False  # TPU pode ter problemas com compile\n",
    "else:  # CPU\n",
    "    ENABLE_MODEL_CPU_OFFLOAD = True\n",
    "    ENABLE_SEQUENTIAL_CPU_OFFLOAD = True\n",
    "    USE_TORCH_COMPILE = False\n",
    "\n",
    "print(f\"\ud83d\udce6 Modelo: {MODEL_ID}\")\n",
    "print(f\"\ud83d\udd22 Dtype: {TORCH_DTYPE}\")\n",
    "print(f\"\ud83d\udcbe Low CPU mem: {LOW_CPU_MEM_USAGE}\")\n",
    "print(f\"\u26a1 Attention slicing: {ENABLE_ATTENTION_SLICING}\")\n",
    "print(f\"\ud83c\udfc3 Model CPU offload: {ENABLE_MODEL_CPU_OFFLOAD}\")\n",
    "print(f\"\ud83d\udd25 Hardware: {device_type.upper()}\")\n",
    "\n",
    "# Fun\u00e7\u00e3o para carregar pipeline com debugging e bypass de autentica\u00e7\u00e3o\n",
    "def load_stable_diffusion_pipeline():\n",
    "    # \\\"\\\"\\\"Carrega pipeline com m\u00e1ximo debugging e configura\u00e7\u00f5es otimizadas\\\"\\\"\\\"\n",
    "    try:\n",
    "        print(\"\u23f3 Carregando modelo...\")\n",
    "        \n",
    "        # Configura\u00e7\u00f5es para bypass de problemas de autentica\u00e7\u00e3o\n",
    "        load_kwargs = {\n",
    "            \"torch_dtype\": TORCH_DTYPE,\n",
    "            \"low_cpu_mem_usage\": LOW_CPU_MEM_USAGE,\n",
    "            \"use_safetensors\": True,\n",
    "        }\n",
    "        \n",
    "        # Configura\u00e7\u00f5es espec\u00edficas para resolver problemas HF\n",
    "        try:\n",
    "            # Tentar com autentica\u00e7\u00e3o padr\u00e3o primeiro\n",
    "            pipe = StableDiffusion3Pipeline.from_pretrained(MODEL_ID, **load_kwargs)\n",
    "            print(\"\u2705 Modelo carregado com autentica\u00e7\u00e3o padr\u00e3o\")\n",
    "        except Exception as auth_error:\n",
    "            print(f\"\u26a0\ufe0f  Problema de autentica\u00e7\u00e3o: {str(auth_error)[:100]}...\")\n",
    "            print(\"\ud83d\udd04 Tentando download for\u00e7ado...\")\n",
    "            \n",
    "            # Bypass de problemas de autentica\u00e7\u00e3o\n",
    "            load_kwargs[\"use_auth_token\"] = False\n",
    "            load_kwargs[\"force_download\"] = False\n",
    "            load_kwargs[\"resume_download\"] = True\n",
    "            \n",
    "            pipe = StableDiffusion3Pipeline.from_pretrained(MODEL_ID, **load_kwargs)\n",
    "            print(\"\u2705 Modelo carregado com bypass de autentica\u00e7\u00e3o\")\n",
    "        \n",
    "        # Mover para device\n",
    "        pipe = pipe.to(device)\n",
    "        print(f\"\ud83d\ude80 Pipeline movido para {device}\")\n",
    "        \n",
    "        # Otimiza\u00e7\u00f5es baseadas no hardware\n",
    "        if ENABLE_ATTENTION_SLICING:\n",
    "            pipe.enable_attention_slicing()\n",
    "            print(\"\u26a1 Attention slicing habilitado\")\n",
    "        \n",
    "        if ENABLE_MODEL_CPU_OFFLOAD and device_type != \"cpu\":\n",
    "            try:\n",
    "                pipe.enable_model_cpu_offload()\n",
    "                print(\"\ud83d\udcbe Model CPU offload habilitado\")\n",
    "            except Exception as e:\n",
    "                print(f\"\u26a0\ufe0f  CPU offload falhou: {e}\")\n",
    "        \n",
    "        if ENABLE_SEQUENTIAL_CPU_OFFLOAD and device_type == \"cpu\":\n",
    "            try:\n",
    "                pipe.enable_sequential_cpu_offload()\n",
    "                print(\"\ud83d\udd04 Sequential CPU offload habilitado\")\n",
    "            except Exception as e:\n",
    "                print(f\"\u26a0\ufe0f  Sequential offload falhou: {e}\")\n",
    "        \n",
    "        # Scheduler otimizado\n",
    "        pipe.scheduler = DPMSolverMultistepScheduler.from_config(pipe.scheduler.config)\n",
    "        print(\"\ud83d\udd27 Scheduler otimizado (DPMSolver)\")\n",
    "        \n",
    "        # Configura\u00e7\u00f5es de mem\u00f3ria espec\u00edficas\n",
    "        if device_type == \"gpu\":\n",
    "            torch.cuda.empty_cache()\n",
    "            allocated = torch.cuda.memory_allocated() / (1024**3)\n",
    "            cached = torch.cuda.memory_reserved() / (1024**3)\n",
    "            print(f\"\ud83d\udcbe GPU Memory - Allocated: {allocated:.2f}GB, Cached: {cached:.2f}GB\")\n",
    "            \n",
    "            # Verificar se h\u00e1 mem\u00f3ria suficiente\n",
    "            if allocated > 10.0:  # >10GB pode causar problemas\n",
    "                print(f\"\u26a0\ufe0f  Alta utiliza\u00e7\u00e3o de mem\u00f3ria GPU!\")\n",
    "                \n",
    "        elif device_type == \"tpu\":\n",
    "            print(\"\ud83d\udd25 TPU configurado - mem\u00f3ria gerenciada automaticamente\")\n",
    "            \n",
    "        else:  # CPU\n",
    "            print(\"\ud83d\udcbb CPU mode - sem monitoramento de GPU memory\")\n",
    "        \n",
    "        print(\"\\\\n\u2705 Pipeline configurado com sucesso!\")\n",
    "        return pipe\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\ud83d\udca5 ERRO ao carregar pipeline: {e}\")\n",
    "        print(f\"\\\\n\ud83d\udccb DEBUG COPY/PASTE:\")\n",
    "        print(f\"Model: {MODEL_ID}\")\n",
    "        print(f\"Device: {device} ({device_type})\")\n",
    "        print(f\"Dtype: {TORCH_DTYPE}\")\n",
    "        print(f\"Hardware info: {hardware_info if 'hardware_info' in locals() else 'N/A'}\")\n",
    "        print(f\"Error type: {type(e).__name__}\")\n",
    "        print(f\"Error message: {e}\")\n",
    "        \n",
    "        # Sugest\u00f5es baseadas no tipo de erro\n",
    "        error_str = str(e).lower()\n",
    "        if \"authentication\" in error_str or \"token\" in error_str:\n",
    "            print(f\"\\\\n\ud83d\udca1 SOLU\u00c7\u00c3O PARA ERRO DE TOKEN:\")\n",
    "            print(f\"1. Ignore o warning - o modelo deve funcionar mesmo assim\")\n",
    "            print(f\"2. Ou configure HF_TOKEN manualmente se necess\u00e1rio\")\n",
    "            \n",
    "        elif \"memory\" in error_str or \"cuda\" in error_str:\n",
    "            print(f\"\\\\n\ud83d\udca1 SOLU\u00c7\u00c3O PARA ERRO DE MEM\u00d3RIA:\")\n",
    "            print(f\"1. Reduzir batch_size\")\n",
    "            print(f\"2. Usar torch.float16 se estiver usando float32\")\n",
    "            print(f\"3. Fechar outros notebooks no Colab\")\n",
    "            \n",
    "        elif \"module\" in error_str or \"import\" in error_str:\n",
    "            print(f\"\\\\n\ud83d\udca1 SOLU\u00c7\u00c3O PARA ERRO DE M\u00d3DULO:\")\n",
    "            print(f\"1. Re-executar c\u00e9lulas de instala\u00e7\u00e3o\")\n",
    "            print(f\"2. Restart runtime se necess\u00e1rio\")\n",
    "            \n",
    "        return None\n",
    "\n",
    "# Carregar pipeline\n",
    "if ALL_READY:\n",
    "    pipe = load_stable_diffusion_pipeline()\n",
    "    PIPELINE_READY = pipe is not None\n",
    "else:\n",
    "    pipe = None\n",
    "    PIPELINE_READY = False\n",
    "    print(\"\u274c Sistema n\u00e3o est\u00e1 pronto para carregar pipeline\")\n",
    "\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# \ud83d\udcda DOWNLOAD DO DATASET GRASSCLOVER ORIGINAL\nprint(\"\ud83d\udcda Baixando dataset GrassClover original do Kaggle...\\n\")\n\n# Inicializar vari\u00e1vel globalmente\nGRASSCLOVER_DATASET_PATH = None\n\ntry:\n    # Instalar kagglehub se necess\u00e1rio\n    try:\n        import kagglehub\n        print(\"\u2705 kagglehub j\u00e1 dispon\u00edvel\")\n    except ImportError:\n        print(\"\ud83d\udce6 Instalando kagglehub...\")\n        import subprocess\n        result = subprocess.run([\"pip\", \"install\", \"kagglehub\", \"--quiet\"], \n                              capture_output=True, text=True)\n        if result.returncode == 0:\n            import kagglehub\n            print(\"\u2705 kagglehub instalado com sucesso\")\n        else:\n            print(f\"\u274c Erro ao instalar kagglehub: {result.stderr}\")\n            raise ImportError(\"kagglehub installation failed\")\n    \n    # Download do dataset\n    print(\"\u23f3 Fazendo download do GrassClover dataset...\")\n    print(\"\ud83d\udca1 Isso pode demorar alguns minutos na primeira vez...\")\n    \n    dataset_path = kagglehub.dataset_download(\"usharengaraju/grassclover-dataset\")\n    \n    if dataset_path and os.path.exists(dataset_path):\n        GRASSCLOVER_DATASET_PATH = dataset_path\n        print(f\"\u2705 Dataset baixado com sucesso!\")\n        print(f\"\ud83d\udcc1 Localiza\u00e7\u00e3o: {dataset_path}\")\n        \n        # Explorar estrutura do dataset\n        print(f\"\\n\ud83d\udccb Estrutura do dataset:\")\n        \n        total_files = 0\n        for root, dirs, files in os.walk(dataset_path):\n            level = root.replace(dataset_path, '').count(os.sep)\n            indent = '  ' * level\n            folder_name = os.path.basename(root) if root != dataset_path else 'grassclover-dataset'\n            \n            # Contar apenas arquivos de imagem\n            image_files = [f for f in files if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n            \n            if image_files:\n                print(f\"{indent}{folder_name}/ ({len(image_files)} imagens)\")\n                total_files += len(image_files)\n                \n                # Mostrar alguns exemplos de nomes\n                for file in image_files[:3]:\n                    print(f\"{indent}  \u2022 {file}\")\n                if len(image_files) > 3:\n                    print(f\"{indent}  \u2022 ... e mais {len(image_files)-3} imagens\")\n            elif dirs:\n                print(f\"{indent}{folder_name}/\")\n        \n        print(f\"\\n\ud83d\udcca Total: {total_files} imagens encontradas\")\n        \n        if total_files == 0:\n            print(\"\u26a0\ufe0f  Nenhuma imagem encontrada no dataset baixado\")\n            GRASSCLOVER_DATASET_PATH = None\n    else:\n        print(\"\u274c Download retornou path inv\u00e1lido\")\n        GRASSCLOVER_DATASET_PATH = None\n    \nexcept Exception as e:\n    print(f\"\u274c Erro ao baixar dataset: {e}\")\n    print(f\"\\n\ud83d\udccb DEBUG INFO:\")\n    print(f\"Error type: {type(e).__name__}\")\n    print(f\"Error message: {str(e)[:200]}...\")\n    \n    # Manter vari\u00e1vel definida como None\n    GRASSCLOVER_DATASET_PATH = None\n    \n    print(f\"\\n\ud83d\udca1 SOLU\u00c7\u00d5ES POSS\u00cdVEIS:\")\n    print(f\"1. Verificar conectividade com internet\")\n    print(f\"2. Tentar novamente em alguns minutos\")\n    print(f\"3. Verificar se Kaggle est\u00e1 acess\u00edvel\")\n    print(f\"4. OPCIONAL: Upload manual de imagens GrassClover\")\n\n# Status final\nif GRASSCLOVER_DATASET_PATH:\n    print(f\"\\n\u2705 Dataset GrassClover dispon\u00edvel para an\u00e1lise!\")\nelse:\n    print(f\"\\n\u26a0\ufe0f  Continuando sem dataset GrassClover\")\n    print(f\"\ud83c\udfaf O notebook ainda funcionar\u00e1, mas sem calibra\u00e7\u00e3o visual\")\n\nprint(\"=\" * 60)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# \ud83d\udd0d AN\u00c1LISE VISUAL DO DATASET GRASSCLOVER ORIGINAL\nprint(\"\ud83d\udd0d Analisando caracter\u00edsticas visuais do GrassClover...\\n\")\n\ndef analyze_grassclover_images(dataset_path, num_samples=6):\n    \"\"\"\n    Analisa imagens do GrassClover para extrair caracter\u00edsticas visuais\n    \"\"\"\n    if not dataset_path or not os.path.exists(dataset_path):\n        print(\"\u274c Dataset n\u00e3o dispon\u00edvel para an\u00e1lise\")\n        return None\n    \n    try:\n        # Encontrar arquivos de imagem\n        image_files = []\n        for root, dirs, files in os.walk(dataset_path):\n            for file in files:\n                if file.lower().endswith(('.png', '.jpg', '.jpeg')):\n                    image_files.append(os.path.join(root, file))\n        \n        if not image_files:\n            print(\"\u274c Nenhuma imagem encontrada no dataset\")\n            return None\n        \n        print(f\"\ud83d\udcf8 Encontradas {len(image_files)} imagens\")\n        print(f\"\ud83c\udfaf Analisando {min(num_samples, len(image_files))} amostras...\")\n        \n        # Selecionar amostras aleat\u00f3rias\n        import random\n        random.seed(42)  # Reprodutibilidade\n        sample_files = random.sample(image_files, min(num_samples, len(image_files)))\n        \n        # An\u00e1lise visual\n        fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n        fig.suptitle('\ud83d\udcda GrassClover Dataset - An\u00e1lise Visual de Refer\u00eancia', \n                    fontsize=16, fontweight='bold')\n        \n        axes = axes.flatten()\n        image_stats = []\n        \n        for i, img_path in enumerate(sample_files):\n            try:\n                # Carregar imagem\n                img = Image.open(img_path)\n                img_array = np.array(img)\n                \n                # Estat\u00edsticas da imagem\n                stats = {\n                    'filename': os.path.basename(img_path),\n                    'size': img.size,\n                    'mode': img.mode,\n                    'mean_rgb': np.mean(img_array, axis=(0, 1)) if len(img_array.shape) == 3 else np.mean(img_array),\n                    'std_rgb': np.std(img_array, axis=(0, 1)) if len(img_array.shape) == 3 else np.std(img_array)\n                }\n                image_stats.append(stats)\n                \n                # Exibir imagem\n                axes[i].imshow(img)\n                axes[i].set_title(f\"{stats['filename']}\\n{stats['size'][0]}x{stats['size'][1]}\", \n                                fontsize=10)\n                axes[i].axis('off')\n                \n            except Exception as e:\n                print(f\"\u26a0\ufe0f  Erro ao carregar {img_path}: {e}\")\n                axes[i].text(0.5, 0.5, 'Erro\\nao carregar', \n                           ha='center', va='center', transform=axes[i].transAxes)\n                axes[i].axis('off')\n        \n        # Ocultar eixos n\u00e3o usados\n        for j in range(len(sample_files), len(axes)):\n            axes[j].axis('off')\n        \n        plt.tight_layout()\n        plt.show()\n        \n        # Estat\u00edsticas gerais\n        if image_stats:\n            print(f\"\\n\ud83d\udcca CARACTER\u00cdSTICAS VISUAIS IDENTIFICADAS:\")\n            \n            # Tamanhos das imagens\n            sizes = [stat['size'] for stat in image_stats]\n            unique_sizes = list(set(sizes))\n            print(f\"\ud83d\udccf Resolu\u00e7\u00f5es encontradas: {unique_sizes}\")\n            \n            # Cores m\u00e9dias (se RGB)\n            rgb_images = [stat for stat in image_stats if len(stat['mean_rgb']) == 3]\n            if rgb_images:\n                avg_colors = np.mean([stat['mean_rgb'] for stat in rgb_images], axis=0)\n                print(f\"\ud83c\udfa8 Cores m\u00e9dias (RGB): R={avg_colors[0]:.1f}, G={avg_colors[1]:.1f}, B={avg_colors[2]:.1f}\")\n                \n                # An\u00e1lise de tons de verde\n                green_dominance = avg_colors[1] / (avg_colors[0] + avg_colors[2] + 0.1)\n                print(f\"\ud83c\udf3f Domin\u00e2ncia verde: {green_dominance:.2f} (quanto maior, mais verde)\")\n            \n            print(f\"\\n\ud83d\udca1 INSIGHTS PARA STABLE DIFFUSION:\")\n            print(f\"\u2022 Vista: Top-down (a\u00e9rea) consistente\")\n            print(f\"\u2022 Textura: Densa cobertura de gram\u00edneas pequenas\")\n            print(f\"\u2022 Cores: Tons de verde predominantes\")\n            print(f\"\u2022 Ilumina\u00e7\u00e3o: Natural, sem sombras fortes\")\n            print(f\"\u2022 Composi\u00e7\u00e3o: Mistura grass + clover (ryegrass + trevo)\")\n            print(f\"\u2022 Resolu\u00e7\u00e3o t\u00edpica: ~512x512 ou similar\")\n            \n        return {\n            'sample_files': sample_files,\n            'image_stats': image_stats,\n            'total_images': len(image_files)\n        }\n        \n    except Exception as e:\n        print(f\"\u274c Erro na an\u00e1lise: {e}\")\n        return None\n\n# Verificar se dataset path existe, sen\u00e3o definir como None\nif 'GRASSCLOVER_DATASET_PATH' not in locals():\n    print(\"\u26a0\ufe0f  GRASSCLOVER_DATASET_PATH n\u00e3o definido - provavelmente erro no download\")\n    GRASSCLOVER_DATASET_PATH = None\n\n# Executar an\u00e1lise\nif GRASSCLOVER_DATASET_PATH:\n    print(f\"\ud83d\udcc1 Usando dataset em: {GRASSCLOVER_DATASET_PATH}\")\n    grassclover_analysis = analyze_grassclover_images(GRASSCLOVER_DATASET_PATH)\n    GRASSCLOVER_REFERENCE_AVAILABLE = grassclover_analysis is not None\nelse:\n    print(\"\u26a0\ufe0f  Dataset GrassClover n\u00e3o dispon\u00edvel\")\n    print(\"\ud83d\udca1 Poss\u00edveis causas:\")\n    print(\"  \u2022 Erro no download do Kaggle\")\n    print(\"  \u2022 Problema de conectividade\")\n    print(\"  \u2022 kagglehub n\u00e3o instalado corretamente\")\n    print(\"\\n\ud83d\udd04 Para resolver:\")\n    print(\"  \u2022 Re-execute a c\u00e9lula de download\")\n    print(\"  \u2022 Verifique se tem conectividade com Kaggle\")\n    print(\"  \u2022 O notebook continuar\u00e1 funcionando sem as refer\u00eancias\")\n    \n    grassclover_analysis = None\n    GRASSCLOVER_REFERENCE_AVAILABLE = False\n\nprint(\"=\" * 60)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83c\udf3e Prompts para Pastagens Brasileiras - Estilo GrassClover\n",
    "\n",
    "Prompts espec\u00edficos para gerar pastagens tropicais seguindo a metodologia visual do GrassClover."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \ud83c\udf3e PROMPTS CALIBRADOS BASEADOS NA IMAGEM GRASSCLOVER REAL",
    "print(\"\ud83c\udf3e Configurando prompts para replicar estilo GrassClover exato...",
    "\")",
    "",
    "# Prompts precisos baseados na imagem GrassClover real fornecida",
    "GRASSCLOVER_PROMPTS = {",
    "    'grassclover_exact_style': {",
    "        'positive': (",
    "            \"overhead top-down view of mixed grass and white clover field, \"",
    "            \"dense green ryegrass with white clover flowers, \"",
    "            \"small spherical white clover blooms scattered throughout, \"",
    "            \"fine thin grass blades, dense ground coverage, \"",
    "            \"natural outdoor lighting, soft daylight, no shadows, \"",
    "            \"detailed grass texture, small clover leaves visible, \"",
    "            \"research quality agricultural photography, \"",
    "            \"grassclover dataset style, scientific documentation, \"",
    "            \"perennial ryegrass, trifolium repens, mixed pasture\"",
    "        ),",
    "        'negative': (",
    "            \"side view, angled view, perspective view, \"",
    "            \"large flowers, colorful flowers, trees, shrubs, \"",
    "            \"buildings, people, animals, vehicles, \"",
    "            \"artificial grass, lawn, decorative plants, \"",
    "            \"dramatic lighting, shadows, high contrast, \"",
    "            \"blurry, low quality, cartoon, painting\"",
    "        ),",
    "        'description': \"Estilo GrassClover exato - ryegrass + trevo branco\"",
    "    },",
    "    ",
    "    'grassclover_dense_flowers': {",
    "        'positive': (",
    "            \"bird's eye view of grassland with abundant white clover flowers, \"",
    "            \"dense small white spherical clover blooms, \"",
    "            \"green grass background, trifolium repens in full bloom, \"",
    "            \"natural field conditions, scientific photography, \"",
    "            \"fine grass texture beneath clover flowers, \"",
    "            \"uniform lighting, no harsh shadows, research quality, \"",
    "            \"mixed grass-clover sward, agricultural study image\"",
    "        ),",
    "        'negative': (",
    "            \"ground level view, human perspective, \"",
    "            \"large decorative flowers, colored flowers, \"",
    "            \"ornamental garden, landscaped area, \"",
    "            \"artificial lighting, studio photography, \"",
    "            \"bare soil, sparse vegetation, weeds\"",
    "        ),",
    "        'description': \"GrassClover com flores densas de trevo\"",
    "    },",
    "    ",
    "    'grassclover_fine_texture': {",
    "        'positive': (",
    "            \"close overhead view of fine grass and clover mixture, \"",
    "            \"detailed texture of ryegrass blades and clover leaves, \"",
    "            \"small white clover flowers interspersed, \"",
    "            \"natural pasture composition, research documentation, \"",
    "            \"soft natural lighting, even illumination, \"",
    "            \"high detail vegetation pattern, grassclover study, \"",
    "            \"mixed species grassland, agricultural research image\"",
    "        ),",
    "        'negative': (",
    "            \"coarse grass, large blade grass, tropical grasses, \"",
    "            \"artificial turf, decorative plants, \"",
    "            \"dramatic shadows, studio lighting, \"",
    "            \"perspective distortion, angled shots\"",
    "        ),",
    "        'description': \"Textura fina GrassClover detalhada\"",
    "    },",
    "    ",
    "    # Adapta\u00e7\u00f5es para gram\u00edneas brasileiras mantendo o estilo visual",
    "    'brazilian_mixed_grassclover_style': {",
    "        'positive': (",
    "            \"top-down view of mixed tropical grass with legume flowers, \"",
    "            \"small white stylosanthes flowers scattered in green grass, \"",
    "            \"dense brachiaria grass coverage with legume blooms, \"",
    "            \"grassclover dataset visual style, research photography, \"",
    "            \"natural field lighting, soft daylight, uniform illumination, \"",
    "            \"detailed grass-legume mixture, scientific documentation, \"",
    "            \"brazilian pasture with flowering legumes, agricultural study\"",
    "        ),",
    "        'negative': (",
    "            \"side perspective, ground level view, \"",
    "            \"large flowers, ornamental plants, \"",
    "            \"buildings, infrastructure, people, animals, \"",
    "            \"artificial lighting, dramatic shadows, \"",
    "            \"low quality, blurry, artistic style\"",
    "        ),",
    "        'description': \"Pastagem brasileira estilo GrassClover\"",
    "    },",
    "    ",
    "    'brachiaria_with_flowers_grassclover_style': {",
    "        'positive': (",
    "            \"aerial view of brachiaria pasture with small white legume flowers, \"",
    "            \"dense tropical grass with scattered small blooms, \"",
    "            \"grassclover research style photography, natural lighting, \"",
    "            \"detailed grass texture with flowering plants, \"",
    "            \"agricultural field study image, scientific quality, \"",
    "            \"mixed brachiaria and flowering legumes, top-down perspective, \"",
    "            \"brazilian tropical grassland research documentation\"",
    "        ),",
    "        'negative': (",
    "            \"temperate climate plants, large decorative flowers, \"",
    "            \"perspective view, human eye level, \"",
    "            \"landscaped garden, ornamental setting, \"",
    "            \"dramatic lighting, artistic photography, \"",
    "            \"poor quality, distorted view\"",
    "        ),",
    "        'description': \"Brachiaria com flores estilo GrassClover\"",
    "    }",
    "}",
    "",
    "# Par\u00e2metros de gera\u00e7\u00e3o",
    "GENERATION_PARAMS = {",
    "    'width': 512,",
    "    'height': 512, ",
    "    'num_inference_steps': 28,  # Balanceio qualidade/velocidade",
    "    'guidance_scale': 4.0,      # Ader\u00eancia ao prompt",
    "    'num_images_per_prompt': 1,",
    "    'eta': 0.0,                 # Determinismo",
    "    'generator_seed': 42        # Reprodutibilidade inicial",
    "}",
    "",
    "print(f\"\ud83d\udcdd {len(GRASSCLOVER_PROMPTS)} prompts configurados:\")",
    "for key, prompt_data in GRASSCLOVER_PROMPTS.items():",
    "    print(f\"  \u2022 {key}: {prompt_data['description']}\")",
    "    ",
    "print(f\"",
    "\u2699\ufe0f  Par\u00e2metros de gera\u00e7\u00e3o:\")",
    "for param, value in GENERATION_PARAMS.items():",
    "    print(f\"  \u2022 {param}: {value}\")",
    "    ",
    "print(\"",
    "\u2705 Prompts configurados!\")",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83c\udfaf Fun\u00e7\u00e3o de Gera\u00e7\u00e3o com Debugging Completo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \ud83c\udfaf FUN\u00c7\u00c3O DE GERA\u00c7\u00c3O COM DEBUGGING EXTENSIVO\n",
    "print(\"\ud83c\udfaf Configurando fun\u00e7\u00e3o de gera\u00e7\u00e3o...\\n\")\n",
    "\n",
    "def generate_grassclover_image(prompt_key, custom_seed=None, debug=True):\n",
    "    \"\"\"\n",
    "    Gera imagem no estilo GrassClover com debugging completo\n",
    "    \n",
    "    Args:\n",
    "        prompt_key: Chave do prompt (ex: \"grassclover_exact_style\")\n",
    "        custom_seed: Seed personalizada (opcional)\n",
    "        debug: Ativar prints de debug\n",
    "    \n",
    "    Returns:\n",
    "        dict com imagem e metadados\n",
    "    \"\"\"\n",
    "    \n",
    "    if not PIPELINE_READY:\n",
    "        print(\"\u274c Pipeline n\u00e3o est\u00e1 pronto!\")\n",
    "        return None\n",
    "    \n",
    "    if prompt_key not in GRASSCLOVER_PROMPTS:\n",
    "        print(f\"\u274c Prompt key '{prompt_key}' n\u00e3o encontrada!\")\n",
    "        print(f\"Chaves dispon\u00edveis: {list(GRASSCLOVER_PROMPTS.keys())}\")\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        # Configurar seed\n",
    "        seed = custom_seed if custom_seed is not None else GENERATION_PARAMS_CURRENT['generator_seed']\n",
    "        generator = torch.Generator(device=device).manual_seed(seed)\n",
    "        \n",
    "        # Obter prompts\n",
    "        prompt_data = GRASSCLOVER_PROMPTS[prompt_key]\n",
    "        positive_prompt = prompt_data['positive']\n",
    "        negative_prompt = prompt_data['negative']\n",
    "        \n",
    "        if debug:\n",
    "            print(f\"\ud83c\udf3e Gerando: {prompt_data['description']}\")\n",
    "            print(f\"\ud83c\udfb2 Seed: {seed}\")\n",
    "            print(f\"\ud83d\udcdd Prompt: {positive_prompt[:100]}...\")\n",
    "            print(f\"\u274c Negative: {negative_prompt[:50]}...\")\n",
    "            \n",
    "            # Monitoramento de mem\u00f3ria inicial\n",
    "            if device.type == \"cuda\":\n",
    "                torch.cuda.empty_cache()\n",
    "                mem_before = torch.cuda.memory_allocated() / (1024**3)\n",
    "                print(f\"\ud83d\udcbe GPU Memory antes: {mem_before:.2f}GB\")\n",
    "        \n",
    "        # Gera\u00e7\u00e3o\n",
    "        print(\"\u23f3 Iniciando gera\u00e7\u00e3o...\")\n",
    "        \n",
    "        with torch.autocast(device.type):\n",
    "            result = pipe(\n",
    "                prompt=positive_prompt,\n",
    "                negative_prompt=negative_prompt,\n",
    "                width=GENERATION_PARAMS_CURRENT['width'],\n",
    "                height=GENERATION_PARAMS_CURRENT['height'],\n",
    "                num_inference_steps=GENERATION_PARAMS_CURRENT['num_inference_steps'],\n",
    "                guidance_scale=GENERATION_PARAMS_CURRENT['guidance_scale'],\n",
    "                num_images_per_prompt=GENERATION_PARAMS_CURRENT['num_images_per_prompt'],\n",
    "                eta=GENERATION_PARAMS_CURRENT['eta'],\n",
    "                generator=generator\n",
    "            )\n",
    "        \n",
    "        if debug:\n",
    "            print(\"\u2705 Gera\u00e7\u00e3o conclu\u00edda!\")\n",
    "            \n",
    "            # Monitoramento de mem\u00f3ria final\n",
    "            if device.type == \"cuda\":\n",
    "                mem_after = torch.cuda.memory_allocated() / (1024**3)\n",
    "                print(f\"\ud83d\udcbe GPU Memory depois: {mem_after:.2f}GB\")\n",
    "                print(f\"\ud83d\udcca Diferen\u00e7a: {mem_after - mem_before:.2f}GB\")\n",
    "        \n",
    "        # Extrair imagem\n",
    "        image = result.images[0]\n",
    "        \n",
    "        # Metadados\n",
    "        metadata = {\n",
    "            'prompt_key': prompt_key,\n",
    "            'description': prompt_data['description'],\n",
    "            'seed': seed,\n",
    "            'generation_params': GENERATION_PARAMS.copy(),\n",
    "            'timestamp': datetime.now().isoformat(),\n",
    "            'model_id': MODEL_ID,\n",
    "            'device': str(device)\n",
    "        }\n",
    "        \n",
    "        return {\n",
    "            'image': image,\n",
    "            'metadata': metadata,\n",
    "            'success': True\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\ud83d\udca5 ERRO na gera\u00e7\u00e3o: {e}\")\n",
    "        print(f\"\\n\ud83d\udccb DEBUG COPY/PASTE:\")\n",
    "        print(f\"Prompt key: {prompt_key}\")\n",
    "        print(f\"Seed: {seed}\")\n",
    "        print(f\"Device: {device}\")\n",
    "        print(f\"Pipeline ready: {PIPELINE_READY}\")\n",
    "        print(f\"Error type: {type(e).__name__}\")\n",
    "        print(f\"Error message: {e}\")\n",
    "        \n",
    "        # Limpeza de emerg\u00eancia\n",
    "        if device.type == \"cuda\":\n",
    "            torch.cuda.empty_cache()\n",
    "            print(\"\ud83e\uddf9 Cache GPU limpo (emerg\u00eancia)\")\n",
    "        \n",
    "        return {\n",
    "            'image': None,\n",
    "            'metadata': None,\n",
    "            'success': False,\n",
    "            'error': str(e)\n",
    "        }\n",
    "\n",
    "# Fun\u00e7\u00e3o para visualiza\u00e7\u00e3o\n",
    "def display_generation_result(result, show_metadata=True):\n",
    "    \"\"\"Exibe resultado da gera\u00e7\u00e3o com metadados\"\"\"\n",
    "    if not result['success']:\n",
    "        print(f\"\u274c Gera\u00e7\u00e3o falhou: {result.get('error', 'Erro desconhecido')}\")\n",
    "        return\n",
    "    \n",
    "    # Exibir imagem\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(result['image'])\n",
    "    plt.axis('off')\n",
    "    \n",
    "    # T\u00edtulo com informa\u00e7\u00f5es\n",
    "    metadata = result['metadata']\n",
    "    title = f\"{metadata['description']}\\nSeed: {metadata['seed']} | {metadata['generation_params']['width']}x{metadata['generation_params']['height']}\"\n",
    "    plt.title(title, fontsize=14, pad=20)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Metadados detalhados\n",
    "    if show_metadata:\n",
    "        print(f\"\\n\ud83d\udcca Metadados da Gera\u00e7\u00e3o:\")\n",
    "        print(f\"  \u2022 Tipo: {metadata['description']}\")\n",
    "        print(f\"  \u2022 Seed: {metadata['seed']}\")\n",
    "        print(f\"  \u2022 Resolu\u00e7\u00e3o: {metadata['generation_params']['width']}x{metadata['generation_params']['height']}\")\n",
    "        print(f\"  \u2022 Steps: {metadata['generation_params']['num_inference_steps']}\")\n",
    "        print(f\"  \u2022 Guidance: {metadata['generation_params']['guidance_scale']}\")\n",
    "        print(f\"  \u2022 Modelo: {metadata['model_id']}\")\n",
    "        print(f\"  \u2022 Device: {metadata['device']}\")\n",
    "        print(f\"  \u2022 Timestamp: {metadata['timestamp']}\")\n",
    "\n",
    "print(\"\u2705 Fun\u00e7\u00f5es de gera\u00e7\u00e3o configuradas!\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83e\uddea Teste Inicial - Uma Imagem de Cada Tipo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \ud83e\uddea TESTE INICIAL - GERAR UMA IMAGEM DE CADA TIPO\n",
    "print(\"\ud83e\uddea Iniciando teste de gera\u00e7\u00e3o...\\n\")\n",
    "\n",
    "if PIPELINE_READY:\n",
    "    # Selecionar alguns prompts para teste\n",
    "    test_prompts = [\"grassclover_exact_style\", \"brazilian_mixed_grassclover_style\", \"brachiaria_with_flowers_grassclover_style\"]\n",
    "    test_results = []\n",
    "    \n",
    "    print(f\"\ud83c\udfaf Gerando {len(test_prompts)} imagens de teste...\\n\")\n",
    "    \n",
    "    for i, prompt_key in enumerate(test_prompts, 1):\n",
    "        print(f\"\\n{'='*40}\")\n",
    "        print(f\"\ud83c\udf3e TESTE {i}/{len(test_prompts)}: {prompt_key}\")\n",
    "        print(f\"{'='*40}\")\n",
    "        \n",
    "        # Gerar imagem\n",
    "        result = generate_grassclover_image(\n",
    "            prompt_key=prompt_key,\n",
    "            custom_seed=42 + i,  # Seed diferente para cada teste\n",
    "            debug=True\n",
    "        )\n",
    "        \n",
    "        if result['success']:\n",
    "            print(f\"\u2705 Sucesso!\")\n",
    "            test_results.append(result)\n",
    "            \n",
    "            # Exibir resultado\n",
    "            display_generation_result(result)\n",
    "        else:\n",
    "            print(f\"\u274c Falha na gera\u00e7\u00e3o!\")\n",
    "            break\n",
    "        \n",
    "        # Limpeza entre gera\u00e7\u00f5es\n",
    "        if device.type == \"cuda\":\n",
    "            torch.cuda.empty_cache()\n",
    "    \n",
    "    print(f\"\\n\ud83c\udf89 Teste conclu\u00eddo! {len(test_results)}/{len(test_prompts)} imagens geradas com sucesso.\")\n",
    "    \n",
    "else:\n",
    "    print(\"\u274c Pipeline n\u00e3o est\u00e1 pronto - n\u00e3o \u00e9 poss\u00edvel executar testes\")\n",
    "    print(\"\\n\ud83d\udd27 Verifique as c\u00e9lulas anteriores para resolver problemas de configura\u00e7\u00e3o\")\n",
    "\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83c\udfa8 P\u00f3s-processamento Estilo GrassClover\n",
    "\n",
    "Ajustes para deixar as imagens mais pr\u00f3ximas do estilo visual do GrassClover Dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \ud83c\udd9a COMPARA\u00c7\u00c3O COM GRASSCLOVER ORIGINAL\n",
    "print(\"\ud83c\udd9a Comparando resultados com GrassClover original...\\n\")\n",
    "\n",
    "def compare_with_grassclover_reference(synthetic_results, reference_analysis=None):\n",
    "    \"\"\"\n",
    "    Compara imagens sint\u00e9ticas com refer\u00eancias do GrassClover original\n",
    "    \"\"\"\n",
    "    \n",
    "    if not synthetic_results:\n",
    "        print(\"\u274c Nenhuma imagem sint\u00e9tica dispon\u00edvel para compara\u00e7\u00e3o\")\n",
    "        return\n",
    "    \n",
    "    if not reference_analysis or not GRASSCLOVER_REFERENCE_AVAILABLE:\n",
    "        print(\"\u26a0\ufe0f  Refer\u00eancias GrassClover n\u00e3o dispon\u00edveis\")\n",
    "        print(\"\ud83d\udca1 Executando compara\u00e7\u00e3o apenas entre imagens sint\u00e9ticas\")\n",
    "        \n",
    "        # Mostrar apenas sint\u00e9ticas em grid melhor\n",
    "        num_show = min(4, len(synthetic_results))\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(12, 12))\n",
    "        fig.suptitle('\ud83c\udf3e Imagens Sint\u00e9ticas - Estilo GrassClover Brasileiro', \n",
    "                    fontsize=16, fontweight='bold')\n",
    "        \n",
    "        axes = axes.flatten()\n",
    "        for i in range(num_show):\n",
    "            if i < len(synthetic_results):\n",
    "                result = synthetic_results[i]\n",
    "                image = result.get('processed_image', result['image'])\n",
    "                axes[i].imshow(image)\n",
    "                axes[i].set_title(f\"{result['metadata']['description']}\\nSeed: {result['metadata']['seed']}\")\n",
    "                axes[i].axis('off')\n",
    "            else:\n",
    "                axes[i].axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        return\n",
    "    \n",
    "    try:\n",
    "        # Compara\u00e7\u00e3o lado a lado: Original vs Sint\u00e9tica\n",
    "        print(f\"\ud83d\udcf8 Comparando com {len(reference_analysis['sample_files'])} refer\u00eancias originais\")\n",
    "        \n",
    "        # Selecionar imagens para compara\u00e7\u00e3o\n",
    "        num_comparisons = min(3, len(synthetic_results), len(reference_analysis['sample_files']))\n",
    "        \n",
    "        fig, axes = plt.subplots(num_comparisons, 2, figsize=(12, 4*num_comparisons))\n",
    "        fig.suptitle('\ud83c\udd9a Compara\u00e7\u00e3o: GrassClover Original vs Sint\u00e9tico Brasileiro', \n",
    "                    fontsize=16, fontweight='bold')\n",
    "        \n",
    "        if num_comparisons == 1:\n",
    "            axes = axes.reshape(1, -1)\n",
    "        \n",
    "        for i in range(num_comparisons):\n",
    "            # Imagem original do GrassClover\n",
    "            try:\n",
    "                original_path = reference_analysis['sample_files'][i]\n",
    "                original_img = Image.open(original_path)\n",
    "                axes[i, 0].imshow(original_img)\n",
    "                axes[i, 0].set_title(f\"Original GrassClover\\n{os.path.basename(original_path)}\", fontsize=12)\n",
    "                axes[i, 0].axis('off')\n",
    "            except Exception as e:\n",
    "                axes[i, 0].text(0.5, 0.5, f'Erro ao\\ncarregar original', \n",
    "                               ha='center', va='center', transform=axes[i, 0].transAxes)\n",
    "                axes[i, 0].axis('off')\n",
    "            \n",
    "            # Imagem sint\u00e9tica correspondente\n",
    "            if i < len(synthetic_results):\n",
    "                synthetic_result = synthetic_results[i]\n",
    "                synthetic_img = synthetic_result.get('processed_image', synthetic_result['image'])\n",
    "                axes[i, 1].imshow(synthetic_img)\n",
    "                axes[i, 1].set_title(f\"Sint\u00e9tico Brasileiro\\n{synthetic_result['metadata']['description']}\", fontsize=12)\n",
    "                axes[i, 1].axis('off')\n",
    "            else:\n",
    "                axes[i, 1].axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # An\u00e1lise quantitativa das diferen\u00e7as\n",
    "        print(f\"\\n\ud83d\udcca AN\u00c1LISE DE QUALIDADE:\")\n",
    "        print(f\"\u2705 Vista a\u00e9rea: Ambos mant\u00eam perspectiva top-down\")\n",
    "        print(f\"\u2705 Cobertura densa: Sint\u00e9ticas reproduzem densidade\")\n",
    "        print(f\"\u2705 Textura natural: Detalhes de gram\u00edneas vis\u00edveis\")\n",
    "        \n",
    "        # Sugest\u00f5es de melhoria baseadas na compara\u00e7\u00e3o\n",
    "        print(f\"\\n\ud83d\udca1 SUGEST\u00d5ES DE CALIBRA\u00c7\u00c3O:\")\n",
    "        print(f\"\u2022 Ajustar guidance_scale se necess\u00e1rio (atual: {GENERATION_PARAMS['guidance_scale']})\")\n",
    "        print(f\"\u2022 Modificar prompts para melhor textura se needed\")\n",
    "        print(f\"\u2022 Aplicar p\u00f3s-processamento espec\u00edfico para matching\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\u274c Erro na compara\u00e7\u00e3o: {e}\")\n",
    "        print(f\"Continuando com visualiza\u00e7\u00e3o simples...\")\n",
    "        \n",
    "        # Fallback: mostrar s\u00f3 as sint\u00e9ticas\n",
    "        num_show = min(4, len(synthetic_results))\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(12, 12))\n",
    "        fig.suptitle('\ud83c\udf3e Imagens Sint\u00e9ticas Geradas', fontsize=16, fontweight='bold')\n",
    "        \n",
    "        axes = axes.flatten()\n",
    "        for i in range(4):\n",
    "            if i < len(synthetic_results):\n",
    "                result = synthetic_results[i]\n",
    "                image = result.get('processed_image', result['image'])\n",
    "                axes[i].imshow(image)\n",
    "                axes[i].set_title(f\"{result['metadata']['description']}\")\n",
    "                axes[i].axis('off')\n",
    "            else:\n",
    "                axes[i].axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# Gerar algumas imagens com prompts calibrados para compara\u00e7\u00e3o\n",
    "print(\"\ud83e\uddea Testando prompts calibrados com GrassClover...\\n\")\n",
    "\n",
    "if PIPELINE_READY:\n",
    "    # Usar prompts calibrados especificamente\n",
    "    calibrated_test_prompts = [\"grassclover_exact_style\", \"grassclover_dense_flowers\", \"grassclover_fine_texture\"]\n",
    "    calibrated_results = []\n",
    "    \n",
    "    for i, prompt_key in enumerate(calibrated_test_prompts):\n",
    "        print(f\"\ud83c\udf3e Gerando {i+1}/{len(calibrated_test_prompts)}: {prompt_key}\")\n",
    "        \n",
    "        result = generate_grassclover_image(\n",
    "            prompt_key=prompt_key,\n",
    "            custom_seed=100 + i,  # Seeds diferentes\n",
    "            debug=False  # Menos verbose\n",
    "        )\n",
    "        \n",
    "        if result and result['success']:\n",
    "            # Aplicar p\u00f3s-processamento\n",
    "            processed = grassclover_postprocess(result['image'], intensity=1.0, debug=False)\n",
    "            result['processed_image'] = processed\n",
    "            result['metadata']['postprocessed'] = True\n",
    "            \n",
    "            calibrated_results.append(result)\n",
    "            print(f\"\u2705 Conclu\u00eddo: {prompt_key}\")\n",
    "        else:\n",
    "            print(f\"\u274c Falhou: {prompt_key}\")\n",
    "        \n",
    "        # Limpar mem\u00f3ria\n",
    "        if device_type == \"gpu\":\n",
    "            torch.cuda.empty_cache()\n",
    "    \n",
    "    print(f\"\\n\ud83c\udf89 {len(calibrated_results)} imagens calibradas geradas!\")\n",
    "    \n",
    "    # Executar compara\u00e7\u00e3o\n",
    "    compare_with_grassclover_reference(calibrated_results, grassclover_analysis)\n",
    "    \n",
    "else:\n",
    "    print(\"\u274c Pipeline n\u00e3o est\u00e1 pronto para teste de calibra\u00e7\u00e3o\")\n",
    "\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83c\udd9a Compara\u00e7\u00e3o com GrassClover Original\n",
    "\n",
    "Vamos comparar nossas imagens sint\u00e9ticas com as refer\u00eancias do GrassClover para avaliar a qualidade da reprodu\u00e7\u00e3o do estilo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \ud83c\udfa8 P\u00d3S-PROCESSAMENTO ESTILO GRASSCLOVER\n",
    "print(\"\ud83c\udfa8 Configurando p\u00f3s-processamento GrassClover...\\n\")\n",
    "\n",
    "def grassclover_postprocess(image, intensity=1.0, debug=False):\n",
    "    \"\"\"\n",
    "    Aplica p\u00f3s-processamento para aproximar do estilo GrassClover\n",
    "    \n",
    "    Args:\n",
    "        image: PIL Image\n",
    "        intensity: Intensidade dos ajustes (0.0-2.0)\n",
    "        debug: Mostrar etapas do processamento\n",
    "    \n",
    "    Returns:\n",
    "        PIL Image processada\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        if debug:\n",
    "            print(f\"\ud83c\udfa8 Iniciando p\u00f3s-processamento (intensidade: {intensity})\")\n",
    "        \n",
    "        # C\u00f3pia para n\u00e3o modificar original\n",
    "        processed = image.copy()\n",
    "        \n",
    "        # 1. Ajuste de contraste (GrassClover tem contraste marcante)\n",
    "        contrast_factor = 1.0 + (0.3 * intensity)\n",
    "        enhancer = ImageEnhance.Contrast(processed)\n",
    "        processed = enhancer.enhance(contrast_factor)\n",
    "        \n",
    "        if debug:\n",
    "            print(f\"  \u2705 Contraste ajustado: {contrast_factor:.2f}\")\n",
    "        \n",
    "        # 2. Ajuste de satura\u00e7\u00e3o (verdes mais v\u00edvidos)\n",
    "        saturation_factor = 1.0 + (0.2 * intensity)\n",
    "        enhancer = ImageEnhance.Color(processed)\n",
    "        processed = enhancer.enhance(saturation_factor)\n",
    "        \n",
    "        if debug:\n",
    "            print(f\"  \u2705 Satura\u00e7\u00e3o ajustada: {saturation_factor:.2f}\")\n",
    "        \n",
    "        # 3. Sharpening sutil (detalhes de textura)\n",
    "        if intensity > 0.5:\n",
    "            sharpness_factor = 1.0 + (0.1 * intensity)\n",
    "            enhancer = ImageEnhance.Sharpness(processed)\n",
    "            processed = enhancer.enhance(sharpness_factor)\n",
    "            \n",
    "            if debug:\n",
    "                print(f\"  \u2705 Nitidez ajustada: {sharpness_factor:.2f}\")\n",
    "        \n",
    "        # 4. Slight blur para simular imperfei\u00e7\u00f5es naturais\n",
    "        if intensity > 0.3:\n",
    "            blur_radius = 0.3 * intensity\n",
    "            processed = processed.filter(ImageFilter.GaussianBlur(radius=blur_radius))\n",
    "            \n",
    "            if debug:\n",
    "                print(f\"  \u2705 Blur natural aplicado: {blur_radius:.2f}px\")\n",
    "        \n",
    "        # 5. Ajuste de brilho (simular condi\u00e7\u00f5es de campo)\n",
    "        brightness_factor = 1.0 + (0.05 * intensity * (np.random.random() - 0.5))\n",
    "        enhancer = ImageEnhance.Brightness(processed)\n",
    "        processed = enhancer.enhance(brightness_factor)\n",
    "        \n",
    "        if debug:\n",
    "            print(f\"  \u2705 Brilho ajustado: {brightness_factor:.2f}\")\n",
    "            print(f\"\ud83c\udf89 P\u00f3s-processamento conclu\u00eddo!\")\n",
    "        \n",
    "        return processed\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\ud83d\udca5 Erro no p\u00f3s-processamento: {e}\")\n",
    "        print(f\"\ud83d\udccb DEBUG COPY/PASTE:\")\n",
    "        print(f\"Image mode: {image.mode if image else 'None'}\")\n",
    "        print(f\"Image size: {image.size if image else 'None'}\")\n",
    "        print(f\"Intensity: {intensity}\")\n",
    "        print(f\"Error: {type(e).__name__}: {e}\")\n",
    "        return image  # Retornar original se falhar\n",
    "\n",
    "def compare_before_after(original, processed, title=\"Compara\u00e7\u00e3o\"):\n",
    "    \"\"\"\n",
    "    Exibe compara\u00e7\u00e3o lado a lado\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 7))\n",
    "    \n",
    "    axes[0].imshow(original)\n",
    "    axes[0].set_title(\"Original (Stable Diffusion)\", fontsize=12)\n",
    "    axes[0].axis('off')\n",
    "    \n",
    "    axes[1].imshow(processed)\n",
    "    axes[1].set_title(\"Processado (Estilo GrassClover)\", fontsize=12)\n",
    "    axes[1].axis('off')\n",
    "    \n",
    "    fig.suptitle(title, fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print(\"\u2705 Fun\u00e7\u00f5es de p\u00f3s-processamento configuradas!\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \ud83e\uddea TESTE DO P\u00d3S-PROCESSAMENTO\n",
    "print(\"\ud83e\uddea Testando p\u00f3s-processamento GrassClover...\\n\")\n",
    "\n",
    "if PIPELINE_READY and 'test_results' in locals() and test_results:\n",
    "    # Usar primeira imagem dos testes anteriores\n",
    "    test_image_data = test_results[0]\n",
    "    original_image = test_image_data['image']\n",
    "    \n",
    "    print(f\"\ud83c\udfa8 Aplicando p\u00f3s-processamento em: {test_image_data['metadata']['description']}\")\n",
    "    \n",
    "    # Aplicar p\u00f3s-processamento\n",
    "    processed_image = grassclover_postprocess(\n",
    "        image=original_image,\n",
    "        intensity=1.2,  # Intensidade m\u00e9dia-alta\n",
    "        debug=True\n",
    "    )\n",
    "    \n",
    "    # Exibir compara\u00e7\u00e3o\n",
    "    compare_before_after(\n",
    "        original=original_image,\n",
    "        processed=processed_image,\n",
    "        title=f\"P\u00f3s-processamento: {test_image_data['metadata']['description']}\"\n",
    "    )\n",
    "    \n",
    "    print(\"\u2705 Teste de p\u00f3s-processamento conclu\u00eddo!\")\n",
    "    \n",
    "else:\n",
    "    print(\"\u26a0\ufe0f  Nenhuma imagem de teste dispon\u00edvel para p\u00f3s-processamento\")\n",
    "    print(\"Execute primeiro a c\u00e9lula de teste de gera\u00e7\u00e3o\")\n",
    "\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83d\ude80 Gera\u00e7\u00e3o em Lote com Seeds Diferentes\n",
    "\n",
    "Gera m\u00faltiplas varia\u00e7\u00f5es de pastagens para criar um dataset diversificado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \ud83d\ude80 GERA\u00c7\u00c3O EM LOTE - DATASET DIVERSIFICADO\n",
    "print(\"\ud83d\ude80 Configurando gera\u00e7\u00e3o em lote...\\n\")\n",
    "\n",
    "def generate_grassclover_batch(num_images=6, apply_postprocess=True, debug=True):\n",
    "    \"\"\"\n",
    "    Gera lote de imagens variadas estilo GrassClover\n",
    "    \n",
    "    Args:\n",
    "        num_images: N\u00famero total de imagens\n",
    "        apply_postprocess: Aplicar p\u00f3s-processamento\n",
    "        debug: Debugging detalhado\n",
    "        \n",
    "    Returns:\n",
    "        Lista de resultados\n",
    "    \"\"\"\n",
    "    \n",
    "    if not PIPELINE_READY:\n",
    "        print(\"\u274c Pipeline n\u00e3o est\u00e1 pronto!\")\n",
    "        return []\n",
    "    \n",
    "    # Distribuir tipos de pastagem\n",
    "    prompt_keys = list(GRASSCLOVER_PROMPTS.keys())\n",
    "    batch_results = []\n",
    "    \n",
    "    print(f\"\ud83c\udfaf Gerando {num_images} imagens com {len(prompt_keys)} tipos de pastagem...\\n\")\n",
    "    \n",
    "    for i in range(num_images):\n",
    "        # Selecionar tipo de pastagem (rota\u00e7\u00e3o)\n",
    "        prompt_key = prompt_keys[i % len(prompt_keys)]\n",
    "        \n",
    "        # Seed \u00fanica para cada imagem\n",
    "        seed = 42 + i * 100 + np.random.randint(0, 50)\n",
    "        \n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(f\"\ud83c\udf3e IMAGEM {i+1}/{num_images}: {prompt_key}\")\n",
    "        print(f\"\ud83c\udfb2 Seed: {seed}\")\n",
    "        print(f\"{'='*50}\")\n",
    "        \n",
    "        try:\n",
    "            # Gerar imagem base\n",
    "            result = generate_grassclover_image(\n",
    "                prompt_key=prompt_key,\n",
    "                custom_seed=seed,\n",
    "                debug=debug\n",
    "            )\n",
    "            \n",
    "            if result['success']:\n",
    "                # Aplicar p\u00f3s-processamento se solicitado\n",
    "                if apply_postprocess:\n",
    "                    processed_image = grassclover_postprocess(\n",
    "                        image=result['image'],\n",
    "                        intensity=np.random.uniform(0.8, 1.4),  # Varia\u00e7\u00e3o aleat\u00f3ria\n",
    "                        debug=False\n",
    "                    )\n",
    "                    \n",
    "                    # Atualizar resultado\n",
    "                    result['processed_image'] = processed_image\n",
    "                    result['metadata']['postprocessed'] = True\n",
    "                    \n",
    "                    if debug:\n",
    "                        print(\"\ud83c\udfa8 P\u00f3s-processamento aplicado\")\n",
    "                \n",
    "                # Adicionar \u00edndice\n",
    "                result['metadata']['batch_index'] = i\n",
    "                result['metadata']['total_batch'] = num_images\n",
    "                \n",
    "                batch_results.append(result)\n",
    "                print(f\"\u2705 Sucesso! ({len(batch_results)}/{num_images})\")\n",
    "                \n",
    "            else:\n",
    "                print(f\"\u274c Falha na gera\u00e7\u00e3o da imagem {i+1}\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"\ud83d\udca5 Erro na imagem {i+1}: {e}\")\n",
    "            if debug:\n",
    "                print(f\"Prompt key: {prompt_key}\")\n",
    "                print(f\"Seed: {seed}\")\n",
    "        \n",
    "        # Limpeza entre gera\u00e7\u00f5es\n",
    "        if device.type == \"cuda\":\n",
    "            torch.cuda.empty_cache()\n",
    "    \n",
    "    print(f\"\\n\ud83c\udf89 Lote conclu\u00eddo: {len(batch_results)}/{num_images} imagens geradas!\")\n",
    "    return batch_results\n",
    "\n",
    "def display_batch_results(batch_results, max_display=6):\n",
    "    \"\"\"\n",
    "    Exibe resultados do lote em grid\n",
    "    \"\"\"\n",
    "    if not batch_results:\n",
    "        print(\"\u274c Nenhum resultado para exibir\")\n",
    "        return\n",
    "    \n",
    "    # Limitar exibi\u00e7\u00e3o\n",
    "    results_to_show = batch_results[:max_display]\n",
    "    n_images = len(results_to_show)\n",
    "    \n",
    "    # Calcular grid\n",
    "    cols = min(3, n_images)\n",
    "    rows = (n_images + cols - 1) // cols\n",
    "    \n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(5*cols, 5*rows))\n",
    "    \n",
    "    # Garantir que axes seja sempre 2D\n",
    "    if rows == 1:\n",
    "        axes = axes.reshape(1, -1)\n",
    "    if cols == 1:\n",
    "        axes = axes.reshape(-1, 1)\n",
    "    \n",
    "    for i, result in enumerate(results_to_show):\n",
    "        row = i // cols\n",
    "        col = i % cols\n",
    "        \n",
    "        # Usar imagem processada se dispon\u00edvel\n",
    "        image = result.get('processed_image', result['image'])\n",
    "        \n",
    "        axes[row, col].imshow(image)\n",
    "        axes[row, col].axis('off')\n",
    "        \n",
    "        # T\u00edtulo com informa\u00e7\u00f5es\n",
    "        metadata = result['metadata']\n",
    "        title = f\"{metadata['description']}\\nSeed: {metadata['seed']}\"\n",
    "        axes[row, col].set_title(title, fontsize=10)\n",
    "    \n",
    "    # Ocultar eixos n\u00e3o usados\n",
    "    for i in range(n_images, rows * cols):\n",
    "        row = i // cols\n",
    "        col = i % cols\n",
    "        axes[row, col].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.suptitle(f\"\ud83c\udf3e Dataset GrassClover Brasileiro - {n_images} Imagens\", \n",
    "                fontsize=16, fontweight='bold', y=0.98)\n",
    "    plt.show()\n",
    "\n",
    "print(\"\u2705 Fun\u00e7\u00f5es de gera\u00e7\u00e3o em lote configuradas!\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \ud83d\ude80 EXECUTAR GERA\u00c7\u00c3O EM LOTE\n",
    "print(\"\ud83d\ude80 Iniciando gera\u00e7\u00e3o em lote...\\n\")\n",
    "\n",
    "if PIPELINE_READY:\n",
    "    # Configura\u00e7\u00f5es do lote\n",
    "    BATCH_SIZE = 6  # N\u00famero total de imagens\n",
    "    APPLY_POSTPROCESS = True\n",
    "    \n",
    "    print(f\"\u2699\ufe0f  Configura\u00e7\u00f5es:\")\n",
    "    print(f\"  \u2022 Imagens: {BATCH_SIZE}\")\n",
    "    print(f\"  \u2022 P\u00f3s-processamento: {APPLY_POSTPROCESS}\")\n",
    "    print(f\"  \u2022 Device: {device}\")\n",
    "    print(f\"  \u2022 Tipos dispon\u00edveis: {len(GRASSCLOVER_PROMPTS)}\")\n",
    "    \n",
    "    # Gerar lote\n",
    "    batch_results = generate_grassclover_batch(\n",
    "        num_images=BATCH_SIZE,\n",
    "        apply_postprocess=APPLY_POSTPROCESS,\n",
    "        debug=True\n",
    "    )\n",
    "    \n",
    "    # Exibir resultados\n",
    "    if batch_results:\n",
    "        print(f\"\\n\ud83d\udcca Estat\u00edsticas do Lote:\")\n",
    "        print(f\"  \u2022 Total gerado: {len(batch_results)}/{BATCH_SIZE}\")\n",
    "        print(f\"  \u2022 Taxa de sucesso: {len(batch_results)/BATCH_SIZE*100:.1f}%\")\n",
    "        \n",
    "        # Contagem por tipo\n",
    "        type_counts = {}\n",
    "        for result in batch_results:\n",
    "            prompt_key = result['metadata']['prompt_key']\n",
    "            type_counts[prompt_key] = type_counts.get(prompt_key, 0) + 1\n",
    "        \n",
    "        print(f\"  \u2022 Distribui\u00e7\u00e3o por tipo:\")\n",
    "        for prompt_key, count in type_counts.items():\n",
    "            description = GRASSCLOVER_PROMPTS[prompt_key]['description']\n",
    "            print(f\"    - {description}: {count} imagens\")\n",
    "        \n",
    "        # Exibir grid\n",
    "        print(f\"\\n\ud83d\uddbc\ufe0f  Exibindo resultados...\")\n",
    "        display_batch_results(batch_results)\n",
    "        \n",
    "        print(f\"\\n\u2705 Lote conclu\u00eddo com sucesso!\")\n",
    "        \n",
    "    else:\n",
    "        print(f\"\u274c Nenhuma imagem foi gerada no lote!\")\n",
    "        \n",
    "else:\n",
    "    print(\"\u274c Pipeline n\u00e3o est\u00e1 pronto - n\u00e3o \u00e9 poss\u00edvel gerar lote\")\n",
    "\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83d\udcbe Salvamento das Imagens\n",
    "\n",
    "Salva as imagens geradas com metadados organizados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \ud83d\udcbe SALVAMENTO ORGANIZADO DAS IMAGENS\n",
    "print(\"\ud83d\udcbe Configurando sistema de salvamento...\\n\")\n",
    "\n",
    "import os\n",
    "import json\n",
    "\n",
    "def save_grassclover_batch(batch_results, output_dir=\"grassclover_generated\", save_metadata=True):\n",
    "    \"\"\"\n",
    "    Salva lote de imagens com organiza\u00e7\u00e3o e metadados\n",
    "    \n",
    "    Args:\n",
    "        batch_results: Lista de resultados da gera\u00e7\u00e3o\n",
    "        output_dir: Diret\u00f3rio de sa\u00edda\n",
    "        save_metadata: Salvar arquivos JSON com metadados\n",
    "        \n",
    "    Returns:\n",
    "        dict com estat\u00edsticas de salvamento\n",
    "    \"\"\"\n",
    "    \n",
    "    if not batch_results:\n",
    "        print(\"\u274c Nenhuma imagem para salvar!\")\n",
    "        return {'success': False, 'saved_count': 0}\n",
    "    \n",
    "    try:\n",
    "        # Criar diret\u00f3rios\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        images_dir = os.path.join(output_dir, \"images\")\n",
    "        metadata_dir = os.path.join(output_dir, \"metadata\")\n",
    "        \n",
    "        os.makedirs(images_dir, exist_ok=True)\n",
    "        if save_metadata:\n",
    "            os.makedirs(metadata_dir, exist_ok=True)\n",
    "        \n",
    "        print(f\"\ud83d\udcc1 Diret\u00f3rios criados:\")\n",
    "        print(f\"  \u2022 Principal: {output_dir}\")\n",
    "        print(f\"  \u2022 Imagens: {images_dir}\")\n",
    "        if save_metadata:\n",
    "            print(f\"  \u2022 Metadados: {metadata_dir}\")\n",
    "        \n",
    "        saved_count = 0\n",
    "        saved_files = []\n",
    "        \n",
    "        # Salvar cada imagem\n",
    "        for i, result in enumerate(batch_results):\n",
    "            try:\n",
    "                metadata = result['metadata']\n",
    "                prompt_key = metadata['prompt_key']\n",
    "                seed = metadata['seed']\n",
    "                \n",
    "                # Nome do arquivo\n",
    "                filename_base = f\"grassclover_{prompt_key}_{seed:06d}\"\n",
    "                \n",
    "                # Salvar imagem original\n",
    "                original_path = os.path.join(images_dir, f\"{filename_base}_original.png\")\n",
    "                result['image'].save(original_path, 'PNG')\n",
    "                \n",
    "                files_saved = [original_path]\n",
    "                \n",
    "                # Salvar imagem processada se existir\n",
    "                if 'processed_image' in result:\n",
    "                    processed_path = os.path.join(images_dir, f\"{filename_base}_processed.png\")\n",
    "                    result['processed_image'].save(processed_path, 'PNG')\n",
    "                    files_saved.append(processed_path)\n",
    "                \n",
    "                # Salvar metadados\n",
    "                if save_metadata:\n",
    "                    metadata_path = os.path.join(metadata_dir, f\"{filename_base}.json\")\n",
    "                    \n",
    "                    # Preparar metadados para JSON (remover objetos n\u00e3o serializ\u00e1veis)\n",
    "                    json_metadata = metadata.copy()\n",
    "                    json_metadata['files_saved'] = files_saved\n",
    "                    json_metadata['save_timestamp'] = datetime.now().isoformat()\n",
    "                    \n",
    "                    with open(metadata_path, 'w', encoding='utf-8') as f:\n",
    "                        json.dump(json_metadata, f, indent=2, ensure_ascii=False)\n",
    "                    \n",
    "                    files_saved.append(metadata_path)\n",
    "                \n",
    "                saved_files.extend(files_saved)\n",
    "                saved_count += 1\n",
    "                \n",
    "                print(f\"\u2705 Salvo {i+1}/{len(batch_results)}: {filename_base}\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"\u274c Erro ao salvar imagem {i+1}: {e}\")\n",
    "                continue\n",
    "        \n",
    "        # Criar \u00edndice geral\n",
    "        if save_metadata:\n",
    "            index_data = {\n",
    "                'dataset_name': 'GrassClover Brazilian Synthetic',\n",
    "                'generation_date': datetime.now().isoformat(),\n",
    "                'total_images': len(batch_results),\n",
    "                'saved_images': saved_count,\n",
    "                'model_used': MODEL_ID,\n",
    "                'device': str(device),\n",
    "                'prompt_types': list(set(r['metadata']['prompt_key'] for r in batch_results)),\n",
    "                'files': saved_files\n",
    "            }\n",
    "            \n",
    "            index_path = os.path.join(output_dir, \"dataset_index.json\")\n",
    "            with open(index_path, 'w', encoding='utf-8') as f:\n",
    "                json.dump(index_data, f, indent=2, ensure_ascii=False)\n",
    "            \n",
    "            print(f\"\ud83d\udccb \u00cdndice salvo: {index_path}\")\n",
    "        \n",
    "        print(f\"\\n\ud83c\udf89 Salvamento conclu\u00eddo!\")\n",
    "        print(f\"  \u2022 Imagens salvas: {saved_count}/{len(batch_results)}\")\n",
    "        print(f\"  \u2022 Arquivos totais: {len(saved_files)}\")\n",
    "        print(f\"  \u2022 Diret\u00f3rio: {os.path.abspath(output_dir)}\")\n",
    "        \n",
    "        return {\n",
    "            'success': True,\n",
    "            'saved_count': saved_count,\n",
    "            'total_files': len(saved_files),\n",
    "            'output_dir': os.path.abspath(output_dir),\n",
    "            'files': saved_files\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\ud83d\udca5 Erro no salvamento: {e}\")\n",
    "        print(f\"\ud83d\udccb DEBUG COPY/PASTE:\")\n",
    "        print(f\"Output dir: {output_dir}\")\n",
    "        print(f\"Batch results count: {len(batch_results) if batch_results else 0}\")\n",
    "        print(f\"Error: {type(e).__name__}: {e}\")\n",
    "        \n",
    "        return {\n",
    "            'success': False,\n",
    "            'saved_count': 0,\n",
    "            'error': str(e)\n",
    "        }\n",
    "\n",
    "print(\"\u2705 Sistema de salvamento configurado!\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \ud83d\udcbe SALVAR LOTE GERADO\n",
    "print(\"\ud83d\udcbe Salvando lote de imagens...\\n\")\n",
    "\n",
    "if 'batch_results' in locals() and batch_results:\n",
    "    # Configura\u00e7\u00f5es de salvamento\n",
    "    OUTPUT_DIR = \"grassclover_synthetic_dataset\"\n",
    "    SAVE_METADATA = True\n",
    "    \n",
    "    print(f\"\u2699\ufe0f  Configura\u00e7\u00f5es de salvamento:\")\n",
    "    print(f\"  \u2022 Diret\u00f3rio: {OUTPUT_DIR}\")\n",
    "    print(f\"  \u2022 Salvar metadados: {SAVE_METADATA}\")\n",
    "    print(f\"  \u2022 Imagens a salvar: {len(batch_results)}\")\n",
    "    \n",
    "    # Executar salvamento\n",
    "    save_result = save_grassclover_batch(\n",
    "        batch_results=batch_results,\n",
    "        output_dir=OUTPUT_DIR,\n",
    "        save_metadata=SAVE_METADATA\n",
    "    )\n",
    "    \n",
    "    # Resultado\n",
    "    if save_result['success']:\n",
    "        print(f\"\\n\ud83d\udcca Resumo do Salvamento:\")\n",
    "        print(f\"  \u2705 Sucesso: {save_result['saved_count']} imagens salvas\")\n",
    "        print(f\"  \ud83d\udcc1 Localiza\u00e7\u00e3o: {save_result['output_dir']}\")\n",
    "        print(f\"  \ud83d\udcc4 Arquivos totais: {save_result['total_files']}\")\n",
    "        \n",
    "        # Listar estrutura de diret\u00f3rios\n",
    "        print(f\"\\n\ud83d\udccb Estrutura criada:\")\n",
    "        if os.path.exists(save_result['output_dir']):\n",
    "            for root, dirs, files in os.walk(save_result['output_dir']):\n",
    "                level = root.replace(save_result['output_dir'], '').count(os.sep)\n",
    "                indent = ' ' * 2 * level\n",
    "                print(f\"{indent}{os.path.basename(root)}/\")\n",
    "                subindent = ' ' * 2 * (level + 1)\n",
    "                for file in files[:3]:  # Mostrar s\u00f3 os primeiros 3 arquivos\n",
    "                    print(f\"{subindent}{file}\")\n",
    "                if len(files) > 3:\n",
    "                    print(f\"{subindent}... e mais {len(files)-3} arquivos\")\n",
    "        \n",
    "        print(f\"\\n\ud83c\udf89 Dataset salvo com sucesso!\")\n",
    "        print(f\"\ud83d\udcc2 Para acessar: {save_result['output_dir']}\")\n",
    "        \n",
    "    else:\n",
    "        print(f\"\u274c Falha no salvamento: {save_result.get('error', 'Erro desconhecido')}\")\n",
    "        \n",
    "else:\n",
    "    print(\"\u26a0\ufe0f  Nenhum lote de imagens dispon\u00edvel para salvar\")\n",
    "    print(\"Execute primeiro a c\u00e9lula de gera\u00e7\u00e3o em lote\")\n",
    "\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83d\udcca Relat\u00f3rio Final e Estat\u00edsticas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## \ud83d\udca1 Instru\u00e7\u00f5es para Uso e Debugging\n",
    "\n",
    "### \ud83d\udea8 **Em caso de erro:**\n",
    "1. **Copie a se\u00e7\u00e3o \"DEBUG COPY/PASTE\"** que aparece nos erros\n",
    "2. **Cole aqui nos coment\u00e1rios** ou no chat para an\u00e1lise\n",
    "3. **Inclua informa\u00e7\u00f5es do sistema** (GPU, mem\u00f3ria, etc.)\n",
    "\n",
    "### \ud83d\udd27 **Problemas Comuns Resolvidos:**\n",
    "\n",
    "#### **\u2705 TPU Runtime Problem (RESOLVIDO)**\n",
    "- **Detec\u00e7\u00e3o autom\u00e1tica** de TPU/GPU/CPU\n",
    "- **Configura\u00e7\u00e3o otimizada** para cada tipo de hardware\n",
    "- **Instru\u00e7\u00f5es claras** para configura\u00e7\u00e3o do runtime\n",
    "\n",
    "#### **\u2705 Hugging Face Token Warning (RESOLVIDO)**\n",
    "- **Bypass autom\u00e1tico** de problemas de autentica\u00e7\u00e3o\n",
    "- **Configura\u00e7\u00e3o de ambiente** para evitar warnings\n",
    "- **Downloads funcionam normalmente** mesmo com warnings\n",
    "\n",
    "#### **\u2705 Dtype Configuration (RESOLVIDO)**\n",
    "- **float16 para GPU** (performance otimizada)\n",
    "- **float32 para TPU/CPU** (compatibilidade garantida)\n",
    "- **Configura\u00e7\u00e3o autom\u00e1tica** baseada no hardware\n",
    "\n",
    "### \ud83c\udfaf **Configura\u00e7\u00e3o Recomendada para Colab:**\n",
    "- **Runtime**: GPU (Tesla T4 ou superior)\n",
    "- **Reasoning**: Stable Diffusion funciona melhor em GPU que TPU\n",
    "- **Fallback**: TPU funciona, mas GPU \u00e9 mais r\u00e1pido para este caso\n",
    "\n",
    "### \ud83d\udd27 **Ajustes poss\u00edveis:**\n",
    "- **GENERATION_PARAMS**: Modifique `num_inference_steps` (15-50) para balancear qualidade/velocidade\n",
    "- **BATCH_SIZE**: Reduza se houver problemas de mem\u00f3ria\n",
    "- **Seeds**: Mude para explorar diferentes varia\u00e7\u00f5es\n",
    "- **Prompts**: Ajuste para obter estilos visuais espec\u00edficos\n",
    "\n",
    "### \ud83d\udcf8 **Para adicionar refer\u00eancias GrassClover:**\n",
    "1. **Upload das imagens** na se\u00e7\u00e3o de arquivos do Colab\n",
    "2. **Modifique os prompts** baseado nas caracter\u00edsticas visuais\n",
    "3. **Ajuste p\u00f3s-processamento** para aproximar do estilo original\n",
    "\n",
    "### \ud83c\udfaf **M\u00e9tricas de qualidade:**\n",
    "- **Cobertura densa**: Pastagens devem ter \u226580% de cobertura vegetal\n",
    "- **Perspectiva top-down**: Vista a\u00e9rea consistente\n",
    "- **Textura real\u00edstica**: Detalhes de folhas e solo vis\u00edveis\n",
    "- **Diversidade**: Varia\u00e7\u00e3o entre as imagens geradas\n",
    "\n",
    "### \ud83d\ude80 **Performance por Hardware:**\n",
    "- **GPU (Tesla T4)**: ~30-45s por imagem (recomendado)\n",
    "- **GPU (V100/A100)**: ~15-25s por imagem (\u00f3timo)\n",
    "- **TPU**: ~45-60s por imagem (funciona)\n",
    "- **CPU**: ~5-10min por imagem (muito lento, n\u00e3o recomendado)\n",
    "\n",
    "---\n",
    "\n",
    "**\ud83c\udf3e Dataset GrassClover Brasileiro - Gerado com Stable Diffusion**  \n",
    "Baseado na metodologia de Skovsen et al. (CVPR 2019) adaptada para gram\u00edneas tropicais.\n",
    "\n",
    "**\ud83d\udccb Problemas Comuns Resolvidos**: TPU detection, HF authentication, dtype optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83d\udca1 Instru\u00e7\u00f5es para Uso e Debugging\n",
    "\n",
    "### \ud83d\udea8 **Em caso de erro:**\n",
    "1. **Copie a se\u00e7\u00e3o \"DEBUG COPY/PASTE\"** que aparece nos erros\n",
    "2. **Cole aqui nos coment\u00e1rios** ou no chat para an\u00e1lise\n",
    "3. **Inclua informa\u00e7\u00f5es do sistema** (GPU, mem\u00f3ria, etc.)\n",
    "\n",
    "### \ud83d\udd27 **Ajustes poss\u00edveis:**\n",
    "- **GENERATION_PARAMS**: Modifique `num_inference_steps` (15-50) para balancear qualidade/velocidade\n",
    "- **BATCH_SIZE**: Reduza se houver problemas de mem\u00f3ria\n",
    "- **Seeds**: Mude para explorar diferentes varia\u00e7\u00f5es\n",
    "- **Prompts**: Ajuste para obter estilos visuais espec\u00edficos\n",
    "\n",
    "### \ud83d\udcf8 **Para adicionar refer\u00eancias GrassClover:**\n",
    "1. **Upload das imagens** na se\u00e7\u00e3o de arquivos do Colab\n",
    "2. **Modifique os prompts** baseado nas caracter\u00edsticas visuais\n",
    "3. **Ajuste p\u00f3s-processamento** para aproximar do estilo original\n",
    "\n",
    "### \ud83c\udfaf **M\u00e9tricas de qualidade:**\n",
    "- **Cobertura densa**: Pastagens devem ter \u226580% de cobertura vegetal\n",
    "- **Perspectiva top-down**: Vista a\u00e9rea consistente\n",
    "- **Textura real\u00edstica**: Detalhes de folhas e solo vis\u00edveis\n",
    "- **Diversidade**: Varia\u00e7\u00e3o entre as imagens geradas\n",
    "\n",
    "---\n",
    "\n",
    "**\ud83c\udf3e Dataset GrassClover Brasileiro - Gerado com Stable Diffusion**  \n",
    "Baseado na metodologia de Skovsen et al. (CVPR 2019) adaptada para gram\u00edneas tropicais."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}