{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üåæ GrassClover-Style Generation with Stable Diffusion\n",
    "\n",
    "Este notebook implementa gera√ß√£o de imagens sint√©ticas de pastagens brasileiras usando **Stable Diffusion**, seguindo o estilo visual do **GrassClover Dataset** (Skovsen et al., CVPR 2019).\n",
    "\n",
    "## üéØ Objetivos:\n",
    "- Gerar imagens **top-down** de pastagens com Stable Diffusion\n",
    "- Adaptar para **gram√≠neas brasileiras** (Brachiaria, Panicum, Cynodon)\n",
    "- Seguir **metodologia GrassClover** (densidade, perspectiva, resolu√ß√£o)\n",
    "- **Ultra-compat√≠vel** com Google Colab (debugging extensivo)\n",
    "\n",
    "## üìö Refer√™ncia:\n",
    "- **Paper**: Skovsen et al. \"The GrassClover Image Dataset for Semantic and Hierarchical Species Understanding in Agriculture\" (CVPR Workshops, 2019)\n",
    "- **Adapta√ß√£o**: Esp√©cies temperadas ‚Üí Tropicais brasileiras\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üöÄ Setup Ultra-Compat√≠vel para Colab\n",
    "\n",
    "**IMPORTANTE**: Este notebook foi desenvolvido para m√°xima compatibilidade com Google Colab Free/Pro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîç VERIFICA√á√ÉO INICIAL DO AMBIENTE\n",
    "print(\"=\" * 60)\n",
    "print(\"üåæ GRASSCLOVER STABLE DIFFUSION GENERATOR\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "import sys\n",
    "import platform\n",
    "from datetime import datetime\n",
    "\n",
    "print(f\"üìÖ Timestamp: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"üêç Python: {sys.version.split()[0]}\")\n",
    "print(f\"üíª Platform: {platform.system()} {platform.release()}\")\n",
    "print(f\"üìç Working Directory: {sys.path[0] if sys.path else 'Unknown'}\")\n",
    "\n",
    "# Detectar se estamos no Colab\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "    print(\"üî• Ambiente: Google Colab (DETECTADO)\")\n",
    "except ImportError:\n",
    "    IN_COLAB = False\n",
    "    print(\"üíª Ambiente: Local/Jupyter (DETECTADO)\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# üß† VERIFICA√á√ÉO AVAN√áADA DE HARDWARE (GPU/TPU/CPU)\nprint(\"üîç Verificando hardware dispon√≠vel...\\n\")\n\n# Vari√°veis de estado\ndevice = None\ndevice_type = \"unknown\"\nhardware_info = {}\n\n# Tentar importar torch primeiro\ntry:\n    import torch\n    TORCH_AVAILABLE = True\n    print(f\"‚úÖ PyTorch: {torch.__version__}\")\n    hardware_info['pytorch_version'] = torch.__version__\nexcept ImportError:\n    TORCH_AVAILABLE = False\n    print(\"‚ùå PyTorch n√£o encontrado - ser√° instalado\")\n\nif TORCH_AVAILABLE:\n    # 1. VERIFICAR TPU (prioridade alta no Colab)\n    try:\n        import torch_xla\n        import torch_xla.core.xla_model as xm\n        \n        # Detectar TPU\n        if xm.xrt_world_size() > 1:\n            device = xm.xla_device()\n            device_type = \"tpu\"\n            print(f\"üî• TPU DETECTADO: {device}\")\n            print(f\"üöÄ TPU cores: {xm.xrt_world_size()}\")\n            hardware_info.update({\n                'device_type': 'tpu',\n                'tpu_cores': xm.xrt_world_size(),\n                'device': str(device)\n            })\n        else:\n            print(\"‚ö†Ô∏è  TPU configurado mas n√£o dispon√≠vel\")\n            \n    except ImportError:\n        print(\"üìù torch_xla n√£o encontrado (normal se n√£o usar TPU)\")\n    except Exception as e:\n        print(f\"‚ö†Ô∏è  Erro ao verificar TPU: {e}\")\n    \n    # 2. VERIFICAR CUDA/GPU (se TPU n√£o dispon√≠vel)\n    if device is None:\n        cuda_available = torch.cuda.is_available()\n        print(f\"üî• CUDA dispon√≠vel: {cuda_available}\")\n        \n        if cuda_available:\n            gpu_count = torch.cuda.device_count()\n            print(f\"üöÄ N√∫mero de GPUs: {gpu_count}\")\n            \n            for i in range(gpu_count):\n                gpu_name = torch.cuda.get_device_name(i)\n                gpu_memory = torch.cuda.get_device_properties(i).total_memory\n                gpu_memory_gb = gpu_memory / (1024**3)\n                print(f\"  GPU {i}: {gpu_name}\")\n                print(f\"  Mem√≥ria: {gpu_memory_gb:.1f} GB\")\n            \n            device = torch.device(\"cuda\")\n            device_type = \"gpu\"\n            hardware_info.update({\n                'device_type': 'gpu',\n                'gpu_count': gpu_count,\n                'gpu_name': torch.cuda.get_device_name(0),\n                'gpu_memory_gb': torch.cuda.get_device_properties(0).total_memory / (1024**3),\n                'device': str(device)\n            })\n            \n            # Limpeza inicial de mem√≥ria GPU\n            torch.cuda.empty_cache()\n            print(\"üßπ Cache GPU limpo\")\n            \n        else:\n            print(\"‚ö†Ô∏è  CUDA n√£o dispon√≠vel\")\n    \n    # 3. FALLBACK PARA CPU\n    if device is None:\n        device = torch.device(\"cpu\")\n        device_type = \"cpu\"\n        hardware_info.update({\n            'device_type': 'cpu',\n            'device': str(device)\n        })\n        print(\"üíª Usando CPU (fallback)\")\n\n    # Status final do hardware\n    print(f\"\\nüéØ DEVICE CONFIGURADO: {device} ({device_type.upper()})\")\n    \n    # Instru√ß√µes espec√≠ficas para problemas\n    if device_type == \"cpu\" and IN_COLAB:\n        print(f\"\\nüö® IMPORTANTE: Voc√™ est√° usando CPU no Colab!\")\n        print(f\"Para ativar acelera√ß√£o de hardware:\")\n        print(f\"1. Runtime ‚Üí Change runtime type\")\n        print(f\"2. Hardware accelerator: GPU ou TPU\") \n        print(f\"3. Save ‚Üí Connect (reconectar)\")\n        print(f\"4. Re-executar este notebook\")\n        \n    elif device_type == \"tpu\":\n        print(f\"‚úÖ TPU configurado! Otimizado para treinamento paralelo.\")\n        \n    elif device_type == \"gpu\":\n        print(f\"‚úÖ GPU configurado! Otimizado para infer√™ncia r√°pida.\")\n\nelse:\n    device = None\n    device_type = \"none\"\n    print(\"\\n‚è≥ PyTorch ser√° instalado na pr√≥xima c√©lula\")\n\nprint(f\"\\nüìä Hardware Info: {hardware_info}\")\nprint(\"\\n\" + \"=\" * 60)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üì¶ INSTALA√á√ÉO DE DEPEND√äNCIAS ESSENCIAIS\n",
    "print(\"üì¶ Instalando depend√™ncias essenciais...\\n\")\n",
    "\n",
    "# Lista de pacotes essenciais\n",
    "essential_packages = [\n",
    "    \"torch\",\n",
    "    \"torchvision\", \n",
    "    \"diffusers\",\n",
    "    \"transformers\",\n",
    "    \"accelerate\",\n",
    "    \"pillow\",\n",
    "    \"matplotlib\",\n",
    "    \"numpy\"\n",
    "]\n",
    "\n",
    "# Fun√ß√£o para instalar com debug\n",
    "def install_package(package_name, quiet=True):\n",
    "    \"\"\"Instala pacote com debugging\"\"\"\n",
    "    import subprocess\n",
    "    \n",
    "    print(f\"‚è≥ Instalando {package_name}...\")\n",
    "    \n",
    "    try:\n",
    "        cmd = [\"pip\", \"install\", package_name]\n",
    "        if quiet:\n",
    "            cmd.append(\"--quiet\")\n",
    "        \n",
    "        result = subprocess.run(cmd, capture_output=True, text=True, timeout=300)\n",
    "        \n",
    "        if result.returncode == 0:\n",
    "            print(f\"‚úÖ {package_name} instalado com sucesso\")\n",
    "            return True\n",
    "        else:\n",
    "            print(f\"‚ùå Erro ao instalar {package_name}:\")\n",
    "            print(f\"STDOUT: {result.stdout}\")\n",
    "            print(f\"STDERR: {result.stderr}\")\n",
    "            return False\n",
    "            \n",
    "    except subprocess.TimeoutExpired:\n",
    "        print(f\"‚è∞ Timeout ao instalar {package_name}\")\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        print(f\"üí• Exce√ß√£o ao instalar {package_name}: {e}\")\n",
    "        return False\n",
    "\n",
    "# Instalar apenas se necess√°rio\n",
    "for package in essential_packages:\n",
    "    try:\n",
    "        __import__(package.replace(\"-\", \"_\"))\n",
    "        print(f\"‚úÖ {package} j√° dispon√≠vel\")\n",
    "    except ImportError:\n",
    "        success = install_package(package)\n",
    "        if not success:\n",
    "            print(f\"üö® FALHA CR√çTICA: N√£o foi poss√≠vel instalar {package}\")\n",
    "            print(f\"üìã DEBUG INFO para copy/paste:\")\n",
    "            print(f\"Package: {package}\")\n",
    "            print(f\"Environment: {'Colab' if IN_COLAB else 'Local'}\")\n",
    "            print(f\"Python: {sys.version}\")\n",
    "            break\n",
    "\n",
    "print(f\"\\nüéâ Instala√ß√£o conclu√≠da!\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# üîÑ REIMPORTA√á√ÉO E VERIFICA√á√ÉO FINAL COM CONFIGURA√á√ïES OTIMIZADAS\nprint(\"üîÑ Verificando importa√ß√µes finais e configurando hardware...\\n\")\n\n# Imports essenciais com debugging\ntry:\n    import torch\n    import torchvision.transforms as transforms\n    print(f\"‚úÖ PyTorch: {torch.__version__}\")\n    \n    # Reconfigurar device ap√≥s instala√ß√£o se necess√°rio\n    if not 'device' in locals() or device is None:\n        if torch.cuda.is_available():\n            device = torch.device(\"cuda\")\n            device_type = \"gpu\"\n            gpu_name = torch.cuda.get_device_name(0)\n            gpu_memory = torch.cuda.get_device_properties(0).total_memory / (1024**3)\n            print(f\"üöÄ GPU: {gpu_name} ({gpu_memory:.1f} GB)\")\n            \n            # Configura√ß√£o otimizada para GPU\n            torch.backends.cudnn.benchmark = True\n            torch.cuda.empty_cache()\n            \n        else:\n            device = torch.device(\"cpu\")\n            device_type = \"cpu\"\n            print(\"üíª Device: CPU\")\n    \n    # Configurar dtype baseado no hardware\n    if device_type == \"gpu\":\n        TORCH_DTYPE = torch.float16  # GPU: usar half precision\n        print(f\"üî¢ Dtype: {TORCH_DTYPE} (GPU otimizado)\")\n    elif device_type == \"tpu\":\n        TORCH_DTYPE = torch.float32  # TPU: full precision recomendado\n        print(f\"üî¢ Dtype: {TORCH_DTYPE} (TPU otimizado)\")\n    else:\n        TORCH_DTYPE = torch.float32  # CPU: full precision\n        print(f\"üî¢ Dtype: {TORCH_DTYPE} (CPU padr√£o)\")\n        \nexcept ImportError as e:\n    print(f\"‚ùå Erro PyTorch: {e}\")\n    device = None\n    device_type = \"none\"\n    TORCH_DTYPE = None\n\ntry:\n    from diffusers import StableDiffusionPipeline, DPMSolverMultistepScheduler\n    print(f\"‚úÖ Diffusers importado\")\n    DIFFUSERS_AVAILABLE = True\nexcept ImportError as e:\n    print(f\"‚ùå Erro Diffusers: {e}\")\n    DIFFUSERS_AVAILABLE = False\n\ntry:\n    from PIL import Image, ImageEnhance, ImageFilter\n    import matplotlib.pyplot as plt\n    import numpy as np\n    print(f\"‚úÖ PIL, Matplotlib, NumPy importados\")\n    BASIC_LIBS_AVAILABLE = True\nexcept ImportError as e:\n    print(f\"‚ùå Erro bibliotecas b√°sicas: {e}\")\n    BASIC_LIBS_AVAILABLE = False\n\n# Configura√ß√£o de ambiente Hugging Face\nprint(f\"\\nü§ó Configurando Hugging Face...\")\ntry:\n    import os\n    # Desabilitar telemetria para evitar warnings\n    os.environ[\"DISABLE_TELEMETRY\"] = \"1\"\n    os.environ[\"HF_HUB_DISABLE_TELEMETRY\"] = \"1\"\n    \n    # Configurar cache offline se necess√°rio\n    if IN_COLAB:\n        os.environ[\"TRANSFORMERS_OFFLINE\"] = \"0\"  # Permitir downloads no Colab\n        os.environ[\"HF_HUB_OFFLINE\"] = \"0\"\n    \n    print(f\"‚úÖ Vari√°veis HF configuradas (telemetria desabilitada)\")\nexcept Exception as e:\n    print(f\"‚ö†Ô∏è  Aviso na configura√ß√£o HF: {e}\")\n\n# Status final\nALL_READY = device is not None and DIFFUSERS_AVAILABLE and BASIC_LIBS_AVAILABLE\n\nprint(f\"\\n{'üéØ SISTEMA PRONTO!' if ALL_READY else 'üö® PROBLEMAS DETECTADOS!'}\")\nif ALL_READY:\n    print(f\"‚úÖ Device: {device} ({device_type})\")\n    print(f\"‚úÖ Dtype: {TORCH_DTYPE}\")\n    print(f\"‚úÖ Todas as bibliotecas carregadas\")\nelse:\n    print(\"\\nüìã DEBUG COPY/PASTE INFO:\")\n    print(f\"Device: {device}\")\n    print(f\"Device type: {device_type if 'device_type' in locals() else 'unknown'}\")\n    print(f\"Diffusers: {DIFFUSERS_AVAILABLE}\")\n    print(f\"Basic libs: {BASIC_LIBS_AVAILABLE}\")\n    print(f\"In Colab: {IN_COLAB}\")\n    \n    if device_type == \"cpu\" and IN_COLAB:\n        print(f\"\\nüîß A√á√ÉO NECESS√ÅRIA:\")\n        print(f\"1. Runtime ‚Üí Change runtime type\")\n        print(f\"2. Hardware accelerator: GPU\")\n        print(f\"3. Save e reconectar\")\n\nprint(\"=\" * 60)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üé® Pipeline Stable Diffusion para GrassClover\n",
    "\n",
    "Configura√ß√£o do pipeline otimizado para gera√ß√£o de pastagens no estilo GrassClover."
   ]
  },
  {
   "cell_type": "markdown",
   "source": "## üîß Troubleshooting - Problemas Comuns no Colab\n\n### üö® **PROBLEMA: TPU Runtime n√£o detectando TPU**\n**Sintomas**: `device_type = \"cpu\"` mesmo com runtime TPU selecionado\n\n**Solu√ß√µes**:\n1. **Verificar configura√ß√£o do runtime**:\n   - Runtime ‚Üí Change runtime type\n   - Hardware accelerator: **TPU v2** ou **GPU** (recomendado para Stable Diffusion)\n   - Save ‚Üí **Disconnect and delete runtime**\n   - **Connect** novamente\n\n2. **TPU vs GPU para Stable Diffusion**:\n   - **GPU √© recomendado** para Stable Diffusion (melhor suporte)\n   - **TPU** √© melhor para treinamento de modelos grandes\n   - Para este notebook: **prefira GPU (Tesla T4, V100, A100)**\n\n### ü§ó **PROBLEMA: Warnings do Hugging Face Token**\n**Sintomas**: `Error while fetching HF_TOKEN secret value`\n\n**Solu√ß√£o**: \n- ‚úÖ **Pode ser ignorado** - o modelo funcionar√° normalmente\n- O warning n√£o afeta a funcionalidade\n- Configura√ß√£o autom√°tica aplicada para bypass\n\n### üíæ **PROBLEMA: Mem√≥ria insuficiente**\n**Solu√ß√µes**:\n- Reduzir `BATCH_SIZE` nas gera√ß√µes em lote\n- Fechar outros notebooks abertos no Colab\n- Usar `torch.float16` (autom√°tico para GPU)\n- Runtime ‚Üí Factory reset runtime se necess√°rio\n\n---",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# üé® CONFIGURA√á√ÉO AVAN√áADA DO PIPELINE STABLE DIFFUSION\nprint(\"üé® Configurando Stable Diffusion Pipeline...\\n\")\n\n# Par√¢metros do pipeline baseados no hardware detectado\nMODEL_ID = \"runwayml/stable-diffusion-v1-5\"  # Modelo base confi√°vel\nLOW_CPU_MEM_USAGE = True\nENABLE_ATTENTION_SLICING = True\n\n# Configura√ß√µes espec√≠ficas por hardware\nif device_type == \"gpu\":\n    ENABLE_MODEL_CPU_OFFLOAD = False\n    ENABLE_SEQUENTIAL_CPU_OFFLOAD = False\n    USE_TORCH_COMPILE = True\nelif device_type == \"tpu\":\n    ENABLE_MODEL_CPU_OFFLOAD = True\n    ENABLE_SEQUENTIAL_CPU_OFFLOAD = False\n    USE_TORCH_COMPILE = False  # TPU pode ter problemas com compile\nelse:  # CPU\n    ENABLE_MODEL_CPU_OFFLOAD = True\n    ENABLE_SEQUENTIAL_CPU_OFFLOAD = True\n    USE_TORCH_COMPILE = False\n\nprint(f\"üì¶ Modelo: {MODEL_ID}\")\nprint(f\"üî¢ Dtype: {TORCH_DTYPE}\")\nprint(f\"üíæ Low CPU mem: {LOW_CPU_MEM_USAGE}\")\nprint(f\"‚ö° Attention slicing: {ENABLE_ATTENTION_SLICING}\")\nprint(f\"üèÉ Model CPU offload: {ENABLE_MODEL_CPU_OFFLOAD}\")\nprint(f\"üî• Hardware: {device_type.upper()}\")\n\n# Fun√ß√£o para carregar pipeline com debugging e bypass de autentica√ß√£o\ndef load_stable_diffusion_pipeline():\n    \\\"\\\"\\\"Carrega pipeline com m√°ximo debugging e configura√ß√µes otimizadas\\\"\\\"\\\"\n    try:\n        print(\"‚è≥ Carregando modelo...\")\n        \n        # Configura√ß√µes para bypass de problemas de autentica√ß√£o\n        load_kwargs = {\n            \"torch_dtype\": TORCH_DTYPE,\n            \"low_cpu_mem_usage\": LOW_CPU_MEM_USAGE,\n            \"use_safetensors\": True,\n        }\n        \n        # Configura√ß√µes espec√≠ficas para resolver problemas HF\n        try:\n            # Tentar com autentica√ß√£o padr√£o primeiro\n            pipe = StableDiffusionPipeline.from_pretrained(MODEL_ID, **load_kwargs)\n            print(\"‚úÖ Modelo carregado com autentica√ß√£o padr√£o\")\n        except Exception as auth_error:\n            print(f\"‚ö†Ô∏è  Problema de autentica√ß√£o: {str(auth_error)[:100]}...\")\n            print(\"üîÑ Tentando download for√ßado...\")\n            \n            # Bypass de problemas de autentica√ß√£o\n            load_kwargs[\"use_auth_token\"] = False\n            load_kwargs[\"force_download\"] = False\n            load_kwargs[\"resume_download\"] = True\n            \n            pipe = StableDiffusionPipeline.from_pretrained(MODEL_ID, **load_kwargs)\n            print(\"‚úÖ Modelo carregado com bypass de autentica√ß√£o\")\n        \n        # Mover para device\n        pipe = pipe.to(device)\n        print(f\"üöÄ Pipeline movido para {device}\")\n        \n        # Otimiza√ß√µes baseadas no hardware\n        if ENABLE_ATTENTION_SLICING:\n            pipe.enable_attention_slicing()\n            print(\"‚ö° Attention slicing habilitado\")\n        \n        if ENABLE_MODEL_CPU_OFFLOAD and device_type != \"cpu\":\n            try:\n                pipe.enable_model_cpu_offload()\n                print(\"üíæ Model CPU offload habilitado\")\n            except Exception as e:\n                print(f\"‚ö†Ô∏è  CPU offload falhou: {e}\")\n        \n        if ENABLE_SEQUENTIAL_CPU_OFFLOAD and device_type == \"cpu\":\n            try:\n                pipe.enable_sequential_cpu_offload()\n                print(\"üîÑ Sequential CPU offload habilitado\")\n            except Exception as e:\n                print(f\"‚ö†Ô∏è  Sequential offload falhou: {e}\")\n        \n        # Scheduler otimizado\n        pipe.scheduler = DPMSolverMultistepScheduler.from_config(pipe.scheduler.config)\n        print(\"üîß Scheduler otimizado (DPMSolver)\")\n        \n        # Configura√ß√µes de mem√≥ria espec√≠ficas\n        if device_type == \"gpu\":\n            torch.cuda.empty_cache()\n            allocated = torch.cuda.memory_allocated() / (1024**3)\n            cached = torch.cuda.memory_reserved() / (1024**3)\n            print(f\"üíæ GPU Memory - Allocated: {allocated:.2f}GB, Cached: {cached:.2f}GB\")\n            \n            # Verificar se h√° mem√≥ria suficiente\n            if allocated > 10.0:  # >10GB pode causar problemas\n                print(f\"‚ö†Ô∏è  Alta utiliza√ß√£o de mem√≥ria GPU!\")\n                \n        elif device_type == \"tpu\":\n            print(\"üî• TPU configurado - mem√≥ria gerenciada automaticamente\")\n            \n        else:  # CPU\n            print(\"üíª CPU mode - sem monitoramento de GPU memory\")\n        \n        print(\"\\\\n‚úÖ Pipeline configurado com sucesso!\")\n        return pipe\n        \n    except Exception as e:\n        print(f\"üí• ERRO ao carregar pipeline: {e}\")\n        print(f\"\\\\nüìã DEBUG COPY/PASTE:\")\n        print(f\"Model: {MODEL_ID}\")\n        print(f\"Device: {device} ({device_type})\")\n        print(f\"Dtype: {TORCH_DTYPE}\")\n        print(f\"Hardware info: {hardware_info if 'hardware_info' in locals() else 'N/A'}\")\n        print(f\"Error type: {type(e).__name__}\")\n        print(f\"Error message: {e}\")\n        \n        # Sugest√µes baseadas no tipo de erro\n        error_str = str(e).lower()\n        if \"authentication\" in error_str or \"token\" in error_str:\n            print(f\"\\\\nüí° SOLU√á√ÉO PARA ERRO DE TOKEN:\")\n            print(f\"1. Ignore o warning - o modelo deve funcionar mesmo assim\")\n            print(f\"2. Ou configure HF_TOKEN manualmente se necess√°rio\")\n            \n        elif \"memory\" in error_str or \"cuda\" in error_str:\n            print(f\"\\\\nüí° SOLU√á√ÉO PARA ERRO DE MEM√ìRIA:\")\n            print(f\"1. Reduzir batch_size\")\n            print(f\"2. Usar torch.float16 se estiver usando float32\")\n            print(f\"3. Fechar outros notebooks no Colab\")\n            \n        elif \"module\" in error_str or \"import\" in error_str:\n            print(f\"\\\\nüí° SOLU√á√ÉO PARA ERRO DE M√ìDULO:\")\n            print(f\"1. Re-executar c√©lulas de instala√ß√£o\")\n            print(f\"2. Restart runtime se necess√°rio\")\n            \n        return None\n\n# Carregar pipeline\nif ALL_READY:\n    pipe = load_stable_diffusion_pipeline()\n    PIPELINE_READY = pipe is not None\nelse:\n    pipe = None\n    PIPELINE_READY = False\n    print(\"‚ùå Sistema n√£o est√° pronto para carregar pipeline\")\n\nprint(\"=\" * 60)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üåæ Prompts para Pastagens Brasileiras - Estilo GrassClover\n",
    "\n",
    "Prompts espec√≠ficos para gerar pastagens tropicais seguindo a metodologia visual do GrassClover."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üåæ DEFINI√á√ÉO DE PROMPTS GRASSCLOVER-STYLE\n",
    "print(\"üåæ Configurando prompts para pastagens brasileiras...\\n\")\n",
    "\n",
    "# Prompts base seguindo metodologia GrassClover\n",
    "GRASSCLOVER_PROMPTS = {\n",
    "    'brachiaria_dominant': {\n",
    "        'positive': (\n",
    "            \"aerial top-down view of dense brazilian brachiaria grass pasture, \"\n",
    "            \"scientific photography, high resolution, natural lighting, \"\n",
    "            \"brachiaria brizantha, thick green grass blades, dense coverage, \"\n",
    "            \"tropical pasture, agricultural field, bird's eye view, \"\n",
    "            \"detailed grass texture, realistic, photorealistic, \"\n",
    "            \"ground sampling distance 4-8 pixels per millimeter, \"\n",
    "            \"green pasture, cattle grazing land, forage grass\"\n",
    "        ),\n",
    "        'negative': (\n",
    "            \"people, animals, buildings, vehicles, roads, fence, \"\n",
    "            \"side view, human perspective, low angle, \"\n",
    "            \"artificial, cartoon, painting, drawing, \"\n",
    "            \"blurry, low quality, watermark, text, \"\n",
    "            \"dead grass, brown grass, desert, sand\"\n",
    "        ),\n",
    "        'description': \"Brachiaria dominante - pastagem densa\"\n",
    "    },\n",
    "    \n",
    "    'panicum_lush': {\n",
    "        'positive': (\n",
    "            \"overhead drone view of panicum maximum grass field, \"\n",
    "            \"momba√ßa grass, tanz√¢nia grass, tall tropical grass, \"\n",
    "            \"lush green pasture, aerial perspective, \"\n",
    "            \"scientific agricultural photography, detailed, \"\n",
    "            \"high quality, natural sunlight, \"\n",
    "            \"dense vegetation, forage quality, \"\n",
    "            \"top-down view, bird's eye perspective\"\n",
    "        ),\n",
    "        'negative': (\n",
    "            \"ground level, eye level, side angle, \"\n",
    "            \"people, animals, machinery, infrastructure, \"\n",
    "            \"artistic, stylized, painted, sketch, \"\n",
    "            \"low resolution, pixelated, compressed, \"\n",
    "            \"autumn, winter, dry season, yellow grass\"\n",
    "        ),\n",
    "        'description': \"Panicum exuberante - gram√≠nea alta\"\n",
    "    },\n",
    "    \n",
    "    'mixed_pasture': {\n",
    "        'positive': (\n",
    "            \"aerial view mixed tropical pasture, brachiaria and panicum, \"\n",
    "            \"diverse grass species, natural grass composition, \"\n",
    "            \"overhead agricultural photography, \"\n",
    "            \"brazilian tropical grassland, cattle pasture, \"\n",
    "            \"varied grass heights, natural diversity, \"\n",
    "            \"realistic lighting, high detail, \"\n",
    "            \"top-down perspective, scientific quality\"\n",
    "        ),\n",
    "        'negative': (\n",
    "            \"uniform, monotonous, artificial lawn, \"\n",
    "            \"human view, ground perspective, \"\n",
    "            \"decorative, ornamental, urban grass, \"\n",
    "            \"low quality, blurred, distorted, \"\n",
    "            \"buildings, roads, people, animals\"\n",
    "        ),\n",
    "        'description': \"Pastagem mista - diversidade de esp√©cies\"\n",
    "    },\n",
    "    \n",
    "    'cynodon_dense': {\n",
    "        'positive': (\n",
    "            \"dense cynodon grass field from above, tifton grass, \"\n",
    "            \"coast-cross grass, aerial photography, \"\n",
    "            \"thick carpet-like grass coverage, \"\n",
    "            \"uniform green pasture, top-down view, \"\n",
    "            \"high quality agricultural image, \"\n",
    "            \"natural lighting, detailed texture, \"\n",
    "            \"scientific photography, realistic\"\n",
    "        ),\n",
    "        'negative': (\n",
    "            \"sparse, patchy, uneven coverage, \"\n",
    "            \"side view, angled view, ground level, \"\n",
    "            \"artistic, stylized, non-photographic, \"\n",
    "            \"poor quality, low resolution, \"\n",
    "            \"weeds, bare soil, brown patches\"\n",
    "        ),\n",
    "        'description': \"Cynodon denso - cobertura uniforme\"\n",
    "    },\n",
    "    \n",
    "    'early_growth': {\n",
    "        'positive': (\n",
    "            \"young grass pasture aerial view, early growth stage, \"\n",
    "            \"emerging brachiaria seedlings, sparse coverage, \"\n",
    "            \"some visible soil between grass, \"\n",
    "            \"top-down agricultural photography, \"\n",
    "            \"natural lighting, realistic, \"\n",
    "            \"establishing pasture, new growth, \"\n",
    "            \"scientific quality, high detail\"\n",
    "        ),\n",
    "        'negative': (\n",
    "            \"mature, fully established, dense coverage, \"\n",
    "            \"ground perspective, side angle, \"\n",
    "            \"artificial, painted, artistic, \"\n",
    "            \"poor lighting, low quality, \"\n",
    "            \"dead vegetation, dried grass\"\n",
    "        ),\n",
    "        'description': \"Crescimento inicial - cobertura esparsa\"\n",
    "    }\n",
    "}\n",
    "\n",
    "# Par√¢metros de gera√ß√£o\n",
    "GENERATION_PARAMS = {\n",
    "    'width': 512,\n",
    "    'height': 512, \n",
    "    'num_inference_steps': 25,  # Balanceio qualidade/velocidade\n",
    "    'guidance_scale': 7.5,      # Ader√™ncia ao prompt\n",
    "    'num_images_per_prompt': 1,\n",
    "    'eta': 0.0,                 # Determinismo\n",
    "    'generator_seed': 42        # Reprodutibilidade inicial\n",
    "}\n",
    "\n",
    "print(f\"üìù {len(GRASSCLOVER_PROMPTS)} prompts configurados:\")\n",
    "for key, prompt_data in GRASSCLOVER_PROMPTS.items():\n",
    "    print(f\"  ‚Ä¢ {key}: {prompt_data['description']}\")\n",
    "    \n",
    "print(f\"\\n‚öôÔ∏è  Par√¢metros de gera√ß√£o:\")\n",
    "for param, value in GENERATION_PARAMS.items():\n",
    "    print(f\"  ‚Ä¢ {param}: {value}\")\n",
    "    \n",
    "print(\"\\n‚úÖ Prompts configurados!\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Fun√ß√£o de Gera√ß√£o com Debugging Completo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üéØ FUN√á√ÉO DE GERA√á√ÉO COM DEBUGGING EXTENSIVO\n",
    "print(\"üéØ Configurando fun√ß√£o de gera√ß√£o...\\n\")\n",
    "\n",
    "def generate_grassclover_image(prompt_key, custom_seed=None, debug=True):\n",
    "    \"\"\"\n",
    "    Gera imagem no estilo GrassClover com debugging completo\n",
    "    \n",
    "    Args:\n",
    "        prompt_key: Chave do prompt (ex: 'brachiaria_dominant')\n",
    "        custom_seed: Seed personalizada (opcional)\n",
    "        debug: Ativar prints de debug\n",
    "    \n",
    "    Returns:\n",
    "        dict com imagem e metadados\n",
    "    \"\"\"\n",
    "    \n",
    "    if not PIPELINE_READY:\n",
    "        print(\"‚ùå Pipeline n√£o est√° pronto!\")\n",
    "        return None\n",
    "    \n",
    "    if prompt_key not in GRASSCLOVER_PROMPTS:\n",
    "        print(f\"‚ùå Prompt key '{prompt_key}' n√£o encontrada!\")\n",
    "        print(f\"Chaves dispon√≠veis: {list(GRASSCLOVER_PROMPTS.keys())}\")\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        # Configurar seed\n",
    "        seed = custom_seed if custom_seed is not None else GENERATION_PARAMS['generator_seed']\n",
    "        generator = torch.Generator(device=device).manual_seed(seed)\n",
    "        \n",
    "        # Obter prompts\n",
    "        prompt_data = GRASSCLOVER_PROMPTS[prompt_key]\n",
    "        positive_prompt = prompt_data['positive']\n",
    "        negative_prompt = prompt_data['negative']\n",
    "        \n",
    "        if debug:\n",
    "            print(f\"üåæ Gerando: {prompt_data['description']}\")\n",
    "            print(f\"üé≤ Seed: {seed}\")\n",
    "            print(f\"üìù Prompt: {positive_prompt[:100]}...\")\n",
    "            print(f\"‚ùå Negative: {negative_prompt[:50]}...\")\n",
    "            \n",
    "            # Monitoramento de mem√≥ria inicial\n",
    "            if device.type == \"cuda\":\n",
    "                torch.cuda.empty_cache()\n",
    "                mem_before = torch.cuda.memory_allocated() / (1024**3)\n",
    "                print(f\"üíæ GPU Memory antes: {mem_before:.2f}GB\")\n",
    "        \n",
    "        # Gera√ß√£o\n",
    "        print(\"‚è≥ Iniciando gera√ß√£o...\")\n",
    "        \n",
    "        with torch.autocast(device.type):\n",
    "            result = pipe(\n",
    "                prompt=positive_prompt,\n",
    "                negative_prompt=negative_prompt,\n",
    "                width=GENERATION_PARAMS['width'],\n",
    "                height=GENERATION_PARAMS['height'],\n",
    "                num_inference_steps=GENERATION_PARAMS['num_inference_steps'],\n",
    "                guidance_scale=GENERATION_PARAMS['guidance_scale'],\n",
    "                num_images_per_prompt=GENERATION_PARAMS['num_images_per_prompt'],\n",
    "                eta=GENERATION_PARAMS['eta'],\n",
    "                generator=generator\n",
    "            )\n",
    "        \n",
    "        if debug:\n",
    "            print(\"‚úÖ Gera√ß√£o conclu√≠da!\")\n",
    "            \n",
    "            # Monitoramento de mem√≥ria final\n",
    "            if device.type == \"cuda\":\n",
    "                mem_after = torch.cuda.memory_allocated() / (1024**3)\n",
    "                print(f\"üíæ GPU Memory depois: {mem_after:.2f}GB\")\n",
    "                print(f\"üìä Diferen√ßa: {mem_after - mem_before:.2f}GB\")\n",
    "        \n",
    "        # Extrair imagem\n",
    "        image = result.images[0]\n",
    "        \n",
    "        # Metadados\n",
    "        metadata = {\n",
    "            'prompt_key': prompt_key,\n",
    "            'description': prompt_data['description'],\n",
    "            'seed': seed,\n",
    "            'generation_params': GENERATION_PARAMS.copy(),\n",
    "            'timestamp': datetime.now().isoformat(),\n",
    "            'model_id': MODEL_ID,\n",
    "            'device': str(device)\n",
    "        }\n",
    "        \n",
    "        return {\n",
    "            'image': image,\n",
    "            'metadata': metadata,\n",
    "            'success': True\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"üí• ERRO na gera√ß√£o: {e}\")\n",
    "        print(f\"\\nüìã DEBUG COPY/PASTE:\")\n",
    "        print(f\"Prompt key: {prompt_key}\")\n",
    "        print(f\"Seed: {seed}\")\n",
    "        print(f\"Device: {device}\")\n",
    "        print(f\"Pipeline ready: {PIPELINE_READY}\")\n",
    "        print(f\"Error type: {type(e).__name__}\")\n",
    "        print(f\"Error message: {e}\")\n",
    "        \n",
    "        # Limpeza de emerg√™ncia\n",
    "        if device.type == \"cuda\":\n",
    "            torch.cuda.empty_cache()\n",
    "            print(\"üßπ Cache GPU limpo (emerg√™ncia)\")\n",
    "        \n",
    "        return {\n",
    "            'image': None,\n",
    "            'metadata': None,\n",
    "            'success': False,\n",
    "            'error': str(e)\n",
    "        }\n",
    "\n",
    "# Fun√ß√£o para visualiza√ß√£o\n",
    "def display_generation_result(result, show_metadata=True):\n",
    "    \"\"\"Exibe resultado da gera√ß√£o com metadados\"\"\"\n",
    "    if not result['success']:\n",
    "        print(f\"‚ùå Gera√ß√£o falhou: {result.get('error', 'Erro desconhecido')}\")\n",
    "        return\n",
    "    \n",
    "    # Exibir imagem\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(result['image'])\n",
    "    plt.axis('off')\n",
    "    \n",
    "    # T√≠tulo com informa√ß√µes\n",
    "    metadata = result['metadata']\n",
    "    title = f\"{metadata['description']}\\nSeed: {metadata['seed']} | {metadata['generation_params']['width']}x{metadata['generation_params']['height']}\"\n",
    "    plt.title(title, fontsize=14, pad=20)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Metadados detalhados\n",
    "    if show_metadata:\n",
    "        print(f\"\\nüìä Metadados da Gera√ß√£o:\")\n",
    "        print(f\"  ‚Ä¢ Tipo: {metadata['description']}\")\n",
    "        print(f\"  ‚Ä¢ Seed: {metadata['seed']}\")\n",
    "        print(f\"  ‚Ä¢ Resolu√ß√£o: {metadata['generation_params']['width']}x{metadata['generation_params']['height']}\")\n",
    "        print(f\"  ‚Ä¢ Steps: {metadata['generation_params']['num_inference_steps']}\")\n",
    "        print(f\"  ‚Ä¢ Guidance: {metadata['generation_params']['guidance_scale']}\")\n",
    "        print(f\"  ‚Ä¢ Modelo: {metadata['model_id']}\")\n",
    "        print(f\"  ‚Ä¢ Device: {metadata['device']}\")\n",
    "        print(f\"  ‚Ä¢ Timestamp: {metadata['timestamp']}\")\n",
    "\n",
    "print(\"‚úÖ Fun√ß√µes de gera√ß√£o configuradas!\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß™ Teste Inicial - Uma Imagem de Cada Tipo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üß™ TESTE INICIAL - GERAR UMA IMAGEM DE CADA TIPO\n",
    "print(\"üß™ Iniciando teste de gera√ß√£o...\\n\")\n",
    "\n",
    "if PIPELINE_READY:\n",
    "    # Selecionar alguns prompts para teste\n",
    "    test_prompts = ['brachiaria_dominant', 'mixed_pasture', 'cynodon_dense']\n",
    "    test_results = []\n",
    "    \n",
    "    print(f\"üéØ Gerando {len(test_prompts)} imagens de teste...\\n\")\n",
    "    \n",
    "    for i, prompt_key in enumerate(test_prompts, 1):\n",
    "        print(f\"\\n{'='*40}\")\n",
    "        print(f\"üåæ TESTE {i}/{len(test_prompts)}: {prompt_key}\")\n",
    "        print(f\"{'='*40}\")\n",
    "        \n",
    "        # Gerar imagem\n",
    "        result = generate_grassclover_image(\n",
    "            prompt_key=prompt_key,\n",
    "            custom_seed=42 + i,  # Seed diferente para cada teste\n",
    "            debug=True\n",
    "        )\n",
    "        \n",
    "        if result['success']:\n",
    "            print(f\"‚úÖ Sucesso!\")\n",
    "            test_results.append(result)\n",
    "            \n",
    "            # Exibir resultado\n",
    "            display_generation_result(result)\n",
    "        else:\n",
    "            print(f\"‚ùå Falha na gera√ß√£o!\")\n",
    "            break\n",
    "        \n",
    "        # Limpeza entre gera√ß√µes\n",
    "        if device.type == \"cuda\":\n",
    "            torch.cuda.empty_cache()\n",
    "    \n",
    "    print(f\"\\nüéâ Teste conclu√≠do! {len(test_results)}/{len(test_prompts)} imagens geradas com sucesso.\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå Pipeline n√£o est√° pronto - n√£o √© poss√≠vel executar testes\")\n",
    "    print(\"\\nüîß Verifique as c√©lulas anteriores para resolver problemas de configura√ß√£o\")\n",
    "\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üé® P√≥s-processamento Estilo GrassClover\n",
    "\n",
    "Ajustes para deixar as imagens mais pr√≥ximas do estilo visual do GrassClover Dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üé® P√ìS-PROCESSAMENTO ESTILO GRASSCLOVER\n",
    "print(\"üé® Configurando p√≥s-processamento GrassClover...\\n\")\n",
    "\n",
    "def grassclover_postprocess(image, intensity=1.0, debug=False):\n",
    "    \"\"\"\n",
    "    Aplica p√≥s-processamento para aproximar do estilo GrassClover\n",
    "    \n",
    "    Args:\n",
    "        image: PIL Image\n",
    "        intensity: Intensidade dos ajustes (0.0-2.0)\n",
    "        debug: Mostrar etapas do processamento\n",
    "    \n",
    "    Returns:\n",
    "        PIL Image processada\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        if debug:\n",
    "            print(f\"üé® Iniciando p√≥s-processamento (intensidade: {intensity})\")\n",
    "        \n",
    "        # C√≥pia para n√£o modificar original\n",
    "        processed = image.copy()\n",
    "        \n",
    "        # 1. Ajuste de contraste (GrassClover tem contraste marcante)\n",
    "        contrast_factor = 1.0 + (0.3 * intensity)\n",
    "        enhancer = ImageEnhance.Contrast(processed)\n",
    "        processed = enhancer.enhance(contrast_factor)\n",
    "        \n",
    "        if debug:\n",
    "            print(f\"  ‚úÖ Contraste ajustado: {contrast_factor:.2f}\")\n",
    "        \n",
    "        # 2. Ajuste de satura√ß√£o (verdes mais v√≠vidos)\n",
    "        saturation_factor = 1.0 + (0.2 * intensity)\n",
    "        enhancer = ImageEnhance.Color(processed)\n",
    "        processed = enhancer.enhance(saturation_factor)\n",
    "        \n",
    "        if debug:\n",
    "            print(f\"  ‚úÖ Satura√ß√£o ajustada: {saturation_factor:.2f}\")\n",
    "        \n",
    "        # 3. Sharpening sutil (detalhes de textura)\n",
    "        if intensity > 0.5:\n",
    "            sharpness_factor = 1.0 + (0.1 * intensity)\n",
    "            enhancer = ImageEnhance.Sharpness(processed)\n",
    "            processed = enhancer.enhance(sharpness_factor)\n",
    "            \n",
    "            if debug:\n",
    "                print(f\"  ‚úÖ Nitidez ajustada: {sharpness_factor:.2f}\")\n",
    "        \n",
    "        # 4. Slight blur para simular imperfei√ß√µes naturais\n",
    "        if intensity > 0.3:\n",
    "            blur_radius = 0.3 * intensity\n",
    "            processed = processed.filter(ImageFilter.GaussianBlur(radius=blur_radius))\n",
    "            \n",
    "            if debug:\n",
    "                print(f\"  ‚úÖ Blur natural aplicado: {blur_radius:.2f}px\")\n",
    "        \n",
    "        # 5. Ajuste de brilho (simular condi√ß√µes de campo)\n",
    "        brightness_factor = 1.0 + (0.05 * intensity * (np.random.random() - 0.5))\n",
    "        enhancer = ImageEnhance.Brightness(processed)\n",
    "        processed = enhancer.enhance(brightness_factor)\n",
    "        \n",
    "        if debug:\n",
    "            print(f\"  ‚úÖ Brilho ajustado: {brightness_factor:.2f}\")\n",
    "            print(f\"üéâ P√≥s-processamento conclu√≠do!\")\n",
    "        \n",
    "        return processed\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"üí• Erro no p√≥s-processamento: {e}\")\n",
    "        print(f\"üìã DEBUG COPY/PASTE:\")\n",
    "        print(f\"Image mode: {image.mode if image else 'None'}\")\n",
    "        print(f\"Image size: {image.size if image else 'None'}\")\n",
    "        print(f\"Intensity: {intensity}\")\n",
    "        print(f\"Error: {type(e).__name__}: {e}\")\n",
    "        return image  # Retornar original se falhar\n",
    "\n",
    "def compare_before_after(original, processed, title=\"Compara√ß√£o\"):\n",
    "    \"\"\"\n",
    "    Exibe compara√ß√£o lado a lado\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 7))\n",
    "    \n",
    "    axes[0].imshow(original)\n",
    "    axes[0].set_title(\"Original (Stable Diffusion)\", fontsize=12)\n",
    "    axes[0].axis('off')\n",
    "    \n",
    "    axes[1].imshow(processed)\n",
    "    axes[1].set_title(\"Processado (Estilo GrassClover)\", fontsize=12)\n",
    "    axes[1].axis('off')\n",
    "    \n",
    "    fig.suptitle(title, fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print(\"‚úÖ Fun√ß√µes de p√≥s-processamento configuradas!\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üß™ TESTE DO P√ìS-PROCESSAMENTO\n",
    "print(\"üß™ Testando p√≥s-processamento GrassClover...\\n\")\n",
    "\n",
    "if PIPELINE_READY and 'test_results' in locals() and test_results:\n",
    "    # Usar primeira imagem dos testes anteriores\n",
    "    test_image_data = test_results[0]\n",
    "    original_image = test_image_data['image']\n",
    "    \n",
    "    print(f\"üé® Aplicando p√≥s-processamento em: {test_image_data['metadata']['description']}\")\n",
    "    \n",
    "    # Aplicar p√≥s-processamento\n",
    "    processed_image = grassclover_postprocess(\n",
    "        image=original_image,\n",
    "        intensity=1.2,  # Intensidade m√©dia-alta\n",
    "        debug=True\n",
    "    )\n",
    "    \n",
    "    # Exibir compara√ß√£o\n",
    "    compare_before_after(\n",
    "        original=original_image,\n",
    "        processed=processed_image,\n",
    "        title=f\"P√≥s-processamento: {test_image_data['metadata']['description']}\"\n",
    "    )\n",
    "    \n",
    "    print(\"‚úÖ Teste de p√≥s-processamento conclu√≠do!\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Nenhuma imagem de teste dispon√≠vel para p√≥s-processamento\")\n",
    "    print(\"Execute primeiro a c√©lula de teste de gera√ß√£o\")\n",
    "\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üöÄ Gera√ß√£o em Lote com Seeds Diferentes\n",
    "\n",
    "Gera m√∫ltiplas varia√ß√µes de pastagens para criar um dataset diversificado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üöÄ GERA√á√ÉO EM LOTE - DATASET DIVERSIFICADO\n",
    "print(\"üöÄ Configurando gera√ß√£o em lote...\\n\")\n",
    "\n",
    "def generate_grassclover_batch(num_images=6, apply_postprocess=True, debug=True):\n",
    "    \"\"\"\n",
    "    Gera lote de imagens variadas estilo GrassClover\n",
    "    \n",
    "    Args:\n",
    "        num_images: N√∫mero total de imagens\n",
    "        apply_postprocess: Aplicar p√≥s-processamento\n",
    "        debug: Debugging detalhado\n",
    "        \n",
    "    Returns:\n",
    "        Lista de resultados\n",
    "    \"\"\"\n",
    "    \n",
    "    if not PIPELINE_READY:\n",
    "        print(\"‚ùå Pipeline n√£o est√° pronto!\")\n",
    "        return []\n",
    "    \n",
    "    # Distribuir tipos de pastagem\n",
    "    prompt_keys = list(GRASSCLOVER_PROMPTS.keys())\n",
    "    batch_results = []\n",
    "    \n",
    "    print(f\"üéØ Gerando {num_images} imagens com {len(prompt_keys)} tipos de pastagem...\\n\")\n",
    "    \n",
    "    for i in range(num_images):\n",
    "        # Selecionar tipo de pastagem (rota√ß√£o)\n",
    "        prompt_key = prompt_keys[i % len(prompt_keys)]\n",
    "        \n",
    "        # Seed √∫nica para cada imagem\n",
    "        seed = 42 + i * 100 + np.random.randint(0, 50)\n",
    "        \n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(f\"üåæ IMAGEM {i+1}/{num_images}: {prompt_key}\")\n",
    "        print(f\"üé≤ Seed: {seed}\")\n",
    "        print(f\"{'='*50}\")\n",
    "        \n",
    "        try:\n",
    "            # Gerar imagem base\n",
    "            result = generate_grassclover_image(\n",
    "                prompt_key=prompt_key,\n",
    "                custom_seed=seed,\n",
    "                debug=debug\n",
    "            )\n",
    "            \n",
    "            if result['success']:\n",
    "                # Aplicar p√≥s-processamento se solicitado\n",
    "                if apply_postprocess:\n",
    "                    processed_image = grassclover_postprocess(\n",
    "                        image=result['image'],\n",
    "                        intensity=np.random.uniform(0.8, 1.4),  # Varia√ß√£o aleat√≥ria\n",
    "                        debug=False\n",
    "                    )\n",
    "                    \n",
    "                    # Atualizar resultado\n",
    "                    result['processed_image'] = processed_image\n",
    "                    result['metadata']['postprocessed'] = True\n",
    "                    \n",
    "                    if debug:\n",
    "                        print(\"üé® P√≥s-processamento aplicado\")\n",
    "                \n",
    "                # Adicionar √≠ndice\n",
    "                result['metadata']['batch_index'] = i\n",
    "                result['metadata']['total_batch'] = num_images\n",
    "                \n",
    "                batch_results.append(result)\n",
    "                print(f\"‚úÖ Sucesso! ({len(batch_results)}/{num_images})\")\n",
    "                \n",
    "            else:\n",
    "                print(f\"‚ùå Falha na gera√ß√£o da imagem {i+1}\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"üí• Erro na imagem {i+1}: {e}\")\n",
    "            if debug:\n",
    "                print(f\"Prompt key: {prompt_key}\")\n",
    "                print(f\"Seed: {seed}\")\n",
    "        \n",
    "        # Limpeza entre gera√ß√µes\n",
    "        if device.type == \"cuda\":\n",
    "            torch.cuda.empty_cache()\n",
    "    \n",
    "    print(f\"\\nüéâ Lote conclu√≠do: {len(batch_results)}/{num_images} imagens geradas!\")\n",
    "    return batch_results\n",
    "\n",
    "def display_batch_results(batch_results, max_display=6):\n",
    "    \"\"\"\n",
    "    Exibe resultados do lote em grid\n",
    "    \"\"\"\n",
    "    if not batch_results:\n",
    "        print(\"‚ùå Nenhum resultado para exibir\")\n",
    "        return\n",
    "    \n",
    "    # Limitar exibi√ß√£o\n",
    "    results_to_show = batch_results[:max_display]\n",
    "    n_images = len(results_to_show)\n",
    "    \n",
    "    # Calcular grid\n",
    "    cols = min(3, n_images)\n",
    "    rows = (n_images + cols - 1) // cols\n",
    "    \n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(5*cols, 5*rows))\n",
    "    \n",
    "    # Garantir que axes seja sempre 2D\n",
    "    if rows == 1:\n",
    "        axes = axes.reshape(1, -1)\n",
    "    if cols == 1:\n",
    "        axes = axes.reshape(-1, 1)\n",
    "    \n",
    "    for i, result in enumerate(results_to_show):\n",
    "        row = i // cols\n",
    "        col = i % cols\n",
    "        \n",
    "        # Usar imagem processada se dispon√≠vel\n",
    "        image = result.get('processed_image', result['image'])\n",
    "        \n",
    "        axes[row, col].imshow(image)\n",
    "        axes[row, col].axis('off')\n",
    "        \n",
    "        # T√≠tulo com informa√ß√µes\n",
    "        metadata = result['metadata']\n",
    "        title = f\"{metadata['description']}\\nSeed: {metadata['seed']}\"\n",
    "        axes[row, col].set_title(title, fontsize=10)\n",
    "    \n",
    "    # Ocultar eixos n√£o usados\n",
    "    for i in range(n_images, rows * cols):\n",
    "        row = i // cols\n",
    "        col = i % cols\n",
    "        axes[row, col].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.suptitle(f\"üåæ Dataset GrassClover Brasileiro - {n_images} Imagens\", \n",
    "                fontsize=16, fontweight='bold', y=0.98)\n",
    "    plt.show()\n",
    "\n",
    "print(\"‚úÖ Fun√ß√µes de gera√ß√£o em lote configuradas!\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üöÄ EXECUTAR GERA√á√ÉO EM LOTE\n",
    "print(\"üöÄ Iniciando gera√ß√£o em lote...\\n\")\n",
    "\n",
    "if PIPELINE_READY:\n",
    "    # Configura√ß√µes do lote\n",
    "    BATCH_SIZE = 6  # N√∫mero total de imagens\n",
    "    APPLY_POSTPROCESS = True\n",
    "    \n",
    "    print(f\"‚öôÔ∏è  Configura√ß√µes:\")\n",
    "    print(f\"  ‚Ä¢ Imagens: {BATCH_SIZE}\")\n",
    "    print(f\"  ‚Ä¢ P√≥s-processamento: {APPLY_POSTPROCESS}\")\n",
    "    print(f\"  ‚Ä¢ Device: {device}\")\n",
    "    print(f\"  ‚Ä¢ Tipos dispon√≠veis: {len(GRASSCLOVER_PROMPTS)}\")\n",
    "    \n",
    "    # Gerar lote\n",
    "    batch_results = generate_grassclover_batch(\n",
    "        num_images=BATCH_SIZE,\n",
    "        apply_postprocess=APPLY_POSTPROCESS,\n",
    "        debug=True\n",
    "    )\n",
    "    \n",
    "    # Exibir resultados\n",
    "    if batch_results:\n",
    "        print(f\"\\nüìä Estat√≠sticas do Lote:\")\n",
    "        print(f\"  ‚Ä¢ Total gerado: {len(batch_results)}/{BATCH_SIZE}\")\n",
    "        print(f\"  ‚Ä¢ Taxa de sucesso: {len(batch_results)/BATCH_SIZE*100:.1f}%\")\n",
    "        \n",
    "        # Contagem por tipo\n",
    "        type_counts = {}\n",
    "        for result in batch_results:\n",
    "            prompt_key = result['metadata']['prompt_key']\n",
    "            type_counts[prompt_key] = type_counts.get(prompt_key, 0) + 1\n",
    "        \n",
    "        print(f\"  ‚Ä¢ Distribui√ß√£o por tipo:\")\n",
    "        for prompt_key, count in type_counts.items():\n",
    "            description = GRASSCLOVER_PROMPTS[prompt_key]['description']\n",
    "            print(f\"    - {description}: {count} imagens\")\n",
    "        \n",
    "        # Exibir grid\n",
    "        print(f\"\\nüñºÔ∏è  Exibindo resultados...\")\n",
    "        display_batch_results(batch_results)\n",
    "        \n",
    "        print(f\"\\n‚úÖ Lote conclu√≠do com sucesso!\")\n",
    "        \n",
    "    else:\n",
    "        print(f\"‚ùå Nenhuma imagem foi gerada no lote!\")\n",
    "        \n",
    "else:\n",
    "    print(\"‚ùå Pipeline n√£o est√° pronto - n√£o √© poss√≠vel gerar lote\")\n",
    "\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üíæ Salvamento das Imagens\n",
    "\n",
    "Salva as imagens geradas com metadados organizados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üíæ SALVAMENTO ORGANIZADO DAS IMAGENS\n",
    "print(\"üíæ Configurando sistema de salvamento...\\n\")\n",
    "\n",
    "import os\n",
    "import json\n",
    "\n",
    "def save_grassclover_batch(batch_results, output_dir=\"grassclover_generated\", save_metadata=True):\n",
    "    \"\"\"\n",
    "    Salva lote de imagens com organiza√ß√£o e metadados\n",
    "    \n",
    "    Args:\n",
    "        batch_results: Lista de resultados da gera√ß√£o\n",
    "        output_dir: Diret√≥rio de sa√≠da\n",
    "        save_metadata: Salvar arquivos JSON com metadados\n",
    "        \n",
    "    Returns:\n",
    "        dict com estat√≠sticas de salvamento\n",
    "    \"\"\"\n",
    "    \n",
    "    if not batch_results:\n",
    "        print(\"‚ùå Nenhuma imagem para salvar!\")\n",
    "        return {'success': False, 'saved_count': 0}\n",
    "    \n",
    "    try:\n",
    "        # Criar diret√≥rios\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        images_dir = os.path.join(output_dir, \"images\")\n",
    "        metadata_dir = os.path.join(output_dir, \"metadata\")\n",
    "        \n",
    "        os.makedirs(images_dir, exist_ok=True)\n",
    "        if save_metadata:\n",
    "            os.makedirs(metadata_dir, exist_ok=True)\n",
    "        \n",
    "        print(f\"üìÅ Diret√≥rios criados:\")\n",
    "        print(f\"  ‚Ä¢ Principal: {output_dir}\")\n",
    "        print(f\"  ‚Ä¢ Imagens: {images_dir}\")\n",
    "        if save_metadata:\n",
    "            print(f\"  ‚Ä¢ Metadados: {metadata_dir}\")\n",
    "        \n",
    "        saved_count = 0\n",
    "        saved_files = []\n",
    "        \n",
    "        # Salvar cada imagem\n",
    "        for i, result in enumerate(batch_results):\n",
    "            try:\n",
    "                metadata = result['metadata']\n",
    "                prompt_key = metadata['prompt_key']\n",
    "                seed = metadata['seed']\n",
    "                \n",
    "                # Nome do arquivo\n",
    "                filename_base = f\"grassclover_{prompt_key}_{seed:06d}\"\n",
    "                \n",
    "                # Salvar imagem original\n",
    "                original_path = os.path.join(images_dir, f\"{filename_base}_original.png\")\n",
    "                result['image'].save(original_path, 'PNG')\n",
    "                \n",
    "                files_saved = [original_path]\n",
    "                \n",
    "                # Salvar imagem processada se existir\n",
    "                if 'processed_image' in result:\n",
    "                    processed_path = os.path.join(images_dir, f\"{filename_base}_processed.png\")\n",
    "                    result['processed_image'].save(processed_path, 'PNG')\n",
    "                    files_saved.append(processed_path)\n",
    "                \n",
    "                # Salvar metadados\n",
    "                if save_metadata:\n",
    "                    metadata_path = os.path.join(metadata_dir, f\"{filename_base}.json\")\n",
    "                    \n",
    "                    # Preparar metadados para JSON (remover objetos n√£o serializ√°veis)\n",
    "                    json_metadata = metadata.copy()\n",
    "                    json_metadata['files_saved'] = files_saved\n",
    "                    json_metadata['save_timestamp'] = datetime.now().isoformat()\n",
    "                    \n",
    "                    with open(metadata_path, 'w', encoding='utf-8') as f:\n",
    "                        json.dump(json_metadata, f, indent=2, ensure_ascii=False)\n",
    "                    \n",
    "                    files_saved.append(metadata_path)\n",
    "                \n",
    "                saved_files.extend(files_saved)\n",
    "                saved_count += 1\n",
    "                \n",
    "                print(f\"‚úÖ Salvo {i+1}/{len(batch_results)}: {filename_base}\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå Erro ao salvar imagem {i+1}: {e}\")\n",
    "                continue\n",
    "        \n",
    "        # Criar √≠ndice geral\n",
    "        if save_metadata:\n",
    "            index_data = {\n",
    "                'dataset_name': 'GrassClover Brazilian Synthetic',\n",
    "                'generation_date': datetime.now().isoformat(),\n",
    "                'total_images': len(batch_results),\n",
    "                'saved_images': saved_count,\n",
    "                'model_used': MODEL_ID,\n",
    "                'device': str(device),\n",
    "                'prompt_types': list(set(r['metadata']['prompt_key'] for r in batch_results)),\n",
    "                'files': saved_files\n",
    "            }\n",
    "            \n",
    "            index_path = os.path.join(output_dir, \"dataset_index.json\")\n",
    "            with open(index_path, 'w', encoding='utf-8') as f:\n",
    "                json.dump(index_data, f, indent=2, ensure_ascii=False)\n",
    "            \n",
    "            print(f\"üìã √çndice salvo: {index_path}\")\n",
    "        \n",
    "        print(f\"\\nüéâ Salvamento conclu√≠do!\")\n",
    "        print(f\"  ‚Ä¢ Imagens salvas: {saved_count}/{len(batch_results)}\")\n",
    "        print(f\"  ‚Ä¢ Arquivos totais: {len(saved_files)}\")\n",
    "        print(f\"  ‚Ä¢ Diret√≥rio: {os.path.abspath(output_dir)}\")\n",
    "        \n",
    "        return {\n",
    "            'success': True,\n",
    "            'saved_count': saved_count,\n",
    "            'total_files': len(saved_files),\n",
    "            'output_dir': os.path.abspath(output_dir),\n",
    "            'files': saved_files\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"üí• Erro no salvamento: {e}\")\n",
    "        print(f\"üìã DEBUG COPY/PASTE:\")\n",
    "        print(f\"Output dir: {output_dir}\")\n",
    "        print(f\"Batch results count: {len(batch_results) if batch_results else 0}\")\n",
    "        print(f\"Error: {type(e).__name__}: {e}\")\n",
    "        \n",
    "        return {\n",
    "            'success': False,\n",
    "            'saved_count': 0,\n",
    "            'error': str(e)\n",
    "        }\n",
    "\n",
    "print(\"‚úÖ Sistema de salvamento configurado!\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üíæ SALVAR LOTE GERADO\n",
    "print(\"üíæ Salvando lote de imagens...\\n\")\n",
    "\n",
    "if 'batch_results' in locals() and batch_results:\n",
    "    # Configura√ß√µes de salvamento\n",
    "    OUTPUT_DIR = \"grassclover_synthetic_dataset\"\n",
    "    SAVE_METADATA = True\n",
    "    \n",
    "    print(f\"‚öôÔ∏è  Configura√ß√µes de salvamento:\")\n",
    "    print(f\"  ‚Ä¢ Diret√≥rio: {OUTPUT_DIR}\")\n",
    "    print(f\"  ‚Ä¢ Salvar metadados: {SAVE_METADATA}\")\n",
    "    print(f\"  ‚Ä¢ Imagens a salvar: {len(batch_results)}\")\n",
    "    \n",
    "    # Executar salvamento\n",
    "    save_result = save_grassclover_batch(\n",
    "        batch_results=batch_results,\n",
    "        output_dir=OUTPUT_DIR,\n",
    "        save_metadata=SAVE_METADATA\n",
    "    )\n",
    "    \n",
    "    # Resultado\n",
    "    if save_result['success']:\n",
    "        print(f\"\\nüìä Resumo do Salvamento:\")\n",
    "        print(f\"  ‚úÖ Sucesso: {save_result['saved_count']} imagens salvas\")\n",
    "        print(f\"  üìÅ Localiza√ß√£o: {save_result['output_dir']}\")\n",
    "        print(f\"  üìÑ Arquivos totais: {save_result['total_files']}\")\n",
    "        \n",
    "        # Listar estrutura de diret√≥rios\n",
    "        print(f\"\\nüìã Estrutura criada:\")\n",
    "        if os.path.exists(save_result['output_dir']):\n",
    "            for root, dirs, files in os.walk(save_result['output_dir']):\n",
    "                level = root.replace(save_result['output_dir'], '').count(os.sep)\n",
    "                indent = ' ' * 2 * level\n",
    "                print(f\"{indent}{os.path.basename(root)}/\")\n",
    "                subindent = ' ' * 2 * (level + 1)\n",
    "                for file in files[:3]:  # Mostrar s√≥ os primeiros 3 arquivos\n",
    "                    print(f\"{subindent}{file}\")\n",
    "                if len(files) > 3:\n",
    "                    print(f\"{subindent}... e mais {len(files)-3} arquivos\")\n",
    "        \n",
    "        print(f\"\\nüéâ Dataset salvo com sucesso!\")\n",
    "        print(f\"üìÇ Para acessar: {save_result['output_dir']}\")\n",
    "        \n",
    "    else:\n",
    "        print(f\"‚ùå Falha no salvamento: {save_result.get('error', 'Erro desconhecido')}\")\n",
    "        \n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Nenhum lote de imagens dispon√≠vel para salvar\")\n",
    "    print(\"Execute primeiro a c√©lula de gera√ß√£o em lote\")\n",
    "\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Relat√≥rio Final e Estat√≠sticas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "## üí° Instru√ß√µes para Uso e Debugging\n\n### üö® **Em caso de erro:**\n1. **Copie a se√ß√£o \"DEBUG COPY/PASTE\"** que aparece nos erros\n2. **Cole aqui nos coment√°rios** ou no chat para an√°lise\n3. **Inclua informa√ß√µes do sistema** (GPU, mem√≥ria, etc.)\n\n### üîß **Problemas Comuns Resolvidos:**\n\n#### **‚úÖ TPU Runtime Problem (RESOLVIDO)**\n- **Detec√ß√£o autom√°tica** de TPU/GPU/CPU\n- **Configura√ß√£o otimizada** para cada tipo de hardware\n- **Instru√ß√µes claras** para configura√ß√£o do runtime\n\n#### **‚úÖ Hugging Face Token Warning (RESOLVIDO)**\n- **Bypass autom√°tico** de problemas de autentica√ß√£o\n- **Configura√ß√£o de ambiente** para evitar warnings\n- **Downloads funcionam normalmente** mesmo com warnings\n\n#### **‚úÖ Dtype Configuration (RESOLVIDO)**\n- **float16 para GPU** (performance otimizada)\n- **float32 para TPU/CPU** (compatibilidade garantida)\n- **Configura√ß√£o autom√°tica** baseada no hardware\n\n### üéØ **Configura√ß√£o Recomendada para Colab:**\n- **Runtime**: GPU (Tesla T4 ou superior)\n- **Reasoning**: Stable Diffusion funciona melhor em GPU que TPU\n- **Fallback**: TPU funciona, mas GPU √© mais r√°pido para este caso\n\n### üîß **Ajustes poss√≠veis:**\n- **GENERATION_PARAMS**: Modifique `num_inference_steps` (15-50) para balancear qualidade/velocidade\n- **BATCH_SIZE**: Reduza se houver problemas de mem√≥ria\n- **Seeds**: Mude para explorar diferentes varia√ß√µes\n- **Prompts**: Ajuste para obter estilos visuais espec√≠ficos\n\n### üì∏ **Para adicionar refer√™ncias GrassClover:**\n1. **Upload das imagens** na se√ß√£o de arquivos do Colab\n2. **Modifique os prompts** baseado nas caracter√≠sticas visuais\n3. **Ajuste p√≥s-processamento** para aproximar do estilo original\n\n### üéØ **M√©tricas de qualidade:**\n- **Cobertura densa**: Pastagens devem ter ‚â•80% de cobertura vegetal\n- **Perspectiva top-down**: Vista a√©rea consistente\n- **Textura real√≠stica**: Detalhes de folhas e solo vis√≠veis\n- **Diversidade**: Varia√ß√£o entre as imagens geradas\n\n### üöÄ **Performance por Hardware:**\n- **GPU (Tesla T4)**: ~30-45s por imagem (recomendado)\n- **GPU (V100/A100)**: ~15-25s por imagem (√≥timo)\n- **TPU**: ~45-60s por imagem (funciona)\n- **CPU**: ~5-10min por imagem (muito lento, n√£o recomendado)\n\n---\n\n**üåæ Dataset GrassClover Brasileiro - Gerado com Stable Diffusion**  \nBaseado na metodologia de Skovsen et al. (CVPR 2019) adaptada para gram√≠neas tropicais.\n\n**üìã Problemas Comuns Resolvidos**: TPU detection, HF authentication, dtype optimization"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üí° Instru√ß√µes para Uso e Debugging\n",
    "\n",
    "### üö® **Em caso de erro:**\n",
    "1. **Copie a se√ß√£o \"DEBUG COPY/PASTE\"** que aparece nos erros\n",
    "2. **Cole aqui nos coment√°rios** ou no chat para an√°lise\n",
    "3. **Inclua informa√ß√µes do sistema** (GPU, mem√≥ria, etc.)\n",
    "\n",
    "### üîß **Ajustes poss√≠veis:**\n",
    "- **GENERATION_PARAMS**: Modifique `num_inference_steps` (15-50) para balancear qualidade/velocidade\n",
    "- **BATCH_SIZE**: Reduza se houver problemas de mem√≥ria\n",
    "- **Seeds**: Mude para explorar diferentes varia√ß√µes\n",
    "- **Prompts**: Ajuste para obter estilos visuais espec√≠ficos\n",
    "\n",
    "### üì∏ **Para adicionar refer√™ncias GrassClover:**\n",
    "1. **Upload das imagens** na se√ß√£o de arquivos do Colab\n",
    "2. **Modifique os prompts** baseado nas caracter√≠sticas visuais\n",
    "3. **Ajuste p√≥s-processamento** para aproximar do estilo original\n",
    "\n",
    "### üéØ **M√©tricas de qualidade:**\n",
    "- **Cobertura densa**: Pastagens devem ter ‚â•80% de cobertura vegetal\n",
    "- **Perspectiva top-down**: Vista a√©rea consistente\n",
    "- **Textura real√≠stica**: Detalhes de folhas e solo vis√≠veis\n",
    "- **Diversidade**: Varia√ß√£o entre as imagens geradas\n",
    "\n",
    "---\n",
    "\n",
    "**üåæ Dataset GrassClover Brasileiro - Gerado com Stable Diffusion**  \n",
    "Baseado na metodologia de Skovsen et al. (CVPR 2019) adaptada para gram√≠neas tropicais."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}