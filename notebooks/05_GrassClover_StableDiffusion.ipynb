{
 "cells": [
  {
   "cell_type": "code",
   "source": "# 🔐 LOGIN HUGGINGFACE - EXECUTAR PRIMEIRO!\nprint(\"🔐 Fazendo login no HuggingFace...\")\nprint(\"📝 Você precisará inserir seu token manualmente\")\nprint(\"🔗 Obtenha seu token em: https://huggingface.co/settings/tokens\")\nprint(\"⚠️ IMPORTANTE: Aceite os termos do modelo SD3.5 Medium antes!\")\nprint(\"🌐 Modelo: https://huggingface.co/stabilityai/stable-diffusion-3.5-medium\")\n\ntry:\n    from huggingface_hub import notebook_login\n    \n    # Login interativo - vai pedir o token\n    notebook_login()\n    \n    print(\"✅ Login realizado com sucesso!\")\n    HUGGINGFACE_LOGGED_IN = True\n    \nexcept Exception as e:\n    print(f\"❌ Erro no login: {e}\")\n    print(\"💡 Certifique-se de:\")\n    print(\"  1. Ter uma conta no HuggingFace\")\n    print(\"  2. Ter gerado um token de acesso\")\n    print(\"  3. Ter aceito os termos do modelo SD3.5\")\n    HUGGINGFACE_LOGGED_IN = False",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# ====== CORREÇÃO: Definir todas as variáveis necessárias ======\nimport torch\n\n# Verificar se device já foi definido, senão definir\nif 'device' not in locals() or 'device' not in globals():\n    print(\"🔧 Configurando device...\")\n    if torch.cuda.is_available():\n        device = torch.device(\"cuda\")\n        print(\"🚀 GPU detectada - usando CUDA\")\n    else:\n        device = torch.device(\"cpu\")\n        print(\"💻 Usando CPU\")\n\n# Verificar se HUGGINGFACE_LOGGED_IN foi definido, senão definir como False\nif 'HUGGINGFACE_LOGGED_IN' not in locals() and 'HUGGINGFACE_LOGGED_IN' not in globals():\n    HUGGINGFACE_LOGGED_IN = False\n    print(\"⚠️ HUGGINGFACE_LOGGED_IN não encontrado - definindo como False\")\n    print(\"💡 Execute a célula de login do HuggingFace primeiro!\")\n\nprint(f\"✅ Device configurado: {device}\")\nprint(f\"✅ HuggingFace Login Status: {HUGGINGFACE_LOGGED_IN}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# ====== CORREÇÃO: Definir device antes de usar ======\nimport torch\n\n# Verificar se device já foi definido, senão definir\nif 'device' not in locals() or device is None:\n    print(\"🔧 Configurando device...\")\n    if torch.cuda.is_available():\n        device = torch.device(\"cuda\")\n        print(\"🚀 GPU detectada - usando CUDA\")\n    else:\n        device = torch.device(\"cpu\")\n        print(\"💻 Usando CPU\")\n        \nprint(f\"✅ Device configurado: {device}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# 🧪 TESTE DA IMPLEMENTAÇÃO COM QUANTIZAÇÃO",
    "print(\"🧪 Testando o modelo SD3.5 Medium Quantizado...\")",
    "",
    "# Prompt de teste simples",
    "test_prompt = \"A whimsical and creative image depicting a hybrid creature that is a mix of a waffle and a hippopotamus\"",
    "",
    "# Verificar se as variáveis necessárias estão definidas",
    "pipeline_ready = 'pipe' in globals() and pipe is not None",
    "device_ready = 'device' in globals() and device is not None",
    "",
    "print(f\"🔍 Status das variáveis:\")",
    "print(f\"  • Pipeline carregado: {'✅' if pipeline_ready else '❌'}\")",
    "print(f\"  • Device configurado: {'✅' if device_ready else '❌'}\")",
    "",
    "if pipeline_ready and device_ready:",
    "    print(f\"🚀 Gerando imagem de teste com prompt: {test_prompt[:50]}...\")",
    "    ",
    "    try:",
    "        # Gerar imagem de teste",
    "        import torch",
    "        generator = torch.Generator(device=device).manual_seed(42) if device.type != 'cpu' else torch.Generator().manual_seed(42)",
    "        ",
    "        test_image = pipe(",
    "            prompt=test_prompt,",
    "            num_inference_steps=20,  # Reduzido para teste rápido",
    "            guidance_scale=4.5,",
    "            max_sequence_length=256, # Reduzido para teste",
    "            generator=generator,",
    "        ).images[0]",
    "        ",
    "        # Salvar imagem de teste",
    "        test_image.save(\"test_quantized_sd35.png\")",
    "        print(\"✅ Teste bem-sucedido! Imagem salva como test_quantized_sd35.png\")",
    "        print(\"🎉 A quantização está funcionando corretamente!\")",
    "        ",
    "        # Informações sobre uso de memória (se disponível)",
    "        if torch.cuda.is_available():",
    "            allocated = torch.cuda.memory_allocated() / 1024**3  # GB",
    "            reserved = torch.cuda.memory_reserved() / 1024**3   # GB",
    "            print(f\"📊 Memória GPU:\")",
    "            print(f\"  • Alocada: {allocated:.2f} GB\")",
    "            print(f\"  • Reservada: {reserved:.2f} GB\")",
    "            print(f\"💡 Quantização reduziu significativamente o uso de VRAM!\")",
    "        ",
    "        # Definir variável global para compatibilidade",
    "        PIPELINE_READY = True",
    "        ",
    "    except Exception as e:",
    "        print(f\"❌ Erro no teste: {e}\")",
    "        print(\"🔧 Possíveis soluções:\")",
    "        print(\"  1. Reinicie o runtime\")",
    "        print(\"  2. Verifique se bitsandbytes foi instalado corretamente\")",
    "        print(\"  3. Execute a célula anterior de carregamento novamente\")",
    "        ",
    "        PIPELINE_READY = False",
    "        ",
    "else:",
    "    print(\"❌ Pipeline não está pronto. Problemas detectados:\")",
    "    if not pipeline_ready:",
    "        print(\"  • Pipeline 'pipe' não está definido ou é None\")",
    "    if not device_ready:",
    "        print(\"  • Device não está configurado\")",
    "    print(\"💡 Execute as células anteriores na ordem correta primeiro.\")",
    "    PIPELINE_READY = False"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "# Install bitsandbytes for quantization\n!pip install bitsandbytes --quiet\n\n# 🚀 STABLE DIFFUSION 3.5 MEDIUM - OTIMIZADO PARA COLAB COM QUANTIZAÇÃO\nprint(\"🚀 Carregando Stable Diffusion 3.5 MEDIUM com Quantização 4-bit...\")\nprint(\"⚡ MODELO OTIMIZADO: Usa muito menos VRAM!\")\nprint(\"🎯 MESMO QUALIDADE: Performance otimizada para GPUs com pouca VRAM\")\n\ndef load_stable_diffusion_35_medium_quantized():\n    \"\"\"\n    Carrega SD3.5 MEDIUM com quantização 4-bit para reduzir VRAM\n    \"\"\"\n    # Verificar se o login foi feito\n    if not HUGGINGFACE_LOGGED_IN:\n        print(\"🚫 ERRO: Login no HuggingFace é obrigatório!\")\n        print(\"📋 Execute a célula anterior para fazer login\")\n        raise SystemExit(\"Login necessário para continuar\")\n    \n    try:\n        # Imports específicos para SD3.5 com quantização\n        from diffusers import BitsAndBytesConfig, SD3Transformer2DModel\n        from diffusers import StableDiffusion3Pipeline\n        import torch\n        \n        print(\"⏳ Carregando SD3.5 MEDIUM com quantização 4-bit...\")\n        print(\"📦 Download inicial pode demorar, mas vale a pena!\")\n        print(\"🔧 Quantização 4-bit reduz drasticamente o uso de VRAM\")\n        \n        # Configurações otimizadas para SD3.5 Medium no Colab\n        if torch.cuda.is_available():\n            torch_dtype = torch.bfloat16  # Melhor para GPU\n            print(\"🚀 Configuração GPU detectada - usando bfloat16\")\n        else:\n            torch_dtype = torch.float32   # CPU fallback\n            print(\"💻 Configuração CPU detectada - usando float32\")\n        \n        model_id = \"stabilityai/stable-diffusion-3.5-medium\"\n        \n        # Configuração de quantização BitsAndBytes\n        nf4_config = BitsAndBytesConfig(\n            load_in_4bit=True,\n            bnb_4bit_quant_type=\"nf4\",\n            bnb_4bit_compute_dtype=torch_dtype\n        )\n        \n        print(\"🔧 Carregando transformer com quantização 4-bit...\")\n        model_nf4 = SD3Transformer2DModel.from_pretrained(\n            model_id,\n            subfolder=\"transformer\",\n            quantization_config=nf4_config,\n            torch_dtype=torch_dtype\n        )\n        \n        print(\"📦 Carregando pipeline completo...\")\n        pipeline = StableDiffusion3Pipeline.from_pretrained(\n            model_id, \n            transformer=model_nf4,\n            torch_dtype=torch_dtype\n        )\n        \n        # Ativar CPU offload para economizar ainda mais VRAM\n        print(\"💾 Ativando CPU offload para economizar VRAM...\")\n        pipeline.enable_model_cpu_offload()\n        \n        print(\"✅ SD3.5 MEDIUM com quantização carregado com sucesso!\")\n        return pipeline, \"3.5-medium-quantized\"\n        \n    except Exception as e:\n        print(f\"❌ ERRO ao carregar SD3.5 Medium quantizado: {e}\")\n        print(f\"🔍 Tipo do erro: {type(e).__name__}\")\n        \n        # Análise específica de erros\n        error_str = str(e).lower()\n        \n        if \"requires you to be logged in\" in error_str or \"authentication\" in error_str:\n            print(\"💡 DIAGNÓSTICO: Problema de autenticação\")\n            print(\"🔧 CORREÇÃO: Verifique se fez login correto na célula anterior\")\n            print(\"🔗 Aceite os termos: https://huggingface.co/stabilityai/stable-diffusion-3.5-medium\")\n            \n        elif \"out of memory\" in error_str or \"oom\" in error_str:\n            print(\"💡 DIAGNÓSTICO: Problema de memória mesmo com quantização\")\n            print(\"🔧 CORREÇÃO: Tente reiniciar o runtime ou usar GPU com mais VRAM\")\n            print(\"💡 TIP: Quantização 4-bit reduz significativamente o uso de VRAM!\")\n            print(\"💡 TIP: Tente definir PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True\")\n            \n        elif \"bitsandbytes\" in error_str or \"bnb\" in error_str:\n            print(\"💡 DIAGNÓSTICO: BitsAndBytes não instalado ou com problema\")\n            print(\"🔧 CORREÇÃO: Instalando bitsandbytes...\")\n            import subprocess\n            try:\n                subprocess.run([\"pip\", \"install\", \"bitsandbytes\", \"--upgrade\"], check=True)\n                print(\"✅ BitsAndBytes atualizado! Tente executar novamente.\")\n            except Exception as install_error:\n                print(f\"❌ Erro ao instalar bitsandbytes: {install_error}\")\n            \n        elif \"connection\" in error_str or \"network\" in error_str:\n            print(\"💡 DIAGNÓSTICO: Problema de conexão\")\n            print(\"🔧 CORREÇÃO: Verifique sua conexão com internet\")\n            \n        # Fallback para versão sem quantização se necessário\n        print(\"\\\\n🔄 TENTANDO FALLBACK: Versão sem quantização...\")\n        try:\n            print(\"📦 Carregando versão padrão sem quantização...\")\n            \n            # Configurações específicas para Medium (mais leve)\n            load_kwargs = {\n                \"torch_dtype\": torch_dtype,\n                \"low_cpu_mem_usage\": True,\n                \"variant\": \"fp16\" if torch.cuda.is_available() else None,\n            }\n            \n            # Remover variant se for None (CPU)\n            if load_kwargs[\"variant\"] is None:\n                del load_kwargs[\"variant\"]\n            \n            pipe = StableDiffusion3Pipeline.from_pretrained(\n                \"stabilityai/stable-diffusion-3.5-medium\", \n                **load_kwargs\n            )\n            \n            # Mover para device\n            print(f\"📱 Movendo modelo para {device}...\")\n            pipe = pipe.to(device)\n                \n            print(\"✅ SD3.5 MEDIUM (sem quantização) carregado como fallback!\")\n            return pipe, \"3.5-medium-fallback\"\n            \n        except Exception as fallback_error:\n            print(f\"❌ Fallback também falhou: {fallback_error}\")\n            \n            # NÃO FAZER FALLBACK - PARAR AQUI\n            print(\"\\\\n🚫 PARANDO EXECUÇÃO - SD3.5 Medium é obrigatório\")\n            print(\"💭 Este notebook foi projetado para SD3.5\")\n            print(\"🔄 SOLUÇÕES:\")\n            print(\"  1. Verifique seu login HuggingFace\")\n            print(\"  2. Aceite os termos do modelo Medium\")\n            print(\"  3. Instale bitsandbytes: !pip install bitsandbytes\")\n            print(\"  4. Defina PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True\")\n            print(\"  5. Tente reiniciar o runtime se necessário\")\n            \n            raise SystemExit(f\"SD3.5 Medium é obrigatório. Erro: {e}\")\n\n# Definir variável de ambiente para fragmentação de memória CUDA\nimport os\nos.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\nprint(\"🔧 Configurando PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True\")\n\n# Definir TORCH_DTYPE se não existir\nif 'TORCH_DTYPE' not in locals():\n    if device.type == \"cuda\":\n        TORCH_DTYPE = torch.bfloat16\n        print(f\"🔢 TORCH_DTYPE: {TORCH_DTYPE} (GPU otimizada)\")\n    else:\n        TORCH_DTYPE = torch.float32\n        print(f\"🔢 TORCH_DTYPE: {TORCH_DTYPE} (CPU compatível)\")\n\n# Carregar pipeline - SD3.5 MEDIUM com quantização\npipe, sd_version = load_stable_diffusion_35_medium_quantized()\n\nif pipe is not None:\n    print(f\"\\\\n🎉 Pipeline SD{sd_version} carregado com sucesso!\")\n    \n    # Scheduler nativo do SD3.5 Medium (já otimizado)\n    print(\"🔧 Mantendo scheduler nativo SD3.5 Medium...\")\n    print(\"✅ Scheduler otimizado para Medium mantido\")\n\n    # Configurações específicas para SD3.5 MEDIUM (mais eficiente)\n    GENERATION_PARAMS_CURRENT = {\n        'width': 1024,              # SD3.5 Medium funciona bem em 1024\n        'height': 1024,\n        'num_inference_steps': 40,  # Aumentado para melhor qualidade\n        'guidance_scale': 4.5,      # Otimizado para SD3.5\n        'num_images_per_prompt': 1,\n        'max_sequence_length': 512, # Parâmetro específico do SD3.5\n        'generator_seed': 42\n    }\n    \n    print(\"⚙️ Parâmetros SD3.5 Medium quantizado otimizados:\")\n    for param, value in GENERATION_PARAMS_CURRENT.items():\n        print(f\"  • {param}: {value}\")\n    \n    print(\"\\\\n⚡ VANTAGENS do SD3.5 Medium Quantizado:\")\n    print(\"  • ~50% menor que Large\")\n    print(\"  • ~2x mais rápido\")\n    print(\"  • Quantização 4-bit reduz VRAM drasticamente\")\n    print(\"  • CPU offload para ainda mais economia\")\n    print(\"  • Mesma arquitetura e qualidade\")\n    print(\"  • Perfeito para GPUs com pouca VRAM\")\n    print(\"  • Ideal para Google Colab\")\n    \n    # Otimizações de memória específicas para Medium quantizado\n    try:\n        if hasattr(pipe, 'enable_attention_slicing'):\n            pipe.enable_attention_slicing()\n            print(\"⚡ Attention slicing ativado\")\n            \n    except Exception as e:\n        print(f\"⚠️ Aviso nas otimizações: {e}\")\n    \n    print(f\"\\\\n🚀 SD3.5 MEDIUM QUANTIZADO PRONTO! Máxima economia de VRAM!\")\n    PIPELINE_READY = True\n    \nelse:\n    print(\"🚫 SISTEMA PARADO - SD3.5 Medium não foi carregado\")\n    PIPELINE_READY = False",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GrassClover-Style Generation with Stable Diffusion\n",
    "Este notebook implementa geração de imagens sintéticas de pastagens brasileiras usando **Stable Diffusion**, seguindo o estilo visual do **GrassClover Dataset** (Skovsen et al., CVPR 2019).\n",
    "## Objetivos:\n",
    "- Gerar imagens **top-down** de pastagens com Stable Diffusion\n",
    "- Adaptar para **gramíneas brasileiras** (Brachiaria, Panicum, Cynodon)\n",
    "- Seguir **metodologia GrassClover** (densidade, perspectiva, resolução)\n",
    "- **Ultra-compatível** com Google Colab (debugging extensivo)\n",
    "## Referência:\n",
    "- **Paper**: Skovsen et al. \"The GrassClover Image Dataset for Semantic and Hierarchical Species Understanding in Agriculture\" (CVPR Workshops, 2019)\n",
    "- **Adaptação**: Espécies temperadas → Tropicais brasileiras\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Ultra-Compatível para Colab\n",
    "**IMPORTANTE**: Este notebook foi desenvolvido para máxima compatibilidade com Google Colab Free/Pro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import platform\n",
    "from datetime import datetime\n",
    "try:\n",
    "    import google.colab\n",
    "    in_colab = True\n",
    "except ImportError:\n",
    "    in_colab = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = None\n",
    "dev_type = \"unknown\"\n",
    "hw_info = {}\n",
    "\n",
    "# Tentar importar torch primeiro\n",
    "try:\n",
    "    import torch\n",
    "    torch_ok = True\n",
    "    hw_info['pytorch_version'] = torch.__version__\n",
    "except ImportError:\n",
    "    torch_ok = False\n",
    "\n",
    "if torch_ok:\n",
    "    # Verificar TPU primeiro\n",
    "    try:\n",
    "        import torch_xla\n",
    "        import torch_xla.core.xla_model as xm\n",
    "        if xm.xrt_world_size() > 1:\n",
    "            device = xm.xla_device()\n",
    "            dev_type = \"tpu\"\n",
    "            hw_info.update({\n",
    "                'dev_type': 'tpu',\n",
    "                'tpu_cores': xm.xrt_world_size(),\n",
    "                'device': str(device)\n",
    "            })\n",
    "        else:\n",
    "            # TPU disponível mas não configurado\n",
    "            device = torch.device(\"cpu\")\n",
    "            dev_type = \"cpu\"\n",
    "    except ImportError:\n",
    "        # TPU não disponível, tentar GPU\n",
    "        pass\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️  Erro ao verificar TPU: {e}\")\n",
    "    \n",
    "    # Se não conseguiu TPU, tentar GPU\n",
    "    if device is None:\n",
    "        cuda_available = torch.cuda.is_available()\n",
    "        if cuda_available:\n",
    "            gpu_count = torch.cuda.device_count()\n",
    "            for i in range(gpu_count):\n",
    "                gpu_name = torch.cuda.get_device_name(i)\n",
    "                gpu_memory = torch.cuda.get_device_properties(i).total_memory\n",
    "                gpu_memory_gb = gpu_memory / (1024**3)\n",
    "            \n",
    "            device = torch.device(\"cuda\")\n",
    "            dev_type = \"gpu\"\n",
    "            hw_info.update({\n",
    "                'dev_type': 'gpu',\n",
    "                'gpu_count': gpu_count,\n",
    "                'gpu_name': torch.cuda.get_device_name(0),\n",
    "                'gpu_memory_gb': torch.cuda.get_device_properties(0).total_memory / (1024**3),\n",
    "                'device': str(device)\n",
    "            })\n",
    "            torch.cuda.empty_cache()\n",
    "        else:\n",
    "            # Fallback para CPU\n",
    "            device = torch.device(\"cpu\")\n",
    "            dev_type = \"cpu\"\n",
    "    \n",
    "    # Se ainda não definiu device, usar CPU\n",
    "    if device is None:\n",
    "        device = torch.device(\"cpu\")\n",
    "        dev_type = \"cpu\"\n",
    "        hw_info.update({\n",
    "            'dev_type': 'cpu',\n",
    "            'device': str(device)\n",
    "        })\n",
    "\n",
    "    # Print do status do hardware\n",
    "    if dev_type == \"cpu\" and in_colab:\n",
    "        print(\"⚠️ CPU detectado - Considere ativar GPU no Colab\")\n",
    "    elif dev_type == \"tpu\":\n",
    "        print(\"🔥 TPU detectado\")\n",
    "    elif dev_type == \"gpu\":\n",
    "        print(f\"🚀 GPU detectado: {hw_info.get('gpu_name', 'Unknown')}\")\n",
    "        \n",
    "else:\n",
    "    device = None\n",
    "    dev_type = \"none\"\n",
    "\n",
    "print(f\"🔧 Hardware configurado: {dev_type.upper()}\")\n",
    "print(f\"📱 Device: {device}\")\n",
    "if hw_info:\n",
    "    print(f\"ℹ️  Info: {hw_info}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# 🔐 AUTENTICAÇÃO HUGGINGFACE OBRIGATÓRIA\nprint(\"🔐 AUTENTICAÇÃO HUGGINGFACE OBRIGATÓRIA\")\nprint(\"=\" * 60)\nprint(\"⚠️  IMPORTANTE: Este notebook REQUER login no HuggingFace para funcionar!\")\nprint(\"📋 Você DEVE aceitar os termos em: https://huggingface.co/stabilityai/stable-diffusion-3.5-medium\")\nprint(\"🔑 Você DEVE ter um token HuggingFace válido\")\nprint(\"⚡ USANDO SD3.5 MEDIUM para melhor performance no Colab!\")\nprint(\"=\" * 60)\n\ntry:\n    from huggingface_hub import notebook_login, whoami\n    \n    print(\"⏳ Iniciando processo de login...\")\n    \n    # Forçar login interativo - isso vai parar e pedir o token\n    notebook_login()\n    \n    # Verificar se o login foi bem-sucedido\n    try:\n        user_info = whoami()\n        print(f\"✅ Login realizado com sucesso!\")\n        print(f\"👤 Usuário logado: {user_info.get('name', 'N/A')}\")\n        HUGGINGFACE_LOGGED_IN = True\n    except Exception as e:\n        print(f\"❌ Falha na verificação do login: {e}\")\n        print(\"🚫 PARANDO EXECUÇÃO - LOGIN NECESSÁRIO\")\n        raise SystemExit(\"Login no HuggingFace é obrigatório para continuar\")\n    \nexcept ImportError as e:\n    print(f\"❌ Erro ao importar huggingface_hub: {e}\")\n    print(\"📦 Instalando huggingface_hub...\")\n    import subprocess\n    result = subprocess.run([\"pip\", \"install\", \"huggingface_hub\", \"--upgrade\", \"--quiet\"], \n                          capture_output=True, text=True)\n    if result.returncode == 0:\n        from huggingface_hub import notebook_login, whoami\n        print(\"✅ huggingface_hub instalado\")\n        \n        # Tentar login novamente após instalação\n        notebook_login()\n        try:\n            user_info = whoami()\n            print(f\"✅ Login realizado com sucesso após instalação!\")\n            print(f\"👤 Usuário logado: {user_info.get('name', 'N/A')}\")\n            HUGGINGFACE_LOGGED_IN = True\n        except:\n            print(\"🚫 PARANDO EXECUÇÃO - LOGIN NECESSÁRIO\")\n            raise SystemExit(\"Login no HuggingFace é obrigatório para continuar\")\n    else:\n        print(\"❌ Falha ao instalar huggingface_hub\")\n        raise SystemExit(\"Não foi possível instalar huggingface_hub\")\n\nexcept Exception as e:\n    print(f\"❌ Erro durante o login: {e}\")\n    print(\"🚫 PARANDO EXECUÇÃO - LOGIN NECESSÁRIO\")\n    print(\"\\n💡 SOLUÇÕES:\")\n    print(\"1. Certifique-se de que tem um token HuggingFace válido\")\n    print(\"2. Acesse: https://huggingface.co/settings/tokens\")\n    print(\"3. Aceite os termos do modelo: https://huggingface.co/stabilityai/stable-diffusion-3.5-medium\")\n    print(\"4. Execute esta célula novamente\")\n    raise SystemExit(\"Login no HuggingFace é obrigatório para continuar\")\n\nprint(\"=\" * 60)\nprint(\"🎉 AUTENTICAÇÃO CONCLUÍDA - NOTEBOOK PODE CONTINUAR\")\nprint(\"⚡ Preparado para SD3.5 MEDIUM (otimizado para Colab)\")\nprint(\"=\" * 60)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# 🚀 STABLE DIFFUSION 3.5 MEDIUM - OTIMIZADO PARA COLAB\nprint(\"🚀 Carregando Stable Diffusion 3.5 MEDIUM...\")\nprint(\"⚡ MODELO OTIMIZADO: Mais rápido e eficiente para Google Colab\")\nprint(\"🎯 MESMO QUALIDADE: Com performance muito melhor\")\n\ndef load_stable_diffusion_35_medium():\n    \"\"\"\n    Carrega SD3.5 MEDIUM - modelo otimizado para Colab\n    \"\"\"\n    # Verificar se o login foi feito\n    if not HUGGINGFACE_LOGGED_IN:\n        print(\"🚫 ERRO: Login no HuggingFace é obrigatório!\")\n        print(\"📋 Execute a célula anterior para fazer login\")\n        raise SystemExit(\"Login necessário para continuar\")\n    \n    try:\n        # Imports específicos para SD3.5\n        from diffusers import StableDiffusion3Pipeline\n        import torch\n        \n        print(\"⏳ Carregando SD3.5 MEDIUM (muito mais rápido que Large)...\")\n        print(\"📦 Download inicial pode demorar, mas vale a pena!\")\n        \n        # Configurações otimizadas para SD3.5 Medium no Colab\n        if torch.cuda.is_available():\n            torch_dtype = torch.bfloat16  # Melhor para GPU\n            print(\"🚀 Configuração GPU detectada - usando bfloat16\")\n        else:\n            torch_dtype = torch.float32   # CPU fallback\n            print(\"💻 Configuração CPU detectada - usando float32\")\n        \n        # Configurações específicas para Medium (mais leve)\n        load_kwargs = {\n            \"torch_dtype\": torch_dtype,\n            \"low_cpu_mem_usage\": True,\n            \"variant\": \"fp16\" if torch.cuda.is_available() else None,  # Versão mais leve para GPU\n        }\n        \n        # Remover variant se for None (CPU)\n        if load_kwargs[\"variant\"] is None:\n            del load_kwargs[\"variant\"]\n        \n        print(\"📦 Iniciando download/carregamento...\")\n        print(\"💡 SD3.5 Medium é ~50% menor que Large, muito mais rápido!\")\n        \n        # Carregar modelo MEDIUM\n        pipe = StableDiffusion3Pipeline.from_pretrained(\n            \"stabilityai/stable-diffusion-3.5-medium\", \n            **load_kwargs\n        )\n        \n        # Mover para device\n        print(f\"📱 Movendo modelo para {device}...\")\n        pipe = pipe.to(device)\n            \n        print(\"✅ SD3.5 MEDIUM carregado com sucesso!\")\n        return pipe, \"3.5-medium\"\n        \n    except Exception as e:\n        print(f\"❌ ERRO ao carregar SD3.5 Medium: {e}\")\n        print(f\"🔍 Tipo do erro: {type(e).__name__}\")\n        \n        # Análise específica de erros\n        error_str = str(e).lower()\n        \n        if \"requires you to be logged in\" in error_str or \"authentication\" in error_str:\n            print(\"💡 DIAGNÓSTICO: Problema de autenticação\")\n            print(\"🔧 CORREÇÃO: Verifique se fez login correto na célula anterior\")\n            print(\"🔗 Aceite os termos: https://huggingface.co/stabilityai/stable-diffusion-3.5-medium\")\n            \n        elif \"out of memory\" in error_str or \"oom\" in error_str:\n            print(\"💡 DIAGNÓSTICO: Problema de memória\")\n            print(\"🔧 CORREÇÃO: SD3.5 Medium requer ~6-8GB VRAM (metade do Large)\")\n            print(\"💡 TIP: Medium é muito mais leve que Large!\")\n            \n        elif \"connection\" in error_str or \"network\" in error_str:\n            print(\"💡 DIAGNÓSTICO: Problema de conexão\")\n            print(\"🔧 CORREÇÃO: Verifique sua conexão com internet\")\n            \n        elif \"variant\" in error_str or \"revision\" in error_str:\n            print(\"💡 DIAGNÓSTICO: Problema com variant fp16\")\n            print(\"🔧 CORREÇÃO: Tentando sem variant...\")\n            \n        # NÃO FAZER FALLBACK - PARAR AQUI\n        print(\"\\n🚫 PARANDO EXECUÇÃO - SD3.5 Medium é obrigatório\")\n        print(\"💭 Este notebook foi projetado para SD3.5\")\n        print(\"🔄 SOLUÇÕES:\")\n        print(\"  1. Verifique seu login HuggingFace\")\n        print(\"  2. Aceite os termos do modelo Medium\")\n        print(\"  3. Medium requer menos VRAM que Large\")\n        print(\"  4. Tente reiniciar o runtime se necessário\")\n        \n        raise SystemExit(f\"SD3.5 Medium é obrigatório. Erro: {e}\")\n\n# Definir TORCH_DTYPE se não existir\nif 'TORCH_DTYPE' not in locals():\n    if device.type == \"cuda\":\n        TORCH_DTYPE = torch.bfloat16\n        print(f\"🔢 TORCH_DTYPE: {TORCH_DTYPE} (GPU otimizada)\")\n    else:\n        TORCH_DTYPE = torch.float32\n        print(f\"🔢 TORCH_DTYPE: {TORCH_DTYPE} (CPU compatível)\")\n\n# Carregar pipeline - APENAS SD3.5 MEDIUM\npipe, sd_version = load_stable_diffusion_35_medium()\n\nif pipe is not None:\n    print(f\"\\n🎉 Pipeline SD{sd_version} carregado com sucesso!\")\n    \n    # Scheduler nativo do SD3.5 Medium (já otimizado)\n    print(\"🔧 Mantendo scheduler nativo SD3.5 Medium...\")\n    print(\"✅ Scheduler otimizado para Medium mantido\")\n\n    # Configurações específicas para SD3.5 MEDIUM (mais eficiente)\n    GENERATION_PARAMS_CURRENT = {\n        'width': 1024,              # SD3.5 Medium funciona bem em 1024\n        'height': 1024,\n        'num_inference_steps': 20,  # REDUZIDO: Medium é mais eficiente\n        'guidance_scale': 4.5,      # Otimizado para SD3.5\n        'num_images_per_prompt': 1,\n        'eta': 0.0,\n        'generator_seed': 42\n    }\n    \n    print(\"⚙️ Parâmetros SD3.5 Medium otimizados:\")\n    for param, value in GENERATION_PARAMS_CURRENT.items():\n        print(f\"  • {param}: {value}\")\n    \n    print(\"\\n⚡ VANTAGENS do SD3.5 Medium:\")\n    print(\"  • ~50% menor que Large\")\n    print(\"  • ~2x mais rápido\")\n    print(\"  • Mesma arquitetura e qualidade\")\n    print(\"  • Perfeito para prototipagem\")\n    print(\"  • Ideal para Google Colab\")\n    \n    # Otimizações de memória específicas para Medium\n    try:\n        if hasattr(pipe, 'enable_attention_slicing'):\n            pipe.enable_attention_slicing()\n            print(\"⚡ Attention slicing ativado\")\n            \n        # Medium não precisa de tanto memory efficient attention\n        if hasattr(pipe, 'enable_memory_efficient_attention') and device.type == \"cuda\":\n            pipe.enable_memory_efficient_attention()  \n            print(\"💾 Memory efficient attention ativado\")\n            \n    except Exception as e:\n        print(f\"⚠️ Aviso nas otimizações: {e}\")\n    \n    print(f\"\\n🚀 SD3.5 MEDIUM PRONTO! Muito mais rápido para geração!\")\n    PIPELINE_READY = True\n    \nelse:\n    print(\"🚫 SISTEMA PARADO - SD3.5 Medium não foi carregado\")\n    PIPELINE_READY = False"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "essential_packages = [\n",
    "    \"torch\",\n",
    "    \"torchvision\", \n",
    "    \"diffusers\",\n",
    "    \"transformers\",\n",
    "    \"accelerate\",\n",
    "    \"pillow\",\n",
    "    \"matplotlib\",\n",
    "    \"numpy\"\n",
    "]\n",
    "\n",
    "def install_package(package_name, quiet=True):\n",
    "    \"\"\"Instala pacote com debugging\"\"\"\n",
    "    import subprocess\n",
    "    try:\n",
    "        cmd = [\"pip\", \"install\", package_name]\n",
    "        if quiet:\n",
    "            cmd.append(\"--quiet\")\n",
    "        result = subprocess.run(cmd, capture_output=True, text=True, timeout=300)\n",
    "        if result.returncode == 0:\n",
    "            return True\n",
    "        else:\n",
    "            print(f\"❌ Erro ao instalar {package_name}:\")\n",
    "            print(result.stderr[:200])\n",
    "            return False\n",
    "    except subprocess.TimeoutExpired:\n",
    "        print(f\"⏱️ Timeout ao instalar {package_name}\")\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        print(f\"💥 Erro inesperado ao instalar {package_name}: {e}\")\n",
    "        return False\n",
    "\n",
    "print(\"📦 Verificando e instalando pacotes essenciais...\")\n",
    "\n",
    "for package in essential_packages:\n",
    "    try:\n",
    "        __import__(package.replace(\"-\", \"_\"))\n",
    "        print(f\"✅ {package} já instalado\")\n",
    "    except ImportError:\n",
    "        print(f\"📦 Instalando {package}...\")\n",
    "        success = install_package(package)\n",
    "        if not success:\n",
    "            print(f\"❌ Falhou ao instalar {package} - continuando mesmo assim\")\n",
    "            break\n",
    "\n",
    "print(\"✅ Verificação de pacotes concluída!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🔄 REIMPORTAÇÃO E VERIFICAÇÃO FINAL COM CONFIGURAÇÕES OTIMIZADAS\n",
    "print(\"🔄 Verificação final do sistema...\")\n",
    "\n",
    "# Imports essenciais com debugging\n",
    "try:\n",
    "    import torch\n",
    "    import torchvision.transforms as transforms\n",
    "    print(\"✅ PyTorch importado\")\n",
    "    \n",
    "    # Reconfigurar device após instalação se necessário\n",
    "    if not 'device' in locals() or device is None:\n",
    "        if torch.cuda.is_available():\n",
    "            device = torch.device(\"cuda\")\n",
    "            dev_type = \"gpu\"\n",
    "            gpu_name = torch.cuda.get_device_name(0)\n",
    "            gpu_memory = torch.cuda.get_device_properties(0).total_memory / (1024**3)\n",
    "            print(f\"🚀 GPU detectada: {gpu_name} ({gpu_memory:.1f}GB)\")\n",
    "            \n",
    "            # Configuração otimizada para GPU\n",
    "            torch.backends.cudnn.benchmark = True\n",
    "            torch.cuda.empty_cache()\n",
    "        else:\n",
    "            device = torch.device(\"cpu\")\n",
    "            dev_type = \"cpu\"\n",
    "            print(\"💻 Usando CPU\")\n",
    "    \n",
    "    # Configurar dtype baseado no hardware\n",
    "    if dev_type == \"gpu\":\n",
    "        TORCH_DTYPE = torch.bfloat16  # GPU: usar half precision\n",
    "    elif dev_type == \"tpu\":\n",
    "        TORCH_DTYPE = torch.float32  # TPU: full precision recomendado\n",
    "    else:\n",
    "        TORCH_DTYPE = torch.float32  # CPU: full precision\n",
    "        \n",
    "    print(f\"🔢 Dtype configurado: {TORCH_DTYPE}\")\n",
    "    \n",
    "except ImportError as e:\n",
    "    print(f\"❌ Erro PyTorch: {e}\")\n",
    "    device = None\n",
    "    dev_type = \"none\"\n",
    "    TORCH_DTYPE = None\n",
    "\n",
    "try:\n",
    "    from diffusers import StableDiffusion3Pipeline, DPMSolverMultistepScheduler\n",
    "    print(\"✅ Diffusers importado\")\n",
    "    diffusers_ok = True\n",
    "except ImportError as e:\n",
    "    print(f\"❌ Erro Diffusers: {e}\")\n",
    "    diffusers_ok = False\n",
    "\n",
    "try:\n",
    "    from PIL import Image, ImageEnhance, ImageFilter\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    print(\"✅ Bibliotecas de imagem importadas\")\n",
    "    libs_ok = True\n",
    "except ImportError as e:\n",
    "    print(f\"❌ Erro bibliotecas básicas: {e}\")\n",
    "    libs_ok = False\n",
    "\n",
    "# Configuração de ambiente Hugging Face\n",
    "try:\n",
    "    import os\n",
    "    os.environ[\"DISABLE_TELEMETRY\"] = \"1\"\n",
    "    os.environ[\"HF_HUB_DISABLE_TELEMETRY\"] = \"1\"\n",
    "    \n",
    "    # Configurar cache offline se necessário\n",
    "    if in_colab:\n",
    "        os.environ[\"TRANSFORMERS_OFFLINE\"] = \"0\"  # Permitir downloads no Colab\n",
    "        os.environ[\"HF_HUB_OFFLINE\"] = \"0\"\n",
    "    print(\"✅ Configuração HF aplicada\")\n",
    "except Exception as e:\n",
    "    print(f\"⚠️ Aviso na configuração HF: {e}\")\n",
    "\n",
    "ALL_READY = device is not None and diffusers_ok and libs_ok\n",
    "\n",
    "if ALL_READY:\n",
    "    print(\"✅ Sistema totalmente configurado e pronto!\")\n",
    "    print(f\"📱 Device: {device}\")\n",
    "    print(f\"🔧 Tipo: {dev_type}\")\n",
    "else:\n",
    "    print(\"❌ Sistema não está completamente configurado\")\n",
    "    if device is None:\n",
    "        print(\"  - Device não configurado\")\n",
    "    if not diffusers_ok:\n",
    "        print(\"  - Diffusers não disponível\")\n",
    "    if not libs_ok:\n",
    "        print(\"  - Bibliotecas básicas com problema\")\n",
    "    \n",
    "    if dev_type == \"cpu\" and in_colab:\n",
    "        print(\"⚠️ Executando em CPU - Performance limitada\")\n",
    "        print(\"💡 Considere ativar GPU no Runtime do Colab\")\n",
    "\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline Stable Diffusion para GrassClover\n",
    "Configuração do pipeline otimizado para geração de pastagens no estilo GrassClover."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CONFIGURAÇÃO AVANÇADA DO PIPELINE STABLE DIFFUSION\n",
    "print(\"🎨 Configurando Stable Diffusion Pipeline...\\n\")\n",
    "# Parâmetros do pipeline baseados no hardware detectado\n",
    "MODEL_ID = \"runwayml/stable-diffusion-v1-5\"  # Modelo base confiável\n",
    "LOW_CPU_MEM_USAGE = True\n",
    "ENABLE_ATTENTION_SLICING = True\n",
    "# Configurações específicas por hardware\n",
    "if device_type == \"gpu\":\n",
    "    ENABLE_MODEL_CPU_OFFLOAD = False\n",
    "    ENABLE_SEQUENTIAL_CPU_OFFLOAD = False\n",
    "    USE_TORCH_COMPILE = True\n",
    "elif device_type == \"tpu\":\n",
    "    ENABLE_MODEL_CPU_OFFLOAD = True\n",
    "    ENABLE_SEQUENTIAL_CPU_OFFLOAD = False\n",
    "    USE_TORCH_COMPILE = False  # TPU pode ter problemas com compile\n",
    "else:  # CPU\n",
    "    ENABLE_MODEL_CPU_OFFLOAD = True\n",
    "    ENABLE_SEQUENTIAL_CPU_OFFLOAD = True\n",
    "    USE_TORCH_COMPILE = False\n",
    "print(f\"📦 Modelo: {MODEL_ID}\")\n",
    "print(f\"🔢 Dtype: {TORCH_DTYPE}\")\n",
    "print(f\"💾 Low CPU mem: {LOW_CPU_MEM_USAGE}\")\n",
    "print(f\"⚡ Attention slicing: {ENABLE_ATTENTION_SLICING}\")\n",
    "print(f\"🏃 Model CPU offload: {ENABLE_MODEL_CPU_OFFLOAD}\")\n",
    "print(f\"🔥 Hardware: {device_type.upper()}\")\n",
    "# Função para carregar pipeline com debugging e bypass de autenticação\n",
    "def load_stable_diffusion_pipeline():\n",
    "    \"\"\"Carrega pipeline com máximo debugging e configurações otimizadas\"\"\"\n",
    "    try:\n",
    "        print(\"⏳ Carregando modelo...\")\n",
    "        # Configurações para bypass de problemas de autenticação\n",
    "        load_kwargs = {\n",
    "            \"torch_dtype\": TORCH_DTYPE,\n",
    "            \"low_cpu_mem_usage\": LOW_CPU_MEM_USAGE,\n",
    "            \"use_safetensors\": True,\n",
    "        }\n",
    "        # Configurações específicas para resolver problemas HF\n",
    "        try:\n",
    "            # Tentar com autenticação padrão primeiro\n",
    "            pipe = StableDiffusionPipeline.from_pretrained(MODEL_ID, **load_kwargs)\n",
    "            print(\"✅ Modelo carregado com autenticação padrão\")\n",
    "        except Exception as auth_error:\n",
    "            print(f\"⚠️  Problema de autenticação: {str(auth_error)[:100]}...\")\n",
    "            print(\"🔄 Tentando download forçado...\")\n",
    "            # Bypass de problemas de autenticação\n",
    "            load_kwargs[\"use_auth_token\"] = False\n",
    "            load_kwargs[\"force_download\"] = False\n",
    "            load_kwargs[\"resume_download\"] = True\n",
    "            pipe = StableDiffusionPipeline.from_pretrained(MODEL_ID, **load_kwargs)\n",
    "            print(\"✅ Modelo carregado com bypass de autenticação\")\n",
    "        # Mover para device\n",
    "        pipe = pipe.to(device)\n",
    "        print(f\"🚀 Pipeline movido para {device}\")\n",
    "        # Otimizações baseadas no hardware\n",
    "        if ENABLE_ATTENTION_SLICING:\n",
    "            pipe.enable_attention_slicing()\n",
    "            print(\"⚡ Attention slicing habilitado\")\n",
    "        if ENABLE_MODEL_CPU_OFFLOAD and device_type != \"cpu\":\n",
    "            try:\n",
    "                pipe.enable_model_cpu_offload()\n",
    "                print(\"💾 Model CPU offload habilitado\")\n",
    "            except Exception as e:\n",
    "                print(f\"⚠️  CPU offload falhou: {e}\")\n",
    "        if ENABLE_SEQUENTIAL_CPU_OFFLOAD and device_type == \"cpu\":\n",
    "            try:\n",
    "                pipe.enable_sequential_cpu_offload()\n",
    "                print(\"🔄 Sequential CPU offload habilitado\")\n",
    "            except Exception as e:\n",
    "                print(f\"⚠️  Sequential offload falhou: {e}\")\n",
    "        # Scheduler otimizado\n",
    "        pipe.scheduler = DPMSolverMultistepScheduler.from_config(pipe.scheduler.config)\n",
    "        print(\"🔧 Scheduler otimizado (DPMSolver)\")\n",
    "        # Configurações de memória específicas\n",
    "        if device_type == \"gpu\":\n",
    "            torch.cuda.empty_cache()\n",
    "            allocated = torch.cuda.memory_allocated() / (1024**3)\n",
    "            cached = torch.cuda.memory_reserved() / (1024**3)\n",
    "            print(f\"💾 GPU Memory - Allocated: {allocated:.2f}GB, Cached: {cached:.2f}GB\")\n",
    "            # Verificar se há memória suficiente\n",
    "            if allocated > 10.0:  # >10GB pode causar problemas\n",
    "                print(f\"⚠️  Alta utilização de memória GPU!\")\n",
    "        elif device_type == \"tpu\":\n",
    "            print(\"🔥 TPU configurado - memória gerenciada automaticamente\")\n",
    "        else:  # CPU\n",
    "            print(\"💻 CPU mode - sem monitoramento de GPU memory\")\n",
    "        print(\"\\n✅ Pipeline configurado com sucesso!\")\n",
    "        return pipe\n",
    "    except Exception as e:\n",
    "        print(f\"💥 ERRO ao carregar pipeline: {e}\")\n",
    "        print(f\"\\n📋 DEBUG COPY/PASTE:\")\n",
    "        print(f\"Model: {MODEL_ID}\")\n",
    "        print(f\"Device: {device} ({device_type})\")\n",
    "        print(f\"Dtype: {TORCH_DTYPE}\")\n",
    "        print(f\"Hardware info: {hardware_info if 'hardware_info' in locals() else 'N/A'}\")\n",
    "        print(f\"Error type: {type(e).__name__}\")\n",
    "        print(f\"Error message: {e}\")\n",
    "        # Sugestões baseadas no tipo de erro\n",
    "        error_str = str(e).lower()\n",
    "        if \"authentication\" in error_str or \"token\" in error_str:\n",
    "            print(f\"\\n💡 SOLUÇÃO PARA ERRO DE TOKEN:\")\n",
    "            print(f\"1. Ignore o warning - o modelo deve funcionar mesmo assim\")\n",
    "            print(f\"2. Ou configure HF_TOKEN manualmente se necessário\")\n",
    "        elif \"memory\" in error_str or \"cuda\" in error_str:\n",
    "            print(f\"\\n💡 SOLUÇÃO PARA ERRO DE MEMÓRIA:\")\n",
    "            print(f\"1. Reduzir batch_size\")\n",
    "            print(f\"2. Usar torch.float16 se estiver usando float32\")\n",
    "            print(f\"3. Fechar outros notebooks no Colab\")\n",
    "        elif \"module\" in error_str or \"import\" in error_str:\n",
    "            print(f\"\\n💡 SOLUÇÃO PARA ERRO DE MÓDULO:\")\n",
    "            print(f\"1. Re-executar células de instalação\")\n",
    "            print(f\"2. Restart runtime se necessário\")\n",
    "        return None\n",
    "# Carregar pipeline\n",
    "if ALL_READY:\n",
    "    pipe = load_stable_diffusion_pipeline()\n",
    "    PIPELINE_READY = pipe is not None\n",
    "else:\n",
    "    pipe = None\n",
    "    PIPELINE_READY = False\n",
    "    print(\"❌ Sistema não está pronto para carregar pipeline\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# 🎨 STATUS DO SISTEMA\nprint(\"🎨 Verificando status do sistema SD3.5...\")\n\n# Verificar se todos os pré-requisitos estão atendidos\ndef check_system_status():\n    \"\"\"Verifica se o sistema está pronto para usar SD3.5\"\"\"\n    \n    status = {\n        'huggingface_login': False,\n        'pipeline_loaded': False,\n        'device_ready': False,\n        'all_ready': False\n    }\n    \n    # Verificar login HuggingFace\n    if 'HUGGINGFACE_LOGGED_IN' in globals() and HUGGINGFACE_LOGGED_IN:\n        print(\"✅ HuggingFace: Login OK\")\n        status['huggingface_login'] = True\n    else:\n        print(\"❌ HuggingFace: Login necessário\")\n        return status\n    \n    # Verificar pipeline\n    if 'PIPELINE_READY' in globals() and PIPELINE_READY:\n        print(\"✅ Pipeline SD3.5: Carregado\")\n        status['pipeline_loaded'] = True\n    else:\n        print(\"❌ Pipeline SD3.5: Não carregado\")\n        return status\n    \n    # Verificar device\n    if 'device' in globals() and device is not None:\n        print(f\"✅ Device: {device} ({dev_type})\")\n        status['device_ready'] = True\n    else:\n        print(\"❌ Device: Não configurado\")\n        return status\n    \n    # Verificar se tudo está pronto\n    if all([status['huggingface_login'], status['pipeline_loaded'], status['device_ready']]):\n        status['all_ready'] = True\n        print(\"🎉 Sistema completamente pronto para geração!\")\n    else:\n        print(\"⚠️ Sistema não está completamente configurado\")\n    \n    return status\n\n# Executar verificação\nsystem_status = check_system_status()\n\nif system_status['all_ready']:\n    print(f\"\\n📋 CONFIGURAÇÃO FINAL:\")\n    print(f\"  • Modelo: Stable Diffusion 3.5 Large\")\n    print(f\"  • Device: {device}\")\n    print(f\"  • Dtype: {TORCH_DTYPE}\")\n    print(f\"  • Resolução: {GENERATION_PARAMS_CURRENT['width']}x{GENERATION_PARAMS_CURRENT['height']}\")\n    print(f\"  • Steps: {GENERATION_PARAMS_CURRENT['num_inference_steps']}\")\n    print(f\"  • Guidance: {GENERATION_PARAMS_CURRENT['guidance_scale']}\")\n    \n    print(f\"\\n🚀 PRONTO PARA GERAR IMAGENS GRASSCLOVER!\")\n    \nelse:\n    print(f\"\\n🚫 SISTEMA NÃO ESTÁ PRONTO\")\n    print(f\"📋 Execute as células anteriores na ordem:\")\n    print(f\"  1. Login HuggingFace (obrigatório)\")\n    print(f\"  2. Configuração de hardware\")\n    print(f\"  3. Carregamento do SD3.5\")\n\nprint(\"=\" * 60)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 📚 DOWNLOAD DO DATASET GRASSCLOVER ORIGINAL\n",
    "print(\"📚 Baixando dataset GrassClover original do Kaggle...\\n\")\n",
    "\n",
    "# Inicializar variável globalmente\n",
    "GRASSCLOVER_DATASET_PATH = None\n",
    "\n",
    "try:\n",
    "    # Instalar kagglehub se necessário\n",
    "    try:\n",
    "        import kagglehub\n",
    "        print(\"✅ kagglehub já disponível\")\n",
    "    except ImportError:\n",
    "        print(\"📦 Instalando kagglehub...\")\n",
    "        import subprocess\n",
    "        result = subprocess.run([\"pip\", \"install\", \"kagglehub\", \"--quiet\"], \n",
    "                              capture_output=True, text=True)\n",
    "        if result.returncode == 0:\n",
    "            import kagglehub\n",
    "            print(\"✅ kagglehub instalado com sucesso\")\n",
    "        else:\n",
    "            print(f\"❌ Erro ao instalar kagglehub: {result.stderr}\")\n",
    "            raise ImportError(\"kagglehub installation failed\")\n",
    "    \n",
    "    # Download do dataset\n",
    "    print(\"⏳ Fazendo download do GrassClover dataset...\")\n",
    "    print(\"💡 Isso pode demorar alguns minutos na primeira vez...\")\n",
    "    \n",
    "    dataset_path = kagglehub.dataset_download(\"usharengaraju/grassclover-dataset\")\n",
    "    \n",
    "    if dataset_path and os.path.exists(dataset_path):\n",
    "        GRASSCLOVER_DATASET_PATH = dataset_path\n",
    "        print(f\"✅ Dataset baixado com sucesso!\")\n",
    "        print(f\"📁 Localização: {dataset_path}\")\n",
    "        \n",
    "        # Explorar estrutura do dataset\n",
    "        print(f\"\\n📋 Estrutura do dataset:\")\n",
    "        \n",
    "        total_files = 0\n",
    "        for root, dirs, files in os.walk(dataset_path):\n",
    "            level = root.replace(dataset_path, '').count(os.sep)\n",
    "            indent = '  ' * level\n",
    "            folder_name = os.path.basename(root) if root != dataset_path else 'grassclover-dataset'\n",
    "            \n",
    "            # Contar apenas arquivos de imagem\n",
    "            image_files = [f for f in files if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "            \n",
    "            if image_files:\n",
    "                print(f\"{indent}{folder_name}/ ({len(image_files)} imagens)\")\n",
    "                total_files += len(image_files)\n",
    "                \n",
    "                # Mostrar alguns exemplos de nomes\n",
    "                for file in image_files[:3]:\n",
    "                    print(f\"{indent}  • {file}\")\n",
    "                if len(image_files) > 3:\n",
    "                    print(f\"{indent}  • ... e mais {len(image_files)-3} imagens\")\n",
    "            elif dirs:\n",
    "                print(f\"{indent}{folder_name}/\")\n",
    "        \n",
    "        print(f\"\\n📊 Total: {total_files} imagens encontradas\")\n",
    "        \n",
    "        if total_files == 0:\n",
    "            print(\"⚠️  Nenhuma imagem encontrada no dataset baixado\")\n",
    "            GRASSCLOVER_DATASET_PATH = None\n",
    "    else:\n",
    "        print(\"❌ Download retornou path inválido\")\n",
    "        GRASSCLOVER_DATASET_PATH = None\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ Erro ao baixar dataset: {e}\")\n",
    "    print(f\"\\n📋 DEBUG INFO:\")\n",
    "    print(f\"Error type: {type(e).__name__}\")\n",
    "    print(f\"Error message: {str(e)[:200]}...\")\n",
    "    \n",
    "    # Manter variável definida como None\n",
    "    GRASSCLOVER_DATASET_PATH = None\n",
    "    \n",
    "    print(f\"\\n💡 SOLUÇÕES POSSÍVEIS:\")\n",
    "    print(f\"1. Verificar conectividade com internet\")\n",
    "    print(f\"2. Tentar novamente em alguns minutos\")\n",
    "    print(f\"3. Verificar se Kaggle está acessível\")\n",
    "    print(f\"4. OPCIONAL: Upload manual de imagens GrassClover\")\n",
    "\n",
    "# Status final\n",
    "if GRASSCLOVER_DATASET_PATH:\n",
    "    print(f\"\\n✅ Dataset GrassClover disponível para análise!\")\n",
    "else:\n",
    "    print(f\"\\n⚠️  Continuando sem dataset GrassClover\")\n",
    "    print(f\"🎯 O notebook ainda funcionará, mas sem calibração visual\")\n",
    "\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🔍 ANÁLISE VISUAL DO DATASET GRASSCLOVER ORIGINAL\n",
    "print(\"🔍 Analisando características visuais do GrassClover...\\n\")\n",
    "\n",
    "def analyze_grassclover_images(dataset_path, num_samples=6):\n",
    "    \"\"\"\n",
    "    Analisa imagens do GrassClover para extrair características visuais\n",
    "    \"\"\"\n",
    "    if not dataset_path or not os.path.exists(dataset_path):\n",
    "        print(\"❌ Dataset não disponível para análise\")\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        # Encontrar arquivos de imagem\n",
    "        image_files = []\n",
    "        for root, dirs, files in os.walk(dataset_path):\n",
    "            for file in files:\n",
    "                if file.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "                    image_files.append(os.path.join(root, file))\n",
    "        \n",
    "        if not image_files:\n",
    "            print(\"❌ Nenhuma imagem encontrada no dataset\")\n",
    "            return None\n",
    "        \n",
    "        print(f\"📸 Encontradas {len(image_files)} imagens\")\n",
    "        print(f\"🎯 Analisando {min(num_samples, len(image_files))} amostras...\")\n",
    "        \n",
    "        # Selecionar amostras aleatórias\n",
    "        import random\n",
    "        random.seed(42)  # Reprodutibilidade\n",
    "        sample_files = random.sample(image_files, min(num_samples, len(image_files)))\n",
    "        \n",
    "        # Análise visual\n",
    "        fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "        fig.suptitle('📚 GrassClover Dataset - Análise Visual de Referência', \n",
    "                    fontsize=16, fontweight='bold')\n",
    "        \n",
    "        axes = axes.flatten()\n",
    "        image_stats = []\n",
    "        \n",
    "        for i, img_path in enumerate(sample_files):\n",
    "            try:\n",
    "                # Carregar imagem\n",
    "                img = Image.open(img_path)\n",
    "                img_array = np.array(img)\n",
    "                \n",
    "                # Estatísticas da imagem\n",
    "                stats = {\n",
    "                    'filename': os.path.basename(img_path),\n",
    "                    'size': img.size,\n",
    "                    'mode': img.mode,\n",
    "                    'mean_rgb': np.mean(img_array, axis=(0, 1)) if len(img_array.shape) == 3 else np.mean(img_array),\n",
    "                    'std_rgb': np.std(img_array, axis=(0, 1)) if len(img_array.shape) == 3 else np.std(img_array)\n",
    "                }\n",
    "                image_stats.append(stats)\n",
    "                \n",
    "                # Exibir imagem\n",
    "                axes[i].imshow(img)\n",
    "                axes[i].set_title(f\"{stats['filename']}\\n{stats['size'][0]}x{stats['size'][1]}\", \n",
    "                                fontsize=10)\n",
    "                axes[i].axis('off')\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"⚠️  Erro ao carregar {img_path}: {e}\")\n",
    "                axes[i].text(0.5, 0.5, 'Erro\\nao carregar', \n",
    "                           ha='center', va='center', transform=axes[i].transAxes)\n",
    "                axes[i].axis('off')\n",
    "        \n",
    "        # Ocultar eixos não usados\n",
    "        for j in range(len(sample_files), len(axes)):\n",
    "            axes[j].axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Estatísticas gerais\n",
    "        if image_stats:\n",
    "            print(f\"\\n📊 CARACTERÍSTICAS VISUAIS IDENTIFICADAS:\")\n",
    "            \n",
    "            # Tamanhos das imagens\n",
    "            sizes = [stat['size'] for stat in image_stats]\n",
    "            unique_sizes = list(set(sizes))\n",
    "            print(f\"📏 Resoluções encontradas: {unique_sizes}\")\n",
    "            \n",
    "            # Cores médias (se RGB)\n",
    "            rgb_images = [stat for stat in image_stats if len(stat['mean_rgb']) == 3]\n",
    "            if rgb_images:\n",
    "                avg_colors = np.mean([stat['mean_rgb'] for stat in rgb_images], axis=0)\n",
    "                print(f\"🎨 Cores médias (RGB): R={avg_colors[0]:.1f}, G={avg_colors[1]:.1f}, B={avg_colors[2]:.1f}\")\n",
    "                \n",
    "                # Análise de tons de verde\n",
    "                green_dominance = avg_colors[1] / (avg_colors[0] + avg_colors[2] + 0.1)\n",
    "                print(f\"🌿 Dominância verde: {green_dominance:.2f} (quanto maior, mais verde)\")\n",
    "            \n",
    "            print(f\"\\n💡 INSIGHTS PARA STABLE DIFFUSION:\")\n",
    "            print(f\"• Vista: Top-down (aérea) consistente\")\n",
    "            print(f\"• Textura: Densa cobertura de gramíneas pequenas\")\n",
    "            print(f\"• Cores: Tons de verde predominantes\")\n",
    "            print(f\"• Iluminação: Natural, sem sombras fortes\")\n",
    "            print(f\"• Composição: Mistura grass + clover (ryegrass + trevo)\")\n",
    "            print(f\"• Resolução típica: ~512x512 ou similar\")\n",
    "            \n",
    "        return {\n",
    "            'sample_files': sample_files,\n",
    "            'image_stats': image_stats,\n",
    "            'total_images': len(image_files)\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Erro na análise: {e}\")\n",
    "        return None\n",
    "\n",
    "# Verificar se dataset path existe, senão definir como None\n",
    "if 'GRASSCLOVER_DATASET_PATH' not in locals():\n",
    "    print(\"⚠️  GRASSCLOVER_DATASET_PATH não definido - provavelmente erro no download\")\n",
    "    GRASSCLOVER_DATASET_PATH = None\n",
    "\n",
    "# Executar análise\n",
    "if GRASSCLOVER_DATASET_PATH:\n",
    "    print(f\"📁 Usando dataset em: {GRASSCLOVER_DATASET_PATH}\")\n",
    "    grassclover_analysis = analyze_grassclover_images(GRASSCLOVER_DATASET_PATH)\n",
    "    GRASSCLOVER_REFERENCE_AVAILABLE = grassclover_analysis is not None\n",
    "else:\n",
    "    print(\"⚠️  Dataset GrassClover não disponível\")\n",
    "    print(\"💡 Possíveis causas:\")\n",
    "    print(\"  • Erro no download do Kaggle\")\n",
    "    print(\"  • Problema de conectividade\")\n",
    "    print(\"  • kagglehub não instalado corretamente\")\n",
    "    print(\"\\n🔄 Para resolver:\")\n",
    "    print(\"  • Re-execute a célula de download\")\n",
    "    print(\"  • Verifique se tem conectividade com Kaggle\")\n",
    "    print(\"  • O notebook continuará funcionando sem as referências\")\n",
    "    \n",
    "    grassclover_analysis = None\n",
    "    GRASSCLOVER_REFERENCE_AVAILABLE = False\n",
    "\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompts para Pastagens Brasileiras - Estilo GrassClover\n",
    "Prompts específicos para gerar pastagens tropicais seguindo a metodologia visual do GrassClover."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "GRASSCLOVER_PROMPTS = {\n    'grassclover_exact_style': {\n        'positive': (\n            \"overhead top-down view of mixed grass and white clover field, \"\n            \"dense green ryegrass with white clover flowers, \"\n            \"small spherical white clover blooms scattered throughout, \"\n            \"fine thin grass blades, dense ground coverage, \"\n            \"natural outdoor lighting, soft daylight, no shadows, \"\n            \"detailed grass texture, small clover leaves visible, \"\n            \"research quality agricultural photography, \"\n            \"grassclover dataset style, scientific documentation, \"\n            \"perennial ryegrass, trifolium repens, mixed pasture\"\n        ),\n        'negative': (\n            \"side view, angled view, perspective view, \"\n            \"large flowers, colorful flowers, trees, shrubs, \"\n            \"buildings, people, animals, vehicles, \"\n            \"artificial grass, lawn, decorative plants, \"\n            \"dramatic lighting, shadows, high contrast, \"\n            \"blurry, low quality, cartoon, painting\"\n        ),\n        'description': \"Estilo GrassClover exato - ryegrass + trevo branco\"\n    },\n    \n    'grassclover_dense_flowers': {\n        'positive': (\n            \"bird's eye view of grassland with abundant white clover flowers, \"\n            \"dense small white spherical clover blooms, \"\n            \"green grass background, trifolium repens in full bloom, \"\n            \"natural field conditions, scientific photography, \"\n            \"fine grass texture beneath clover flowers, \"\n            \"uniform lighting, no harsh shadows, research quality, \"\n            \"mixed grass-clover sward, agricultural study image\"\n        ),\n        'negative': (\n            \"ground level view, human perspective, \"\n            \"large decorative flowers, colored flowers, \"\n            \"ornamental garden, landscaped area, \"\n            \"artificial lighting, studio photography, \"\n            \"bare soil, sparse vegetation, weeds\"\n        ),\n        'description': \"GrassClover com flores densas de trevo\"\n    },\n    \n    'grassclover_fine_texture': {\n        'positive': (\n            \"close overhead view of fine grass and clover mixture, \"\n            \"detailed texture of ryegrass blades and clover leaves, \"\n            \"small white clover flowers interspersed, \"\n            \"natural pasture composition, research documentation, \"\n            \"soft natural lighting, even illumination, \"\n            \"high detail vegetation pattern, grassclover study, \"\n            \"mixed species grassland, agricultural research image\"\n        ),\n        'negative': (\n            \"coarse grass, large blade grass, tropical grasses, \"\n            \"artificial turf, decorative plants, \"\n            \"dramatic shadows, studio lighting, \"\n            \"perspective distortion, angled shots\"\n        ),\n        'description': \"Textura fina GrassClover detalhada\"\n    },\n    \n    'brazilian_mixed_grassclover_style': {\n        'positive': (\n            \"top-down view of mixed tropical grass with legume flowers, \"\n            \"small white stylosanthes flowers scattered in green grass, \"\n            \"dense brachiaria grass coverage with legume blooms, \"\n            \"grassclover dataset visual style, research photography, \"\n            \"natural field lighting, soft daylight, uniform illumination, \"\n            \"detailed grass-legume mixture, scientific documentation, \"\n            \"brazilian pasture with flowering legumes, agricultural study\"\n        ),\n        'negative': (\n            \"side perspective, ground level view, \"\n            \"large flowers, ornamental plants, \"\n            \"buildings, infrastructure, people, animals, \"\n            \"artificial lighting, dramatic shadows, \"\n            \"low quality, blurry, artistic style\"\n        ),\n        'description': \"Pastagem brasileira estilo GrassClover\"\n    },\n    \n    'brachiaria_with_flowers_grassclover_style': {\n        'positive': (\n            \"aerial view of brachiaria pasture with small white legume flowers, \"\n            \"dense tropical grass with scattered small blooms, \"\n            \"grassclover research style photography, natural lighting, \"\n            \"detailed grass texture with flowering plants, \"\n            \"agricultural field study image, scientific quality, \"\n            \"mixed brachiaria and flowering legumes, top-down perspective, \"\n            \"brazilian tropical grassland research documentation\"\n        ),\n        'negative': (\n            \"temperate climate plants, large decorative flowers, \"\n            \"perspective view, human eye level, \"\n            \"landscaped garden, ornamental setting, \"\n            \"dramatic lighting, artistic photography, \"\n            \"poor quality, distorted view\"\n        ),\n        'description': \"Brachiaria com flores estilo GrassClover\"\n    }\n}\n\n# Parâmetros OTIMIZADOS para SD3.5 Medium (mais rápido)\nif 'GENERATION_PARAMS_CURRENT' not in locals():\n    GENERATION_PARAMS_CURRENT = {\n        'width': 1024,               # Boa qualidade sem ser muito pesado\n        'height': 1024, \n        'num_inference_steps': 20,   # OTIMIZADO: Medium é mais eficiente\n        'guidance_scale': 4.5,       # Ideal para SD3.5\n        'num_images_per_prompt': 1,\n        'eta': 0.0,\n        'generator_seed': 42\n    }\n\nprint(\"🎯 Prompts GrassClover configurados para SD3.5 MEDIUM:\")\nfor key, prompt_data in GRASSCLOVER_PROMPTS.items():\n    print(f\"  • {prompt_data['description']}\")\n\nprint(f\"\\n⚡ Parâmetros OTIMIZADOS para SD3.5 Medium:\")\nfor param, value in GENERATION_PARAMS_CURRENT.items():\n    print(f\"  • {param}: {value}\")\n\nprint(\"\\n🚀 VANTAGENS da configuração Medium:\")\nprint(\"  • 20 steps (vs 28 Large) = ~40% mais rápido\")\nprint(\"  • 1024x1024 = qualidade excelente\") \nprint(\"  • Guidance 4.5 = otimizado para SD3.5\")\nprint(\"  • Perfeito para iteração rápida\")\nprint(\"  • Ideal para prototipagem no Colab\")\n\nprint(\"✅ Sistema configurado exclusivamente para SD3.5 MEDIUM!\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Função de Geração com Debugging Completo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_grassclover_image(prompt_key, custom_seed=None, debug=True):\n",
    "    \"\"\"\n",
    "    Gera imagem no estilo GrassClover com debugging completo\n",
    "    Args:\n",
    "        prompt_key: Chave do prompt (ex: \"grassclover_exact_style\")\n",
    "        custom_seed: Seed personalizada (opcional)\n",
    "        debug: Ativar prints de debug\n",
    "    Returns:\n",
    "        dict com imagem e metadados\n",
    "    \"\"\"\n",
    "    if not PIPELINE_READY:\n",
    "        print(\"❌ Pipeline não está pronto\")\n",
    "        return {'success': False, 'error': 'Pipeline não configurado'}\n",
    "    \n",
    "    if prompt_key not in GRASSCLOVER_PROMPTS:\n",
    "        print(f\"❌ Prompt key '{prompt_key}' não encontrada\")\n",
    "        return {'success': False, 'error': f'Prompt key inválida: {prompt_key}'}\n",
    "    \n",
    "    try:\n",
    "        # Configurar seed\n",
    "        seed = custom_seed if custom_seed is not None else GENERATION_PARAMS_CURRENT['generator_seed']\n",
    "        generator = torch.Generator(device=device).manual_seed(seed)\n",
    "        \n",
    "        prompt_data = GRASSCLOVER_PROMPTS[prompt_key]\n",
    "        positive_prompt = prompt_data['positive']\n",
    "        negative_prompt = prompt_data['negative']\n",
    "        \n",
    "        if debug:\n",
    "            print(f\"🎯 Gerando: {prompt_data['description']}\")\n",
    "            print(f\"🌱 Seed: {seed}\")\n",
    "            \n",
    "        # Monitoramento de memória antes\n",
    "        if device.type == \"cuda\":\n",
    "            torch.cuda.empty_cache()\n",
    "            mem_before = torch.cuda.memory_allocated() / (1024**3)\n",
    "            if debug:\n",
    "                print(f\"💾 Memória GPU antes: {mem_before:.2f}GB\")\n",
    "        \n",
    "        # Geração com autocast para otimização\n",
    "        with torch.autocast(device.type):\n",
    "            result = pipe(\n",
    "                prompt=positive_prompt,\n",
    "                negative_prompt=negative_prompt,\n",
    "                width=GENERATION_PARAMS_CURRENT['width'],\n",
    "                height=GENERATION_PARAMS_CURRENT['height'],\n",
    "                num_inference_steps=GENERATION_PARAMS_CURRENT['num_inference_steps'],\n",
    "                guidance_scale=GENERATION_PARAMS_CURRENT['guidance_scale'],\n",
    "                num_images_per_prompt=GENERATION_PARAMS_CURRENT['num_images_per_prompt'],\n",
    "                eta=GENERATION_PARAMS_CURRENT['eta'],\n",
    "                generator=generator\n",
    "            )\n",
    "        \n",
    "        # Monitoramento de memória depois\n",
    "        if debug:\n",
    "            if device.type == \"cuda\":\n",
    "                mem_after = torch.cuda.memory_allocated() / (1024**3)\n",
    "                print(f\"💾 Memória GPU depois: {mem_after:.2f}GB\")\n",
    "        \n",
    "        image = result.images[0]\n",
    "        \n",
    "        # Metadados completos\n",
    "        metadata = {\n",
    "            'prompt_key': prompt_key,\n",
    "            'description': prompt_data['description'],\n",
    "            'seed': seed,\n",
    "            'generation_params': GENERATION_PARAMS.copy(),\n",
    "            'timestamp': datetime.now().isoformat(),\n",
    "            'model_id': MODEL_ID,\n",
    "            'device': str(device)\n",
    "        }\n",
    "        \n",
    "        if debug:\n",
    "            print(\"✅ Imagem gerada com sucesso!\")\n",
    "        \n",
    "        return {\n",
    "            'image': image,\n",
    "            'metadata': metadata,\n",
    "            'success': True\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"💥 ERRO na geração: {e}\")\n",
    "        print(f\"Error type: {type(e).__name__}\")\n",
    "        print(f\"Error message: {e}\")\n",
    "        \n",
    "        # Limpeza de memória em caso de erro\n",
    "        if device.type == \"cuda\":\n",
    "            torch.cuda.empty_cache()\n",
    "        \n",
    "        return {\n",
    "            'image': None,\n",
    "            'metadata': None,\n",
    "            'success': False,\n",
    "            'error': str(e)\n",
    "        }\n",
    "\n",
    "def display_generation_result(result, show_metadata=True):\n",
    "    \"\"\"Exibe resultado da geração com metadados\"\"\"\n",
    "    if not result['success']:\n",
    "        print(f\"❌ Erro na geração: {result.get('error', 'Erro desconhecido')}\")\n",
    "        return\n",
    "    \n",
    "    # Exibir imagem\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(result['image'])\n",
    "    plt.axis('off')\n",
    "    \n",
    "    # Título com informações\n",
    "    metadata = result['metadata']\n",
    "    title = f\"{metadata['description']}\\nSeed: {metadata['seed']} | {metadata['generation_params']['width']}x{metadata['generation_params']['height']}\"\n",
    "    plt.title(title, fontsize=14, pad=20)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    if show_metadata:\n",
    "        print(f\"📊 Metadados:\")\n",
    "        print(f\"  • Prompt: {metadata['prompt_key']}\")\n",
    "        print(f\"  • Seed: {metadata['seed']}\")\n",
    "        print(f\"  • Resolução: {metadata['generation_params']['width']}x{metadata['generation_params']['height']}\")\n",
    "        print(f\"  • Steps: {metadata['generation_params']['num_inference_steps']}\")\n",
    "        print(f\"  • Guidance: {metadata['generation_params']['guidance_scale']}\")\n",
    "        print(f\"  • Timestamp: {metadata['timestamp']}\")\n",
    "\n",
    "print(\"🔧 Função de geração configurada!\")\n",
    "print(\"💡 Use: generate_grassclover_image('prompt_key', custom_seed=42)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🧪 Teste Inicial - Uma Imagem de Cada Tipo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"🧪 Iniciando teste do sistema...\")\n",
    "\n",
    "if PIPELINE_READY:\n",
    "    print(\"✅ Pipeline está pronto - executando testes\")\n",
    "    \n",
    "    test_prompts = [\"grassclover_exact_style\", \"brazilian_mixed_grassclover_style\", \"brachiaria_with_flowers_grassclover_style\"]\n",
    "    test_results = []\n",
    "    \n",
    "    for i, prompt_key in enumerate(test_prompts, 1):\n",
    "        print(f\"\\n🧪 Teste {i}/{len(test_prompts)}: {prompt_key}\")\n",
    "        \n",
    "        result = generate_grassclover_image(\n",
    "            prompt_key=prompt_key,\n",
    "            custom_seed=42 + i,  # Seed diferente para cada teste\n",
    "            debug=True\n",
    "        )\n",
    "        \n",
    "        if result['success']:\n",
    "            test_results.append(result)\n",
    "            display_generation_result(result)\n",
    "        else:\n",
    "            print(f\"❌ Teste {i} falhou: {result.get('error', 'Erro desconhecido')}\")\n",
    "            break\n",
    "        \n",
    "        # Limpeza de memória entre testes\n",
    "        if device.type == \"cuda\":\n",
    "            torch.cuda.empty_cache()\n",
    "    \n",
    "    # Resumo dos testes\n",
    "    print(f\"\\n📊 RESUMO DOS TESTES:\")\n",
    "    print(f\"✅ Sucessos: {len(test_results)}/{len(test_prompts)}\")\n",
    "    \n",
    "    if len(test_results) == len(test_prompts):\n",
    "        print(\"🎉 Todos os testes passaram - sistema funcionando!\")\n",
    "    else:\n",
    "        print(\"⚠️ Alguns testes falharam - verifique os erros acima\")\n",
    "        \n",
    "else:\n",
    "    print(\"❌ Pipeline não está pronto\")\n",
    "    print(\"💡 Possíveis soluções:\")\n",
    "    print(\"  • Re-executar células de configuração\")\n",
    "    print(\"  • Verificar se há GPU/CUDA disponível\")\n",
    "    print(\"  • Conferir se todas as bibliotecas foram instaladas\")\n",
    "    print(\"  • Restart runtime se necessário\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pós-processamento Estilo GrassClover\n",
    "Ajustes para deixar as imagens mais próximas do estilo visual do GrassClover Dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_with_grassclover_reference(synthetic_results, reference_analysis=None):\n",
    "    \"\"\"\n",
    "    Compara imagens sintéticas com referências do GrassClover original\n",
    "    \"\"\"\n",
    "    if not synthetic_results:\n",
    "        print(\"❌ Nenhum resultado sintético para comparar\")\n",
    "        return\n",
    "        \n",
    "    if not reference_analysis or not GRASSCLOVER_REFERENCE_AVAILABLE:\n",
    "        print(\"⚠️ Dataset GrassClover original não disponível - mostrando apenas sintéticas\")\n",
    "        \n",
    "        # Mostrar apenas as imagens sintéticas em grid\n",
    "        num_show = min(4, len(synthetic_results))\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(12, 12))\n",
    "        fig.suptitle('🌾 Imagens Sintéticas - Estilo GrassClover Brasileiro', \n",
    "                    fontsize=16, fontweight='bold')\n",
    "        \n",
    "        axes = axes.flatten()\n",
    "        \n",
    "        for i in range(num_show):\n",
    "            if i < len(synthetic_results):\n",
    "                result = synthetic_results[i]\n",
    "                image = result.get('processed_image', result['image'])\n",
    "                axes[i].imshow(image)\n",
    "                axes[i].set_title(f\"{result['metadata']['description']}\\nSeed: {result['metadata']['seed']}\")\n",
    "                axes[i].axis('off')\n",
    "            else:\n",
    "                axes[i].axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        return\n",
    "    \n",
    "    # Comparação lado a lado com dataset original\n",
    "    try:\n",
    "        num_comparisons = min(3, len(synthetic_results), len(reference_analysis['sample_files']))\n",
    "        \n",
    "        fig, axes = plt.subplots(num_comparisons, 2, figsize=(12, 4*num_comparisons))\n",
    "        fig.suptitle('🆚 Comparação: GrassClover Original vs Sintético Brasileiro', \n",
    "                    fontsize=16, fontweight='bold')\n",
    "        \n",
    "        if num_comparisons == 1:\n",
    "            axes = axes.reshape(1, -1)\n",
    "        \n",
    "        for i in range(num_comparisons):\n",
    "            # Imagem original do GrassClover\n",
    "            try:\n",
    "                original_path = reference_analysis['sample_files'][i]\n",
    "                original_img = Image.open(original_path)\n",
    "                axes[i, 0].imshow(original_img)\n",
    "                axes[i, 0].set_title(f\"Original GrassClover\\n{os.path.basename(original_path)}\", fontsize=12)\n",
    "                axes[i, 0].axis('off')\n",
    "            except Exception as e:\n",
    "                print(f\"⚠️ Erro ao carregar original {i}: {e}\")\n",
    "                axes[i, 0].text(0.5, 0.5, f'Erro ao\\ncarregar original', \n",
    "                               ha='center', va='center', transform=axes[i, 0].transAxes)\n",
    "                axes[i, 0].axis('off')\n",
    "            \n",
    "            # Imagem sintética correspondente\n",
    "            if i < len(synthetic_results):\n",
    "                synthetic_result = synthetic_results[i]\n",
    "                synthetic_img = synthetic_result.get('processed_image', synthetic_result['image'])\n",
    "                axes[i, 1].imshow(synthetic_img)\n",
    "                axes[i, 1].set_title(f\"Sintético Brasileiro\\n{synthetic_result['metadata']['description']}\", fontsize=12)\n",
    "                axes[i, 1].axis('off')\n",
    "            else:\n",
    "                axes[i, 1].axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Erro na comparação: {e}\")\n",
    "        \n",
    "        # Fallback para mostrar apenas sintéticas\n",
    "        num_show = min(4, len(synthetic_results))\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(12, 12))\n",
    "        fig.suptitle('🌾 Imagens Sintéticas Geradas', fontsize=16, fontweight='bold')\n",
    "        axes = axes.flatten()\n",
    "        \n",
    "        for i in range(4):\n",
    "            if i < len(synthetic_results):\n",
    "                result = synthetic_results[i]\n",
    "                image = result.get('processed_image', result['image'])\n",
    "                axes[i].imshow(image)\n",
    "                axes[i].set_title(f\"{result['metadata']['description']}\")\n",
    "                axes[i].axis('off')\n",
    "            else:\n",
    "                axes[i].axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# Executar teste com pós-processamento se o pipeline estiver pronto\n",
    "if PIPELINE_READY:\n",
    "    print(\"🎨 Testando geração com pós-processamento...\")\n",
    "    \n",
    "    calibrated_test_prompts = [\"grassclover_exact_style\", \"grassclover_dense_flowers\", \"grassclover_fine_texture\"]\n",
    "    calibrated_results = []\n",
    "    \n",
    "    for i, prompt_key in enumerate(calibrated_test_prompts):\n",
    "        print(f\"⏳ Gerando {prompt_key}...\")\n",
    "        \n",
    "        result = generate_grassclover_image(\n",
    "            prompt_key=prompt_key,\n",
    "            custom_seed=100 + i,  # Seeds diferentes\n",
    "            debug=False  # Menos verbose\n",
    "        )\n",
    "        \n",
    "        if result and result['success']:\n",
    "            # Aplicar pós-processamento (função será definida na próxima célula)\n",
    "            try:\n",
    "                processed = grassclover_postprocess(result['image'], intensity=1.0, debug=False)\n",
    "                result['processed_image'] = processed\n",
    "                result['metadata']['postprocessed'] = True\n",
    "            except:\n",
    "                print(\"⚠️ Pós-processamento não disponível ainda\")\n",
    "                \n",
    "            calibrated_results.append(result)\n",
    "            print(\"✅ Sucesso!\")\n",
    "        else:\n",
    "            print(f\"❌ Falhou: {result.get('error', 'Erro desconhecido')}\")\n",
    "        \n",
    "        # Limpeza de memória\n",
    "        if dev_type == \"gpu\":\n",
    "            torch.cuda.empty_cache()\n",
    "    \n",
    "    # Mostrar comparação (mesmo sem dataset original)\n",
    "    compare_with_grassclover_reference(calibrated_results, grassclover_analysis if 'grassclover_analysis' in locals() else None)\n",
    "    \n",
    "else:\n",
    "    print(\"❌ Pipeline não está pronto - pule esta célula por enquanto\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🆚 Comparação com GrassClover Original\n",
    "Vamos comparar nossas imagens sintéticas com as referências do GrassClover para avaliar a qualidade da reprodução do estilo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grassclover_postprocess(image, intensity=1.0, debug=False):\n",
    "    \"\"\"\n",
    "    Aplica pós-processamento para aproximar do estilo GrassClover\n",
    "    Args:\n",
    "        image: PIL Image\n",
    "        intensity: Intensidade dos ajustes (0.0-2.0)\n",
    "        debug: Mostrar etapas do processamento\n",
    "    Returns:\n",
    "        PIL Image processada\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if debug:\n",
    "            print(f\"🎨 Aplicando pós-processamento (intensidade: {intensity})\")\n",
    "        \n",
    "        processed = image.copy()\n",
    "        \n",
    "        # 1. Ajuste de contraste\n",
    "        contrast_factor = 1.0 + (0.3 * intensity)\n",
    "        enhancer = ImageEnhance.Contrast(processed)\n",
    "        processed = enhancer.enhance(contrast_factor)\n",
    "        if debug:\n",
    "            print(f\"  ✅ Contraste ajustado ({contrast_factor:.2f}x)\")\n",
    "        \n",
    "        # 2. Saturação de cores (realce de verdes)\n",
    "        saturation_factor = 1.0 + (0.2 * intensity)\n",
    "        enhancer = ImageEnhance.Color(processed)\n",
    "        processed = enhancer.enhance(saturation_factor)\n",
    "        if debug:\n",
    "            print(f\"  ✅ Saturação ajustada ({saturation_factor:.2f}x)\")\n",
    "        \n",
    "        # 3. Nitidez sutil\n",
    "        if intensity > 0.5:\n",
    "            sharpness_factor = 1.0 + (0.1 * intensity)\n",
    "            enhancer = ImageEnhance.Sharpness(processed)\n",
    "            processed = enhancer.enhance(sharpness_factor)\n",
    "            if debug:\n",
    "                print(f\"  ✅ Nitidez aplicada ({sharpness_factor:.2f}x)\")\n",
    "        \n",
    "        # 4. Suavização muito leve (simular textura natural)\n",
    "        if intensity > 0.3:\n",
    "            blur_radius = 0.3 * intensity\n",
    "            processed = processed.filter(ImageFilter.GaussianBlur(radius=blur_radius))\n",
    "            if debug:\n",
    "                print(f\"  ✅ Suavização aplicada (radius: {blur_radius:.2f})\")\n",
    "        \n",
    "        # 5. Pequeno ajuste de brilho aleatório\n",
    "        brightness_factor = 1.0 + (0.05 * intensity * (np.random.random() - 0.5))\n",
    "        enhancer = ImageEnhance.Brightness(processed)\n",
    "        processed = enhancer.enhance(brightness_factor)\n",
    "        if debug:\n",
    "            print(f\"  ✅ Brilho ajustado ({brightness_factor:.3f}x)\")\n",
    "        \n",
    "        return processed\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"💥 Erro no pós-processamento: {e}\")\n",
    "        print(f\"Error: {type(e).__name__}: {e}\")\n",
    "        return image  # Retornar original se falhar\n",
    "\n",
    "def compare_before_after(original, processed, title=\"Comparação\"):\n",
    "    \"\"\"\n",
    "    Exibe comparação lado a lado\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 7))\n",
    "    \n",
    "    # Imagem original\n",
    "    axes[0].imshow(original)\n",
    "    axes[0].set_title(\"Original (Stable Diffusion)\", fontsize=12)\n",
    "    axes[0].axis('off')\n",
    "    \n",
    "    # Imagem processada\n",
    "    axes[1].imshow(processed)\n",
    "    axes[1].set_title(\"Processado (Estilo GrassClover)\", fontsize=12)\n",
    "    axes[1].axis('off')\n",
    "    \n",
    "    fig.suptitle(title, fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print(\"🎨 Funções de pós-processamento configuradas!\")\n",
    "print(\"💡 Use: grassclover_postprocess(image, intensity=1.2)\")\n",
    "print(\"💡 Use: compare_before_after(original, processed)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Teste do pós-processamento com uma imagem de exemplo\n",
    "if PIPELINE_READY and 'test_results' in locals() and test_results:\n",
    "    print(\"🧪 Testando pós-processamento...\")\n",
    "    \n",
    "    # Usar primeira imagem dos testes anteriores\n",
    "    test_image_data = test_results[0]\n",
    "    original_image = test_image_data['image']\n",
    "    \n",
    "    # Aplicar pós-processamento\n",
    "    processed_image = grassclover_postprocess(\n",
    "        image=original_image,\n",
    "        intensity=1.2,  # Intensidade média-alta\n",
    "        debug=True\n",
    "    )\n",
    "    \n",
    "    # Mostrar comparação\n",
    "    compare_before_after(\n",
    "        original=original_image,\n",
    "        processed=processed_image,\n",
    "        title=f\"Pós-processamento: {test_image_data['metadata']['description']}\"\n",
    "    )\n",
    "    \n",
    "    print(\"✅ Teste de pós-processamento concluído!\")\n",
    "    \n",
    "else:\n",
    "    print(\"⚠️ Teste de pós-processamento pulado\")\n",
    "    print(\"💡 Motivos possíveis:\")\n",
    "    print(\"  • Pipeline não está pronto\")\n",
    "    print(\"  • Nenhum resultado de teste disponível\")\n",
    "    print(\"  • Execute as células anteriores primeiro\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Geração em Lote com Seeds Diferentes\n",
    "Gera múltiplas variações de pastagens para criar um dataset diversificado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def generate_grassclover_batch(num_images=6, apply_postprocess=True, debug=True):\n    \"\"\"\n    Gera lote de imagens variadas estilo GrassClover - OTIMIZADO para SD3.5 Medium\n    Args:\n        num_images: Número total de imagens\n        apply_postprocess: Aplicar pós-processamento\n        debug: Debugging detalhado\n    Returns:\n        Lista de resultados\n    \"\"\"\n    if not PIPELINE_READY:\n        print(\"❌ Pipeline não está pronto\")\n        return []\n    \n    prompt_keys = list(GRASSCLOVER_PROMPTS.keys())\n    batch_results = []\n    \n    print(f\"🚀 Gerando lote de {num_images} imagens com SD3.5 MEDIUM...\")\n    print(\"⚡ Velocidade otimizada: ~2x mais rápido que Large!\")\n    \n    # Estimativa de tempo para SD3.5 Medium\n    estimated_time_per_image = 15 if torch.cuda.is_available() else 45  # segundos\n    total_estimated = (estimated_time_per_image * num_images) / 60  # minutos\n    print(f\"⏱️ Tempo estimado: ~{total_estimated:.1f} minutos total\")\n    \n    for i in range(num_images):\n        prompt_key = prompt_keys[i % len(prompt_keys)]\n        seed = 42 + i * 100 + np.random.randint(0, 50)\n        \n        if debug:\n            print(f\"\\n📸 Imagem {i+1}/{num_images}: {GRASSCLOVER_PROMPTS[prompt_key]['description']}\")\n            print(f\"🌱 Seed: {seed}\")\n        \n        try:\n            result = generate_grassclover_image(\n                prompt_key=prompt_key,\n                custom_seed=seed,\n                debug=debug\n            )\n            \n            if result['success']:\n                # Aplicar pós-processamento se solicitado\n                if apply_postprocess:\n                    processed_image = grassclover_postprocess(\n                        image=result['image'],\n                        intensity=np.random.uniform(0.8, 1.4),  # Variação aleatória\n                        debug=False\n                    )\n                    result['processed_image'] = processed_image\n                    result['metadata']['postprocessed'] = True\n                    if debug:\n                        print(\"  🎨 Pós-processamento aplicado\")\n                \n                result['metadata']['batch_index'] = i\n                result['metadata']['total_batch'] = num_images\n                result['metadata']['model_version'] = \"SD3.5-Medium\"\n                batch_results.append(result)\n                \n                if debug:\n                    print(\"  ✅ Sucesso!\")\n            else:\n                print(f\"  ❌ Falhou: {result.get('error', 'Erro desconhecido')}\")\n                \n        except Exception as e:\n            print(f\"💥 Erro na imagem {i+1}: {e}\")\n            if debug:\n                print(f\"  Error type: {type(e).__name__}\")\n        \n        # Limpeza de memória mais agressiva para Medium (pode gerar mais imagens)\n        if device.type == \"cuda\":\n            torch.cuda.empty_cache()\n            if debug and i % 2 == 0:  # A cada 2 imagens, mostrar status de memória\n                allocated = torch.cuda.memory_allocated() / (1024**3)\n                print(f\"  💾 GPU Memory: {allocated:.2f}GB\")\n    \n    print(f\"\\n📊 Lote SD3.5 Medium concluído: {len(batch_results)}/{num_images} imagens geradas\")\n    \n    if len(batch_results) > 0:\n        avg_time = total_estimated / len(batch_results) if len(batch_results) > 0 else 0\n        print(f\"⚡ Performance: ~{avg_time:.1f} min/imagem (Medium é muito mais rápido!)\")\n    \n    return batch_results\n\ndef display_batch_results(batch_results, max_display=6):\n    \"\"\"\n    Exibe resultados do lote em grid - otimizado para SD3.5 Medium\n    \"\"\"\n    if not batch_results:\n        print(\"❌ Nenhum resultado para exibir\")\n        return\n    \n    results_to_show = batch_results[:max_display]\n    n_images = len(results_to_show)\n    \n    # Calcular grid\n    cols = min(3, n_images)\n    rows = (n_images + cols - 1) // cols\n    \n    fig, axes = plt.subplots(rows, cols, figsize=(5*cols, 5*rows))\n    \n    # Ajustar axes para casos especiais\n    if rows == 1 and cols == 1:\n        axes = [axes]\n    elif rows == 1:\n        axes = axes.reshape(1, -1)\n    elif cols == 1:\n        axes = axes.reshape(-1, 1)\n    \n    # Mostrar imagens\n    for i, result in enumerate(results_to_show):\n        row = i // cols\n        col = i % cols\n        \n        # Usar imagem processada se disponível\n        image = result.get('processed_image', result['image'])\n        \n        if rows == 1 and cols == 1:\n            ax = axes[0]\n        elif rows == 1:\n            ax = axes[col]\n        elif cols == 1:\n            ax = axes[row]\n        else:\n            ax = axes[row, col]\n        \n        ax.imshow(image)\n        ax.axis('off')\n        \n        # Título da imagem\n        metadata = result['metadata']\n        title = f\"{metadata['description']}\\nSeed: {metadata['seed']} | SD3.5-Medium\"\n        ax.set_title(title, fontsize=10)\n    \n    # Ocultar eixos não utilizados\n    total_subplots = rows * cols\n    for i in range(n_images, total_subplots):\n        row = i // cols\n        col = i % cols\n        \n        if rows == 1 and cols > 1:\n            axes[col].axis('off')\n        elif cols == 1 and rows > 1:\n            axes[row].axis('off')\n        elif rows > 1 and cols > 1:\n            axes[row, col].axis('off')\n    \n    plt.tight_layout()\n    plt.suptitle(f\"🌾 Dataset GrassClover Brasileiro - SD3.5 Medium - {n_images} Imagens\", \n                fontsize=16, fontweight='bold', y=0.98)\n    plt.show()\n    \n    # Estatísticas\n    if batch_results:\n        print(f\"\\n📊 Estatísticas do lote SD3.5 Medium:\")\n        print(f\"  • Total de imagens: {len(batch_results)}\")\n        print(f\"  • Modelo usado: SD3.5 Medium (otimizado)\")\n        print(f\"  • Resolução: 1024x1024\")\n        print(f\"  • Steps: 20 (vs 28 Large)\")\n        \n        # Contar tipos de prompt\n        type_counts = {}\n        for result in batch_results:\n            prompt_key = result['metadata']['prompt_key']\n            description = result['metadata']['description']\n            type_counts[description] = type_counts.get(description, 0) + 1\n        \n        print(f\"  • Tipos gerados:\")\n        for description, count in type_counts.items():\n            print(f\"    - {description}: {count}\")\n            \n        print(f\"\\n⚡ VANTAGENS SD3.5 Medium utilizadas:\")\n        print(f\"  • ~50% menos uso de VRAM\")\n        print(f\"  • ~2x mais rápido que Large\")\n        print(f\"  • Mesma qualidade visual\")\n        print(f\"  • Perfeito para iteração rápida\")\n\nprint(\"📦 Funções de geração em lote otimizadas para SD3.5 Medium!\")\nprint(\"💡 Use: generate_grassclover_batch(num_images=6)\")\nprint(\"💡 Use: display_batch_results(results)\")\nprint(\"⚡ Medium = velocidade + qualidade no Colab!\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Executar geração em lote se o pipeline estiver pronto\n",
    "if PIPELINE_READY:\n",
    "    print(\"🚀 Iniciando geração em lote...\")\n",
    "    \n",
    "    # Configurações do lote\n",
    "    BATCH_SIZE = 6  # Número total de imagens\n",
    "    APPLY_POSTPROCESS = True\n",
    "    \n",
    "    batch_results = generate_grassclover_batch(\n",
    "        num_images=BATCH_SIZE,\n",
    "        apply_postprocess=APPLY_POSTPROCESS,\n",
    "        debug=True\n",
    "    )\n",
    "    \n",
    "    if batch_results:\n",
    "        print(f\"\\n✅ Lote gerado com sucesso!\")\n",
    "        \n",
    "        # Estatísticas por tipo\n",
    "        type_counts = {}\n",
    "        for result in batch_results:\n",
    "            prompt_key = result['metadata']['prompt_key']\n",
    "            type_counts[prompt_key] = type_counts.get(prompt_key, 0) + 1\n",
    "        \n",
    "        print(f\"\\n📋 Distribuição por tipo:\")\n",
    "        for prompt_key, count in type_counts.items():\n",
    "            description = GRASSCLOVER_PROMPTS[prompt_key]['description']\n",
    "            print(f\"  • {description}: {count} imagens\")\n",
    "        \n",
    "        # Exibir grid de resultados\n",
    "        display_batch_results(batch_results)\n",
    "        \n",
    "        print(f\"\\n🎉 Dataset brasileiro estilo GrassClover gerado!\")\n",
    "        print(f\"💾 {len(batch_results)} imagens prontas para análise e salvamento\")\n",
    "        \n",
    "    else:\n",
    "        print(\"❌ Nenhuma imagem foi gerada no lote\")\n",
    "        print(\"💡 Possíveis causas:\")\n",
    "        print(\"  • Problemas de memória\")\n",
    "        print(\"  • Erros no pipeline\")\n",
    "        print(\"  • Configurações incorretas\")\n",
    "        \n",
    "else:\n",
    "    print(\"❌ Pipeline não está pronto\")\n",
    "    print(\"💡 Execute as células anteriores para configurar o sistema\")\n",
    "    print(\"⚠️ Esta célula será pulada por enquanto\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Salvamento das Imagens\n",
    "Salva as imagens geradas com metadados organizados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import os\nimport json\nfrom datetime import datetime\n\ndef save_grassclover_batch(batch_results, output_dir=\"grassclover_generated\", save_metadata=True):\n    \"\"\"\n    Salva lote de imagens com organização e metadados - SD3.5 Medium optimized\n    Args:\n        batch_results: Lista de resultados da geração\n        output_dir: Diretório de saída\n        save_metadata: Salvar arquivos JSON com metadados\n    Returns:\n        dict com estatísticas de salvamento\n    \"\"\"\n    if not batch_results:\n        print(\"❌ Nenhum resultado para salvar\")\n        return {'success': False, 'saved_count': 0}\n    \n    try:\n        print(f\"💾 Salvando {len(batch_results)} imagens SD3.5 Medium em {output_dir}...\")\n        \n        # Criar diretórios\n        os.makedirs(output_dir, exist_ok=True)\n        images_dir = os.path.join(output_dir, \"images\")\n        metadata_dir = os.path.join(output_dir, \"metadata\")\n        \n        os.makedirs(images_dir, exist_ok=True)\n        if save_metadata:\n            os.makedirs(metadata_dir, exist_ok=True)\n            print(f\"📁 Diretórios criados: images/ e metadata/\")\n        else:\n            print(f\"📁 Diretório criado: images/\")\n        \n        # Salvar index geral se metadata estiver habilitado\n        if save_metadata:\n            print(\"📝 Preparando índice do dataset SD3.5 Medium...\")\n        \n        saved_count = 0\n        saved_files = []\n        \n        for i, result in enumerate(batch_results):\n            try:\n                metadata = result['metadata']\n                prompt_key = metadata['prompt_key']\n                seed = metadata['seed']\n                \n                # Nome base dos arquivos - incluindo versão do modelo\n                filename_base = f\"grassclover_sd35medium_{prompt_key}_{seed:06d}\"\n                \n                # Salvar imagem original\n                original_path = os.path.join(images_dir, f\"{filename_base}_original.png\")\n                result['image'].save(original_path, 'PNG', optimize=True)  # Otimizar para economizar espaço\n                files_saved = [original_path]\n                print(f\"  💾 Salvou original: {os.path.basename(original_path)}\")\n                \n                # Salvar imagem processada se existir\n                if 'processed_image' in result:\n                    processed_path = os.path.join(images_dir, f\"{filename_base}_processed.png\")\n                    result['processed_image'].save(processed_path, 'PNG', optimize=True)\n                    files_saved.append(processed_path)\n                    print(f\"  🎨 Salvou processada: {os.path.basename(processed_path)}\")\n                \n                # Salvar metadados se solicitado\n                if save_metadata:\n                    metadata_path = os.path.join(metadata_dir, f\"{filename_base}.json\")\n                    \n                    # Preparar JSON metadata com informações do SD3.5 Medium\n                    json_metadata = metadata.copy()\n                    json_metadata['files_saved'] = files_saved\n                    json_metadata['save_timestamp'] = datetime.now().isoformat()\n                    json_metadata['model_family'] = 'SD3.5'\n                    json_metadata['model_size'] = 'Medium'\n                    json_metadata['optimization'] = 'Colab-optimized'\n                    \n                    with open(metadata_path, 'w', encoding='utf-8') as f:\n                        json.dump(json_metadata, f, indent=2, ensure_ascii=False)\n                    \n                    files_saved.append(metadata_path)\n                    print(f\"  📊 Salvou metadata: {os.path.basename(metadata_path)}\")\n                \n                saved_files.extend(files_saved)\n                saved_count += 1\n                \n            except Exception as e:\n                print(f\"❌ Erro ao salvar imagem {i+1}: {e}\")\n                continue\n        \n        # Criar índice geral do dataset\n        if save_metadata:\n            print(f\"\\n📋 Criando índice do dataset SD3.5 Medium...\")\n            \n            index_data = {\n                'dataset_name': 'GrassClover Brazilian Synthetic - SD3.5 Medium',\n                'model_info': {\n                    'name': 'stable-diffusion-3.5-medium',\n                    'family': 'SD3.5',\n                    'size': 'Medium',\n                    'optimization': 'Colab-optimized',\n                    'advantages': [\n                        '~50% smaller than Large',\n                        '~2x faster generation',\n                        'Same quality output',\n                        'Ideal for rapid prototyping'\n                    ]\n                },\n                'generation_date': datetime.now().isoformat(),\n                'total_images': len(batch_results),\n                'saved_images': saved_count,\n                'device': str(device) if 'device' in globals() else 'unknown',\n                'prompt_types': list(set(r['metadata']['prompt_key'] for r in batch_results)),\n                'files': saved_files,\n                'generation_params': batch_results[0]['metadata']['generation_params'] if batch_results else {},\n                'performance_notes': {\n                    'steps_used': 20,\n                    'resolution': '1024x1024',\n                    'estimated_time_per_image': '15-45 seconds',\n                    'memory_efficient': True\n                }\n            }\n            \n            index_path = os.path.join(output_dir, \"dataset_index.json\")\n            with open(index_path, 'w', encoding='utf-8') as f:\n                json.dump(index_data, f, indent=2, ensure_ascii=False)\n            \n            print(f\"✅ Índice SD3.5 Medium criado: {os.path.basename(index_path)}\")\n        \n        # Resultado final\n        result_data = {\n            'success': True,\n            'saved_count': saved_count,\n            'total_files': len(saved_files),\n            'output_dir': os.path.abspath(output_dir),\n            'files': saved_files,\n            'model_used': 'SD3.5-Medium'\n        }\n        \n        print(f\"\\n🎉 Salvamento SD3.5 Medium concluído!\")\n        print(f\"  ✅ Imagens salvas: {saved_count}\")\n        print(f\"  📁 Arquivos totais: {len(saved_files)}\")\n        print(f\"  📂 Localização: {result_data['output_dir']}\")\n        print(f\"  ⚡ Modelo: SD3.5 Medium (otimizado para Colab)\")\n        \n        return result_data\n        \n    except Exception as e:\n        print(f\"💥 Erro no salvamento: {e}\")\n        print(f\"Error: {type(e).__name__}: {e}\")\n        return {\n            'success': False,\n            'saved_count': 0,\n            'error': str(e)\n        }\n\nprint(\"💾 Função de salvamento otimizada para SD3.5 Medium!\")\nprint(\"💡 Use: save_grassclover_batch(batch_results, 'meu_dataset')\")\nprint(\"⚡ Metadados incluem informações sobre otimizações Medium!\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvar resultados do lote se existir\n",
    "if 'batch_results' in locals() and batch_results:\n",
    "    print(\"💾 Salvando dataset gerado...\")\n",
    "    \n",
    "    # Configurações de salvamento\n",
    "    OUTPUT_DIR = \"grassclover_synthetic_dataset\"\n",
    "    SAVE_METADATA = True\n",
    "    \n",
    "    save_result = save_grassclover_batch(\n",
    "        batch_results=batch_results,\n",
    "        output_dir=OUTPUT_DIR,\n",
    "        save_metadata=SAVE_METADATA\n",
    "    )\n",
    "    \n",
    "    if save_result['success']:\n",
    "        print(f\"\\n🎉 Dataset salvo com sucesso!\")\n",
    "        print(f\"\\n📊 Resumo:\")\n",
    "        print(f\"  • Imagens salvas: {save_result['saved_count']}\")\n",
    "        print(f\"  • Arquivos totais: {save_result['total_files']}\")\n",
    "        \n",
    "        # Mostrar estrutura do diretório\n",
    "        if os.path.exists(save_result['output_dir']):\n",
    "            print(f\"\\n📁 Estrutura do dataset:\")\n",
    "            for root, dirs, files in os.walk(save_result['output_dir']):\n",
    "                level = root.replace(save_result['output_dir'], '').count(os.sep)\n",
    "                indent = ' ' * 2 * level\n",
    "                folder_name = os.path.basename(root) if root != save_result['output_dir'] else OUTPUT_DIR\n",
    "                print(f\"{indent}{folder_name}/\")\n",
    "                \n",
    "                subindent = ' ' * 2 * (level + 1)\n",
    "                # Mostrar só os primeiros 3 arquivos por diretório\n",
    "                for file in files[:3]:\n",
    "                    print(f\"{subindent}{file}\")\n",
    "                if len(files) > 3:\n",
    "                    print(f\"{subindent}... e mais {len(files)-3} arquivos\")\n",
    "        \n",
    "        print(f\"\\n💡 Para usar o dataset:\")\n",
    "        print(f\"  • Imagens: {os.path.join(save_result['output_dir'], 'images')}\")\n",
    "        print(f\"  • Metadados: {os.path.join(save_result['output_dir'], 'metadata')}\")\n",
    "        print(f\"  • Índice: {os.path.join(save_result['output_dir'], 'dataset_index.json')}\")\n",
    "        \n",
    "    else:\n",
    "        print(f\"❌ Erro ao salvar dataset:\")\n",
    "        print(f\"  Error: {save_result.get('error', 'Erro desconhecido')}\")\n",
    "        \n",
    "else:\n",
    "    print(\"⚠️ Salvamento pulado\")\n",
    "    print(\"💡 Motivos possíveis:\")\n",
    "    print(\"  • Nenhum lote foi gerado ainda\")\n",
    "    print(\"  • Variável 'batch_results' não existe\")\n",
    "    print(\"  • Execute as células anteriores primeiro\")\n",
    "    print(\"\\n🔄 Para gerar e salvar:\")\n",
    "    print(\"  1. Execute a célula de geração em lote\")\n",
    "    print(\"  2. Execute esta célula novamente\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📊 Relatório Final e Estatísticas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Copie a seção \"DEBUG COPY/PASTE\"** que aparece nos erros\n",
    "2. **Cole aqui nos comentários** ou no chat para análise\n",
    "3. **Inclua informações do sistema** (GPU, memória, etc.)\n",
    "- **Detecção automática** de TPU/GPU/CPU\n",
    "- **Configuração otimizada** para cada tipo de hardware\n",
    "- **Instruções claras** para configuração do runtime\n",
    "- **Bypass automático** de problemas de autenticação\n",
    "- **Configuração de ambiente** para evitar warnings\n",
    "- **Downloads funcionam normalmente** mesmo com warnings\n",
    "#### **✅ Dtype Configuration (RESOLVIDO)**\n",
    "- **float16 para GPU** (performance otimizada)\n",
    "- **float32 para TPU/CPU** (compatibilidade garantida)\n",
    "- **Configuração automática** baseada no hardware\n",
    "### 🎯 **Configuração Recomendada para Colab:**\n",
    "- **Runtime**: GPU (Tesla T4 ou superior)\n",
    "- **Reasoning**: Stable Diffusion funciona melhor em GPU que TPU\n",
    "- **Fallback**: TPU funciona, mas GPU é mais rápido para este caso\n",
    "- **GENERATION_PARAMS**: Modifique `num_inference_steps` (15-50) para balancear qualidade/velocidade\n",
    "- **BATCH_SIZE**: Reduza se houver problemas de memória\n",
    "- **Seeds**: Mude para explorar diferentes variações\n",
    "- **Prompts**: Ajuste para obter estilos visuais específicos\n",
    "1. **Upload das imagens** na seção de arquivos do Colab\n",
    "2. **Modifique os prompts** baseado nas características visuais\n",
    "3. **Ajuste pós-processamento** para aproximar do estilo original\n",
    "- **Cobertura densa**: Pastagens devem ter ≥80% de cobertura vegetal\n",
    "- **Perspectiva top-down**: Vista aérea consistente\n",
    "- **Textura realística**: Detalhes de folhas e solo visíveis\n",
    "- **Diversidade**: Variação entre as imagens geradas\n",
    "- **GPU (Tesla T4)**: ~30-45s por imagem (recomendado)\n",
    "- **GPU (V100/A100)**: ~15-25s por imagem (ótimo)\n",
    "- **TPU**: ~45-60s por imagem (funciona)\n",
    "- **CPU**: ~5-10min por imagem (muito lento, não recomendado)\n",
    "---\n",
    "**🌾 Dataset GrassClover Brasileiro - Gerado com Stable Diffusion**  \n",
    "Baseado na metodologia de Skovsen et al. (CVPR 2019) adaptada para gramíneas tropicais.\n",
    "**📋 Problemas Comuns Resolvidos**: TPU detection, HF authentication, dtype optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 💡 Instruções para Uso e Debugging\n",
    "### 🚨 **Em caso de erro:**\n",
    "1. **Copie a seção \"DEBUG COPY/PASTE\"** que aparece nos erros\n",
    "2. **Cole aqui nos comentários** ou no chat para análise\n",
    "3. **Inclua informações do sistema** (GPU, memória, etc.)\n",
    "### 🔧 **Ajustes possíveis:**\n",
    "- **GENERATION_PARAMS**: Modifique `num_inference_steps` (15-50) para balancear qualidade/velocidade\n",
    "- **BATCH_SIZE**: Reduza se houver problemas de memória\n",
    "- **Seeds**: Mude para explorar diferentes variações\n",
    "- **Prompts**: Ajuste para obter estilos visuais específicos\n",
    "### 📸 **Para adicionar referências GrassClover:**\n",
    "1. **Upload das imagens** na seção de arquivos do Colab\n",
    "2. **Modifique os prompts** baseado nas características visuais\n",
    "3. **Ajuste pós-processamento** para aproximar do estilo original\n",
    "### **Métricas de qualidade:**\n",
    "- **Cobertura densa**: Pastagens devem ter ≥80% de cobertura vegetal\n",
    "- **Perspectiva top-down**: Vista aérea consistente\n",
    "- **Textura realística**: Detalhes de folhas e solo visíveis\n",
    "- **Diversidade**: Variação entre as imagens geradas\n",
    "**🌾 Dataset GrassClover Brasileiro - Gerado com Stable Diffusion**  \n",
    "Baseado na metodologia de Skovsen et al. (CVPR 2019) adaptada para gramíneas tropicais."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}