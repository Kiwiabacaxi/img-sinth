{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üåæ GrassClover-Style Generation with Stable Diffusion\n",
    "\n",
    "Este notebook implementa gera√ß√£o de imagens sint√©ticas de pastagens brasileiras usando **Stable Diffusion**, seguindo o estilo visual do **GrassClover Dataset** (Skovsen et al., CVPR 2019).\n",
    "\n",
    "## üéØ Objetivos:\n",
    "- Gerar imagens **top-down** de pastagens com Stable Diffusion\n",
    "- Adaptar para **gram√≠neas brasileiras** (Brachiaria, Panicum, Cynodon)\n",
    "- Seguir **metodologia GrassClover** (densidade, perspectiva, resolu√ß√£o)\n",
    "- **Ultra-compat√≠vel** com Google Colab (debugging extensivo)\n",
    "\n",
    "## üìö Refer√™ncia:\n",
    "- **Paper**: Skovsen et al. \"The GrassClover Image Dataset for Semantic and Hierarchical Species Understanding in Agriculture\" (CVPR Workshops, 2019)\n",
    "- **Adapta√ß√£o**: Esp√©cies temperadas ‚Üí Tropicais brasileiras\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üöÄ Setup Ultra-Compat√≠vel para Colab\n",
    "\n",
    "**IMPORTANTE**: Este notebook foi desenvolvido para m√°xima compatibilidade com Google Colab Free/Pro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîç VERIFICA√á√ÉO INICIAL DO AMBIENTE\n",
    "print(\"=\" * 60)\n",
    "print(\"üåæ GRASSCLOVER STABLE DIFFUSION GENERATOR\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "import sys\n",
    "import platform\n",
    "from datetime import datetime\n",
    "\n",
    "print(f\"üìÖ Timestamp: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"üêç Python: {sys.version.split()[0]}\")\n",
    "print(f\"üíª Platform: {platform.system()} {platform.release()}\")\n",
    "print(f\"üìç Working Directory: {sys.path[0] if sys.path else 'Unknown'}\")\n",
    "\n",
    "# Detectar se estamos no Colab\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "    print(\"üî• Ambiente: Google Colab (DETECTADO)\")\n",
    "except ImportError:\n",
    "    IN_COLAB = False\n",
    "    print(\"üíª Ambiente: Local/Jupyter (DETECTADO)\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üß† VERIFICA√á√ÉO AVAN√áADA DE HARDWARE (GPU/TPU/CPU)\n",
    "print(\"üîç Verificando hardware dispon√≠vel...\\n\")\n",
    "\n",
    "# Vari√°veis de estado\n",
    "device = None\n",
    "device_type = \"unknown\"\n",
    "hardware_info = {}\n",
    "\n",
    "# Tentar importar torch primeiro\n",
    "try:\n",
    "    import torch\n",
    "    TORCH_AVAILABLE = True\n",
    "    print(f\"‚úÖ PyTorch: {torch.__version__}\")\n",
    "    hardware_info['pytorch_version'] = torch.__version__\n",
    "except ImportError:\n",
    "    TORCH_AVAILABLE = False\n",
    "    print(\"‚ùå PyTorch n√£o encontrado - ser√° instalado\")\n",
    "\n",
    "if TORCH_AVAILABLE:\n",
    "    # 1. VERIFICAR TPU (prioridade alta no Colab)\n",
    "    try:\n",
    "        import torch_xla\n",
    "        import torch_xla.core.xla_model as xm\n",
    "        \n",
    "        # Detectar TPU\n",
    "        if xm.xrt_world_size() > 1:\n",
    "            device = xm.xla_device()\n",
    "            device_type = \"tpu\"\n",
    "            print(f\"üî• TPU DETECTADO: {device}\")\n",
    "            print(f\"üöÄ TPU cores: {xm.xrt_world_size()}\")\n",
    "            hardware_info.update({\n",
    "                'device_type': 'tpu',\n",
    "                'tpu_cores': xm.xrt_world_size(),\n",
    "                'device': str(device)\n",
    "            })\n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è  TPU configurado mas n√£o dispon√≠vel\")\n",
    "            \n",
    "    except ImportError:\n",
    "        print(\"üìù torch_xla n√£o encontrado (normal se n√£o usar TPU)\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è  Erro ao verificar TPU: {e}\")\n",
    "    \n",
    "    # 2. VERIFICAR CUDA/GPU (se TPU n√£o dispon√≠vel)\n",
    "    if device is None:\n",
    "        cuda_available = torch.cuda.is_available()\n",
    "        print(f\"üî• CUDA dispon√≠vel: {cuda_available}\")\n",
    "        \n",
    "        if cuda_available:\n",
    "            gpu_count = torch.cuda.device_count()\n",
    "            print(f\"üöÄ N√∫mero de GPUs: {gpu_count}\")\n",
    "            \n",
    "            for i in range(gpu_count):\n",
    "                gpu_name = torch.cuda.get_device_name(i)\n",
    "                gpu_memory = torch.cuda.get_device_properties(i).total_memory\n",
    "                gpu_memory_gb = gpu_memory / (1024**3)\n",
    "                print(f\"  GPU {i}: {gpu_name}\")\n",
    "                print(f\"  Mem√≥ria: {gpu_memory_gb:.1f} GB\")\n",
    "            \n",
    "            device = torch.device(\"cuda\")\n",
    "            device_type = \"gpu\"\n",
    "            hardware_info.update({\n",
    "                'device_type': 'gpu',\n",
    "                'gpu_count': gpu_count,\n",
    "                'gpu_name': torch.cuda.get_device_name(0),\n",
    "                'gpu_memory_gb': torch.cuda.get_device_properties(0).total_memory / (1024**3),\n",
    "                'device': str(device)\n",
    "            })\n",
    "            \n",
    "            # Limpeza inicial de mem√≥ria GPU\n",
    "            torch.cuda.empty_cache()\n",
    "            print(\"üßπ Cache GPU limpo\")\n",
    "            \n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è  CUDA n√£o dispon√≠vel\")\n",
    "    \n",
    "    # 3. FALLBACK PARA CPU\n",
    "    if device is None:\n",
    "        device = torch.device(\"cpu\")\n",
    "        device_type = \"cpu\"\n",
    "        hardware_info.update({\n",
    "            'device_type': 'cpu',\n",
    "            'device': str(device)\n",
    "        })\n",
    "        print(\"üíª Usando CPU (fallback)\")\n",
    "\n",
    "    # Status final do hardware\n",
    "    print(f\"\\nüéØ DEVICE CONFIGURADO: {device} ({device_type.upper()})\")\n",
    "    \n",
    "    # Instru√ß√µes espec√≠ficas para problemas\n",
    "    if device_type == \"cpu\" and IN_COLAB:\n",
    "        print(f\"\\nüö® IMPORTANTE: Voc√™ est√° usando CPU no Colab!\")\n",
    "        print(f\"Para ativar acelera√ß√£o de hardware:\")\n",
    "        print(f\"1. Runtime ‚Üí Change runtime type\")\n",
    "        print(f\"2. Hardware accelerator: GPU ou TPU\") \n",
    "        print(f\"3. Save ‚Üí Connect (reconectar)\")\n",
    "        print(f\"4. Re-executar este notebook\")\n",
    "        \n",
    "    elif device_type == \"tpu\":\n",
    "        print(f\"‚úÖ TPU configurado! Otimizado para treinamento paralelo.\")\n",
    "        \n",
    "    elif device_type == \"gpu\":\n",
    "        print(f\"‚úÖ GPU configurado! Otimizado para infer√™ncia r√°pida.\")\n",
    "\n",
    "else:\n",
    "    device = None\n",
    "    device_type = \"none\"\n",
    "    print(\"\\n‚è≥ PyTorch ser√° instalado na pr√≥xima c√©lula\")\n",
    "\n",
    "print(f\"\\nüìä Hardware Info: {hardware_info}\")\n",
    "print(\"\\n\" + \"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üì¶ INSTALA√á√ÉO DE DEPEND√äNCIAS ESSENCIAIS\n",
    "print(\"üì¶ Instalando depend√™ncias essenciais...\\n\")\n",
    "\n",
    "# Lista de pacotes essenciais\n",
    "essential_packages = [\n",
    "    \"torch\",\n",
    "    \"torchvision\", \n",
    "    \"diffusers\",\n",
    "    \"transformers\",\n",
    "    \"accelerate\",\n",
    "    \"pillow\",\n",
    "    \"matplotlib\",\n",
    "    \"numpy\"\n",
    "]\n",
    "\n",
    "# Fun√ß√£o para instalar com debug\n",
    "def install_package(package_name, quiet=True):\n",
    "    \"\"\"Instala pacote com debugging\"\"\"\n",
    "    import subprocess\n",
    "    \n",
    "    print(f\"‚è≥ Instalando {package_name}...\")\n",
    "    \n",
    "    try:\n",
    "        cmd = [\"pip\", \"install\", package_name]\n",
    "        if quiet:\n",
    "            cmd.append(\"--quiet\")\n",
    "        \n",
    "        result = subprocess.run(cmd, capture_output=True, text=True, timeout=300)\n",
    "        \n",
    "        if result.returncode == 0:\n",
    "            print(f\"‚úÖ {package_name} instalado com sucesso\")\n",
    "            return True\n",
    "        else:\n",
    "            print(f\"‚ùå Erro ao instalar {package_name}:\")\n",
    "            print(f\"STDOUT: {result.stdout}\")\n",
    "            print(f\"STDERR: {result.stderr}\")\n",
    "            return False\n",
    "            \n",
    "    except subprocess.TimeoutExpired:\n",
    "        print(f\"‚è∞ Timeout ao instalar {package_name}\")\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        print(f\"üí• Exce√ß√£o ao instalar {package_name}: {e}\")\n",
    "        return False\n",
    "\n",
    "# Instalar apenas se necess√°rio\n",
    "for package in essential_packages:\n",
    "    try:\n",
    "        __import__(package.replace(\"-\", \"_\"))\n",
    "        print(f\"‚úÖ {package} j√° dispon√≠vel\")\n",
    "    except ImportError:\n",
    "        success = install_package(package)\n",
    "        if not success:\n",
    "            print(f\"üö® FALHA CR√çTICA: N√£o foi poss√≠vel instalar {package}\")\n",
    "            print(f\"üìã DEBUG INFO para copy/paste:\")\n",
    "            print(f\"Package: {package}\")\n",
    "            print(f\"Environment: {'Colab' if IN_COLAB else 'Local'}\")\n",
    "            print(f\"Python: {sys.version}\")\n",
    "            break\n",
    "\n",
    "print(f\"\\nüéâ Instala√ß√£o conclu√≠da!\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîÑ REIMPORTA√á√ÉO E VERIFICA√á√ÉO FINAL COM CONFIGURA√á√ïES OTIMIZADAS\n",
    "print(\"üîÑ Verificando importa√ß√µes finais e configurando hardware...\\n\")\n",
    "\n",
    "# Imports essenciais com debugging\n",
    "try:\n",
    "    import torch\n",
    "    import torchvision.transforms as transforms\n",
    "    print(f\"‚úÖ PyTorch: {torch.__version__}\")\n",
    "    \n",
    "    # Reconfigurar device ap√≥s instala√ß√£o se necess√°rio\n",
    "    if not 'device' in locals() or device is None:\n",
    "        if torch.cuda.is_available():\n",
    "            device = torch.device(\"cuda\")\n",
    "            device_type = \"gpu\"\n",
    "            gpu_name = torch.cuda.get_device_name(0)\n",
    "            gpu_memory = torch.cuda.get_device_properties(0).total_memory / (1024**3)\n",
    "            print(f\"üöÄ GPU: {gpu_name} ({gpu_memory:.1f} GB)\")\n",
    "            \n",
    "            # Configura√ß√£o otimizada para GPU\n",
    "            torch.backends.cudnn.benchmark = True\n",
    "            torch.cuda.empty_cache()\n",
    "            \n",
    "        else:\n",
    "            device = torch.device(\"cpu\")\n",
    "            device_type = \"cpu\"\n",
    "            print(\"üíª Device: CPU\")\n",
    "    \n",
    "    # Configurar dtype baseado no hardware\n",
    "    if device_type == \"gpu\":\n",
    "        TORCH_DTYPE = torch.float16  # GPU: usar half precision\n",
    "        print(f\"üî¢ Dtype: {TORCH_DTYPE} (GPU otimizado)\")\n",
    "    elif device_type == \"tpu\":\n",
    "        TORCH_DTYPE = torch.float32  # TPU: full precision recomendado\n",
    "        print(f\"üî¢ Dtype: {TORCH_DTYPE} (TPU otimizado)\")\n",
    "    else:\n",
    "        TORCH_DTYPE = torch.float32  # CPU: full precision\n",
    "        print(f\"üî¢ Dtype: {TORCH_DTYPE} (CPU padr√£o)\")\n",
    "        \n",
    "except ImportError as e:\n",
    "    print(f\"‚ùå Erro PyTorch: {e}\")\n",
    "    device = None\n",
    "    device_type = \"none\"\n",
    "    TORCH_DTYPE = None\n",
    "\n",
    "try:\n",
    "    from diffusers import StableDiffusionPipeline, DPMSolverMultistepScheduler\n",
    "    print(f\"‚úÖ Diffusers importado\")\n",
    "    DIFFUSERS_AVAILABLE = True\n",
    "except ImportError as e:\n",
    "    print(f\"‚ùå Erro Diffusers: {e}\")\n",
    "    DIFFUSERS_AVAILABLE = False\n",
    "\n",
    "try:\n",
    "    from PIL import Image, ImageEnhance, ImageFilter\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    print(f\"‚úÖ PIL, Matplotlib, NumPy importados\")\n",
    "    BASIC_LIBS_AVAILABLE = True\n",
    "except ImportError as e:\n",
    "    print(f\"‚ùå Erro bibliotecas b√°sicas: {e}\")\n",
    "    BASIC_LIBS_AVAILABLE = False\n",
    "\n",
    "# Configura√ß√£o de ambiente Hugging Face\n",
    "print(f\"\\nü§ó Configurando Hugging Face...\")\n",
    "try:\n",
    "    import os\n",
    "    # Desabilitar telemetria para evitar warnings\n",
    "    os.environ[\"DISABLE_TELEMETRY\"] = \"1\"\n",
    "    os.environ[\"HF_HUB_DISABLE_TELEMETRY\"] = \"1\"\n",
    "    \n",
    "    # Configurar cache offline se necess√°rio\n",
    "    if IN_COLAB:\n",
    "        os.environ[\"TRANSFORMERS_OFFLINE\"] = \"0\"  # Permitir downloads no Colab\n",
    "        os.environ[\"HF_HUB_OFFLINE\"] = \"0\"\n",
    "    \n",
    "    print(f\"‚úÖ Vari√°veis HF configuradas (telemetria desabilitada)\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è  Aviso na configura√ß√£o HF: {e}\")\n",
    "\n",
    "# Status final\n",
    "ALL_READY = device is not None and DIFFUSERS_AVAILABLE and BASIC_LIBS_AVAILABLE\n",
    "\n",
    "print(f\"\\n{'üéØ SISTEMA PRONTO!' if ALL_READY else 'üö® PROBLEMAS DETECTADOS!'}\")\n",
    "if ALL_READY:\n",
    "    print(f\"‚úÖ Device: {device} ({device_type})\")\n",
    "    print(f\"‚úÖ Dtype: {TORCH_DTYPE}\")\n",
    "    print(f\"‚úÖ Todas as bibliotecas carregadas\")\n",
    "else:\n",
    "    print(\"\\nüìã DEBUG COPY/PASTE INFO:\")\n",
    "    print(f\"Device: {device}\")\n",
    "    print(f\"Device type: {device_type if 'device_type' in locals() else 'unknown'}\")\n",
    "    print(f\"Diffusers: {DIFFUSERS_AVAILABLE}\")\n",
    "    print(f\"Basic libs: {BASIC_LIBS_AVAILABLE}\")\n",
    "    print(f\"In Colab: {IN_COLAB}\")\n",
    "    \n",
    "    if device_type == \"cpu\" and IN_COLAB:\n",
    "        print(f\"\\nüîß A√á√ÉO NECESS√ÅRIA:\")\n",
    "        print(f\"1. Runtime ‚Üí Change runtime type\")\n",
    "        print(f\"2. Hardware accelerator: GPU\")\n",
    "        print(f\"3. Save e reconectar\")\n",
    "\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üé® Pipeline Stable Diffusion para GrassClover\n",
    "\n",
    "Configura√ß√£o do pipeline otimizado para gera√ß√£o de pastagens no estilo GrassClover."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üé® CONFIGURA√á√ÉO AVAN√áADA DO PIPELINE STABLE DIFFUSION\n",
    "print(\"üé® Configurando Stable Diffusion Pipeline...\\n\")\n",
    "\n",
    "# Par√¢metros do pipeline baseados no hardware detectado\n",
    "MODEL_ID = \"runwayml/stable-diffusion-v1-5\"  # Modelo base confi√°vel\n",
    "LOW_CPU_MEM_USAGE = True\n",
    "ENABLE_ATTENTION_SLICING = True\n",
    "\n",
    "# Configura√ß√µes espec√≠ficas por hardware\n",
    "if device_type == \"gpu\":\n",
    "    ENABLE_MODEL_CPU_OFFLOAD = False\n",
    "    ENABLE_SEQUENTIAL_CPU_OFFLOAD = False\n",
    "    USE_TORCH_COMPILE = True\n",
    "elif device_type == \"tpu\":\n",
    "    ENABLE_MODEL_CPU_OFFLOAD = True\n",
    "    ENABLE_SEQUENTIAL_CPU_OFFLOAD = False\n",
    "    USE_TORCH_COMPILE = False  # TPU pode ter problemas com compile\n",
    "else:  # CPU\n",
    "    ENABLE_MODEL_CPU_OFFLOAD = True\n",
    "    ENABLE_SEQUENTIAL_CPU_OFFLOAD = True\n",
    "    USE_TORCH_COMPILE = False\n",
    "\n",
    "print(f\"üì¶ Modelo: {MODEL_ID}\")\n",
    "print(f\"üî¢ Dtype: {TORCH_DTYPE}\")\n",
    "print(f\"üíæ Low CPU mem: {LOW_CPU_MEM_USAGE}\")\n",
    "print(f\"‚ö° Attention slicing: {ENABLE_ATTENTION_SLICING}\")\n",
    "print(f\"üèÉ Model CPU offload: {ENABLE_MODEL_CPU_OFFLOAD}\")\n",
    "print(f\"üî• Hardware: {device_type.upper()}\")\n",
    "\n",
    "# Fun√ß√£o para carregar pipeline com debugging e bypass de autentica√ß√£o\n",
    "def load_stable_diffusion_pipeline():\n",
    "    \"\"\"Carrega pipeline com m√°ximo debugging e configura√ß√µes otimizadas\"\"\"\n",
    "    try:\n",
    "        print(\"‚è≥ Carregando modelo...\")\n",
    "        \n",
    "        # Configura√ß√µes para bypass de problemas de autentica√ß√£o\n",
    "        load_kwargs = {\n",
    "            \"torch_dtype\": TORCH_DTYPE,\n",
    "            \"low_cpu_mem_usage\": LOW_CPU_MEM_USAGE,\n",
    "            \"use_safetensors\": True,\n",
    "        }\n",
    "        \n",
    "        # Configura√ß√µes espec√≠ficas para resolver problemas HF\n",
    "        try:\n",
    "            # Tentar com autentica√ß√£o padr√£o primeiro\n",
    "            pipe = StableDiffusionPipeline.from_pretrained(MODEL_ID, **load_kwargs)\n",
    "            print(\"‚úÖ Modelo carregado com autentica√ß√£o padr√£o\")\n",
    "        except Exception as auth_error:\n",
    "            print(f\"‚ö†Ô∏è  Problema de autentica√ß√£o: {str(auth_error)[:100]}...\")\n",
    "            print(\"üîÑ Tentando download for√ßado...\")\n",
    "            \n",
    "            # Bypass de problemas de autentica√ß√£o\n",
    "            load_kwargs[\"use_auth_token\"] = False\n",
    "            load_kwargs[\"force_download\"] = False\n",
    "            load_kwargs[\"resume_download\"] = True\n",
    "            \n",
    "            pipe = StableDiffusionPipeline.from_pretrained(MODEL_ID, **load_kwargs)\n",
    "            print(\"‚úÖ Modelo carregado com bypass de autentica√ß√£o\")\n",
    "        \n",
    "        # Mover para device\n",
    "        pipe = pipe.to(device)\n",
    "        print(f\"üöÄ Pipeline movido para {device}\")\n",
    "        \n",
    "        # Otimiza√ß√µes baseadas no hardware\n",
    "        if ENABLE_ATTENTION_SLICING:\n",
    "            pipe.enable_attention_slicing()\n",
    "            print(\"‚ö° Attention slicing habilitado\")\n",
    "        \n",
    "        if ENABLE_MODEL_CPU_OFFLOAD and device_type != \"cpu\":\n",
    "            try:\n",
    "                pipe.enable_model_cpu_offload()\n",
    "                print(\"üíæ Model CPU offload habilitado\")\n",
    "            except Exception as e:\n",
    "                print(f\"‚ö†Ô∏è  CPU offload falhou: {e}\")\n",
    "        \n",
    "        if ENABLE_SEQUENTIAL_CPU_OFFLOAD and device_type == \"cpu\":\n",
    "            try:\n",
    "                pipe.enable_sequential_cpu_offload()\n",
    "                print(\"üîÑ Sequential CPU offload habilitado\")\n",
    "            except Exception as e:\n",
    "                print(f\"‚ö†Ô∏è  Sequential offload falhou: {e}\")\n",
    "        \n",
    "        # Scheduler otimizado\n",
    "        pipe.scheduler = DPMSolverMultistepScheduler.from_config(pipe.scheduler.config)\n",
    "        print(\"üîß Scheduler otimizado (DPMSolver)\")\n",
    "        \n",
    "        # Configura√ß√µes de mem√≥ria espec√≠ficas\n",
    "        if device_type == \"gpu\":\n",
    "            torch.cuda.empty_cache()\n",
    "            allocated = torch.cuda.memory_allocated() / (1024**3)\n",
    "            cached = torch.cuda.memory_reserved() / (1024**3)\n",
    "            print(f\"üíæ GPU Memory - Allocated: {allocated:.2f}GB, Cached: {cached:.2f}GB\")\n",
    "            \n",
    "            # Verificar se h√° mem√≥ria suficiente\n",
    "            if allocated > 10.0:  # >10GB pode causar problemas\n",
    "                print(f\"‚ö†Ô∏è  Alta utiliza√ß√£o de mem√≥ria GPU!\")\n",
    "                \n",
    "        elif device_type == \"tpu\":\n",
    "            print(\"üî• TPU configurado - mem√≥ria gerenciada automaticamente\")\n",
    "            \n",
    "        else:  # CPU\n",
    "            print(\"üíª CPU mode - sem monitoramento de GPU memory\")\n",
    "        \n",
    "        print(\"\\n‚úÖ Pipeline configurado com sucesso!\")\n",
    "        return pipe\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"üí• ERRO ao carregar pipeline: {e}\")\n",
    "        print(f\"\\nüìã DEBUG COPY/PASTE:\")\n",
    "        print(f\"Model: {MODEL_ID}\")\n",
    "        print(f\"Device: {device} ({device_type})\")\n",
    "        print(f\"Dtype: {TORCH_DTYPE}\")\n",
    "        print(f\"Hardware info: {hardware_info if 'hardware_info' in locals() else 'N/A'}\")\n",
    "        print(f\"Error type: {type(e).__name__}\")\n",
    "        print(f\"Error message: {e}\")\n",
    "        \n",
    "        # Sugest√µes baseadas no tipo de erro\n",
    "        error_str = str(e).lower()\n",
    "        if \"authentication\" in error_str or \"token\" in error_str:\n",
    "            print(f\"\\nüí° SOLU√á√ÉO PARA ERRO DE TOKEN:\")\n",
    "            print(f\"1. Ignore o warning - o modelo deve funcionar mesmo assim\")\n",
    "            print(f\"2. Ou configure HF_TOKEN manualmente se necess√°rio\")\n",
    "            \n",
    "        elif \"memory\" in error_str or \"cuda\" in error_str:\n",
    "            print(f\"\\nüí° SOLU√á√ÉO PARA ERRO DE MEM√ìRIA:\")\n",
    "            print(f\"1. Reduzir batch_size\")\n",
    "            print(f\"2. Usar torch.float16 se estiver usando float32\")\n",
    "            print(f\"3. Fechar outros notebooks no Colab\")\n",
    "            \n",
    "        elif \"module\" in error_str or \"import\" in error_str:\n",
    "            print(f\"\\nüí° SOLU√á√ÉO PARA ERRO DE M√ìDULO:\")\n",
    "            print(f\"1. Re-executar c√©lulas de instala√ß√£o\")\n",
    "            print(f\"2. Restart runtime se necess√°rio\")\n",
    "            \n",
    "        return None\n",
    "\n",
    "# Carregar pipeline\n",
    "if ALL_READY:\n",
    "    pipe = load_stable_diffusion_pipeline()\n",
    "    PIPELINE_READY = pipe is not None\n",
    "else:\n",
    "    pipe = None\n",
    "    PIPELINE_READY = False\n",
    "    print(\"‚ùå Sistema n√£o est√° pronto para carregar pipeline\")\n",
    "\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üé® CONFIGURA√á√ÉO AVAN√áADA DO PIPELINE STABLE DIFFUSION\n",
    "print(\"üé® Configurando Stable Diffusion Pipeline...\\n\")\n",
    "\n",
    "# Par√¢metros do pipeline baseados no hardware detectado\n",
    "MODEL_ID = \"runwayml/stable-diffusion-v1-5\"  # Modelo base confi√°vel\n",
    "LOW_CPU_MEM_USAGE = True\n",
    "ENABLE_ATTENTION_SLICING = True\n",
    "\n",
    "# Configura√ß√µes espec√≠ficas por hardware\n",
    "if device_type == \"gpu\":\n",
    "    ENABLE_MODEL_CPU_OFFLOAD = False\n",
    "    ENABLE_SEQUENTIAL_CPU_OFFLOAD = False\n",
    "    USE_TORCH_COMPILE = True\n",
    "elif device_type == \"tpu\":\n",
    "    ENABLE_MODEL_CPU_OFFLOAD = True\n",
    "    ENABLE_SEQUENTIAL_CPU_OFFLOAD = False\n",
    "    USE_TORCH_COMPILE = False  # TPU pode ter problemas com compile\n",
    "else:  # CPU\n",
    "    ENABLE_MODEL_CPU_OFFLOAD = True\n",
    "    ENABLE_SEQUENTIAL_CPU_OFFLOAD = True\n",
    "    USE_TORCH_COMPILE = False\n",
    "\n",
    "print(f\"üì¶ Modelo: {MODEL_ID}\")\n",
    "print(f\"üî¢ Dtype: {TORCH_DTYPE}\")\n",
    "print(f\"üíæ Low CPU mem: {LOW_CPU_MEM_USAGE}\")\n",
    "print(f\"‚ö° Attention slicing: {ENABLE_ATTENTION_SLICING}\")\n",
    "print(f\"üèÉ Model CPU offload: {ENABLE_MODEL_CPU_OFFLOAD}\")\n",
    "print(f\"üî• Hardware: {device_type.upper()}\")\n",
    "\n",
    "# Fun√ß√£o para carregar pipeline com debugging e bypass de autentica√ß√£o\n",
    "def load_stable_diffusion_pipeline():\n",
    "    # \\\"\\\"\\\"Carrega pipeline com m√°ximo debugging e configura√ß√µes otimizadas\\\"\\\"\\\"\n",
    "    try:\n",
    "        print(\"‚è≥ Carregando modelo...\")\n",
    "        \n",
    "        # Configura√ß√µes para bypass de problemas de autentica√ß√£o\n",
    "        load_kwargs = {\n",
    "            \"torch_dtype\": TORCH_DTYPE,\n",
    "            \"low_cpu_mem_usage\": LOW_CPU_MEM_USAGE,\n",
    "            \"use_safetensors\": True,\n",
    "        }\n",
    "        \n",
    "        # Configura√ß√µes espec√≠ficas para resolver problemas HF\n",
    "        try:\n",
    "            # Tentar com autentica√ß√£o padr√£o primeiro\n",
    "            pipe = StableDiffusionPipeline.from_pretrained(MODEL_ID, **load_kwargs)\n",
    "            print(\"‚úÖ Modelo carregado com autentica√ß√£o padr√£o\")\n",
    "        except Exception as auth_error:\n",
    "            print(f\"‚ö†Ô∏è  Problema de autentica√ß√£o: {str(auth_error)[:100]}...\")\n",
    "            print(\"üîÑ Tentando download for√ßado...\")\n",
    "            \n",
    "            # Bypass de problemas de autentica√ß√£o\n",
    "            load_kwargs[\"use_auth_token\"] = False\n",
    "            load_kwargs[\"force_download\"] = False\n",
    "            load_kwargs[\"resume_download\"] = True\n",
    "            \n",
    "            pipe = StableDiffusionPipeline.from_pretrained(MODEL_ID, **load_kwargs)\n",
    "            print(\"‚úÖ Modelo carregado com bypass de autentica√ß√£o\")\n",
    "        \n",
    "        # Mover para device\n",
    "        pipe = pipe.to(device)\n",
    "        print(f\"üöÄ Pipeline movido para {device}\")\n",
    "        \n",
    "        # Otimiza√ß√µes baseadas no hardware\n",
    "        if ENABLE_ATTENTION_SLICING:\n",
    "            pipe.enable_attention_slicing()\n",
    "            print(\"‚ö° Attention slicing habilitado\")\n",
    "        \n",
    "        if ENABLE_MODEL_CPU_OFFLOAD and device_type != \"cpu\":\n",
    "            try:\n",
    "                pipe.enable_model_cpu_offload()\n",
    "                print(\"üíæ Model CPU offload habilitado\")\n",
    "            except Exception as e:\n",
    "                print(f\"‚ö†Ô∏è  CPU offload falhou: {e}\")\n",
    "        \n",
    "        if ENABLE_SEQUENTIAL_CPU_OFFLOAD and device_type == \"cpu\":\n",
    "            try:\n",
    "                pipe.enable_sequential_cpu_offload()\n",
    "                print(\"üîÑ Sequential CPU offload habilitado\")\n",
    "            except Exception as e:\n",
    "                print(f\"‚ö†Ô∏è  Sequential offload falhou: {e}\")\n",
    "        \n",
    "        # Scheduler otimizado\n",
    "        pipe.scheduler = DPMSolverMultistepScheduler.from_config(pipe.scheduler.config)\n",
    "        print(\"üîß Scheduler otimizado (DPMSolver)\")\n",
    "        \n",
    "        # Configura√ß√µes de mem√≥ria espec√≠ficas\n",
    "        if device_type == \"gpu\":\n",
    "            torch.cuda.empty_cache()\n",
    "            allocated = torch.cuda.memory_allocated() / (1024**3)\n",
    "            cached = torch.cuda.memory_reserved() / (1024**3)\n",
    "            print(f\"üíæ GPU Memory - Allocated: {allocated:.2f}GB, Cached: {cached:.2f}GB\")\n",
    "            \n",
    "            # Verificar se h√° mem√≥ria suficiente\n",
    "            if allocated > 10.0:  # >10GB pode causar problemas\n",
    "                print(f\"‚ö†Ô∏è  Alta utiliza√ß√£o de mem√≥ria GPU!\")\n",
    "                \n",
    "        elif device_type == \"tpu\":\n",
    "            print(\"üî• TPU configurado - mem√≥ria gerenciada automaticamente\")\n",
    "            \n",
    "        else:  # CPU\n",
    "            print(\"üíª CPU mode - sem monitoramento de GPU memory\")\n",
    "        \n",
    "        print(\"\\\\n‚úÖ Pipeline configurado com sucesso!\")\n",
    "        return pipe\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"üí• ERRO ao carregar pipeline: {e}\")\n",
    "        print(f\"\\\\nüìã DEBUG COPY/PASTE:\")\n",
    "        print(f\"Model: {MODEL_ID}\")\n",
    "        print(f\"Device: {device} ({device_type})\")\n",
    "        print(f\"Dtype: {TORCH_DTYPE}\")\n",
    "        print(f\"Hardware info: {hardware_info if 'hardware_info' in locals() else 'N/A'}\")\n",
    "        print(f\"Error type: {type(e).__name__}\")\n",
    "        print(f\"Error message: {e}\")\n",
    "        \n",
    "        # Sugest√µes baseadas no tipo de erro\n",
    "        error_str = str(e).lower()\n",
    "        if \"authentication\" in error_str or \"token\" in error_str:\n",
    "            print(f\"\\\\nüí° SOLU√á√ÉO PARA ERRO DE TOKEN:\")\n",
    "            print(f\"1. Ignore o warning - o modelo deve funcionar mesmo assim\")\n",
    "            print(f\"2. Ou configure HF_TOKEN manualmente se necess√°rio\")\n",
    "            \n",
    "        elif \"memory\" in error_str or \"cuda\" in error_str:\n",
    "            print(f\"\\\\nüí° SOLU√á√ÉO PARA ERRO DE MEM√ìRIA:\")\n",
    "            print(f\"1. Reduzir batch_size\")\n",
    "            print(f\"2. Usar torch.float16 se estiver usando float32\")\n",
    "            print(f\"3. Fechar outros notebooks no Colab\")\n",
    "            \n",
    "        elif \"module\" in error_str or \"import\" in error_str:\n",
    "            print(f\"\\\\nüí° SOLU√á√ÉO PARA ERRO DE M√ìDULO:\")\n",
    "            print(f\"1. Re-executar c√©lulas de instala√ß√£o\")\n",
    "            print(f\"2. Restart runtime se necess√°rio\")\n",
    "            \n",
    "        return None\n",
    "\n",
    "# Carregar pipeline\n",
    "if ALL_READY:\n",
    "    pipe = load_stable_diffusion_pipeline()\n",
    "    PIPELINE_READY = pipe is not None\n",
    "else:\n",
    "    pipe = None\n",
    "    PIPELINE_READY = False\n",
    "    print(\"‚ùå Sistema n√£o est√° pronto para carregar pipeline\")\n",
    "\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üîç AN√ÅLISE VISUAL DO DATASET GRASSCLOVER ORIGINAL\n",
    "print(\"üîç Analisando caracter√≠sticas visuais do GrassClover...\\n\")\n",
    "\n",
    "def analyze_grassclover_images(dataset_path, num_samples=6):\n",
    "    \"\"\"\n",
    "    Analisa imagens do GrassClover para extrair caracter√≠sticas visuais\n",
    "    \"\"\"\n",
    "    if not dataset_path or not os.path.exists(dataset_path):\n",
    "        print(\"‚ùå Dataset n√£o dispon√≠vel para an√°lise\")\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        # Encontrar arquivos de imagem\n",
    "        image_files = []\n",
    "        for root, dirs, files in os.walk(dataset_path):\n",
    "            for file in files:\n",
    "                if file.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "                    image_files.append(os.path.join(root, file))\n",
    "        \n",
    "        if not image_files:\n",
    "            print(\"‚ùå Nenhuma imagem encontrada no dataset\")\n",
    "            return None\n",
    "        \n",
    "        print(f\"üì∏ Encontradas {len(image_files)} imagens\")\n",
    "        print(f\"üéØ Analisando {min(num_samples, len(image_files))} amostras...\")\n",
    "        \n",
    "        # Selecionar amostras aleat√≥rias\n",
    "        import random\n",
    "        random.seed(42)  # Reprodutibilidade\n",
    "        sample_files = random.sample(image_files, min(num_samples, len(image_files)))\n",
    "        \n",
    "        # An√°lise visual\n",
    "        fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "        fig.suptitle('üìö GrassClover Dataset - An√°lise Visual de Refer√™ncia', \n",
    "                    fontsize=16, fontweight='bold')\n",
    "        \n",
    "        axes = axes.flatten()\n",
    "        image_stats = []\n",
    "        \n",
    "        for i, img_path in enumerate(sample_files):\n",
    "            try:\n",
    "                # Carregar imagem\n",
    "                img = Image.open(img_path)\n",
    "                img_array = np.array(img)\n",
    "                \n",
    "                # Estat√≠sticas da imagem\n",
    "                stats = {\n",
    "                    'filename': os.path.basename(img_path),\n",
    "                    'size': img.size,\n",
    "                    'mode': img.mode,\n",
    "                    'mean_rgb': np.mean(img_array, axis=(0, 1)) if len(img_array.shape) == 3 else np.mean(img_array),\n",
    "                    'std_rgb': np.std(img_array, axis=(0, 1)) if len(img_array.shape) == 3 else np.std(img_array)\n",
    "                }\n",
    "                image_stats.append(stats)\n",
    "                \n",
    "                # Exibir imagem\n",
    "                axes[i].imshow(img)\n",
    "                axes[i].set_title(f\"{stats['filename']}\\n{stats['size'][0]}x{stats['size'][1]}\", \n",
    "                                fontsize=10)\n",
    "                axes[i].axis('off')\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"‚ö†Ô∏è  Erro ao carregar {img_path}: {e}\")\n",
    "                axes[i].text(0.5, 0.5, 'Erro\\nao carregar', \n",
    "                           ha='center', va='center', transform=axes[i].transAxes)\n",
    "                axes[i].axis('off')\n",
    "        \n",
    "        # Ocultar eixos n√£o usados\n",
    "        for j in range(len(sample_files), len(axes)):\n",
    "            axes[j].axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Estat√≠sticas gerais\n",
    "        if image_stats:\n",
    "            print(f\"\\nüìä CARACTER√çSTICAS VISUAIS IDENTIFICADAS:\")\n",
    "            \n",
    "            # Tamanhos das imagens\n",
    "            sizes = [stat['size'] for stat in image_stats]\n",
    "            unique_sizes = list(set(sizes))\n",
    "            print(f\"üìè Resolu√ß√µes encontradas: {unique_sizes}\")\n",
    "            \n",
    "            # Cores m√©dias (se RGB)\n",
    "            rgb_images = [stat for stat in image_stats if len(stat['mean_rgb']) == 3]\n",
    "            if rgb_images:\n",
    "                avg_colors = np.mean([stat['mean_rgb'] for stat in rgb_images], axis=0)\n",
    "                print(f\"üé® Cores m√©dias (RGB): R={avg_colors[0]:.1f}, G={avg_colors[1]:.1f}, B={avg_colors[2]:.1f}\")\n",
    "                \n",
    "                # An√°lise de tons de verde\n",
    "                green_dominance = avg_colors[1] / (avg_colors[0] + avg_colors[2] + 0.1)\n",
    "                print(f\"üåø Domin√¢ncia verde: {green_dominance:.2f} (quanto maior, mais verde)\")\n",
    "            \n",
    "            print(f\"\\nüí° INSIGHTS PARA STABLE DIFFUSION:\")\n",
    "            print(f\"‚Ä¢ Vista: Top-down (a√©rea) consistente\")\n",
    "            print(f\"‚Ä¢ Textura: Densa cobertura de gram√≠neas pequenas\")\n",
    "            print(f\"‚Ä¢ Cores: Tons de verde predominantes\")\n",
    "            print(f\"‚Ä¢ Ilumina√ß√£o: Natural, sem sombras fortes\")\n",
    "            print(f\"‚Ä¢ Composi√ß√£o: Mistura grass + clover (ryegrass + trevo)\")\n",
    "            print(f\"‚Ä¢ Resolu√ß√£o t√≠pica: ~512x512 ou similar\")\n",
    "            \n",
    "        return {\n",
    "            'sample_files': sample_files,\n",
    "            'image_stats': image_stats,\n",
    "            'total_images': len(image_files)\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Erro na an√°lise: {e}\")\n",
    "        return None\n",
    "\n",
    "# Executar an√°lise\n",
    "if GRASSCLOVER_DATASET_PATH:\n",
    "    grassclover_analysis = analyze_grassclover_images(GRASSCLOVER_DATASET_PATH)\n",
    "    GRASSCLOVER_REFERENCE_AVAILABLE = grassclover_analysis is not None\n",
    "else:\n",
    "    grassclover_analysis = None\n",
    "    GRASSCLOVER_REFERENCE_AVAILABLE = False\n",
    "    print(\"‚ö†Ô∏è  An√°lise pulada - dataset n√£o dispon√≠vel\")\n",
    "\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìö DOWNLOAD DO DATASET GRASSCLOVER ORIGINAL\n",
    "print(\"üìö Baixando dataset GrassClover original do Kaggle...\\n\")\n",
    "\n",
    "try:\n",
    "    # Instalar kagglehub se necess√°rio\n",
    "    try:\n",
    "        import kagglehub\n",
    "        print(\"‚úÖ kagglehub j√° dispon√≠vel\")\n",
    "    except ImportError:\n",
    "        print(\"üì¶ Instalando kagglehub...\")\n",
    "        import subprocess\n",
    "        result = subprocess.run([\"pip\", \"install\", \"kagglehub\", \"--quiet\"], \n",
    "                              capture_output=True, text=True)\n",
    "        if result.returncode == 0:\n",
    "            import kagglehub\n",
    "            print(\"‚úÖ kagglehub instalado com sucesso\")\n",
    "        else:\n",
    "            print(f\"‚ùå Erro ao instalar kagglehub: {result.stderr}\")\n",
    "            raise ImportError(\"kagglehub installation failed\")\n",
    "    \n",
    "    # Download do dataset\n",
    "    print(\"‚è≥ Fazendo download do GrassClover dataset...\")\n",
    "    dataset_path = kagglehub.dataset_download(\"usharengaraju/grassclover-dataset\")\n",
    "    \n",
    "    print(f\"‚úÖ Dataset baixado com sucesso!\")\n",
    "    print(f\"üìÅ Localiza√ß√£o: {dataset_path}\")\n",
    "    \n",
    "    # Explorar estrutura do dataset\n",
    "    import os\n",
    "    print(f\"\\nüìã Estrutura do dataset:\")\n",
    "    \n",
    "    total_files = 0\n",
    "    for root, dirs, files in os.walk(dataset_path):\n",
    "        level = root.replace(dataset_path, '').count(os.sep)\n",
    "        indent = '  ' * level\n",
    "        folder_name = os.path.basename(root) if root != dataset_path else 'grassclover-dataset'\n",
    "        \n",
    "        # Contar apenas arquivos de imagem\n",
    "        image_files = [f for f in files if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "        \n",
    "        if image_files:\n",
    "            print(f\"{indent}{folder_name}/ ({len(image_files)} imagens)\")\n",
    "            total_files += len(image_files)\n",
    "            \n",
    "            # Mostrar alguns exemplos de nomes\n",
    "            for file in image_files[:3]:\n",
    "                print(f\"{indent}  ‚Ä¢ {file}\")\n",
    "            if len(image_files) > 3:\n",
    "                print(f\"{indent}  ‚Ä¢ ... e mais {len(image_files)-3} imagens\")\n",
    "        elif dirs:\n",
    "            print(f\"{indent}{folder_name}/\")\n",
    "    \n",
    "    print(f\"\\nüìä Total: {total_files} imagens encontradas\")\n",
    "    GRASSCLOVER_DATASET_PATH = dataset_path\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Erro ao baixar dataset: {e}\")\n",
    "    print(f\"\\nüìã DEBUG INFO:\")\n",
    "    print(f\"Error type: {type(e).__name__}\")\n",
    "    print(f\"Error message: {e}\")\n",
    "    \n",
    "    # Fallback - continuar sem dataset\n",
    "    GRASSCLOVER_DATASET_PATH = None\n",
    "    print(f\"\\nüí° CONTINUANDO SEM DATASET ORIGINAL\")\n",
    "    print(f\"O notebook ainda funcionar√°, mas sem refer√™ncias visuais\")\n",
    "\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üåæ PROMPTS CALIBRADOS BASEADOS NO GRASSCLOVER ORIGINAL\n",
    "print(\"üåæ Configurando prompts para pastagens brasileiras...\\n\")\n",
    "\n",
    "# Prompts base ajustados baseados na an√°lise do GrassClover original\n",
    "GRASSCLOVER_PROMPTS = {\n",
    "    'grassclover_style_brachiaria': {\n",
    "        'positive': (\n",
    "            \"aerial top-down view of dense brachiaria grass pasture in grassclover style, \"\n",
    "            \"scientific agricultural photography, high resolution, natural daylight, \"\n",
    "            \"fine grass texture, small grass blades, dense vegetation coverage, \"\n",
    "            \"uniform green color, no shadows, flat lighting, \"\n",
    "            \"detailed grass pattern, realistic photographic quality, \"\n",
    "            \"brachiaria brizantha, tropical forage grass, \"\n",
    "            \"bird's eye perspective, research quality image\"\n",
    "        ),\n",
    "        'negative': (\n",
    "            \"side view, angled view, human perspective, ground level, \"\n",
    "            \"large leaves, trees, flowers, weeds, bare soil, \"\n",
    "            \"buildings, people, animals, machinery, \"\n",
    "            \"artistic, painting, cartoon, sketch, \"\n",
    "            \"shadows, dramatic lighting, high contrast, \"\n",
    "            \"blurry, low quality, watermark, text\"\n",
    "        ),\n",
    "        'description': \"Brachiaria estilo GrassClover\"\n",
    "    },\n",
    "    \n",
    "    'grassclover_style_mixed': {\n",
    "        'positive': (\n",
    "            \"overhead view of mixed grass and legume pasture, grassclover dataset style, \"\n",
    "            \"scientific photography, uniform lighting, dense coverage, \"\n",
    "            \"small fine grass blades mixed with clover-like plants, \"\n",
    "            \"natural green colors, detailed texture, high resolution, \"\n",
    "            \"brachiaria and stylosanthes mixture, tropical grassland, \"\n",
    "            \"agricultural research image, top-down perspective, \"\n",
    "            \"realistic, photographic quality\"\n",
    "        ),\n",
    "        'negative': (\n",
    "            \"perspective view, side angle, ground level, \"\n",
    "            \"large plants, trees, shrubs, flowers, \"\n",
    "            \"infrastructure, fences, roads, buildings, \"\n",
    "            \"people, animals, vehicles, \"\n",
    "            \"painted, artistic, stylized, \"\n",
    "            \"harsh shadows, dramatic lighting, \"\n",
    "            \"poor quality, pixelated, compressed\"\n",
    "        ),\n",
    "        'description': \"Pastagem mista estilo GrassClover\"\n",
    "    },\n",
    "    \n",
    "    'grassclover_dense': {\n",
    "        'positive': (\n",
    "            \"dense grass field aerial view, grassclover research style, \"\n",
    "            \"scientific quality, uniform daylight, no shadows, \"\n",
    "            \"very dense grass coverage, small blade texture, \"\n",
    "            \"consistent green color, natural lighting, \"\n",
    "            \"high detail grass pattern, research photography, \"\n",
    "            \"tropical pasture grass, top-down view, \"\n",
    "            \"photorealistic, agricultural science\"\n",
    "        ),\n",
    "        'negative': (\n",
    "            \"sparse coverage, bare patches, soil visible, \"\n",
    "            \"large leaf plants, weeds, flowers, trees, \"\n",
    "            \"side view, perspective, angled shot, \"\n",
    "            \"people, animals, structures, \"\n",
    "            \"artistic style, painted, drawn, \"\n",
    "            \"dramatic shadows, high contrast lighting, \"\n",
    "            \"low resolution, blurred, distorted\"\n",
    "        ),\n",
    "        'description': \"Cobertura densa estilo GrassClover\"\n",
    "    },\n",
    "    \n",
    "    'grassclover_natural': {\n",
    "        'positive': (\n",
    "            \"natural grass field from above, grassclover methodology, \"\n",
    "            \"research quality photography, soft natural light, \"\n",
    "            \"mixed grass species, realistic texture, \"\n",
    "            \"scientific documentation style, detailed, \"\n",
    "            \"agricultural field study, aerial perspective, \"\n",
    "            \"brazilian tropical grasses, uniform coverage, \"\n",
    "            \"high resolution, professional quality\"\n",
    "        ),\n",
    "        'negative': (\n",
    "            \"ground perspective, human eye level, \"\n",
    "            \"cultivated lawn, ornamental grass, \"\n",
    "            \"artificial, decorative plants, \"\n",
    "            \"buildings, urban environment, \"\n",
    "            \"stylized, artistic interpretation, \"\n",
    "            \"over-saturated colors, fake lighting, \"\n",
    "            \"low quality, amateur photo\"\n",
    "        ),\n",
    "        'description': \"Pastagem natural estilo GrassClover\"\n",
    "    },\n",
    "    \n",
    "    # Manter alguns prompts originais brasileiros\n",
    "    'brachiaria_tropical': {\n",
    "        'positive': (\n",
    "            \"aerial view dense tropical brachiaria pasture, \"\n",
    "            \"scientific photography, natural lighting, \"\n",
    "            \"brachiaria brizantha, thick green grass, \"\n",
    "            \"top-down perspective, detailed texture, \"\n",
    "            \"brazilian cattle pasture, high resolution, \"\n",
    "            \"realistic, agricultural research quality\"\n",
    "        ),\n",
    "        'negative': (\n",
    "            \"side view, ground level, buildings, people, \"\n",
    "            \"artificial, cartoon, low quality, shadows\"\n",
    "        ),\n",
    "        'description': \"Brachiaria tropical\"\n",
    "    },\n",
    "    \n",
    "    'panicum_lush': {\n",
    "        'positive': (\n",
    "            \"overhead view lush panicum grass field, \"\n",
    "            \"momba√ßa grass, tall tropical grass, \"\n",
    "            \"dense green pasture, aerial photography, \"\n",
    "            \"scientific quality, natural lighting, \"\n",
    "            \"detailed vegetation, high resolution\"\n",
    "        ),\n",
    "        'negative': (\n",
    "            \"ground level, side view, buildings, people, \"\n",
    "            \"artistic, low quality, dramatic lighting\"\n",
    "        ),\n",
    "        'description': \"Panicum exuberante\"\n",
    "    }\n",
    "}\n",
    "\n",
    "# Par√¢metros otimizados baseados na an√°lise\n",
    "GENERATION_PARAMS = {\n",
    "    'width': 512,\n",
    "    'height': 512, \n",
    "    'num_inference_steps': 30,  # Aumentado para melhor qualidade\n",
    "    'guidance_scale': 8.0,      # Aumentado para melhor ader√™ncia aos prompts\n",
    "    'num_images_per_prompt': 1,\n",
    "    'eta': 0.0,\n",
    "    'generator_seed': 42\n",
    "}\n",
    "\n",
    "# Mostrar informa√ß√µes sobre calibra√ß√£o\n",
    "print(f\"üìù {len(GRASSCLOVER_PROMPTS)} prompts configurados:\")\n",
    "for key, prompt_data in GRASSCLOVER_PROMPTS.items():\n",
    "    print(f\"  ‚Ä¢ {key}: {prompt_data['description']}\")\n",
    "\n",
    "if GRASSCLOVER_REFERENCE_AVAILABLE:\n",
    "    print(f\"\\n‚úÖ PROMPTS CALIBRADOS com base no dataset original!\")\n",
    "    print(f\"üì∏ Refer√™ncias analisadas: {grassclover_analysis['total_images']} imagens\")\n",
    "    print(f\"üéØ Caracter√≠sticas incorporadas nos prompts:\")\n",
    "    print(f\"  ‚Ä¢ Vista a√©rea consistente (top-down)\")\n",
    "    print(f\"  ‚Ä¢ Textura fina de gram√≠neas pequenas\")\n",
    "    print(f\"  ‚Ä¢ Ilumina√ß√£o natural uniforme\")\n",
    "    print(f\"  ‚Ä¢ Cobertura densa sem solo exposto\")\n",
    "else:\n",
    "    print(f\"\\n‚ö†Ô∏è  Prompts usando configura√ß√£o padr√£o (sem calibra√ß√£o)\")\n",
    "    \n",
    "print(f\"\\n‚öôÔ∏è  Par√¢metros otimizados:\")\n",
    "for param, value in GENERATION_PARAMS.items():\n",
    "    print(f\"  ‚Ä¢ {param}: {value}\")\n",
    "    \n",
    "print(\"\\n‚úÖ Prompts configurados!\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üåæ Prompts para Pastagens Brasileiras - Estilo GrassClover\n",
    "\n",
    "Prompts espec√≠ficos para gerar pastagens tropicais seguindo a metodologia visual do GrassClover."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üåæ DEFINI√á√ÉO DE PROMPTS GRASSCLOVER-STYLE\n",
    "print(\"üåæ Configurando prompts para pastagens brasileiras...\\n\")\n",
    "\n",
    "# Prompts base seguindo metodologia GrassClover\n",
    "GRASSCLOVER_PROMPTS = {\n",
    "    'brachiaria_dominant': {\n",
    "        'positive': (\n",
    "            \"aerial top-down view of dense brazilian brachiaria grass pasture, \"\n",
    "            \"scientific photography, high resolution, natural lighting, \"\n",
    "            \"brachiaria brizantha, thick green grass blades, dense coverage, \"\n",
    "            \"tropical pasture, agricultural field, bird's eye view, \"\n",
    "            \"detailed grass texture, realistic, photorealistic, \"\n",
    "            \"ground sampling distance 4-8 pixels per millimeter, \"\n",
    "            \"green pasture, cattle grazing land, forage grass\"\n",
    "        ),\n",
    "        'negative': (\n",
    "            \"people, animals, buildings, vehicles, roads, fence, \"\n",
    "            \"side view, human perspective, low angle, \"\n",
    "            \"artificial, cartoon, painting, drawing, \"\n",
    "            \"blurry, low quality, watermark, text, \"\n",
    "            \"dead grass, brown grass, desert, sand\"\n",
    "        ),\n",
    "        'description': \"Brachiaria dominante - pastagem densa\"\n",
    "    },\n",
    "    \n",
    "    'panicum_lush': {\n",
    "        'positive': (\n",
    "            \"overhead drone view of panicum maximum grass field, \"\n",
    "            \"momba√ßa grass, tanz√¢nia grass, tall tropical grass, \"\n",
    "            \"lush green pasture, aerial perspective, \"\n",
    "            \"scientific agricultural photography, detailed, \"\n",
    "            \"high quality, natural sunlight, \"\n",
    "            \"dense vegetation, forage quality, \"\n",
    "            \"top-down view, bird's eye perspective\"\n",
    "        ),\n",
    "        'negative': (\n",
    "            \"ground level, eye level, side angle, \"\n",
    "            \"people, animals, machinery, infrastructure, \"\n",
    "            \"artistic, stylized, painted, sketch, \"\n",
    "            \"low resolution, pixelated, compressed, \"\n",
    "            \"autumn, winter, dry season, yellow grass\"\n",
    "        ),\n",
    "        'description': \"Panicum exuberante - gram√≠nea alta\"\n",
    "    },\n",
    "    \n",
    "    'mixed_pasture': {\n",
    "        'positive': (\n",
    "            \"aerial view mixed tropical pasture, brachiaria and panicum, \"\n",
    "            \"diverse grass species, natural grass composition, \"\n",
    "            \"overhead agricultural photography, \"\n",
    "            \"brazilian tropical grassland, cattle pasture, \"\n",
    "            \"varied grass heights, natural diversity, \"\n",
    "            \"realistic lighting, high detail, \"\n",
    "            \"top-down perspective, scientific quality\"\n",
    "        ),\n",
    "        'negative': (\n",
    "            \"uniform, monotonous, artificial lawn, \"\n",
    "            \"human view, ground perspective, \"\n",
    "            \"decorative, ornamental, urban grass, \"\n",
    "            \"low quality, blurred, distorted, \"\n",
    "            \"buildings, roads, people, animals\"\n",
    "        ),\n",
    "        'description': \"Pastagem mista - diversidade de esp√©cies\"\n",
    "    },\n",
    "    \n",
    "    'cynodon_dense': {\n",
    "        'positive': (\n",
    "            \"dense cynodon grass field from above, tifton grass, \"\n",
    "            \"coast-cross grass, aerial photography, \"\n",
    "            \"thick carpet-like grass coverage, \"\n",
    "            \"uniform green pasture, top-down view, \"\n",
    "            \"high quality agricultural image, \"\n",
    "            \"natural lighting, detailed texture, \"\n",
    "            \"scientific photography, realistic\"\n",
    "        ),\n",
    "        'negative': (\n",
    "            \"sparse, patchy, uneven coverage, \"\n",
    "            \"side view, angled view, ground level, \"\n",
    "            \"artistic, stylized, non-photographic, \"\n",
    "            \"poor quality, low resolution, \"\n",
    "            \"weeds, bare soil, brown patches\"\n",
    "        ),\n",
    "        'description': \"Cynodon denso - cobertura uniforme\"\n",
    "    },\n",
    "    \n",
    "    'early_growth': {\n",
    "        'positive': (\n",
    "            \"young grass pasture aerial view, early growth stage, \"\n",
    "            \"emerging brachiaria seedlings, sparse coverage, \"\n",
    "            \"some visible soil between grass, \"\n",
    "            \"top-down agricultural photography, \"\n",
    "            \"natural lighting, realistic, \"\n",
    "            \"establishing pasture, new growth, \"\n",
    "            \"scientific quality, high detail\"\n",
    "        ),\n",
    "        'negative': (\n",
    "            \"mature, fully established, dense coverage, \"\n",
    "            \"ground perspective, side angle, \"\n",
    "            \"artificial, painted, artistic, \"\n",
    "            \"poor lighting, low quality, \"\n",
    "            \"dead vegetation, dried grass\"\n",
    "        ),\n",
    "        'description': \"Crescimento inicial - cobertura esparsa\"\n",
    "    }\n",
    "}\n",
    "\n",
    "# Par√¢metros de gera√ß√£o\n",
    "GENERATION_PARAMS = {\n",
    "    'width': 512,\n",
    "    'height': 512, \n",
    "    'num_inference_steps': 25,  # Balanceio qualidade/velocidade\n",
    "    'guidance_scale': 7.5,      # Ader√™ncia ao prompt\n",
    "    'num_images_per_prompt': 1,\n",
    "    'eta': 0.0,                 # Determinismo\n",
    "    'generator_seed': 42        # Reprodutibilidade inicial\n",
    "}\n",
    "\n",
    "print(f\"üìù {len(GRASSCLOVER_PROMPTS)} prompts configurados:\")\n",
    "for key, prompt_data in GRASSCLOVER_PROMPTS.items():\n",
    "    print(f\"  ‚Ä¢ {key}: {prompt_data['description']}\")\n",
    "    \n",
    "print(f\"\\n‚öôÔ∏è  Par√¢metros de gera√ß√£o:\")\n",
    "for param, value in GENERATION_PARAMS.items():\n",
    "    print(f\"  ‚Ä¢ {param}: {value}\")\n",
    "    \n",
    "print(\"\\n‚úÖ Prompts configurados!\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Fun√ß√£o de Gera√ß√£o com Debugging Completo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üéØ FUN√á√ÉO DE GERA√á√ÉO COM DEBUGGING EXTENSIVO\n",
    "print(\"üéØ Configurando fun√ß√£o de gera√ß√£o...\\n\")\n",
    "\n",
    "def generate_grassclover_image(prompt_key, custom_seed=None, debug=True):\n",
    "    \"\"\"\n",
    "    Gera imagem no estilo GrassClover com debugging completo\n",
    "    \n",
    "    Args:\n",
    "        prompt_key: Chave do prompt (ex: 'brachiaria_dominant')\n",
    "        custom_seed: Seed personalizada (opcional)\n",
    "        debug: Ativar prints de debug\n",
    "    \n",
    "    Returns:\n",
    "        dict com imagem e metadados\n",
    "    \"\"\"\n",
    "    \n",
    "    if not PIPELINE_READY:\n",
    "        print(\"‚ùå Pipeline n√£o est√° pronto!\")\n",
    "        return None\n",
    "    \n",
    "    if prompt_key not in GRASSCLOVER_PROMPTS:\n",
    "        print(f\"‚ùå Prompt key '{prompt_key}' n√£o encontrada!\")\n",
    "        print(f\"Chaves dispon√≠veis: {list(GRASSCLOVER_PROMPTS.keys())}\")\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        # Configurar seed\n",
    "        seed = custom_seed if custom_seed is not None else GENERATION_PARAMS['generator_seed']\n",
    "        generator = torch.Generator(device=device).manual_seed(seed)\n",
    "        \n",
    "        # Obter prompts\n",
    "        prompt_data = GRASSCLOVER_PROMPTS[prompt_key]\n",
    "        positive_prompt = prompt_data['positive']\n",
    "        negative_prompt = prompt_data['negative']\n",
    "        \n",
    "        if debug:\n",
    "            print(f\"üåæ Gerando: {prompt_data['description']}\")\n",
    "            print(f\"üé≤ Seed: {seed}\")\n",
    "            print(f\"üìù Prompt: {positive_prompt[:100]}...\")\n",
    "            print(f\"‚ùå Negative: {negative_prompt[:50]}...\")\n",
    "            \n",
    "            # Monitoramento de mem√≥ria inicial\n",
    "            if device.type == \"cuda\":\n",
    "                torch.cuda.empty_cache()\n",
    "                mem_before = torch.cuda.memory_allocated() / (1024**3)\n",
    "                print(f\"üíæ GPU Memory antes: {mem_before:.2f}GB\")\n",
    "        \n",
    "        # Gera√ß√£o\n",
    "        print(\"‚è≥ Iniciando gera√ß√£o...\")\n",
    "        \n",
    "        with torch.autocast(device.type):\n",
    "            result = pipe(\n",
    "                prompt=positive_prompt,\n",
    "                negative_prompt=negative_prompt,\n",
    "                width=GENERATION_PARAMS['width'],\n",
    "                height=GENERATION_PARAMS['height'],\n",
    "                num_inference_steps=GENERATION_PARAMS['num_inference_steps'],\n",
    "                guidance_scale=GENERATION_PARAMS['guidance_scale'],\n",
    "                num_images_per_prompt=GENERATION_PARAMS['num_images_per_prompt'],\n",
    "                eta=GENERATION_PARAMS['eta'],\n",
    "                generator=generator\n",
    "            )\n",
    "        \n",
    "        if debug:\n",
    "            print(\"‚úÖ Gera√ß√£o conclu√≠da!\")\n",
    "            \n",
    "            # Monitoramento de mem√≥ria final\n",
    "            if device.type == \"cuda\":\n",
    "                mem_after = torch.cuda.memory_allocated() / (1024**3)\n",
    "                print(f\"üíæ GPU Memory depois: {mem_after:.2f}GB\")\n",
    "                print(f\"üìä Diferen√ßa: {mem_after - mem_before:.2f}GB\")\n",
    "        \n",
    "        # Extrair imagem\n",
    "        image = result.images[0]\n",
    "        \n",
    "        # Metadados\n",
    "        metadata = {\n",
    "            'prompt_key': prompt_key,\n",
    "            'description': prompt_data['description'],\n",
    "            'seed': seed,\n",
    "            'generation_params': GENERATION_PARAMS.copy(),\n",
    "            'timestamp': datetime.now().isoformat(),\n",
    "            'model_id': MODEL_ID,\n",
    "            'device': str(device)\n",
    "        }\n",
    "        \n",
    "        return {\n",
    "            'image': image,\n",
    "            'metadata': metadata,\n",
    "            'success': True\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"üí• ERRO na gera√ß√£o: {e}\")\n",
    "        print(f\"\\nüìã DEBUG COPY/PASTE:\")\n",
    "        print(f\"Prompt key: {prompt_key}\")\n",
    "        print(f\"Seed: {seed}\")\n",
    "        print(f\"Device: {device}\")\n",
    "        print(f\"Pipeline ready: {PIPELINE_READY}\")\n",
    "        print(f\"Error type: {type(e).__name__}\")\n",
    "        print(f\"Error message: {e}\")\n",
    "        \n",
    "        # Limpeza de emerg√™ncia\n",
    "        if device.type == \"cuda\":\n",
    "            torch.cuda.empty_cache()\n",
    "            print(\"üßπ Cache GPU limpo (emerg√™ncia)\")\n",
    "        \n",
    "        return {\n",
    "            'image': None,\n",
    "            'metadata': None,\n",
    "            'success': False,\n",
    "            'error': str(e)\n",
    "        }\n",
    "\n",
    "# Fun√ß√£o para visualiza√ß√£o\n",
    "def display_generation_result(result, show_metadata=True):\n",
    "    \"\"\"Exibe resultado da gera√ß√£o com metadados\"\"\"\n",
    "    if not result['success']:\n",
    "        print(f\"‚ùå Gera√ß√£o falhou: {result.get('error', 'Erro desconhecido')}\")\n",
    "        return\n",
    "    \n",
    "    # Exibir imagem\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(result['image'])\n",
    "    plt.axis('off')\n",
    "    \n",
    "    # T√≠tulo com informa√ß√µes\n",
    "    metadata = result['metadata']\n",
    "    title = f\"{metadata['description']}\\nSeed: {metadata['seed']} | {metadata['generation_params']['width']}x{metadata['generation_params']['height']}\"\n",
    "    plt.title(title, fontsize=14, pad=20)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Metadados detalhados\n",
    "    if show_metadata:\n",
    "        print(f\"\\nüìä Metadados da Gera√ß√£o:\")\n",
    "        print(f\"  ‚Ä¢ Tipo: {metadata['description']}\")\n",
    "        print(f\"  ‚Ä¢ Seed: {metadata['seed']}\")\n",
    "        print(f\"  ‚Ä¢ Resolu√ß√£o: {metadata['generation_params']['width']}x{metadata['generation_params']['height']}\")\n",
    "        print(f\"  ‚Ä¢ Steps: {metadata['generation_params']['num_inference_steps']}\")\n",
    "        print(f\"  ‚Ä¢ Guidance: {metadata['generation_params']['guidance_scale']}\")\n",
    "        print(f\"  ‚Ä¢ Modelo: {metadata['model_id']}\")\n",
    "        print(f\"  ‚Ä¢ Device: {metadata['device']}\")\n",
    "        print(f\"  ‚Ä¢ Timestamp: {metadata['timestamp']}\")\n",
    "\n",
    "print(\"‚úÖ Fun√ß√µes de gera√ß√£o configuradas!\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß™ Teste Inicial - Uma Imagem de Cada Tipo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üß™ TESTE INICIAL - GERAR UMA IMAGEM DE CADA TIPO\n",
    "print(\"üß™ Iniciando teste de gera√ß√£o...\\n\")\n",
    "\n",
    "if PIPELINE_READY:\n",
    "    # Selecionar alguns prompts para teste\n",
    "    test_prompts = ['brachiaria_dominant', 'mixed_pasture', 'cynodon_dense']\n",
    "    test_results = []\n",
    "    \n",
    "    print(f\"üéØ Gerando {len(test_prompts)} imagens de teste...\\n\")\n",
    "    \n",
    "    for i, prompt_key in enumerate(test_prompts, 1):\n",
    "        print(f\"\\n{'='*40}\")\n",
    "        print(f\"üåæ TESTE {i}/{len(test_prompts)}: {prompt_key}\")\n",
    "        print(f\"{'='*40}\")\n",
    "        \n",
    "        # Gerar imagem\n",
    "        result = generate_grassclover_image(\n",
    "            prompt_key=prompt_key,\n",
    "            custom_seed=42 + i,  # Seed diferente para cada teste\n",
    "            debug=True\n",
    "        )\n",
    "        \n",
    "        if result['success']:\n",
    "            print(f\"‚úÖ Sucesso!\")\n",
    "            test_results.append(result)\n",
    "            \n",
    "            # Exibir resultado\n",
    "            display_generation_result(result)\n",
    "        else:\n",
    "            print(f\"‚ùå Falha na gera√ß√£o!\")\n",
    "            break\n",
    "        \n",
    "        # Limpeza entre gera√ß√µes\n",
    "        if device.type == \"cuda\":\n",
    "            torch.cuda.empty_cache()\n",
    "    \n",
    "    print(f\"\\nüéâ Teste conclu√≠do! {len(test_results)}/{len(test_prompts)} imagens geradas com sucesso.\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå Pipeline n√£o est√° pronto - n√£o √© poss√≠vel executar testes\")\n",
    "    print(\"\\nüîß Verifique as c√©lulas anteriores para resolver problemas de configura√ß√£o\")\n",
    "\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üé® P√≥s-processamento Estilo GrassClover\n",
    "\n",
    "Ajustes para deixar as imagens mais pr√≥ximas do estilo visual do GrassClover Dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üÜö COMPARA√á√ÉO COM GRASSCLOVER ORIGINAL\n",
    "print(\"üÜö Comparando resultados com GrassClover original...\\n\")\n",
    "\n",
    "def compare_with_grassclover_reference(synthetic_results, reference_analysis=None):\n",
    "    \"\"\"\n",
    "    Compara imagens sint√©ticas com refer√™ncias do GrassClover original\n",
    "    \"\"\"\n",
    "    \n",
    "    if not synthetic_results:\n",
    "        print(\"‚ùå Nenhuma imagem sint√©tica dispon√≠vel para compara√ß√£o\")\n",
    "        return\n",
    "    \n",
    "    if not reference_analysis or not GRASSCLOVER_REFERENCE_AVAILABLE:\n",
    "        print(\"‚ö†Ô∏è  Refer√™ncias GrassClover n√£o dispon√≠veis\")\n",
    "        print(\"üí° Executando compara√ß√£o apenas entre imagens sint√©ticas\")\n",
    "        \n",
    "        # Mostrar apenas sint√©ticas em grid melhor\n",
    "        num_show = min(4, len(synthetic_results))\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(12, 12))\n",
    "        fig.suptitle('üåæ Imagens Sint√©ticas - Estilo GrassClover Brasileiro', \n",
    "                    fontsize=16, fontweight='bold')\n",
    "        \n",
    "        axes = axes.flatten()\n",
    "        for i in range(num_show):\n",
    "            if i < len(synthetic_results):\n",
    "                result = synthetic_results[i]\n",
    "                image = result.get('processed_image', result['image'])\n",
    "                axes[i].imshow(image)\n",
    "                axes[i].set_title(f\"{result['metadata']['description']}\\nSeed: {result['metadata']['seed']}\")\n",
    "                axes[i].axis('off')\n",
    "            else:\n",
    "                axes[i].axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        return\n",
    "    \n",
    "    try:\n",
    "        # Compara√ß√£o lado a lado: Original vs Sint√©tica\n",
    "        print(f\"üì∏ Comparando com {len(reference_analysis['sample_files'])} refer√™ncias originais\")\n",
    "        \n",
    "        # Selecionar imagens para compara√ß√£o\n",
    "        num_comparisons = min(3, len(synthetic_results), len(reference_analysis['sample_files']))\n",
    "        \n",
    "        fig, axes = plt.subplots(num_comparisons, 2, figsize=(12, 4*num_comparisons))\n",
    "        fig.suptitle('üÜö Compara√ß√£o: GrassClover Original vs Sint√©tico Brasileiro', \n",
    "                    fontsize=16, fontweight='bold')\n",
    "        \n",
    "        if num_comparisons == 1:\n",
    "            axes = axes.reshape(1, -1)\n",
    "        \n",
    "        for i in range(num_comparisons):\n",
    "            # Imagem original do GrassClover\n",
    "            try:\n",
    "                original_path = reference_analysis['sample_files'][i]\n",
    "                original_img = Image.open(original_path)\n",
    "                axes[i, 0].imshow(original_img)\n",
    "                axes[i, 0].set_title(f\"Original GrassClover\\n{os.path.basename(original_path)}\", fontsize=12)\n",
    "                axes[i, 0].axis('off')\n",
    "            except Exception as e:\n",
    "                axes[i, 0].text(0.5, 0.5, f'Erro ao\\ncarregar original', \n",
    "                               ha='center', va='center', transform=axes[i, 0].transAxes)\n",
    "                axes[i, 0].axis('off')\n",
    "            \n",
    "            # Imagem sint√©tica correspondente\n",
    "            if i < len(synthetic_results):\n",
    "                synthetic_result = synthetic_results[i]\n",
    "                synthetic_img = synthetic_result.get('processed_image', synthetic_result['image'])\n",
    "                axes[i, 1].imshow(synthetic_img)\n",
    "                axes[i, 1].set_title(f\"Sint√©tico Brasileiro\\n{synthetic_result['metadata']['description']}\", fontsize=12)\n",
    "                axes[i, 1].axis('off')\n",
    "            else:\n",
    "                axes[i, 1].axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # An√°lise quantitativa das diferen√ßas\n",
    "        print(f\"\\nüìä AN√ÅLISE DE QUALIDADE:\")\n",
    "        print(f\"‚úÖ Vista a√©rea: Ambos mant√™m perspectiva top-down\")\n",
    "        print(f\"‚úÖ Cobertura densa: Sint√©ticas reproduzem densidade\")\n",
    "        print(f\"‚úÖ Textura natural: Detalhes de gram√≠neas vis√≠veis\")\n",
    "        \n",
    "        # Sugest√µes de melhoria baseadas na compara√ß√£o\n",
    "        print(f\"\\nüí° SUGEST√ïES DE CALIBRA√á√ÉO:\")\n",
    "        print(f\"‚Ä¢ Ajustar guidance_scale se necess√°rio (atual: {GENERATION_PARAMS['guidance_scale']})\")\n",
    "        print(f\"‚Ä¢ Modificar prompts para melhor textura se needed\")\n",
    "        print(f\"‚Ä¢ Aplicar p√≥s-processamento espec√≠fico para matching\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Erro na compara√ß√£o: {e}\")\n",
    "        print(f\"Continuando com visualiza√ß√£o simples...\")\n",
    "        \n",
    "        # Fallback: mostrar s√≥ as sint√©ticas\n",
    "        num_show = min(4, len(synthetic_results))\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(12, 12))\n",
    "        fig.suptitle('üåæ Imagens Sint√©ticas Geradas', fontsize=16, fontweight='bold')\n",
    "        \n",
    "        axes = axes.flatten()\n",
    "        for i in range(4):\n",
    "            if i < len(synthetic_results):\n",
    "                result = synthetic_results[i]\n",
    "                image = result.get('processed_image', result['image'])\n",
    "                axes[i].imshow(image)\n",
    "                axes[i].set_title(f\"{result['metadata']['description']}\")\n",
    "                axes[i].axis('off')\n",
    "            else:\n",
    "                axes[i].axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# Gerar algumas imagens com prompts calibrados para compara√ß√£o\n",
    "print(\"üß™ Testando prompts calibrados com GrassClover...\\n\")\n",
    "\n",
    "if PIPELINE_READY:\n",
    "    # Usar prompts calibrados especificamente\n",
    "    calibrated_test_prompts = ['grassclover_style_brachiaria', 'grassclover_style_mixed', 'grassclover_dense']\n",
    "    calibrated_results = []\n",
    "    \n",
    "    for i, prompt_key in enumerate(calibrated_test_prompts):\n",
    "        print(f\"üåæ Gerando {i+1}/{len(calibrated_test_prompts)}: {prompt_key}\")\n",
    "        \n",
    "        result = generate_grassclover_image(\n",
    "            prompt_key=prompt_key,\n",
    "            custom_seed=100 + i,  # Seeds diferentes\n",
    "            debug=False  # Menos verbose\n",
    "        )\n",
    "        \n",
    "        if result and result['success']:\n",
    "            # Aplicar p√≥s-processamento\n",
    "            processed = grassclover_postprocess(result['image'], intensity=1.0, debug=False)\n",
    "            result['processed_image'] = processed\n",
    "            result['metadata']['postprocessed'] = True\n",
    "            \n",
    "            calibrated_results.append(result)\n",
    "            print(f\"‚úÖ Conclu√≠do: {prompt_key}\")\n",
    "        else:\n",
    "            print(f\"‚ùå Falhou: {prompt_key}\")\n",
    "        \n",
    "        # Limpar mem√≥ria\n",
    "        if device_type == \"gpu\":\n",
    "            torch.cuda.empty_cache()\n",
    "    \n",
    "    print(f\"\\nüéâ {len(calibrated_results)} imagens calibradas geradas!\")\n",
    "    \n",
    "    # Executar compara√ß√£o\n",
    "    compare_with_grassclover_reference(calibrated_results, grassclover_analysis)\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå Pipeline n√£o est√° pronto para teste de calibra√ß√£o\")\n",
    "\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üÜö Compara√ß√£o com GrassClover Original\n",
    "\n",
    "Vamos comparar nossas imagens sint√©ticas com as refer√™ncias do GrassClover para avaliar a qualidade da reprodu√ß√£o do estilo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üé® P√ìS-PROCESSAMENTO ESTILO GRASSCLOVER\n",
    "print(\"üé® Configurando p√≥s-processamento GrassClover...\\n\")\n",
    "\n",
    "def grassclover_postprocess(image, intensity=1.0, debug=False):\n",
    "    \"\"\"\n",
    "    Aplica p√≥s-processamento para aproximar do estilo GrassClover\n",
    "    \n",
    "    Args:\n",
    "        image: PIL Image\n",
    "        intensity: Intensidade dos ajustes (0.0-2.0)\n",
    "        debug: Mostrar etapas do processamento\n",
    "    \n",
    "    Returns:\n",
    "        PIL Image processada\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        if debug:\n",
    "            print(f\"üé® Iniciando p√≥s-processamento (intensidade: {intensity})\")\n",
    "        \n",
    "        # C√≥pia para n√£o modificar original\n",
    "        processed = image.copy()\n",
    "        \n",
    "        # 1. Ajuste de contraste (GrassClover tem contraste marcante)\n",
    "        contrast_factor = 1.0 + (0.3 * intensity)\n",
    "        enhancer = ImageEnhance.Contrast(processed)\n",
    "        processed = enhancer.enhance(contrast_factor)\n",
    "        \n",
    "        if debug:\n",
    "            print(f\"  ‚úÖ Contraste ajustado: {contrast_factor:.2f}\")\n",
    "        \n",
    "        # 2. Ajuste de satura√ß√£o (verdes mais v√≠vidos)\n",
    "        saturation_factor = 1.0 + (0.2 * intensity)\n",
    "        enhancer = ImageEnhance.Color(processed)\n",
    "        processed = enhancer.enhance(saturation_factor)\n",
    "        \n",
    "        if debug:\n",
    "            print(f\"  ‚úÖ Satura√ß√£o ajustada: {saturation_factor:.2f}\")\n",
    "        \n",
    "        # 3. Sharpening sutil (detalhes de textura)\n",
    "        if intensity > 0.5:\n",
    "            sharpness_factor = 1.0 + (0.1 * intensity)\n",
    "            enhancer = ImageEnhance.Sharpness(processed)\n",
    "            processed = enhancer.enhance(sharpness_factor)\n",
    "            \n",
    "            if debug:\n",
    "                print(f\"  ‚úÖ Nitidez ajustada: {sharpness_factor:.2f}\")\n",
    "        \n",
    "        # 4. Slight blur para simular imperfei√ß√µes naturais\n",
    "        if intensity > 0.3:\n",
    "            blur_radius = 0.3 * intensity\n",
    "            processed = processed.filter(ImageFilter.GaussianBlur(radius=blur_radius))\n",
    "            \n",
    "            if debug:\n",
    "                print(f\"  ‚úÖ Blur natural aplicado: {blur_radius:.2f}px\")\n",
    "        \n",
    "        # 5. Ajuste de brilho (simular condi√ß√µes de campo)\n",
    "        brightness_factor = 1.0 + (0.05 * intensity * (np.random.random() - 0.5))\n",
    "        enhancer = ImageEnhance.Brightness(processed)\n",
    "        processed = enhancer.enhance(brightness_factor)\n",
    "        \n",
    "        if debug:\n",
    "            print(f\"  ‚úÖ Brilho ajustado: {brightness_factor:.2f}\")\n",
    "            print(f\"üéâ P√≥s-processamento conclu√≠do!\")\n",
    "        \n",
    "        return processed\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"üí• Erro no p√≥s-processamento: {e}\")\n",
    "        print(f\"üìã DEBUG COPY/PASTE:\")\n",
    "        print(f\"Image mode: {image.mode if image else 'None'}\")\n",
    "        print(f\"Image size: {image.size if image else 'None'}\")\n",
    "        print(f\"Intensity: {intensity}\")\n",
    "        print(f\"Error: {type(e).__name__}: {e}\")\n",
    "        return image  # Retornar original se falhar\n",
    "\n",
    "def compare_before_after(original, processed, title=\"Compara√ß√£o\"):\n",
    "    \"\"\"\n",
    "    Exibe compara√ß√£o lado a lado\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 7))\n",
    "    \n",
    "    axes[0].imshow(original)\n",
    "    axes[0].set_title(\"Original (Stable Diffusion)\", fontsize=12)\n",
    "    axes[0].axis('off')\n",
    "    \n",
    "    axes[1].imshow(processed)\n",
    "    axes[1].set_title(\"Processado (Estilo GrassClover)\", fontsize=12)\n",
    "    axes[1].axis('off')\n",
    "    \n",
    "    fig.suptitle(title, fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print(\"‚úÖ Fun√ß√µes de p√≥s-processamento configuradas!\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üß™ TESTE DO P√ìS-PROCESSAMENTO\n",
    "print(\"üß™ Testando p√≥s-processamento GrassClover...\\n\")\n",
    "\n",
    "if PIPELINE_READY and 'test_results' in locals() and test_results:\n",
    "    # Usar primeira imagem dos testes anteriores\n",
    "    test_image_data = test_results[0]\n",
    "    original_image = test_image_data['image']\n",
    "    \n",
    "    print(f\"üé® Aplicando p√≥s-processamento em: {test_image_data['metadata']['description']}\")\n",
    "    \n",
    "    # Aplicar p√≥s-processamento\n",
    "    processed_image = grassclover_postprocess(\n",
    "        image=original_image,\n",
    "        intensity=1.2,  # Intensidade m√©dia-alta\n",
    "        debug=True\n",
    "    )\n",
    "    \n",
    "    # Exibir compara√ß√£o\n",
    "    compare_before_after(\n",
    "        original=original_image,\n",
    "        processed=processed_image,\n",
    "        title=f\"P√≥s-processamento: {test_image_data['metadata']['description']}\"\n",
    "    )\n",
    "    \n",
    "    print(\"‚úÖ Teste de p√≥s-processamento conclu√≠do!\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Nenhuma imagem de teste dispon√≠vel para p√≥s-processamento\")\n",
    "    print(\"Execute primeiro a c√©lula de teste de gera√ß√£o\")\n",
    "\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üöÄ Gera√ß√£o em Lote com Seeds Diferentes\n",
    "\n",
    "Gera m√∫ltiplas varia√ß√µes de pastagens para criar um dataset diversificado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üöÄ GERA√á√ÉO EM LOTE - DATASET DIVERSIFICADO\n",
    "print(\"üöÄ Configurando gera√ß√£o em lote...\\n\")\n",
    "\n",
    "def generate_grassclover_batch(num_images=6, apply_postprocess=True, debug=True):\n",
    "    \"\"\"\n",
    "    Gera lote de imagens variadas estilo GrassClover\n",
    "    \n",
    "    Args:\n",
    "        num_images: N√∫mero total de imagens\n",
    "        apply_postprocess: Aplicar p√≥s-processamento\n",
    "        debug: Debugging detalhado\n",
    "        \n",
    "    Returns:\n",
    "        Lista de resultados\n",
    "    \"\"\"\n",
    "    \n",
    "    if not PIPELINE_READY:\n",
    "        print(\"‚ùå Pipeline n√£o est√° pronto!\")\n",
    "        return []\n",
    "    \n",
    "    # Distribuir tipos de pastagem\n",
    "    prompt_keys = list(GRASSCLOVER_PROMPTS.keys())\n",
    "    batch_results = []\n",
    "    \n",
    "    print(f\"üéØ Gerando {num_images} imagens com {len(prompt_keys)} tipos de pastagem...\\n\")\n",
    "    \n",
    "    for i in range(num_images):\n",
    "        # Selecionar tipo de pastagem (rota√ß√£o)\n",
    "        prompt_key = prompt_keys[i % len(prompt_keys)]\n",
    "        \n",
    "        # Seed √∫nica para cada imagem\n",
    "        seed = 42 + i * 100 + np.random.randint(0, 50)\n",
    "        \n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(f\"üåæ IMAGEM {i+1}/{num_images}: {prompt_key}\")\n",
    "        print(f\"üé≤ Seed: {seed}\")\n",
    "        print(f\"{'='*50}\")\n",
    "        \n",
    "        try:\n",
    "            # Gerar imagem base\n",
    "            result = generate_grassclover_image(\n",
    "                prompt_key=prompt_key,\n",
    "                custom_seed=seed,\n",
    "                debug=debug\n",
    "            )\n",
    "            \n",
    "            if result['success']:\n",
    "                # Aplicar p√≥s-processamento se solicitado\n",
    "                if apply_postprocess:\n",
    "                    processed_image = grassclover_postprocess(\n",
    "                        image=result['image'],\n",
    "                        intensity=np.random.uniform(0.8, 1.4),  # Varia√ß√£o aleat√≥ria\n",
    "                        debug=False\n",
    "                    )\n",
    "                    \n",
    "                    # Atualizar resultado\n",
    "                    result['processed_image'] = processed_image\n",
    "                    result['metadata']['postprocessed'] = True\n",
    "                    \n",
    "                    if debug:\n",
    "                        print(\"üé® P√≥s-processamento aplicado\")\n",
    "                \n",
    "                # Adicionar √≠ndice\n",
    "                result['metadata']['batch_index'] = i\n",
    "                result['metadata']['total_batch'] = num_images\n",
    "                \n",
    "                batch_results.append(result)\n",
    "                print(f\"‚úÖ Sucesso! ({len(batch_results)}/{num_images})\")\n",
    "                \n",
    "            else:\n",
    "                print(f\"‚ùå Falha na gera√ß√£o da imagem {i+1}\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"üí• Erro na imagem {i+1}: {e}\")\n",
    "            if debug:\n",
    "                print(f\"Prompt key: {prompt_key}\")\n",
    "                print(f\"Seed: {seed}\")\n",
    "        \n",
    "        # Limpeza entre gera√ß√µes\n",
    "        if device.type == \"cuda\":\n",
    "            torch.cuda.empty_cache()\n",
    "    \n",
    "    print(f\"\\nüéâ Lote conclu√≠do: {len(batch_results)}/{num_images} imagens geradas!\")\n",
    "    return batch_results\n",
    "\n",
    "def display_batch_results(batch_results, max_display=6):\n",
    "    \"\"\"\n",
    "    Exibe resultados do lote em grid\n",
    "    \"\"\"\n",
    "    if not batch_results:\n",
    "        print(\"‚ùå Nenhum resultado para exibir\")\n",
    "        return\n",
    "    \n",
    "    # Limitar exibi√ß√£o\n",
    "    results_to_show = batch_results[:max_display]\n",
    "    n_images = len(results_to_show)\n",
    "    \n",
    "    # Calcular grid\n",
    "    cols = min(3, n_images)\n",
    "    rows = (n_images + cols - 1) // cols\n",
    "    \n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(5*cols, 5*rows))\n",
    "    \n",
    "    # Garantir que axes seja sempre 2D\n",
    "    if rows == 1:\n",
    "        axes = axes.reshape(1, -1)\n",
    "    if cols == 1:\n",
    "        axes = axes.reshape(-1, 1)\n",
    "    \n",
    "    for i, result in enumerate(results_to_show):\n",
    "        row = i // cols\n",
    "        col = i % cols\n",
    "        \n",
    "        # Usar imagem processada se dispon√≠vel\n",
    "        image = result.get('processed_image', result['image'])\n",
    "        \n",
    "        axes[row, col].imshow(image)\n",
    "        axes[row, col].axis('off')\n",
    "        \n",
    "        # T√≠tulo com informa√ß√µes\n",
    "        metadata = result['metadata']\n",
    "        title = f\"{metadata['description']}\\nSeed: {metadata['seed']}\"\n",
    "        axes[row, col].set_title(title, fontsize=10)\n",
    "    \n",
    "    # Ocultar eixos n√£o usados\n",
    "    for i in range(n_images, rows * cols):\n",
    "        row = i // cols\n",
    "        col = i % cols\n",
    "        axes[row, col].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.suptitle(f\"üåæ Dataset GrassClover Brasileiro - {n_images} Imagens\", \n",
    "                fontsize=16, fontweight='bold', y=0.98)\n",
    "    plt.show()\n",
    "\n",
    "print(\"‚úÖ Fun√ß√µes de gera√ß√£o em lote configuradas!\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üöÄ EXECUTAR GERA√á√ÉO EM LOTE\n",
    "print(\"üöÄ Iniciando gera√ß√£o em lote...\\n\")\n",
    "\n",
    "if PIPELINE_READY:\n",
    "    # Configura√ß√µes do lote\n",
    "    BATCH_SIZE = 6  # N√∫mero total de imagens\n",
    "    APPLY_POSTPROCESS = True\n",
    "    \n",
    "    print(f\"‚öôÔ∏è  Configura√ß√µes:\")\n",
    "    print(f\"  ‚Ä¢ Imagens: {BATCH_SIZE}\")\n",
    "    print(f\"  ‚Ä¢ P√≥s-processamento: {APPLY_POSTPROCESS}\")\n",
    "    print(f\"  ‚Ä¢ Device: {device}\")\n",
    "    print(f\"  ‚Ä¢ Tipos dispon√≠veis: {len(GRASSCLOVER_PROMPTS)}\")\n",
    "    \n",
    "    # Gerar lote\n",
    "    batch_results = generate_grassclover_batch(\n",
    "        num_images=BATCH_SIZE,\n",
    "        apply_postprocess=APPLY_POSTPROCESS,\n",
    "        debug=True\n",
    "    )\n",
    "    \n",
    "    # Exibir resultados\n",
    "    if batch_results:\n",
    "        print(f\"\\nüìä Estat√≠sticas do Lote:\")\n",
    "        print(f\"  ‚Ä¢ Total gerado: {len(batch_results)}/{BATCH_SIZE}\")\n",
    "        print(f\"  ‚Ä¢ Taxa de sucesso: {len(batch_results)/BATCH_SIZE*100:.1f}%\")\n",
    "        \n",
    "        # Contagem por tipo\n",
    "        type_counts = {}\n",
    "        for result in batch_results:\n",
    "            prompt_key = result['metadata']['prompt_key']\n",
    "            type_counts[prompt_key] = type_counts.get(prompt_key, 0) + 1\n",
    "        \n",
    "        print(f\"  ‚Ä¢ Distribui√ß√£o por tipo:\")\n",
    "        for prompt_key, count in type_counts.items():\n",
    "            description = GRASSCLOVER_PROMPTS[prompt_key]['description']\n",
    "            print(f\"    - {description}: {count} imagens\")\n",
    "        \n",
    "        # Exibir grid\n",
    "        print(f\"\\nüñºÔ∏è  Exibindo resultados...\")\n",
    "        display_batch_results(batch_results)\n",
    "        \n",
    "        print(f\"\\n‚úÖ Lote conclu√≠do com sucesso!\")\n",
    "        \n",
    "    else:\n",
    "        print(f\"‚ùå Nenhuma imagem foi gerada no lote!\")\n",
    "        \n",
    "else:\n",
    "    print(\"‚ùå Pipeline n√£o est√° pronto - n√£o √© poss√≠vel gerar lote\")\n",
    "\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üíæ Salvamento das Imagens\n",
    "\n",
    "Salva as imagens geradas com metadados organizados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üíæ SALVAMENTO ORGANIZADO DAS IMAGENS\n",
    "print(\"üíæ Configurando sistema de salvamento...\\n\")\n",
    "\n",
    "import os\n",
    "import json\n",
    "\n",
    "def save_grassclover_batch(batch_results, output_dir=\"grassclover_generated\", save_metadata=True):\n",
    "    \"\"\"\n",
    "    Salva lote de imagens com organiza√ß√£o e metadados\n",
    "    \n",
    "    Args:\n",
    "        batch_results: Lista de resultados da gera√ß√£o\n",
    "        output_dir: Diret√≥rio de sa√≠da\n",
    "        save_metadata: Salvar arquivos JSON com metadados\n",
    "        \n",
    "    Returns:\n",
    "        dict com estat√≠sticas de salvamento\n",
    "    \"\"\"\n",
    "    \n",
    "    if not batch_results:\n",
    "        print(\"‚ùå Nenhuma imagem para salvar!\")\n",
    "        return {'success': False, 'saved_count': 0}\n",
    "    \n",
    "    try:\n",
    "        # Criar diret√≥rios\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        images_dir = os.path.join(output_dir, \"images\")\n",
    "        metadata_dir = os.path.join(output_dir, \"metadata\")\n",
    "        \n",
    "        os.makedirs(images_dir, exist_ok=True)\n",
    "        if save_metadata:\n",
    "            os.makedirs(metadata_dir, exist_ok=True)\n",
    "        \n",
    "        print(f\"üìÅ Diret√≥rios criados:\")\n",
    "        print(f\"  ‚Ä¢ Principal: {output_dir}\")\n",
    "        print(f\"  ‚Ä¢ Imagens: {images_dir}\")\n",
    "        if save_metadata:\n",
    "            print(f\"  ‚Ä¢ Metadados: {metadata_dir}\")\n",
    "        \n",
    "        saved_count = 0\n",
    "        saved_files = []\n",
    "        \n",
    "        # Salvar cada imagem\n",
    "        for i, result in enumerate(batch_results):\n",
    "            try:\n",
    "                metadata = result['metadata']\n",
    "                prompt_key = metadata['prompt_key']\n",
    "                seed = metadata['seed']\n",
    "                \n",
    "                # Nome do arquivo\n",
    "                filename_base = f\"grassclover_{prompt_key}_{seed:06d}\"\n",
    "                \n",
    "                # Salvar imagem original\n",
    "                original_path = os.path.join(images_dir, f\"{filename_base}_original.png\")\n",
    "                result['image'].save(original_path, 'PNG')\n",
    "                \n",
    "                files_saved = [original_path]\n",
    "                \n",
    "                # Salvar imagem processada se existir\n",
    "                if 'processed_image' in result:\n",
    "                    processed_path = os.path.join(images_dir, f\"{filename_base}_processed.png\")\n",
    "                    result['processed_image'].save(processed_path, 'PNG')\n",
    "                    files_saved.append(processed_path)\n",
    "                \n",
    "                # Salvar metadados\n",
    "                if save_metadata:\n",
    "                    metadata_path = os.path.join(metadata_dir, f\"{filename_base}.json\")\n",
    "                    \n",
    "                    # Preparar metadados para JSON (remover objetos n√£o serializ√°veis)\n",
    "                    json_metadata = metadata.copy()\n",
    "                    json_metadata['files_saved'] = files_saved\n",
    "                    json_metadata['save_timestamp'] = datetime.now().isoformat()\n",
    "                    \n",
    "                    with open(metadata_path, 'w', encoding='utf-8') as f:\n",
    "                        json.dump(json_metadata, f, indent=2, ensure_ascii=False)\n",
    "                    \n",
    "                    files_saved.append(metadata_path)\n",
    "                \n",
    "                saved_files.extend(files_saved)\n",
    "                saved_count += 1\n",
    "                \n",
    "                print(f\"‚úÖ Salvo {i+1}/{len(batch_results)}: {filename_base}\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"‚ùå Erro ao salvar imagem {i+1}: {e}\")\n",
    "                continue\n",
    "        \n",
    "        # Criar √≠ndice geral\n",
    "        if save_metadata:\n",
    "            index_data = {\n",
    "                'dataset_name': 'GrassClover Brazilian Synthetic',\n",
    "                'generation_date': datetime.now().isoformat(),\n",
    "                'total_images': len(batch_results),\n",
    "                'saved_images': saved_count,\n",
    "                'model_used': MODEL_ID,\n",
    "                'device': str(device),\n",
    "                'prompt_types': list(set(r['metadata']['prompt_key'] for r in batch_results)),\n",
    "                'files': saved_files\n",
    "            }\n",
    "            \n",
    "            index_path = os.path.join(output_dir, \"dataset_index.json\")\n",
    "            with open(index_path, 'w', encoding='utf-8') as f:\n",
    "                json.dump(index_data, f, indent=2, ensure_ascii=False)\n",
    "            \n",
    "            print(f\"üìã √çndice salvo: {index_path}\")\n",
    "        \n",
    "        print(f\"\\nüéâ Salvamento conclu√≠do!\")\n",
    "        print(f\"  ‚Ä¢ Imagens salvas: {saved_count}/{len(batch_results)}\")\n",
    "        print(f\"  ‚Ä¢ Arquivos totais: {len(saved_files)}\")\n",
    "        print(f\"  ‚Ä¢ Diret√≥rio: {os.path.abspath(output_dir)}\")\n",
    "        \n",
    "        return {\n",
    "            'success': True,\n",
    "            'saved_count': saved_count,\n",
    "            'total_files': len(saved_files),\n",
    "            'output_dir': os.path.abspath(output_dir),\n",
    "            'files': saved_files\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"üí• Erro no salvamento: {e}\")\n",
    "        print(f\"üìã DEBUG COPY/PASTE:\")\n",
    "        print(f\"Output dir: {output_dir}\")\n",
    "        print(f\"Batch results count: {len(batch_results) if batch_results else 0}\")\n",
    "        print(f\"Error: {type(e).__name__}: {e}\")\n",
    "        \n",
    "        return {\n",
    "            'success': False,\n",
    "            'saved_count': 0,\n",
    "            'error': str(e)\n",
    "        }\n",
    "\n",
    "print(\"‚úÖ Sistema de salvamento configurado!\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üíæ SALVAR LOTE GERADO\n",
    "print(\"üíæ Salvando lote de imagens...\\n\")\n",
    "\n",
    "if 'batch_results' in locals() and batch_results:\n",
    "    # Configura√ß√µes de salvamento\n",
    "    OUTPUT_DIR = \"grassclover_synthetic_dataset\"\n",
    "    SAVE_METADATA = True\n",
    "    \n",
    "    print(f\"‚öôÔ∏è  Configura√ß√µes de salvamento:\")\n",
    "    print(f\"  ‚Ä¢ Diret√≥rio: {OUTPUT_DIR}\")\n",
    "    print(f\"  ‚Ä¢ Salvar metadados: {SAVE_METADATA}\")\n",
    "    print(f\"  ‚Ä¢ Imagens a salvar: {len(batch_results)}\")\n",
    "    \n",
    "    # Executar salvamento\n",
    "    save_result = save_grassclover_batch(\n",
    "        batch_results=batch_results,\n",
    "        output_dir=OUTPUT_DIR,\n",
    "        save_metadata=SAVE_METADATA\n",
    "    )\n",
    "    \n",
    "    # Resultado\n",
    "    if save_result['success']:\n",
    "        print(f\"\\nüìä Resumo do Salvamento:\")\n",
    "        print(f\"  ‚úÖ Sucesso: {save_result['saved_count']} imagens salvas\")\n",
    "        print(f\"  üìÅ Localiza√ß√£o: {save_result['output_dir']}\")\n",
    "        print(f\"  üìÑ Arquivos totais: {save_result['total_files']}\")\n",
    "        \n",
    "        # Listar estrutura de diret√≥rios\n",
    "        print(f\"\\nüìã Estrutura criada:\")\n",
    "        if os.path.exists(save_result['output_dir']):\n",
    "            for root, dirs, files in os.walk(save_result['output_dir']):\n",
    "                level = root.replace(save_result['output_dir'], '').count(os.sep)\n",
    "                indent = ' ' * 2 * level\n",
    "                print(f\"{indent}{os.path.basename(root)}/\")\n",
    "                subindent = ' ' * 2 * (level + 1)\n",
    "                for file in files[:3]:  # Mostrar s√≥ os primeiros 3 arquivos\n",
    "                    print(f\"{subindent}{file}\")\n",
    "                if len(files) > 3:\n",
    "                    print(f\"{subindent}... e mais {len(files)-3} arquivos\")\n",
    "        \n",
    "        print(f\"\\nüéâ Dataset salvo com sucesso!\")\n",
    "        print(f\"üìÇ Para acessar: {save_result['output_dir']}\")\n",
    "        \n",
    "    else:\n",
    "        print(f\"‚ùå Falha no salvamento: {save_result.get('error', 'Erro desconhecido')}\")\n",
    "        \n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Nenhum lote de imagens dispon√≠vel para salvar\")\n",
    "    print(\"Execute primeiro a c√©lula de gera√ß√£o em lote\")\n",
    "\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Relat√≥rio Final e Estat√≠sticas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## üí° Instru√ß√µes para Uso e Debugging\n",
    "\n",
    "### üö® **Em caso de erro:**\n",
    "1. **Copie a se√ß√£o \"DEBUG COPY/PASTE\"** que aparece nos erros\n",
    "2. **Cole aqui nos coment√°rios** ou no chat para an√°lise\n",
    "3. **Inclua informa√ß√µes do sistema** (GPU, mem√≥ria, etc.)\n",
    "\n",
    "### üîß **Problemas Comuns Resolvidos:**\n",
    "\n",
    "#### **‚úÖ TPU Runtime Problem (RESOLVIDO)**\n",
    "- **Detec√ß√£o autom√°tica** de TPU/GPU/CPU\n",
    "- **Configura√ß√£o otimizada** para cada tipo de hardware\n",
    "- **Instru√ß√µes claras** para configura√ß√£o do runtime\n",
    "\n",
    "#### **‚úÖ Hugging Face Token Warning (RESOLVIDO)**\n",
    "- **Bypass autom√°tico** de problemas de autentica√ß√£o\n",
    "- **Configura√ß√£o de ambiente** para evitar warnings\n",
    "- **Downloads funcionam normalmente** mesmo com warnings\n",
    "\n",
    "#### **‚úÖ Dtype Configuration (RESOLVIDO)**\n",
    "- **float16 para GPU** (performance otimizada)\n",
    "- **float32 para TPU/CPU** (compatibilidade garantida)\n",
    "- **Configura√ß√£o autom√°tica** baseada no hardware\n",
    "\n",
    "### üéØ **Configura√ß√£o Recomendada para Colab:**\n",
    "- **Runtime**: GPU (Tesla T4 ou superior)\n",
    "- **Reasoning**: Stable Diffusion funciona melhor em GPU que TPU\n",
    "- **Fallback**: TPU funciona, mas GPU √© mais r√°pido para este caso\n",
    "\n",
    "### üîß **Ajustes poss√≠veis:**\n",
    "- **GENERATION_PARAMS**: Modifique `num_inference_steps` (15-50) para balancear qualidade/velocidade\n",
    "- **BATCH_SIZE**: Reduza se houver problemas de mem√≥ria\n",
    "- **Seeds**: Mude para explorar diferentes varia√ß√µes\n",
    "- **Prompts**: Ajuste para obter estilos visuais espec√≠ficos\n",
    "\n",
    "### üì∏ **Para adicionar refer√™ncias GrassClover:**\n",
    "1. **Upload das imagens** na se√ß√£o de arquivos do Colab\n",
    "2. **Modifique os prompts** baseado nas caracter√≠sticas visuais\n",
    "3. **Ajuste p√≥s-processamento** para aproximar do estilo original\n",
    "\n",
    "### üéØ **M√©tricas de qualidade:**\n",
    "- **Cobertura densa**: Pastagens devem ter ‚â•80% de cobertura vegetal\n",
    "- **Perspectiva top-down**: Vista a√©rea consistente\n",
    "- **Textura real√≠stica**: Detalhes de folhas e solo vis√≠veis\n",
    "- **Diversidade**: Varia√ß√£o entre as imagens geradas\n",
    "\n",
    "### üöÄ **Performance por Hardware:**\n",
    "- **GPU (Tesla T4)**: ~30-45s por imagem (recomendado)\n",
    "- **GPU (V100/A100)**: ~15-25s por imagem (√≥timo)\n",
    "- **TPU**: ~45-60s por imagem (funciona)\n",
    "- **CPU**: ~5-10min por imagem (muito lento, n√£o recomendado)\n",
    "\n",
    "---\n",
    "\n",
    "**üåæ Dataset GrassClover Brasileiro - Gerado com Stable Diffusion**  \n",
    "Baseado na metodologia de Skovsen et al. (CVPR 2019) adaptada para gram√≠neas tropicais.\n",
    "\n",
    "**üìã Problemas Comuns Resolvidos**: TPU detection, HF authentication, dtype optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üí° Instru√ß√µes para Uso e Debugging\n",
    "\n",
    "### üö® **Em caso de erro:**\n",
    "1. **Copie a se√ß√£o \"DEBUG COPY/PASTE\"** que aparece nos erros\n",
    "2. **Cole aqui nos coment√°rios** ou no chat para an√°lise\n",
    "3. **Inclua informa√ß√µes do sistema** (GPU, mem√≥ria, etc.)\n",
    "\n",
    "### üîß **Ajustes poss√≠veis:**\n",
    "- **GENERATION_PARAMS**: Modifique `num_inference_steps` (15-50) para balancear qualidade/velocidade\n",
    "- **BATCH_SIZE**: Reduza se houver problemas de mem√≥ria\n",
    "- **Seeds**: Mude para explorar diferentes varia√ß√µes\n",
    "- **Prompts**: Ajuste para obter estilos visuais espec√≠ficos\n",
    "\n",
    "### üì∏ **Para adicionar refer√™ncias GrassClover:**\n",
    "1. **Upload das imagens** na se√ß√£o de arquivos do Colab\n",
    "2. **Modifique os prompts** baseado nas caracter√≠sticas visuais\n",
    "3. **Ajuste p√≥s-processamento** para aproximar do estilo original\n",
    "\n",
    "### üéØ **M√©tricas de qualidade:**\n",
    "- **Cobertura densa**: Pastagens devem ter ‚â•80% de cobertura vegetal\n",
    "- **Perspectiva top-down**: Vista a√©rea consistente\n",
    "- **Textura real√≠stica**: Detalhes de folhas e solo vis√≠veis\n",
    "- **Diversidade**: Varia√ß√£o entre as imagens geradas\n",
    "\n",
    "---\n",
    "\n",
    "**üåæ Dataset GrassClover Brasileiro - Gerado com Stable Diffusion**  \n",
    "Baseado na metodologia de Skovsen et al. (CVPR 2019) adaptada para gram√≠neas tropicais."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
