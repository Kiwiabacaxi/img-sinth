{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stable Diffusion 3.5 Medium - Validation Test\n",
    "\n",
    "Simple notebook to validate Stable Diffusion 3.5 Medium model functionality on Google Colab Pro (L4 GPU).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install diffusers transformers accelerate torch torchvision huggingface_hub --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import torch\n",
    "from diffusers import StableDiffusion3Pipeline\n",
    "from huggingface_hub import login\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU availability\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hugging Face login (required for SD 3.5 Medium)\n",
    "# You'll need to enter your HF token when prompted\n",
    "login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Load the Stable Diffusion 3.5 Medium model\nprint(\"Loading Stable Diffusion 3.5 Medium...\")\npipe = StableDiffusion3Pipeline.from_pretrained(\n    \"stabilityai/stable-diffusion-3.5-medium\",\n    torch_dtype=torch.float16,\n    device_map=\"balanced\"\n)\n\nprint(\"Model loaded successfully!\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test prompt for validation\n",
    "test_prompt = \"A serene landscape with mountains and a lake at sunset, photorealistic\"\n",
    "\n",
    "print(f\"Generating image with prompt: '{test_prompt}'\")\n",
    "print(\"This may take a few minutes...\")\n",
    "\n",
    "# Generate image\n",
    "with torch.inference_mode():\n",
    "    image = pipe(\n",
    "        test_prompt,\n",
    "        num_inference_steps=20,\n",
    "        guidance_scale=7.0,\n",
    "        height=1024,\n",
    "        width=1024\n",
    "    ).images[0]\n",
    "\n",
    "print(\"Image generated successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the generated image\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(image)\n",
    "plt.axis('off')\n",
    "plt.title(f\"Generated Image: {test_prompt}\")\n",
    "plt.show()\n",
    "\n",
    "# Save the image\n",
    "image.save(\"test_generation.png\")\n",
    "print(\"Image saved as 'test_generation.png'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for easy prompt testing\n",
    "def generate_image(prompt, steps=20, guidance=7.0, width=1024, height=1024):\n",
    "    \"\"\"\n",
    "    Generate an image with the given prompt\n",
    "    \"\"\"\n",
    "    print(f\"Generating: '{prompt}'\")\n",
    "    \n",
    "    with torch.inference_mode():\n",
    "        image = pipe(\n",
    "            prompt,\n",
    "            num_inference_steps=steps,\n",
    "            guidance_scale=guidance,\n",
    "            height=height,\n",
    "            width=width\n",
    "        ).images[0]\n",
    "    \n",
    "    # Display\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.imshow(image)\n",
    "    plt.axis('off')\n",
    "    plt.title(prompt)\n",
    "    plt.show()\n",
    "    \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Test with your own prompts\n",
    "# Uncomment and modify the line below to test different prompts\n",
    "\n",
    "# custom_prompt = \"Your custom prompt here\"\n",
    "# custom_image = generate_image(custom_prompt)\n",
    "# custom_image.save(\"custom_generation.png\")\n",
    "\n",
    "print(\"Ready for custom prompt testing!\")\n",
    "print(\"Use the generate_image() function to test your own prompts.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}