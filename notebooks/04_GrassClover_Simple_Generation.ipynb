{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# 🌾 Brazilian GrassClover: Geração Sintética Simplificada\n",
    "\n",
    "Este notebook implementa a metodologia do **GrassClover Dataset** para gramíneas brasileiras usando **geração procedural** e **bibliotecas básicas** para evitar conflitos de dependências.\n",
    "\n",
    "**Baseado em:** Skovsen et al. \"The GrassClover Image Dataset for Semantic and Hierarchical Species Understanding in Agriculture\" (CVPR Workshops, 2019)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "## 📦 Instalação Simplificada (Sem Conflitos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependências básicas e estáveis\n",
    "!pip install \"numpy==1.26.4\" \"opencv-python-headless\" \"pillow\" \"matplotlib\" \"seaborn\" --quiet\n",
    "!pip install \"scikit-image\" \"scipy\" \"albumentations\" --quiet\n",
    "!pip install \"ultralytics\" --quiet\n",
    "\n",
    "# Verificar instalação\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image, ImageDraw, ImageFilter, ImageEnhance\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from matplotlib.colors import ListedColormap\n",
    "import seaborn as sns\n",
    "from skimage import filters, morphology, segmentation, measure\n",
    "from scipy import ndimage\n",
    "import albumentations as A\n",
    "\n",
    "import os\n",
    "import json\n",
    "import random\n",
    "import math\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from collections import defaultdict, Counter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Seeds para reprodutibilidade\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "print(f\"✅ NumPy: {np.__version__}\")\n",
    "print(f\"✅ OpenCV: {cv2.__version__}\")\n",
    "print(f\"✅ Todas as dependências carregadas com sucesso!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-3",
   "metadata": {},
   "source": [
    "## 🌱 Classes e Configurações - GrassClover Brasileiro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classes hierárquicas seguindo metodologia GrassClover\n",
    "GRASS_CLOVER_CLASSES = {\n",
    "    'background': {'id': 0, 'color': (0, 0, 0), 'name': 'Background'},\n",
    "    'soil': {'id': 1, 'color': (139, 69, 19), 'name': 'Solo'},\n",
    "    'brachiaria': {'id': 2, 'color': (34, 139, 34), 'name': 'Brachiaria'},\n",
    "    'panicum': {'id': 3, 'color': (50, 205, 50), 'name': 'Panicum'},\n",
    "    'cynodon': {'id': 4, 'color': (0, 255, 127), 'name': 'Cynodon'},\n",
    "    'leguminous': {'id': 5, 'color': (255, 20, 147), 'name': 'Leguminosas'},\n",
    "    'weeds': {'id': 6, 'color': (255, 165, 0), 'name': 'Ervas Daninhas'}\n",
    "}\n",
    "\n",
    "CLASS_COLORS = [cls['color'] for cls in GRASS_CLOVER_CLASSES.values()]\n",
    "CLASS_NAMES = [cls['name'] for cls in GRASS_CLOVER_CLASSES.values()]\n",
    "NUM_CLASSES = len(GRASS_CLOVER_CLASSES)\n",
    "\n",
    "# Colormap personalizado\n",
    "cmap_grass = ListedColormap([np.array(color)/255.0 for color in CLASS_COLORS])\n",
    "\n",
    "print(f\"📊 {NUM_CLASSES} classes definidas:\")\n",
    "for name, info in GRASS_CLOVER_CLASSES.items():\n",
    "    print(f\"  {info['id']}: {info['name']}\")\n",
    "\n",
    "# Visualizar paleta\n",
    "fig, ax = plt.subplots(1, 1, figsize=(12, 2))\n",
    "colors_array = np.array(CLASS_COLORS).reshape(1, -1, 3) / 255.0\n",
    "ax.imshow(colors_array, aspect='auto')\n",
    "ax.set_xticks(range(len(CLASS_NAMES)))\n",
    "ax.set_xticklabels(CLASS_NAMES, rotation=45, ha='right')\n",
    "ax.set_yticks([])\n",
    "ax.set_title('🎨 Paleta de Classes - GrassClover Brasileiro')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-5",
   "metadata": {},
   "source": [
    "## 🎨 Gerador Procedural de Texturas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProceduralTextureGenerator:\n",
    "    \"\"\"\n",
    "    Gerador procedural de texturas para solo e plantas\n",
    "    Evita dependências problemáticas do Stable Diffusion\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, image_size=(512, 512)):\n",
    "        self.image_size = image_size\n",
    "        \n",
    "    def generate_soil_texture(self, soil_type=\"tropical\"):\n",
    "        \"\"\"Gera textura de solo procedural\"\"\"\n",
    "        h, w = self.image_size\n",
    "        \n",
    "        # Cores base do solo brasileiro\n",
    "        soil_colors = {\n",
    "            'tropical': [(139, 69, 19), (160, 82, 45), (205, 133, 63)],\n",
    "            'cerrado': [(139, 90, 43), (165, 108, 64), (188, 143, 107)],\n",
    "            'clay': [(139, 54, 38), (160, 65, 47), (181, 83, 65)]\n",
    "        }\n",
    "        \n",
    "        colors = soil_colors.get(soil_type, soil_colors['tropical'])\n",
    "        \n",
    "        # Criar textura base com ruído\n",
    "        noise = np.random.random((h, w))\n",
    "        \n",
    "        # Aplicar filtro gaussiano para suavizar\n",
    "        noise_smooth = filters.gaussian(noise, sigma=2)\n",
    "        \n",
    "        # Criar imagem colorida\n",
    "        soil_img = np.zeros((h, w, 3), dtype=np.uint8)\n",
    "        \n",
    "        # Aplicar cores baseadas no ruído\n",
    "        for i in range(len(colors)):\n",
    "            threshold_low = i / len(colors)\n",
    "            threshold_high = (i + 1) / len(colors)\n",
    "            \n",
    "            mask = (noise_smooth >= threshold_low) & (noise_smooth < threshold_high)\n",
    "            soil_img[mask] = colors[i]\n",
    "        \n",
    "        # Adicionar variação de brilho\n",
    "        brightness_var = (np.random.random((h, w, 1)) - 0.5) * 30\n",
    "        soil_img = np.clip(soil_img + brightness_var, 0, 255).astype(np.uint8)\n",
    "        \n",
    "        return Image.fromarray(soil_img)\n",
    "    \n",
    "    def generate_grass_blade(self, grass_type=\"brachiaria\", size=(64, 64)):\n",
    "        \"\"\"Gera uma folha de grama individual\"\"\"\n",
    "        h, w = size\n",
    "        \n",
    "        # Parâmetros por tipo de gramínea\n",
    "        grass_params = {\n",
    "            'brachiaria': {'color': (34, 139, 34), 'width_ratio': 0.6, 'curve': 0.3},\n",
    "            'panicum': {'color': (50, 205, 50), 'width_ratio': 0.8, 'curve': 0.5},\n",
    "            'cynodon': {'color': (0, 255, 127), 'width_ratio': 0.4, 'curve': 0.2},\n",
    "            'leguminous': {'color': (255, 20, 147), 'width_ratio': 0.9, 'curve': 0.1},\n",
    "            'weeds': {'color': (255, 165, 0), 'width_ratio': 0.5, 'curve': 0.7}\n",
    "        }\n",
    "        \n",
    "        params = grass_params.get(grass_type, grass_params['brachiaria'])\n",
    "        \n",
    "        # Criar imagem transparente\n",
    "        img = Image.new('RGBA', (w, h), (0, 0, 0, 0))\n",
    "        draw = ImageDraw.Draw(img)\n",
    "        \n",
    "        # Desenhar folha de grama\n",
    "        blade_width = int(w * params['width_ratio'])\n",
    "        center_x = w // 2\n",
    "        \n",
    "        # Pontos para criar uma folha curvada\n",
    "        points = []\n",
    "        for y in range(h):\n",
    "            progress = y / h\n",
    "            \n",
    "            # Largura varia do topo para a base\n",
    "            current_width = blade_width * (0.1 + 0.9 * progress)\n",
    "            \n",
    "            # Curvatura\n",
    "            curve_offset = int(params['curve'] * w * math.sin(progress * math.pi))\n",
    "            \n",
    "            left_x = center_x - current_width // 2 + curve_offset\n",
    "            right_x = center_x + current_width // 2 + curve_offset\n",
    "            \n",
    "            points.append((left_x, y))\n",
    "        \n",
    "        # Adicionar pontos da volta (lado direito)\n",
    "        for y in range(h-1, -1, -1):\n",
    "            progress = y / h\n",
    "            current_width = blade_width * (0.1 + 0.9 * progress)\n",
    "            curve_offset = int(params['curve'] * w * math.sin(progress * math.pi))\n",
    "            right_x = center_x + current_width // 2 + curve_offset\n",
    "            points.append((right_x, y))\n",
    "        \n",
    "        # Desenhar polígono da folha\n",
    "        base_color = params['color']\n",
    "        \n",
    "        # Variação de cor para realismo\n",
    "        color_var = [random.randint(-20, 20) for _ in range(3)]\n",
    "        final_color = tuple(max(0, min(255, base_color[i] + color_var[i])) for i in range(3))\n",
    "        \n",
    "        draw.polygon(points, fill=final_color + (255,))\n",
    "        \n",
    "        # Adicionar nervura central\n",
    "        nervure_color = tuple(max(0, c - 30) for c in final_color)\n",
    "        for y in range(h):\n",
    "            progress = y / h\n",
    "            curve_offset = int(params['curve'] * w * math.sin(progress * math.pi))\n",
    "            x = center_x + curve_offset\n",
    "            draw.point((x, y), fill=nervure_color + (255,))\n",
    "        \n",
    "        return img\n",
    "    \n",
    "    def create_plant_cluster(self, plant_type=\"brachiaria\", num_blades=5):\n",
    "        \"\"\"Cria um agrupamento de folhas\"\"\"\n",
    "        cluster_size = (128, 128)\n",
    "        cluster = Image.new('RGBA', cluster_size, (0, 0, 0, 0))\n",
    "        \n",
    "        for _ in range(num_blades):\n",
    "            # Gerar folha individual\n",
    "            blade_size = (random.randint(40, 80), random.randint(60, 100))\n",
    "            blade = self.generate_grass_blade(plant_type, blade_size)\n",
    "            \n",
    "            # Rotação aleatória\n",
    "            angle = random.randint(-30, 30)\n",
    "            blade = blade.rotate(angle, expand=True)\n",
    "            \n",
    "            # Posição aleatória no cluster\n",
    "            max_x = cluster_size[0] - blade.size[0]\n",
    "            max_y = cluster_size[1] - blade.size[1]\n",
    "            \n",
    "            if max_x > 0 and max_y > 0:\n",
    "                pos_x = random.randint(0, max_x)\n",
    "                pos_y = random.randint(0, max_y)\n",
    "                \n",
    "                # Compor no cluster\n",
    "                cluster.alpha_composite(blade, (pos_x, pos_y))\n",
    "        \n",
    "        return cluster\n",
    "\n",
    "# Criar gerador\n",
    "generator = ProceduralTextureGenerator()\n",
    "print(\"🎨 Gerador procedural criado!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-7",
   "metadata": {},
   "source": [
    "## 🌾 Gerador de Dataset Sintético - Metodologia GrassClover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BrazilianGrassCloverDataset:\n",
    "    \"\"\"\n",
    "    Gerador de dataset seguindo metodologia GrassClover\n",
    "    Usando geração procedural ao invés de Stable Diffusion\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, image_size=(512, 512), gsd=6):\n",
    "        self.image_size = image_size\n",
    "        self.gsd = gsd  # Ground Sampling Distance (px/mm)\n",
    "        self.texture_gen = ProceduralTextureGenerator(image_size)\n",
    "        \n",
    "    def generate_synthetic_scene(self, target_lai=2.0, composition=None):\n",
    "        \"\"\"\n",
    "        Gera cena sintética completa\n",
    "        \n",
    "        Args:\n",
    "            target_lai: Leaf Area Index desejado (1.0-4.0)\n",
    "            composition: Dict com proporção de cada classe\n",
    "        \"\"\"\n",
    "        if composition is None:\n",
    "            composition = {\n",
    "                'brachiaria': 0.4,\n",
    "                'panicum': 0.3, \n",
    "                'cynodon': 0.15,\n",
    "                'leguminous': 0.1,\n",
    "                'weeds': 0.05\n",
    "            }\n",
    "        \n",
    "        print(f\"🌱 Gerando cena (LAI: {target_lai:.1f})...\")\n",
    "        \n",
    "        # 1. Gerar solo base\n",
    "        soil_types = ['tropical', 'cerrado', 'clay']\n",
    "        soil_type = random.choice(soil_types)\n",
    "        scene_img = self.texture_gen.generate_soil_texture(soil_type)\n",
    "        \n",
    "        # 2. Criar máscara de segmentação\n",
    "        segmentation_mask = np.ones(self.image_size, dtype=np.uint8)  # Solo = 1\n",
    "        \n",
    "        # 3. Calcular número de plantas baseado no LAI\n",
    "        base_plants = int(target_lai * 15)  # Ajustado para geração procedural\n",
    "        \n",
    "        plant_positions = []\n",
    "        \n",
    "        # 4. Adicionar plantas por tipo\n",
    "        for plant_type, proportion in composition.items():\n",
    "            num_plants = int(base_plants * proportion)\n",
    "            class_id = GRASS_CLOVER_CLASSES[plant_type]['id']\n",
    "            \n",
    "            for _ in range(num_plants):\n",
    "                # Criar cluster de plantas\n",
    "                num_blades = random.randint(3, 8)\n",
    "                plant_cluster = self.texture_gen.create_plant_cluster(plant_type, num_blades)\n",
    "                \n",
    "                # Escala aleatória\n",
    "                scale = random.uniform(0.5, 1.5)\n",
    "                new_size = (int(plant_cluster.size[0] * scale), int(plant_cluster.size[1] * scale))\n",
    "                plant_cluster = plant_cluster.resize(new_size, Image.Resampling.LANCZOS)\n",
    "                \n",
    "                # Posição aleatória (evitando bordas)\n",
    "                margin = 50\n",
    "                max_x = self.image_size[0] - plant_cluster.size[0] - margin\n",
    "                max_y = self.image_size[1] - plant_cluster.size[1] - margin\n",
    "                \n",
    "                if max_x > margin and max_y > margin:\n",
    "                    pos_x = random.randint(margin, max_x)\n",
    "                    pos_y = random.randint(margin, max_y)\n",
    "                    \n",
    "                    # Adicionar à cena\n",
    "                    scene_img.paste(plant_cluster, (pos_x, pos_y), plant_cluster)\n",
    "                    \n",
    "                    # Atualizar máscara de segmentação\n",
    "                    plant_array = np.array(plant_cluster)\n",
    "                    alpha_mask = plant_array[:, :, 3] > 0  # Canal alfa\n",
    "                    \n",
    "                    # Aplicar máscara na região correspondente\n",
    "                    end_x = min(pos_x + plant_cluster.size[0], self.image_size[0])\n",
    "                    end_y = min(pos_y + plant_cluster.size[1], self.image_size[1])\n",
    "                    \n",
    "                    mask_region = alpha_mask[:end_y-pos_y, :end_x-pos_x]\n",
    "                    segmentation_mask[pos_y:end_y, pos_x:end_x][mask_region] = class_id\n",
    "                    \n",
    "                    plant_positions.append({\n",
    "                        'type': plant_type,\n",
    "                        'position': (pos_x, pos_y),\n",
    "                        'size': plant_cluster.size,\n",
    "                        'scale': scale,\n",
    "                        'class_id': class_id\n",
    "                    })\n",
    "        \n",
    "        # 5. Pós-processamento para simular condições naturais\n",
    "        scene_img = self._apply_natural_effects(scene_img)\n",
    "        \n",
    "        return {\n",
    "            'image': scene_img,\n",
    "            'segmentation_mask': segmentation_mask,\n",
    "            'plant_positions': plant_positions,\n",
    "            'composition': composition,\n",
    "            'lai': target_lai,\n",
    "            'soil_type': soil_type,\n",
    "            'metadata': {\n",
    "                'gsd': self.gsd,\n",
    "                'image_size': self.image_size,\n",
    "                'num_plants': len(plant_positions),\n",
    "                'generation_method': 'procedural',\n",
    "                'timestamp': datetime.now().isoformat()\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    def _apply_natural_effects(self, image):\n",
    "        \"\"\"Aplica efeitos para simular condições naturais\"\"\"\n",
    "        # Converter para array numpy\n",
    "        img_array = np.array(image)\n",
    "        \n",
    "        # 1. Variação de iluminação\n",
    "        enhancer = ImageEnhance.Brightness(image)\n",
    "        brightness_factor = random.uniform(0.8, 1.2)\n",
    "        image = enhancer.enhance(brightness_factor)\n",
    "        \n",
    "        # 2. Ajuste de contraste\n",
    "        enhancer = ImageEnhance.Contrast(image)\n",
    "        contrast_factor = random.uniform(0.9, 1.1)\n",
    "        image = enhancer.enhance(contrast_factor)\n",
    "        \n",
    "        # 3. Leve desfoque para simular movimento do vento\n",
    "        if random.random() < 0.3:  # 30% de chance\n",
    "            blur_radius = random.uniform(0.5, 1.0)\n",
    "            image = image.filter(ImageFilter.GaussianBlur(radius=blur_radius))\n",
    "        \n",
    "        return image\n",
    "\n",
    "# Criar gerador de dataset\n",
    "dataset_generator = BrazilianGrassCloverDataset()\n",
    "print(\"✅ Gerador de dataset GrassClover criado!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-9",
   "metadata": {},
   "source": [
    "## 🚀 Geração do Dataset Sintético"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configurações do dataset\n",
    "num_images = 12  # Quantidade de imagens sintéticas\n",
    "lai_range = (1.0, 3.5)\n",
    "\n",
    "# Diferentes composições de pastagem\n",
    "composition_variants = [\n",
    "    {'brachiaria': 0.6, 'panicum': 0.2, 'cynodon': 0.1, 'leguminous': 0.08, 'weeds': 0.02},\n",
    "    {'brachiaria': 0.3, 'panicum': 0.5, 'cynodon': 0.1, 'leguminous': 0.07, 'weeds': 0.03},\n",
    "    {'brachiaria': 0.2, 'panicum': 0.2, 'cynodon': 0.4, 'leguminous': 0.15, 'weeds': 0.05},\n",
    "    {'brachiaria': 0.4, 'panicum': 0.3, 'cynodon': 0.2, 'leguminous': 0.05, 'weeds': 0.05},\n",
    "    {'brachiaria': 0.5, 'panicum': 0.15, 'cynodon': 0.15, 'leguminous': 0.1, 'weeds': 0.1},\n",
    "    {'brachiaria': 0.35, 'panicum': 0.35, 'cynodon': 0.2, 'leguminous': 0.08, 'weeds': 0.02}\n",
    "]\n",
    "\n",
    "print(f\"🌾 Gerando {num_images} imagens sintéticas...\")\n",
    "\n",
    "synthetic_dataset = []\n",
    "\n",
    "for i in range(num_images):\n",
    "    print(f\"\\n📸 Imagem {i+1}/{num_images}\")\n",
    "    \n",
    "    # Parâmetros variáveis\n",
    "    target_lai = random.uniform(*lai_range)\n",
    "    composition = random.choice(composition_variants)\n",
    "    \n",
    "    try:\n",
    "        # Gerar cena\n",
    "        scene_data = dataset_generator.generate_synthetic_scene(\n",
    "            target_lai=target_lai,\n",
    "            composition=composition\n",
    "        )\n",
    "        \n",
    "        scene_data['scene_id'] = i\n",
    "        synthetic_dataset.append(scene_data)\n",
    "        \n",
    "        print(f\"  ✅ Gerada com {len(scene_data['plant_positions'])} plantas\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  ❌ Erro: {e}\")\n",
    "        continue\n",
    "\n",
    "print(f\"\\n🎉 Dataset criado com {len(synthetic_dataset)} imagens!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-11",
   "metadata": {},
   "source": [
    "## 📊 Visualização do Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar dataset gerado\n",
    "if synthetic_dataset:\n",
    "    print(\"📊 Visualizando dataset sintético...\")\n",
    "    \n",
    "    # Mostrar primeiras 6 imagens\n",
    "    num_show = min(6, len(synthetic_dataset))\n",
    "    \n",
    "    fig, axes = plt.subplots(num_show, 3, figsize=(15, 5 * num_show))\n",
    "    fig.suptitle('🌾 Dataset Sintético Brazilian GrassClover', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    if num_show == 1:\n",
    "        axes = axes.reshape(1, -1)\n",
    "    \n",
    "    for i in range(num_show):\n",
    "        scene = synthetic_dataset[i]\n",
    "        \n",
    "        # 1. Imagem RGB\n",
    "        axes[i, 0].imshow(scene['image'])\n",
    "        axes[i, 0].set_title(f\"Cena {i+1}\\nLAI: {scene['lai']:.2f} | Solo: {scene['soil_type']}\")\n",
    "        axes[i, 0].axis('off')\n",
    "        \n",
    "        # 2. Máscara de segmentação\n",
    "        seg_colored = cmap_grass(scene['segmentation_mask'] / (NUM_CLASSES - 1))\n",
    "        axes[i, 1].imshow(seg_colored)\n",
    "        axes[i, 1].set_title(f\"Segmentação\\n{len(scene['plant_positions'])} plantas\")\n",
    "        axes[i, 1].axis('off')\n",
    "        \n",
    "        # 3. Overlay\n",
    "        img_array = np.array(scene['image'])\n",
    "        overlay = img_array * 0.6 + (seg_colored[:, :, :3] * 255) * 0.4\n",
    "        axes[i, 2].imshow(overlay.astype(np.uint8))\n",
    "        axes[i, 2].set_title('Overlay RGB + Segmentação')\n",
    "        axes[i, 2].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Estatísticas\n",
    "    total_plants = sum(len(scene['plant_positions']) for scene in synthetic_dataset)\n",
    "    avg_lai = np.mean([scene['lai'] for scene in synthetic_dataset])\n",
    "    \n",
    "    print(f\"\\n📈 Estatísticas do Dataset:\")\n",
    "    print(f\"Total de imagens: {len(synthetic_dataset)}\")\n",
    "    print(f\"Total de plantas: {total_plants}\")\n",
    "    print(f\"Plantas por imagem: {total_plants/len(synthetic_dataset):.1f}\")\n",
    "    print(f\"LAI médio: {avg_lai:.2f}\")\n",
    "    \n",
    "    # Distribuição por classe\n",
    "    class_counts = Counter()\n",
    "    for scene in synthetic_dataset:\n",
    "        for plant in scene['plant_positions']:\n",
    "            class_counts[plant['type']] += 1\n",
    "    \n",
    "    print(\"\\n🌱 Distribuição por classe:\")\n",
    "    for plant_type, count in class_counts.most_common():\n",
    "        percentage = (count / total_plants) * 100\n",
    "        class_name = GRASS_CLOVER_CLASSES[plant_type]['name']\n",
    "        print(f\"  {class_name}: {count} plantas ({percentage:.1f}%)\")\n",
    "\n",
    "else:\n",
    "    print(\"❌ Nenhuma imagem foi gerada\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-13",
   "metadata": {},
   "source": [
    "## 🎯 Análise de Composição e Métricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Análise detalhada da composição\n",
    "def analyze_scene_composition(scene_data):\n",
    "    \"\"\"Análise seguindo metodologia GrassClover\"\"\"\n",
    "    seg_mask = scene_data['segmentation_mask']\n",
    "    total_pixels = seg_mask.shape[0] * seg_mask.shape[1]\n",
    "    \n",
    "    # Contagem por classe\n",
    "    class_pixels = {}\n",
    "    class_percentages = {}\n",
    "    \n",
    "    for class_name, class_info in GRASS_CLOVER_CLASSES.items():\n",
    "        class_id = class_info['id']\n",
    "        pixels = np.sum(seg_mask == class_id)\n",
    "        percentage = (pixels / total_pixels) * 100\n",
    "        \n",
    "        class_pixels[class_name] = pixels\n",
    "        class_percentages[class_name] = percentage\n",
    "    \n",
    "    # Cobertura vegetacional\n",
    "    vegetation_pixels = total_pixels - class_pixels['background'] - class_pixels['soil']\n",
    "    vegetation_coverage = (vegetation_pixels / total_pixels) * 100\n",
    "    \n",
    "    return {\n",
    "        'scene_id': scene_data['scene_id'],\n",
    "        'class_percentages': class_percentages,\n",
    "        'vegetation_coverage': vegetation_coverage,\n",
    "        'lai': scene_data['lai'],\n",
    "        'num_plants': len(scene_data['plant_positions'])\n",
    "    }\n",
    "\n",
    "# Analisar todas as cenas\n",
    "if synthetic_dataset:\n",
    "    analyses = [analyze_scene_composition(scene) for scene in synthetic_dataset]\n",
    "    \n",
    "    # Visualização da análise\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 10))\n",
    "    fig.suptitle('📊 Análise de Composição - Metodologia GrassClover', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # 1. Cobertura vegetacional por cena\n",
    "    scene_ids = [a['scene_id'] for a in analyses]\n",
    "    coverages = [a['vegetation_coverage'] for a in analyses]\n",
    "    \n",
    "    axes[0, 0].bar(scene_ids, coverages, color='green', alpha=0.7)\n",
    "    axes[0, 0].set_xlabel('ID da Cena')\n",
    "    axes[0, 0].set_ylabel('Cobertura Vegetacional (%)')\n",
    "    axes[0, 0].set_title('Cobertura Vegetacional por Cena')\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 2. LAI vs Cobertura\n",
    "    lais = [a['lai'] for a in analyses]\n",
    "    \n",
    "    axes[0, 1].scatter(lais, coverages, c=scene_ids, cmap='viridis', s=100)\n",
    "    axes[0, 1].set_xlabel('Leaf Area Index (LAI)')\n",
    "    axes[0, 1].set_ylabel('Cobertura Vegetacional (%)')\n",
    "    axes[0, 1].set_title('Relação LAI vs Cobertura')\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 3. Distribuição LAI\n",
    "    axes[1, 0].hist(lais, bins=8, alpha=0.7, color='green', edgecolor='black')\n",
    "    axes[1, 0].set_xlabel('Leaf Area Index (LAI)')\n",
    "    axes[1, 0].set_ylabel('Frequência')\n",
    "    axes[1, 0].set_title('Distribuição do LAI')\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 4. Composição média\n",
    "    avg_percentages = {}\n",
    "    for class_name in GRASS_CLOVER_CLASSES.keys():\n",
    "        percentages = [a['class_percentages'][class_name] for a in analyses]\n",
    "        avg_percentages[class_name] = np.mean(percentages)\n",
    "    \n",
    "    # Filtrar classes significativas\n",
    "    significant_classes = {k: v for k, v in avg_percentages.items() if v > 1.0}\n",
    "    \n",
    "    if significant_classes:\n",
    "        class_names = list(significant_classes.keys())\n",
    "        percentages = list(significant_classes.values())\n",
    "        colors = [np.array(GRASS_CLOVER_CLASSES[cls]['color'])/255.0 for cls in class_names]\n",
    "        \n",
    "        axes[1, 1].pie(percentages, labels=[GRASS_CLOVER_CLASSES[cls]['name'] for cls in class_names], \n",
    "                      colors=colors, autopct='%1.1f%%')\n",
    "        axes[1, 1].set_title('Composição Média por Classe')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Relatório estatístico\n",
    "    print(f\"\\n📊 Relatório de Análise:\")\n",
    "    print(f\"Cobertura vegetacional média: {np.mean(coverages):.1f}%\")\n",
    "    print(f\"LAI médio: {np.mean(lais):.2f}\")\n",
    "    print(f\"Número médio de plantas: {np.mean([a['num_plants'] for a in analyses]):.1f}\")\n",
    "    \n",
    "    print(\"\\nComposição média:\")\n",
    "    for class_name, avg_pct in avg_percentages.items():\n",
    "        if avg_pct > 0.5:\n",
    "            print(f\"  {GRASS_CLOVER_CLASSES[class_name]['name']}: {avg_pct:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-15",
   "metadata": {},
   "source": [
    "## 🔍 Demonstração de Detecção com YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Teste básico com YOLO (se disponível)\n",
    "try:\n",
    "    from ultralytics import YOLO\n",
    "    \n",
    "    print(\"🎯 Testando detecção YOLO...\")\n",
    "    \n",
    "    # Carregar modelo YOLO\n",
    "    model = YOLO('yolov8n.pt')  # Modelo nano para teste\n",
    "    \n",
    "    if synthetic_dataset:\n",
    "        # Testar em uma imagem\n",
    "        test_image = synthetic_dataset[0]['image']\n",
    "        \n",
    "        # Executar detecção\n",
    "        results = model(test_image, conf=0.25)\n",
    "        result = results[0]\n",
    "        \n",
    "        # Visualizar resultado\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "        \n",
    "        # Imagem original\n",
    "        axes[0].imshow(test_image)\n",
    "        axes[0].set_title('Imagem Original')\n",
    "        axes[0].axis('off')\n",
    "        \n",
    "        # Detecções YOLO\n",
    "        annotated_img = result.plot()\n",
    "        axes[1].imshow(cv2.cvtColor(annotated_img, cv2.COLOR_BGR2RGB))\n",
    "        axes[1].set_title('Detecções YOLO')\n",
    "        axes[1].axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Estatísticas de detecção\n",
    "        if result.boxes is not None:\n",
    "            num_detections = len(result.boxes)\n",
    "            print(f\"✅ {num_detections} detecções encontradas\")\n",
    "            \n",
    "            # Classes detectadas\n",
    "            detected_classes = []\n",
    "            for cls, conf in zip(result.boxes.cls, result.boxes.conf):\n",
    "                class_name = model.names[int(cls)]\n",
    "                confidence = float(conf)\n",
    "                detected_classes.append((class_name, confidence))\n",
    "            \n",
    "            print(\"Classes detectadas:\")\n",
    "            for class_name, conf in detected_classes:\n",
    "                print(f\"  {class_name}: {conf:.2f}\")\n",
    "        else:\n",
    "            print(\"⚠️ Nenhuma detecção encontrada\")\n",
    "            \n",
    "        print(\"\\n💡 Nota: YOLO padrão detecta objetos gerais.\")\n",
    "        print(\"   Para gramíneas específicas, seria necessário treino customizado.\")\n",
    "\n",
    "except ImportError:\n",
    "    print(\"⚠️ YOLO não disponível. Pulando teste de detecção.\")\n",
    "except Exception as e:\n",
    "    print(f\"⚠️ Erro no teste YOLO: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-17",
   "metadata": {},
   "source": [
    "## 💾 Exportação do Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exportar dataset completo\n",
    "def export_grassclover_dataset(dataset, output_dir=\"brazilian_grassclover_simple\"):\n",
    "    \"\"\"Exporta dataset no formato GrassClover\"\"\"\n",
    "    output_path = Path(output_dir)\n",
    "    output_path.mkdir(exist_ok=True)\n",
    "    \n",
    "    # Estrutura de diretórios\n",
    "    (output_path / \"images\").mkdir(exist_ok=True)\n",
    "    (output_path / \"masks\").mkdir(exist_ok=True)\n",
    "    (output_path / \"metadata\").mkdir(exist_ok=True)\n",
    "    \n",
    "    dataset_info = {\n",
    "        'name': 'Brazilian GrassClover Simple Dataset',\n",
    "        'description': 'Synthetic dataset using procedural generation following GrassClover methodology',\n",
    "        'created': datetime.now().isoformat(),\n",
    "        'num_images': len(dataset),\n",
    "        'image_size': list(dataset[0]['image'].size) if dataset else [512, 512],\n",
    "        'classes': GRASS_CLOVER_CLASSES,\n",
    "        'methodology': 'GrassClover with procedural generation',\n",
    "        'ground_sampling_distance': '6 px/mm',\n",
    "        'generation_method': 'procedural_textures'\n",
    "    }\n",
    "    \n",
    "    exported_scenes = []\n",
    "    \n",
    "    print(f\"💾 Exportando {len(dataset)} cenas...\")\n",
    "    \n",
    "    for i, scene in enumerate(dataset):\n",
    "        scene_id = f\"scene_{i:04d}\"\n",
    "        \n",
    "        # Salvar imagem RGB\n",
    "        image_path = output_path / \"images\" / f\"{scene_id}.png\"\n",
    "        scene['image'].save(image_path)\n",
    "        \n",
    "        # Salvar máscara de segmentação\n",
    "        mask_path = output_path / \"masks\" / f\"{scene_id}_mask.png\"\n",
    "        mask_image = Image.fromarray(scene['segmentation_mask'].astype(np.uint8))\n",
    "        mask_image.save(mask_path)\n",
    "        \n",
    "        # Salvar máscara colorida\n",
    "        mask_colored_path = output_path / \"masks\" / f\"{scene_id}_colored.png\"\n",
    "        mask_colored = cmap_grass(scene['segmentation_mask'] / (NUM_CLASSES - 1))\n",
    "        mask_colored_image = Image.fromarray((mask_colored * 255).astype(np.uint8))\n",
    "        mask_colored_image.save(mask_colored_path)\n",
    "        \n",
    "        # Metadata da cena\n",
    "        scene_metadata = {\n",
    "            'scene_id': scene_id,\n",
    "            'lai': float(scene['lai']),\n",
    "            'composition': scene['composition'],\n",
    "            'soil_type': scene['soil_type'],\n",
    "            'num_plants': len(scene['plant_positions']),\n",
    "            'plant_positions': scene['plant_positions'],\n",
    "            'files': {\n",
    "                'image': str(image_path.name),\n",
    "                'mask': str(mask_path.name),\n",
    "                'colored_mask': str(mask_colored_path.name)\n",
    "            },\n",
    "            'metadata': scene['metadata']\n",
    "        }\n",
    "        \n",
    "        # Salvar metadata individual\n",
    "        metadata_path = output_path / \"metadata\" / f\"{scene_id}.json\"\n",
    "        with open(metadata_path, 'w') as f:\n",
    "            json.dump(scene_metadata, f, indent=2)\n",
    "        \n",
    "        exported_scenes.append(scene_metadata)\n",
    "        \n",
    "        if (i + 1) % 3 == 0:\n",
    "            print(f\"  ✅ {i+1} cenas exportadas\")\n",
    "    \n",
    "    # Informações gerais\n",
    "    dataset_info['scenes'] = exported_scenes\n",
    "    \n",
    "    with open(output_path / \"dataset_info.json\", 'w') as f:\n",
    "        json.dump(dataset_info, f, indent=2)\n",
    "    \n",
    "    # README\n",
    "    readme_content = f\"\"\"# Brazilian GrassClover Simple Dataset\n",
    "\n",
    "## Descrição\n",
    "Dataset sintético de gramíneas brasileiras usando geração procedural.\n",
    "Baseado na metodologia GrassClover (Skovsen et al., CVPR 2019).\n",
    "\n",
    "## Características\n",
    "- **Método:** Geração procedural (sem Stable Diffusion)\n",
    "- **Classes:** {NUM_CLASSES} classes de pastagem brasileira\n",
    "- **Resolução:** {dataset[0]['image'].size if dataset else '512x512'}\n",
    "- **Total:** {len(dataset)} imagens sintéticas\n",
    "- **LAI Range:** 1.0-3.5\n",
    "\n",
    "## Classes\n",
    "{chr(10).join([f\"- {info['id']}: {info['name']}\" for info in GRASS_CLOVER_CLASSES.values()])}\n",
    "\n",
    "## Estrutura\n",
    "- `images/`: Imagens RGB\n",
    "- `masks/`: Máscaras de segmentação \n",
    "- `metadata/`: Metadados detalhados\n",
    "- `dataset_info.json`: Informações gerais\n",
    "\n",
    "## Uso\n",
    "Ideal para:\n",
    "- Treinamento de modelos de segmentação\n",
    "- Análise de pastagens brasileiras\n",
    "- Desenvolvimento de algoritmos agrícolas\n",
    "- Prototipagem rápida sem dependências complexas\n",
    "\n",
    "Gerado em: {datetime.now().strftime('%d/%m/%Y %H:%M:%S')}\n",
    "\"\"\"\n",
    "    \n",
    "    with open(output_path / \"README.md\", 'w', encoding='utf-8') as f:\n",
    "        f.write(readme_content)\n",
    "    \n",
    "    print(f\"\\n🎉 Dataset exportado para {output_path}!\")\n",
    "    return output_path\n",
    "\n",
    "# Exportar dataset\n",
    "if synthetic_dataset:\n",
    "    dataset_path = export_grassclover_dataset(synthetic_dataset)\n",
    "    \n",
    "    print(f\"\\n📊 Dataset Final:\")\n",
    "    print(f\"Localização: {dataset_path.absolute()}\")\n",
    "    print(f\"Total de imagens: {len(synthetic_dataset)}\")\n",
    "    print(f\"Método: Geração procedural (sem conflitos de dependências)\")\n",
    "    print(f\"Compatível com: PyTorch, TensorFlow, OpenCV, YOLO\")\n",
    "    \n",
    "else:\n",
    "    print(\"❌ Nenhum dataset para exportar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-19",
   "metadata": {},
   "source": [
    "## 📝 Relatório Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relatório final\n",
    "print(\"📝 RELATÓRIO FINAL - Brazilian GrassClover Simple\")\n",
    "print(\"=\" * 55)\n",
    "\n",
    "if synthetic_dataset:\n",
    "    print(f\"\\n🌾 DATASET GERADO:\")\n",
    "    print(f\"Método: Geração procedural (sem Stable Diffusion)\")\n",
    "    print(f\"Total de imagens: {len(synthetic_dataset)}\")\n",
    "    print(f\"Resolução: {synthetic_dataset[0]['image'].size}\")\n",
    "    print(f\"Classes: {NUM_CLASSES} (gramíneas brasileiras)\")\n",
    "    \n",
    "    total_plants = sum(len(scene['plant_positions']) for scene in synthetic_dataset)\n",
    "    avg_lai = np.mean([scene['lai'] for scene in synthetic_dataset])\n",
    "    \n",
    "    print(f\"\\n📊 ESTATÍSTICAS:\")\n",
    "    print(f\"Total de plantas: {total_plants}\")\n",
    "    print(f\"Plantas por imagem: {total_plants/len(synthetic_dataset):.1f}\")\n",
    "    print(f\"LAI médio: {avg_lai:.2f}\")\n",
    "    print(f\"Ground Sampling Distance: 6 px/mm\")\n",
    "    \n",
    "print(f\"\\n✅ VANTAGENS DA ABORDAGEM PROCEDURAL:\")\n",
    "print(f\"✓ Sem conflitos de dependências\")\n",
    "print(f\"✓ Execução rápida e estável\")\n",
    "print(f\"✓ Controle total dos parâmetros\")\n",
    "print(f\"✓ Máscaras pixel-perfect\")\n",
    "print(f\"✓ Compatível com qualquer ambiente\")\n",
    "print(f\"✓ Reprodutível e determinística\")\n",
    "\n",
    "print(f\"\\n🔬 METODOLOGIA IMPLEMENTADA:\")\n",
    "print(f\"✓ Geração procedural de texturas\")\n",
    "print(f\"✓ Composição sobre solo realista\")\n",
    "print(f\"✓ Controle de LAI e densidade\")\n",
    "print(f\"✓ Variações de espécies brasileiras\")\n",
    "print(f\"✓ Máscaras hierárquicas de segmentação\")\n",
    "print(f\"✓ Efeitos naturais (iluminação, blur)\")\n",
    "\n",
    "print(f\"\\n🎯 APLICAÇÕES:\")\n",
    "print(f\"• Treinamento de modelos YOLO/DeepLab\")\n",
    "print(f\"• Prototipagem rápida de algoritmos\")\n",
    "print(f\"• Validação de metodologias\")\n",
    "print(f\"• Baseline para comparações\")\n",
    "print(f\"• Educação e demonstrações\")\n",
    "\n",
    "print(f\"\\n🚀 PRÓXIMOS PASSOS:\")\n",
    "print(f\"• Expandir variedade de texturas\")\n",
    "print(f\"• Adicionar simulação de doenças\")\n",
    "print(f\"• Implementar mudanças sazonais\")\n",
    "print(f\"• Validar com dados reais\")\n",
    "print(f\"• Treinar modelos específicos\")\n",
    "\n",
    "print(f\"\\n🏁 CONCLUSÃO:\")\n",
    "print(f\"Dataset sintético brasileiro criado com sucesso usando abordagem\")\n",
    "print(f\"procedural estável. Mantém a essência da metodologia GrassClover\")\n",
    "print(f\"sem dependências problemáticas, sendo ideal para prototipagem\")\n",
    "print(f\"e desenvolvimento inicial de sistemas de visão computacional\")\n",
    "print(f\"aplicados à agricultura brasileira.\")\n",
    "\n",
    "print(f\"\\n🌾🇧🇷 Brazilian GrassClover Simple - Stable & Ready! 🇧🇷🌾\")\n",
    "print(f\"📅 {datetime.now().strftime('%d/%m/%Y %H:%M:%S')}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",\n   "language": "python",\n   "name": "python3"\n  },\n  "language_info": {\n   "codemirror_mode": {\n    "name": "ipython",\n    "version": 3\n   },\n   "file_extension": ".py",\n   "mimetype": "text/x-python",\n   "name": "python",\n   "nbconvert_exporter": "python",\n   "pygments_lexer": "ipython3",\n   "version": "3.8.5"\n  }\n },\n "nbformat": 4,\n "nbformat_minor": 5\n}