{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# üåæ Brazilian GrassClover: Gera√ß√£o Sint√©tica Simplificada\n",
    "\n",
    "Este notebook implementa a metodologia do **GrassClover Dataset** para gram√≠neas brasileiras usando **gera√ß√£o procedural** e **bibliotecas b√°sicas** para evitar conflitos de depend√™ncias.\n",
    "\n",
    "**Baseado em:** Skovsen et al. \"The GrassClover Image Dataset for Semantic and Hierarchical Species Understanding in Agriculture\" (CVPR Workshops, 2019)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "## üì¶ Instala√ß√£o Simplificada (Sem Conflitos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Depend√™ncias b√°sicas e est√°veis\n",
    "!pip install \"numpy==1.26.4\" \"opencv-python-headless\" \"pillow\" \"matplotlib\" \"seaborn\" --quiet\n",
    "!pip install \"scikit-image\" \"scipy\" \"albumentations\" --quiet\n",
    "!pip install \"ultralytics\" --quiet\n",
    "\n",
    "# Verificar instala√ß√£o\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image, ImageDraw, ImageFilter, ImageEnhance\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from matplotlib.colors import ListedColormap\n",
    "import seaborn as sns\n",
    "from skimage import filters, morphology, segmentation, measure\n",
    "from scipy import ndimage\n",
    "import albumentations as A\n",
    "\n",
    "import os\n",
    "import json\n",
    "import random\n",
    "import math\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from collections import defaultdict, Counter\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Seeds para reprodutibilidade\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "print(f\"‚úÖ NumPy: {np.__version__}\")\n",
    "print(f\"‚úÖ OpenCV: {cv2.__version__}\")\n",
    "print(f\"‚úÖ Todas as depend√™ncias carregadas com sucesso!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-3",
   "metadata": {},
   "source": [
    "## üå± Classes e Configura√ß√µes - GrassClover Brasileiro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classes hier√°rquicas seguindo metodologia GrassClover\n",
    "GRASS_CLOVER_CLASSES = {\n",
    "    'background': {'id': 0, 'color': (0, 0, 0), 'name': 'Background'},\n",
    "    'soil': {'id': 1, 'color': (139, 69, 19), 'name': 'Solo'},\n",
    "    'brachiaria': {'id': 2, 'color': (34, 139, 34), 'name': 'Brachiaria'},\n",
    "    'panicum': {'id': 3, 'color': (50, 205, 50), 'name': 'Panicum'},\n",
    "    'cynodon': {'id': 4, 'color': (0, 255, 127), 'name': 'Cynodon'},\n",
    "    'leguminous': {'id': 5, 'color': (255, 20, 147), 'name': 'Leguminosas'},\n",
    "    'weeds': {'id': 6, 'color': (255, 165, 0), 'name': 'Ervas Daninhas'}\n",
    "}\n",
    "\n",
    "CLASS_COLORS = [cls['color'] for cls in GRASS_CLOVER_CLASSES.values()]\n",
    "CLASS_NAMES = [cls['name'] for cls in GRASS_CLOVER_CLASSES.values()]\n",
    "NUM_CLASSES = len(GRASS_CLOVER_CLASSES)\n",
    "\n",
    "# Colormap personalizado\n",
    "cmap_grass = ListedColormap([np.array(color)/255.0 for color in CLASS_COLORS])\n",
    "\n",
    "print(f\"üìä {NUM_CLASSES} classes definidas:\")\n",
    "for name, info in GRASS_CLOVER_CLASSES.items():\n",
    "    print(f\"  {info['id']}: {info['name']}\")\n",
    "\n",
    "# Visualizar paleta\n",
    "fig, ax = plt.subplots(1, 1, figsize=(12, 2))\n",
    "colors_array = np.array(CLASS_COLORS).reshape(1, -1, 3) / 255.0\n",
    "ax.imshow(colors_array, aspect='auto')\n",
    "ax.set_xticks(range(len(CLASS_NAMES)))\n",
    "ax.set_xticklabels(CLASS_NAMES, rotation=45, ha='right')\n",
    "ax.set_yticks([])\n",
    "ax.set_title('üé® Paleta de Classes - GrassClover Brasileiro')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-5",
   "metadata": {},
   "source": [
    "## üé® Gerador Procedural de Texturas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProceduralTextureGenerator:\n",
    "    \"\"\"\n",
    "    Gerador procedural de texturas para solo e plantas\n",
    "    Evita depend√™ncias problem√°ticas do Stable Diffusion\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, image_size=(512, 512)):\n",
    "        self.image_size = image_size\n",
    "        \n",
    "    def generate_soil_texture(self, soil_type=\"tropical\"):\n",
    "        \"\"\"Gera textura de solo procedural\"\"\"\n",
    "        h, w = self.image_size\n",
    "        \n",
    "        # Cores base do solo brasileiro\n",
    "        soil_colors = {\n",
    "            'tropical': [(139, 69, 19), (160, 82, 45), (205, 133, 63)],\n",
    "            'cerrado': [(139, 90, 43), (165, 108, 64), (188, 143, 107)],\n",
    "            'clay': [(139, 54, 38), (160, 65, 47), (181, 83, 65)]\n",
    "        }\n",
    "        \n",
    "        colors = soil_colors.get(soil_type, soil_colors['tropical'])\n",
    "        \n",
    "        # Criar textura base com ru√≠do\n",
    "        noise = np.random.random((h, w))\n",
    "        \n",
    "        # Aplicar filtro gaussiano para suavizar\n",
    "        noise_smooth = filters.gaussian(noise, sigma=2)\n",
    "        \n",
    "        # Criar imagem colorida\n",
    "        soil_img = np.zeros((h, w, 3), dtype=np.uint8)\n",
    "        \n",
    "        # Aplicar cores baseadas no ru√≠do\n",
    "        for i in range(len(colors)):\n",
    "            threshold_low = i / len(colors)\n",
    "            threshold_high = (i + 1) / len(colors)\n",
    "            \n",
    "            mask = (noise_smooth >= threshold_low) & (noise_smooth < threshold_high)\n",
    "            soil_img[mask] = colors[i]\n",
    "        \n",
    "        # Adicionar varia√ß√£o de brilho\n",
    "        brightness_var = (np.random.random((h, w, 1)) - 0.5) * 30\n",
    "        soil_img = np.clip(soil_img + brightness_var, 0, 255).astype(np.uint8)\n",
    "        \n",
    "        return Image.fromarray(soil_img)\n",
    "    \n",
    "    def generate_grass_blade(self, grass_type=\"brachiaria\", size=(64, 64)):\n",
    "        \"\"\"Gera uma folha de grama individual\"\"\"\n",
    "        h, w = size\n",
    "        \n",
    "        # Par√¢metros por tipo de gram√≠nea\n",
    "        grass_params = {\n",
    "            'brachiaria': {'color': (34, 139, 34), 'width_ratio': 0.6, 'curve': 0.3},\n",
    "            'panicum': {'color': (50, 205, 50), 'width_ratio': 0.8, 'curve': 0.5},\n",
    "            'cynodon': {'color': (0, 255, 127), 'width_ratio': 0.4, 'curve': 0.2},\n",
    "            'leguminous': {'color': (255, 20, 147), 'width_ratio': 0.9, 'curve': 0.1},\n",
    "            'weeds': {'color': (255, 165, 0), 'width_ratio': 0.5, 'curve': 0.7}\n",
    "        }\n",
    "        \n",
    "        params = grass_params.get(grass_type, grass_params['brachiaria'])\n",
    "        \n",
    "        # Criar imagem transparente\n",
    "        img = Image.new('RGBA', (w, h), (0, 0, 0, 0))\n",
    "        draw = ImageDraw.Draw(img)\n",
    "        \n",
    "        # Desenhar folha de grama\n",
    "        blade_width = int(w * params['width_ratio'])\n",
    "        center_x = w // 2\n",
    "        \n",
    "        # Pontos para criar uma folha curvada\n",
    "        points = []\n",
    "        for y in range(h):\n",
    "            progress = y / h\n",
    "            \n",
    "            # Largura varia do topo para a base\n",
    "            current_width = blade_width * (0.1 + 0.9 * progress)\n",
    "            \n",
    "            # Curvatura\n",
    "            curve_offset = int(params['curve'] * w * math.sin(progress * math.pi))\n",
    "            \n",
    "            left_x = center_x - current_width // 2 + curve_offset\n",
    "            right_x = center_x + current_width // 2 + curve_offset\n",
    "            \n",
    "            points.append((left_x, y))\n",
    "        \n",
    "        # Adicionar pontos da volta (lado direito)\n",
    "        for y in range(h-1, -1, -1):\n",
    "            progress = y / h\n",
    "            current_width = blade_width * (0.1 + 0.9 * progress)\n",
    "            curve_offset = int(params['curve'] * w * math.sin(progress * math.pi))\n",
    "            right_x = center_x + current_width // 2 + curve_offset\n",
    "            points.append((right_x, y))\n",
    "        \n",
    "        # Desenhar pol√≠gono da folha\n",
    "        base_color = params['color']\n",
    "        \n",
    "        # Varia√ß√£o de cor para realismo\n",
    "        color_var = [random.randint(-20, 20) for _ in range(3)]\n",
    "        final_color = tuple(max(0, min(255, base_color[i] + color_var[i])) for i in range(3))\n",
    "        \n",
    "        draw.polygon(points, fill=final_color + (255,))\n",
    "        \n",
    "        # Adicionar nervura central\n",
    "        nervure_color = tuple(max(0, c - 30) for c in final_color)\n",
    "        for y in range(h):\n",
    "            progress = y / h\n",
    "            curve_offset = int(params['curve'] * w * math.sin(progress * math.pi))\n",
    "            x = center_x + curve_offset\n",
    "            draw.point((x, y), fill=nervure_color + (255,))\n",
    "        \n",
    "        return img\n",
    "    \n",
    "    def create_plant_cluster(self, plant_type=\"brachiaria\", num_blades=5):\n",
    "        \"\"\"Cria um agrupamento de folhas\"\"\"\n",
    "        cluster_size = (128, 128)\n",
    "        cluster = Image.new('RGBA', cluster_size, (0, 0, 0, 0))\n",
    "        \n",
    "        for _ in range(num_blades):\n",
    "            # Gerar folha individual\n",
    "            blade_size = (random.randint(40, 80), random.randint(60, 100))\n",
    "            blade = self.generate_grass_blade(plant_type, blade_size)\n",
    "            \n",
    "            # Rota√ß√£o aleat√≥ria\n",
    "            angle = random.randint(-30, 30)\n",
    "            blade = blade.rotate(angle, expand=True)\n",
    "            \n",
    "            # Posi√ß√£o aleat√≥ria no cluster\n",
    "            max_x = cluster_size[0] - blade.size[0]\n",
    "            max_y = cluster_size[1] - blade.size[1]\n",
    "            \n",
    "            if max_x > 0 and max_y > 0:\n",
    "                pos_x = random.randint(0, max_x)\n",
    "                pos_y = random.randint(0, max_y)\n",
    "                \n",
    "                # Compor no cluster\n",
    "                cluster.alpha_composite(blade, (pos_x, pos_y))\n",
    "        \n",
    "        return cluster\n",
    "\n",
    "# Criar gerador\n",
    "generator = ProceduralTextureGenerator()\n",
    "print(\"üé® Gerador procedural criado!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-7",
   "metadata": {},
   "source": [
    "## üåæ Gerador de Dataset Sint√©tico - Metodologia GrassClover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BrazilianGrassCloverDataset:\n",
    "    \"\"\"\n",
    "    Gerador de dataset seguindo metodologia GrassClover\n",
    "    Usando gera√ß√£o procedural ao inv√©s de Stable Diffusion\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, image_size=(512, 512), gsd=6):\n",
    "        self.image_size = image_size\n",
    "        self.gsd = gsd  # Ground Sampling Distance (px/mm)\n",
    "        self.texture_gen = ProceduralTextureGenerator(image_size)\n",
    "        \n",
    "    def generate_synthetic_scene(self, target_lai=2.0, composition=None):\n",
    "        \"\"\"\n",
    "        Gera cena sint√©tica completa\n",
    "        \n",
    "        Args:\n",
    "            target_lai: Leaf Area Index desejado (1.0-4.0)\n",
    "            composition: Dict com propor√ß√£o de cada classe\n",
    "        \"\"\"\n",
    "        if composition is None:\n",
    "            composition = {\n",
    "                'brachiaria': 0.4,\n",
    "                'panicum': 0.3, \n",
    "                'cynodon': 0.15,\n",
    "                'leguminous': 0.1,\n",
    "                'weeds': 0.05\n",
    "            }\n",
    "        \n",
    "        print(f\"üå± Gerando cena (LAI: {target_lai:.1f})...\")\n",
    "        \n",
    "        # 1. Gerar solo base\n",
    "        soil_types = ['tropical', 'cerrado', 'clay']\n",
    "        soil_type = random.choice(soil_types)\n",
    "        scene_img = self.texture_gen.generate_soil_texture(soil_type)\n",
    "        \n",
    "        # 2. Criar m√°scara de segmenta√ß√£o\n",
    "        segmentation_mask = np.ones(self.image_size, dtype=np.uint8)  # Solo = 1\n",
    "        \n",
    "        # 3. Calcular n√∫mero de plantas baseado no LAI\n",
    "        base_plants = int(target_lai * 15)  # Ajustado para gera√ß√£o procedural\n",
    "        \n",
    "        plant_positions = []\n",
    "        \n",
    "        # 4. Adicionar plantas por tipo\n",
    "        for plant_type, proportion in composition.items():\n",
    "            num_plants = int(base_plants * proportion)\n",
    "            class_id = GRASS_CLOVER_CLASSES[plant_type]['id']\n",
    "            \n",
    "            for _ in range(num_plants):\n",
    "                # Criar cluster de plantas\n",
    "                num_blades = random.randint(3, 8)\n",
    "                plant_cluster = self.texture_gen.create_plant_cluster(plant_type, num_blades)\n",
    "                \n",
    "                # Escala aleat√≥ria\n",
    "                scale = random.uniform(0.5, 1.5)\n",
    "                new_size = (int(plant_cluster.size[0] * scale), int(plant_cluster.size[1] * scale))\n",
    "                plant_cluster = plant_cluster.resize(new_size, Image.Resampling.LANCZOS)\n",
    "                \n",
    "                # Posi√ß√£o aleat√≥ria (evitando bordas)\n",
    "                margin = 50\n",
    "                max_x = self.image_size[0] - plant_cluster.size[0] - margin\n",
    "                max_y = self.image_size[1] - plant_cluster.size[1] - margin\n",
    "                \n",
    "                if max_x > margin and max_y > margin:\n",
    "                    pos_x = random.randint(margin, max_x)\n",
    "                    pos_y = random.randint(margin, max_y)\n",
    "                    \n",
    "                    # Adicionar √† cena\n",
    "                    scene_img.paste(plant_cluster, (pos_x, pos_y), plant_cluster)\n",
    "                    \n",
    "                    # Atualizar m√°scara de segmenta√ß√£o\n",
    "                    plant_array = np.array(plant_cluster)\n",
    "                    alpha_mask = plant_array[:, :, 3] > 0  # Canal alfa\n",
    "                    \n",
    "                    # Aplicar m√°scara na regi√£o correspondente\n",
    "                    end_x = min(pos_x + plant_cluster.size[0], self.image_size[0])\n",
    "                    end_y = min(pos_y + plant_cluster.size[1], self.image_size[1])\n",
    "                    \n",
    "                    mask_region = alpha_mask[:end_y-pos_y, :end_x-pos_x]\n",
    "                    segmentation_mask[pos_y:end_y, pos_x:end_x][mask_region] = class_id\n",
    "                    \n",
    "                    plant_positions.append({\n",
    "                        'type': plant_type,\n",
    "                        'position': (pos_x, pos_y),\n",
    "                        'size': plant_cluster.size,\n",
    "                        'scale': scale,\n",
    "                        'class_id': class_id\n",
    "                    })\n",
    "        \n",
    "        # 5. P√≥s-processamento para simular condi√ß√µes naturais\n",
    "        scene_img = self._apply_natural_effects(scene_img)\n",
    "        \n",
    "        return {\n",
    "            'image': scene_img,\n",
    "            'segmentation_mask': segmentation_mask,\n",
    "            'plant_positions': plant_positions,\n",
    "            'composition': composition,\n",
    "            'lai': target_lai,\n",
    "            'soil_type': soil_type,\n",
    "            'metadata': {\n",
    "                'gsd': self.gsd,\n",
    "                'image_size': self.image_size,\n",
    "                'num_plants': len(plant_positions),\n",
    "                'generation_method': 'procedural',\n",
    "                'timestamp': datetime.now().isoformat()\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    def _apply_natural_effects(self, image):\n",
    "        \"\"\"Aplica efeitos para simular condi√ß√µes naturais\"\"\"\n",
    "        # Converter para array numpy\n",
    "        img_array = np.array(image)\n",
    "        \n",
    "        # 1. Varia√ß√£o de ilumina√ß√£o\n",
    "        enhancer = ImageEnhance.Brightness(image)\n",
    "        brightness_factor = random.uniform(0.8, 1.2)\n",
    "        image = enhancer.enhance(brightness_factor)\n",
    "        \n",
    "        # 2. Ajuste de contraste\n",
    "        enhancer = ImageEnhance.Contrast(image)\n",
    "        contrast_factor = random.uniform(0.9, 1.1)\n",
    "        image = enhancer.enhance(contrast_factor)\n",
    "        \n",
    "        # 3. Leve desfoque para simular movimento do vento\n",
    "        if random.random() < 0.3:  # 30% de chance\n",
    "            blur_radius = random.uniform(0.5, 1.0)\n",
    "            image = image.filter(ImageFilter.GaussianBlur(radius=blur_radius))\n",
    "        \n",
    "        return image\n",
    "\n",
    "# Criar gerador de dataset\n",
    "dataset_generator = BrazilianGrassCloverDataset()\n",
    "print(\"‚úÖ Gerador de dataset GrassClover criado!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-9",
   "metadata": {},
   "source": [
    "## üöÄ Gera√ß√£o do Dataset Sint√©tico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configura√ß√µes do dataset\n",
    "num_images = 12  # Quantidade de imagens sint√©ticas\n",
    "lai_range = (1.0, 3.5)\n",
    "\n",
    "# Diferentes composi√ß√µes de pastagem\n",
    "composition_variants = [\n",
    "    {'brachiaria': 0.6, 'panicum': 0.2, 'cynodon': 0.1, 'leguminous': 0.08, 'weeds': 0.02},\n",
    "    {'brachiaria': 0.3, 'panicum': 0.5, 'cynodon': 0.1, 'leguminous': 0.07, 'weeds': 0.03},\n",
    "    {'brachiaria': 0.2, 'panicum': 0.2, 'cynodon': 0.4, 'leguminous': 0.15, 'weeds': 0.05},\n",
    "    {'brachiaria': 0.4, 'panicum': 0.3, 'cynodon': 0.2, 'leguminous': 0.05, 'weeds': 0.05},\n",
    "    {'brachiaria': 0.5, 'panicum': 0.15, 'cynodon': 0.15, 'leguminous': 0.1, 'weeds': 0.1},\n",
    "    {'brachiaria': 0.35, 'panicum': 0.35, 'cynodon': 0.2, 'leguminous': 0.08, 'weeds': 0.02}\n",
    "]\n",
    "\n",
    "print(f\"üåæ Gerando {num_images} imagens sint√©ticas...\")\n",
    "\n",
    "synthetic_dataset = []\n",
    "\n",
    "for i in range(num_images):\n",
    "    print(f\"\\nüì∏ Imagem {i+1}/{num_images}\")\n",
    "    \n",
    "    # Par√¢metros vari√°veis\n",
    "    target_lai = random.uniform(*lai_range)\n",
    "    composition = random.choice(composition_variants)\n",
    "    \n",
    "    try:\n",
    "        # Gerar cena\n",
    "        scene_data = dataset_generator.generate_synthetic_scene(\n",
    "            target_lai=target_lai,\n",
    "            composition=composition\n",
    "        )\n",
    "        \n",
    "        scene_data['scene_id'] = i\n",
    "        synthetic_dataset.append(scene_data)\n",
    "        \n",
    "        print(f\"  ‚úÖ Gerada com {len(scene_data['plant_positions'])} plantas\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  ‚ùå Erro: {e}\")\n",
    "        continue\n",
    "\n",
    "print(f\"\\nüéâ Dataset criado com {len(synthetic_dataset)} imagens!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-11",
   "metadata": {},
   "source": [
    "## üìä Visualiza√ß√£o do Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar dataset gerado\n",
    "if synthetic_dataset:\n",
    "    print(\"üìä Visualizando dataset sint√©tico...\")\n",
    "    \n",
    "    # Mostrar primeiras 6 imagens\n",
    "    num_show = min(6, len(synthetic_dataset))\n",
    "    \n",
    "    fig, axes = plt.subplots(num_show, 3, figsize=(15, 5 * num_show))\n",
    "    fig.suptitle('üåæ Dataset Sint√©tico Brazilian GrassClover', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    if num_show == 1:\n",
    "        axes = axes.reshape(1, -1)\n",
    "    \n",
    "    for i in range(num_show):\n",
    "        scene = synthetic_dataset[i]\n",
    "        \n",
    "        # 1. Imagem RGB\n",
    "        axes[i, 0].imshow(scene['image'])\n",
    "        axes[i, 0].set_title(f\"Cena {i+1}\\nLAI: {scene['lai']:.2f} | Solo: {scene['soil_type']}\")\n",
    "        axes[i, 0].axis('off')\n",
    "        \n",
    "        # 2. M√°scara de segmenta√ß√£o\n",
    "        seg_colored = cmap_grass(scene['segmentation_mask'] / (NUM_CLASSES - 1))\n",
    "        axes[i, 1].imshow(seg_colored)\n",
    "        axes[i, 1].set_title(f\"Segmenta√ß√£o\\n{len(scene['plant_positions'])} plantas\")\n",
    "        axes[i, 1].axis('off')\n",
    "        \n",
    "        # 3. Overlay\n",
    "        img_array = np.array(scene['image'])\n",
    "        overlay = img_array * 0.6 + (seg_colored[:, :, :3] * 255) * 0.4\n",
    "        axes[i, 2].imshow(overlay.astype(np.uint8))\n",
    "        axes[i, 2].set_title('Overlay RGB + Segmenta√ß√£o')\n",
    "        axes[i, 2].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Estat√≠sticas\n",
    "    total_plants = sum(len(scene['plant_positions']) for scene in synthetic_dataset)\n",
    "    avg_lai = np.mean([scene['lai'] for scene in synthetic_dataset])\n",
    "    \n",
    "    print(f\"\\nüìà Estat√≠sticas do Dataset:\")\n",
    "    print(f\"Total de imagens: {len(synthetic_dataset)}\")\n",
    "    print(f\"Total de plantas: {total_plants}\")\n",
    "    print(f\"Plantas por imagem: {total_plants/len(synthetic_dataset):.1f}\")\n",
    "    print(f\"LAI m√©dio: {avg_lai:.2f}\")\n",
    "    \n",
    "    # Distribui√ß√£o por classe\n",
    "    class_counts = Counter()\n",
    "    for scene in synthetic_dataset:\n",
    "        for plant in scene['plant_positions']:\n",
    "            class_counts[plant['type']] += 1\n",
    "    \n",
    "    print(\"\\nüå± Distribui√ß√£o por classe:\")\n",
    "    for plant_type, count in class_counts.most_common():\n",
    "        percentage = (count / total_plants) * 100\n",
    "        class_name = GRASS_CLOVER_CLASSES[plant_type]['name']\n",
    "        print(f\"  {class_name}: {count} plantas ({percentage:.1f}%)\")\n",
    "\n",
    "else:\n",
    "    print(\"‚ùå Nenhuma imagem foi gerada\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-13",
   "metadata": {},
   "source": [
    "## üéØ An√°lise de Composi√ß√£o e M√©tricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# An√°lise detalhada da composi√ß√£o\n",
    "def analyze_scene_composition(scene_data):\n",
    "    \"\"\"An√°lise seguindo metodologia GrassClover\"\"\"\n",
    "    seg_mask = scene_data['segmentation_mask']\n",
    "    total_pixels = seg_mask.shape[0] * seg_mask.shape[1]\n",
    "    \n",
    "    # Contagem por classe\n",
    "    class_pixels = {}\n",
    "    class_percentages = {}\n",
    "    \n",
    "    for class_name, class_info in GRASS_CLOVER_CLASSES.items():\n",
    "        class_id = class_info['id']\n",
    "        pixels = np.sum(seg_mask == class_id)\n",
    "        percentage = (pixels / total_pixels) * 100\n",
    "        \n",
    "        class_pixels[class_name] = pixels\n",
    "        class_percentages[class_name] = percentage\n",
    "    \n",
    "    # Cobertura vegetacional\n",
    "    vegetation_pixels = total_pixels - class_pixels['background'] - class_pixels['soil']\n",
    "    vegetation_coverage = (vegetation_pixels / total_pixels) * 100\n",
    "    \n",
    "    return {\n",
    "        'scene_id': scene_data['scene_id'],\n",
    "        'class_percentages': class_percentages,\n",
    "        'vegetation_coverage': vegetation_coverage,\n",
    "        'lai': scene_data['lai'],\n",
    "        'num_plants': len(scene_data['plant_positions'])\n",
    "    }\n",
    "\n",
    "# Analisar todas as cenas\n",
    "if synthetic_dataset:\n",
    "    analyses = [analyze_scene_composition(scene) for scene in synthetic_dataset]\n",
    "    \n",
    "    # Visualiza√ß√£o da an√°lise\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 10))\n",
    "    fig.suptitle('üìä An√°lise de Composi√ß√£o - Metodologia GrassClover', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # 1. Cobertura vegetacional por cena\n",
    "    scene_ids = [a['scene_id'] for a in analyses]\n",
    "    coverages = [a['vegetation_coverage'] for a in analyses]\n",
    "    \n",
    "    axes[0, 0].bar(scene_ids, coverages, color='green', alpha=0.7)\n",
    "    axes[0, 0].set_xlabel('ID da Cena')\n",
    "    axes[0, 0].set_ylabel('Cobertura Vegetacional (%)')\n",
    "    axes[0, 0].set_title('Cobertura Vegetacional por Cena')\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 2. LAI vs Cobertura\n",
    "    lais = [a['lai'] for a in analyses]\n",
    "    \n",
    "    axes[0, 1].scatter(lais, coverages, c=scene_ids, cmap='viridis', s=100)\n",
    "    axes[0, 1].set_xlabel('Leaf Area Index (LAI)')\n",
    "    axes[0, 1].set_ylabel('Cobertura Vegetacional (%)')\n",
    "    axes[0, 1].set_title('Rela√ß√£o LAI vs Cobertura')\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 3. Distribui√ß√£o LAI\n",
    "    axes[1, 0].hist(lais, bins=8, alpha=0.7, color='green', edgecolor='black')\n",
    "    axes[1, 0].set_xlabel('Leaf Area Index (LAI)')\n",
    "    axes[1, 0].set_ylabel('Frequ√™ncia')\n",
    "    axes[1, 0].set_title('Distribui√ß√£o do LAI')\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 4. Composi√ß√£o m√©dia\n",
    "    avg_percentages = {}\n",
    "    for class_name in GRASS_CLOVER_CLASSES.keys():\n",
    "        percentages = [a['class_percentages'][class_name] for a in analyses]\n",
    "        avg_percentages[class_name] = np.mean(percentages)\n",
    "    \n",
    "    # Filtrar classes significativas\n",
    "    significant_classes = {k: v for k, v in avg_percentages.items() if v > 1.0}\n",
    "    \n",
    "    if significant_classes:\n",
    "        class_names = list(significant_classes.keys())\n",
    "        percentages = list(significant_classes.values())\n",
    "        colors = [np.array(GRASS_CLOVER_CLASSES[cls]['color'])/255.0 for cls in class_names]\n",
    "        \n",
    "        axes[1, 1].pie(percentages, labels=[GRASS_CLOVER_CLASSES[cls]['name'] for cls in class_names], \n",
    "                      colors=colors, autopct='%1.1f%%')\n",
    "        axes[1, 1].set_title('Composi√ß√£o M√©dia por Classe')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Relat√≥rio estat√≠stico\n",
    "    print(f\"\\nüìä Relat√≥rio de An√°lise:\")\n",
    "    print(f\"Cobertura vegetacional m√©dia: {np.mean(coverages):.1f}%\")\n",
    "    print(f\"LAI m√©dio: {np.mean(lais):.2f}\")\n",
    "    print(f\"N√∫mero m√©dio de plantas: {np.mean([a['num_plants'] for a in analyses]):.1f}\")\n",
    "    \n",
    "    print(\"\\nComposi√ß√£o m√©dia:\")\n",
    "    for class_name, avg_pct in avg_percentages.items():\n",
    "        if avg_pct > 0.5:\n",
    "            print(f\"  {GRASS_CLOVER_CLASSES[class_name]['name']}: {avg_pct:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-15",
   "metadata": {},
   "source": [
    "## üîç Demonstra√ß√£o de Detec√ß√£o com YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Teste b√°sico com YOLO (se dispon√≠vel)\n",
    "try:\n",
    "    from ultralytics import YOLO\n",
    "    \n",
    "    print(\"üéØ Testando detec√ß√£o YOLO...\")\n",
    "    \n",
    "    # Carregar modelo YOLO\n",
    "    model = YOLO('yolov8n.pt')  # Modelo nano para teste\n",
    "    \n",
    "    if synthetic_dataset:\n",
    "        # Testar em uma imagem\n",
    "        test_image = synthetic_dataset[0]['image']\n",
    "        \n",
    "        # Executar detec√ß√£o\n",
    "        results = model(test_image, conf=0.25)\n",
    "        result = results[0]\n",
    "        \n",
    "        # Visualizar resultado\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "        \n",
    "        # Imagem original\n",
    "        axes[0].imshow(test_image)\n",
    "        axes[0].set_title('Imagem Original')\n",
    "        axes[0].axis('off')\n",
    "        \n",
    "        # Detec√ß√µes YOLO\n",
    "        annotated_img = result.plot()\n",
    "        axes[1].imshow(cv2.cvtColor(annotated_img, cv2.COLOR_BGR2RGB))\n",
    "        axes[1].set_title('Detec√ß√µes YOLO')\n",
    "        axes[1].axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Estat√≠sticas de detec√ß√£o\n",
    "        if result.boxes is not None:\n",
    "            num_detections = len(result.boxes)\n",
    "            print(f\"‚úÖ {num_detections} detec√ß√µes encontradas\")\n",
    "            \n",
    "            # Classes detectadas\n",
    "            detected_classes = []\n",
    "            for cls, conf in zip(result.boxes.cls, result.boxes.conf):\n",
    "                class_name = model.names[int(cls)]\n",
    "                confidence = float(conf)\n",
    "                detected_classes.append((class_name, confidence))\n",
    "            \n",
    "            print(\"Classes detectadas:\")\n",
    "            for class_name, conf in detected_classes:\n",
    "                print(f\"  {class_name}: {conf:.2f}\")\n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è Nenhuma detec√ß√£o encontrada\")\n",
    "            \n",
    "        print(\"\\nüí° Nota: YOLO padr√£o detecta objetos gerais.\")\n",
    "        print(\"   Para gram√≠neas espec√≠ficas, seria necess√°rio treino customizado.\")\n",
    "\n",
    "except ImportError:\n",
    "    print(\"‚ö†Ô∏è YOLO n√£o dispon√≠vel. Pulando teste de detec√ß√£o.\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Erro no teste YOLO: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-17",
   "metadata": {},
   "source": [
    "## üíæ Exporta√ß√£o do Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exportar dataset completo\n",
    "def export_grassclover_dataset(dataset, output_dir=\"brazilian_grassclover_simple\"):\n",
    "    \"\"\"Exporta dataset no formato GrassClover\"\"\"\n",
    "    output_path = Path(output_dir)\n",
    "    output_path.mkdir(exist_ok=True)\n",
    "    \n",
    "    # Estrutura de diret√≥rios\n",
    "    (output_path / \"images\").mkdir(exist_ok=True)\n",
    "    (output_path / \"masks\").mkdir(exist_ok=True)\n",
    "    (output_path / \"metadata\").mkdir(exist_ok=True)\n",
    "    \n",
    "    dataset_info = {\n",
    "        'name': 'Brazilian GrassClover Simple Dataset',\n",
    "        'description': 'Synthetic dataset using procedural generation following GrassClover methodology',\n",
    "        'created': datetime.now().isoformat(),\n",
    "        'num_images': len(dataset),\n",
    "        'image_size': list(dataset[0]['image'].size) if dataset else [512, 512],\n",
    "        'classes': GRASS_CLOVER_CLASSES,\n",
    "        'methodology': 'GrassClover with procedural generation',\n",
    "        'ground_sampling_distance': '6 px/mm',\n",
    "        'generation_method': 'procedural_textures'\n",
    "    }\n",
    "    \n",
    "    exported_scenes = []\n",
    "    \n",
    "    print(f\"üíæ Exportando {len(dataset)} cenas...\")\n",
    "    \n",
    "    for i, scene in enumerate(dataset):\n",
    "        scene_id = f\"scene_{i:04d}\"\n",
    "        \n",
    "        # Salvar imagem RGB\n",
    "        image_path = output_path / \"images\" / f\"{scene_id}.png\"\n",
    "        scene['image'].save(image_path)\n",
    "        \n",
    "        # Salvar m√°scara de segmenta√ß√£o\n",
    "        mask_path = output_path / \"masks\" / f\"{scene_id}_mask.png\"\n",
    "        mask_image = Image.fromarray(scene['segmentation_mask'].astype(np.uint8))\n",
    "        mask_image.save(mask_path)\n",
    "        \n",
    "        # Salvar m√°scara colorida\n",
    "        mask_colored_path = output_path / \"masks\" / f\"{scene_id}_colored.png\"\n",
    "        mask_colored = cmap_grass(scene['segmentation_mask'] / (NUM_CLASSES - 1))\n",
    "        mask_colored_image = Image.fromarray((mask_colored * 255).astype(np.uint8))\n",
    "        mask_colored_image.save(mask_colored_path)\n",
    "        \n",
    "        # Metadata da cena\n",
    "        scene_metadata = {\n",
    "            'scene_id': scene_id,\n",
    "            'lai': float(scene['lai']),\n",
    "            'composition': scene['composition'],\n",
    "            'soil_type': scene['soil_type'],\n",
    "            'num_plants': len(scene['plant_positions']),\n",
    "            'plant_positions': scene['plant_positions'],\n",
    "            'files': {\n",
    "                'image': str(image_path.name),\n",
    "                'mask': str(mask_path.name),\n",
    "                'colored_mask': str(mask_colored_path.name)\n",
    "            },\n",
    "            'metadata': scene['metadata']\n",
    "        }\n",
    "        \n",
    "        # Salvar metadata individual\n",
    "        metadata_path = output_path / \"metadata\" / f\"{scene_id}.json\"\n",
    "        with open(metadata_path, 'w') as f:\n",
    "            json.dump(scene_metadata, f, indent=2)\n",
    "        \n",
    "        exported_scenes.append(scene_metadata)\n",
    "        \n",
    "        if (i + 1) % 3 == 0:\n",
    "            print(f\"  ‚úÖ {i+1} cenas exportadas\")\n",
    "    \n",
    "    # Informa√ß√µes gerais\n",
    "    dataset_info['scenes'] = exported_scenes\n",
    "    \n",
    "    with open(output_path / \"dataset_info.json\", 'w') as f:\n",
    "        json.dump(dataset_info, f, indent=2)\n",
    "    \n",
    "    # README\n",
    "    readme_content = f\"\"\"# Brazilian GrassClover Simple Dataset\n",
    "\n",
    "## Descri√ß√£o\n",
    "Dataset sint√©tico de gram√≠neas brasileiras usando gera√ß√£o procedural.\n",
    "Baseado na metodologia GrassClover (Skovsen et al., CVPR 2019).\n",
    "\n",
    "## Caracter√≠sticas\n",
    "- **M√©todo:** Gera√ß√£o procedural (sem Stable Diffusion)\n",
    "- **Classes:** {NUM_CLASSES} classes de pastagem brasileira\n",
    "- **Resolu√ß√£o:** {dataset[0]['image'].size if dataset else '512x512'}\n",
    "- **Total:** {len(dataset)} imagens sint√©ticas\n",
    "- **LAI Range:** 1.0-3.5\n",
    "\n",
    "## Classes\n",
    "{chr(10).join([f\"- {info['id']}: {info['name']}\" for info in GRASS_CLOVER_CLASSES.values()])}\n",
    "\n",
    "## Estrutura\n",
    "- `images/`: Imagens RGB\n",
    "- `masks/`: M√°scaras de segmenta√ß√£o \n",
    "- `metadata/`: Metadados detalhados\n",
    "- `dataset_info.json`: Informa√ß√µes gerais\n",
    "\n",
    "## Uso\n",
    "Ideal para:\n",
    "- Treinamento de modelos de segmenta√ß√£o\n",
    "- An√°lise de pastagens brasileiras\n",
    "- Desenvolvimento de algoritmos agr√≠colas\n",
    "- Prototipagem r√°pida sem depend√™ncias complexas\n",
    "\n",
    "Gerado em: {datetime.now().strftime('%d/%m/%Y %H:%M:%S')}\n",
    "\"\"\"\n",
    "    \n",
    "    with open(output_path / \"README.md\", 'w', encoding='utf-8') as f:\n",
    "        f.write(readme_content)\n",
    "    \n",
    "    print(f\"\\nüéâ Dataset exportado para {output_path}!\")\n",
    "    return output_path\n",
    "\n",
    "# Exportar dataset\n",
    "if synthetic_dataset:\n",
    "    dataset_path = export_grassclover_dataset(synthetic_dataset)\n",
    "    \n",
    "    print(f\"\\nüìä Dataset Final:\")\n",
    "    print(f\"Localiza√ß√£o: {dataset_path.absolute()}\")\n",
    "    print(f\"Total de imagens: {len(synthetic_dataset)}\")\n",
    "    print(f\"M√©todo: Gera√ß√£o procedural (sem conflitos de depend√™ncias)\")\n",
    "    print(f\"Compat√≠vel com: PyTorch, TensorFlow, OpenCV, YOLO\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå Nenhum dataset para exportar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-19",
   "metadata": {},
   "source": [
    "## üìù Relat√≥rio Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relat√≥rio final\n",
    "print(\"üìù RELAT√ìRIO FINAL - Brazilian GrassClover Simple\")\n",
    "print(\"=\" * 55)\n",
    "\n",
    "if synthetic_dataset:\n",
    "    print(f\"\\nüåæ DATASET GERADO:\")\n",
    "    print(f\"M√©todo: Gera√ß√£o procedural (sem Stable Diffusion)\")\n",
    "    print(f\"Total de imagens: {len(synthetic_dataset)}\")\n",
    "    print(f\"Resolu√ß√£o: {synthetic_dataset[0]['image'].size}\")\n",
    "    print(f\"Classes: {NUM_CLASSES} (gram√≠neas brasileiras)\")\n",
    "    \n",
    "    total_plants = sum(len(scene['plant_positions']) for scene in synthetic_dataset)\n",
    "    avg_lai = np.mean([scene['lai'] for scene in synthetic_dataset])\n",
    "    \n",
    "    print(f\"\\nüìä ESTAT√çSTICAS:\")\n",
    "    print(f\"Total de plantas: {total_plants}\")\n",
    "    print(f\"Plantas por imagem: {total_plants/len(synthetic_dataset):.1f}\")\n",
    "    print(f\"LAI m√©dio: {avg_lai:.2f}\")\n",
    "    print(f\"Ground Sampling Distance: 6 px/mm\")\n",
    "    \n",
    "print(f\"\\n‚úÖ VANTAGENS DA ABORDAGEM PROCEDURAL:\")\n",
    "print(f\"‚úì Sem conflitos de depend√™ncias\")\n",
    "print(f\"‚úì Execu√ß√£o r√°pida e est√°vel\")\n",
    "print(f\"‚úì Controle total dos par√¢metros\")\n",
    "print(f\"‚úì M√°scaras pixel-perfect\")\n",
    "print(f\"‚úì Compat√≠vel com qualquer ambiente\")\n",
    "print(f\"‚úì Reprodut√≠vel e determin√≠stica\")\n",
    "\n",
    "print(f\"\\nüî¨ METODOLOGIA IMPLEMENTADA:\")\n",
    "print(f\"‚úì Gera√ß√£o procedural de texturas\")\n",
    "print(f\"‚úì Composi√ß√£o sobre solo realista\")\n",
    "print(f\"‚úì Controle de LAI e densidade\")\n",
    "print(f\"‚úì Varia√ß√µes de esp√©cies brasileiras\")\n",
    "print(f\"‚úì M√°scaras hier√°rquicas de segmenta√ß√£o\")\n",
    "print(f\"‚úì Efeitos naturais (ilumina√ß√£o, blur)\")\n",
    "\n",
    "print(f\"\\nüéØ APLICA√á√ïES:\")\n",
    "print(f\"‚Ä¢ Treinamento de modelos YOLO/DeepLab\")\n",
    "print(f\"‚Ä¢ Prototipagem r√°pida de algoritmos\")\n",
    "print(f\"‚Ä¢ Valida√ß√£o de metodologias\")\n",
    "print(f\"‚Ä¢ Baseline para compara√ß√µes\")\n",
    "print(f\"‚Ä¢ Educa√ß√£o e demonstra√ß√µes\")\n",
    "\n",
    "print(f\"\\nüöÄ PR√ìXIMOS PASSOS:\")\n",
    "print(f\"‚Ä¢ Expandir variedade de texturas\")\n",
    "print(f\"‚Ä¢ Adicionar simula√ß√£o de doen√ßas\")\n",
    "print(f\"‚Ä¢ Implementar mudan√ßas sazonais\")\n",
    "print(f\"‚Ä¢ Validar com dados reais\")\n",
    "print(f\"‚Ä¢ Treinar modelos espec√≠ficos\")\n",
    "\n",
    "print(f\"\\nüèÅ CONCLUS√ÉO:\")\n",
    "print(f\"Dataset sint√©tico brasileiro criado com sucesso usando abordagem\")\n",
    "print(f\"procedural est√°vel. Mant√©m a ess√™ncia da metodologia GrassClover\")\n",
    "print(f\"sem depend√™ncias problem√°ticas, sendo ideal para prototipagem\")\n",
    "print(f\"e desenvolvimento inicial de sistemas de vis√£o computacional\")\n",
    "print(f\"aplicados √† agricultura brasileira.\")\n",
    "\n",
    "print(f\"\\nüåæüáßüá∑ Brazilian GrassClover Simple - Stable & Ready! üáßüá∑üåæ\")\n",
    "print(f\"üìÖ {datetime.now().strftime('%d/%m/%Y %H:%M:%S')}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",\n   "language": "python",\n   "name": "python3"\n  },\n  "language_info": {\n   "codemirror_mode": {\n    "name": "ipython",\n    "version": 3\n   },\n   "file_extension": ".py",\n   "mimetype": "text/x-python",\n   "name": "python",\n   "nbconvert_exporter": "python",\n   "pygments_lexer": "ipython3",\n   "version": "3.8.5"\n  }\n },\n "nbformat": 4,\n "nbformat_minor": 5\n}