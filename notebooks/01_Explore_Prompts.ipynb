{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "prompts-title"
   },
   "source": [
    "# üé® Explora√ß√£o de Prompts - Pastagens Brasileiras\n",
    "\n",
    "Este notebook permite explorar e testar o sistema de prompt engineering especializado em pastagens brasileiras.\n",
    "\n",
    "**Funcionalidades:**\n",
    "- ‚úÖ Teste de prompts espec√≠ficos por bioma\n",
    "- ‚úÖ Varia√ß√µes sazonais autom√°ticas\n",
    "- ‚úÖ An√°lise de qualidade de imagens geradas\n",
    "- ‚úÖ Compara√ß√£o visual entre diferentes configura√ß√µes\n",
    "- ‚úÖ Exporta√ß√£o de prompts para uso posterior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "imports-section"
   },
   "source": [
    "## üì¶ 1. Importa√ß√µes e Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "imports"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Adicionar projeto ao path\n",
    "if '/content/brazilian-pasture-synthesis' not in sys.path:\n",
    "    sys.path.append('/content/brazilian-pasture-synthesis')\n",
    "    \n",
    "# Mudan√ßa para diret√≥rio do projeto se necess√°rio\n",
    "if not Path('src').exists():\n",
    "    os.chdir('/content/brazilian-pasture-synthesis')\n",
    "\n",
    "# Importa√ß√µes principais\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import json\n",
    "import yaml\n",
    "from tqdm.auto import tqdm\n",
    "from dataclasses import asdict\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, HTML, clear_output\n",
    "import time\n",
    "\n",
    "# Importa√ß√µes do projeto\n",
    "from src.diffusion.pipeline_manager import PipelineManager\n",
    "from src.diffusion.prompt_engine import (\n",
    "    PromptEngine, PastureConfig, Biome, Season, PastureQuality\n",
    ")\n",
    "from src.diffusion.image_postprocess import ImagePostProcessor, ProcessingConfig\n",
    "from src.dataset.quality_metrics import QualityMetrics\n",
    "\n",
    "# Configura√ß√£o matplotlib\n",
    "plt.style.use('default')\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"‚úÖ Importa√ß√µes conclu√≠das!\")\n",
    "print(f\"üñ•Ô∏è Device dispon√≠vel: {'CUDA' if torch.cuda.is_available() else 'CPU'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "init-components-section"
   },
   "source": [
    "## üîß 2. Inicializa√ß√£o dos Componentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "init-components"
   },
   "outputs": [],
   "source": [
    "print(\"üîß Inicializando componentes...\")\n",
    "\n",
    "# Inicializar pipeline manager\n",
    "pipeline_manager = PipelineManager(\n",
    "    model_name=\"stabilityai/stable-diffusion-xl-base-1.0\",\n",
    "    cache_dir=\"/content/model_cache\",\n",
    "    device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    ")\n",
    "\n",
    "# Inicializar prompt engine\n",
    "prompt_engine = PromptEngine(config_dir=\"configs/prompts\")\n",
    "\n",
    "# Inicializar p√≥s-processador\n",
    "post_processor = ImagePostProcessor()\n",
    "\n",
    "# Inicializar avaliador de qualidade\n",
    "quality_metrics = QualityMetrics()\n",
    "\n",
    "print(\"‚úÖ Componentes inicializados!\")\n",
    "print(\"‚è≥ Pipeline ser√° carregado na primeira gera√ß√£o...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "interactive-explorer-section"
   },
   "source": [
    "## üéõÔ∏è 3. Explorador Interativo de Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "interactive-explorer"
   },
   "outputs": [],
   "source": [
    "# Widgets para explora√ß√£o interativa\n",
    "biome_widget = widgets.Dropdown(\n",
    "    options=[('Cerrado', 'cerrado'), ('Mata Atl√¢ntica', 'mata_atlantica'), ('Pampa', 'pampa')],\n",
    "    value='cerrado',\n",
    "    description='Bioma:'\n",
    ")\n",
    "\n",
    "season_widget = widgets.Dropdown(\n",
    "    options=[('Esta√ß√£o Seca', 'seca'), ('Esta√ß√£o Chuvosa', 'chuvas'), ('Transi√ß√£o', 'transicao')],\n",
    "    value='chuvas',\n",
    "    description='Esta√ß√£o:'\n",
    ")\n",
    "\n",
    "quality_widget = widgets.Dropdown(\n",
    "    options=[('Boa', 'boa'), ('Moderada', 'moderada'), ('Degradada', 'degradada')],\n",
    "    value='moderada',\n",
    "    description='Qualidade:'\n",
    ")\n",
    "\n",
    "coverage_widget = widgets.IntSlider(\n",
    "    value=70,\n",
    "    min=20,\n",
    "    max=95,\n",
    "    step=5,\n",
    "    description='Cobertura (%)'\n",
    ")\n",
    "\n",
    "invasive_widget = widgets.SelectMultiple(\n",
    "    options=[('Capim Gordura', 'capim_gordura'), ('Carqueja', 'carqueja'), \n",
    "             ('Samambaia', 'samambaia'), ('Cupinzeiro', 'cupinzeiro')],\n",
    "    description='Invasoras:'\n",
    ")\n",
    "\n",
    "# Bot√µes de a√ß√£o\n",
    "generate_btn = widgets.Button(\n",
    "    description='üé® Gerar Prompt',\n",
    "    button_style='info',\n",
    "    layout=widgets.Layout(width='150px')\n",
    ")\n",
    "\n",
    "generate_image_btn = widgets.Button(\n",
    "    description='üñºÔ∏è Gerar Imagem',\n",
    "    button_style='success',\n",
    "    layout=widgets.Layout(width='150px')\n",
    ")\n",
    "\n",
    "# Widget de sa√≠da\n",
    "output_widget = widgets.Output()\n",
    "\n",
    "# Layout\n",
    "config_box = widgets.VBox([\n",
    "    widgets.HTML(\"<h3>üîß Configura√ß√£o da Pastagem</h3>\"),\n",
    "    biome_widget,\n",
    "    season_widget, \n",
    "    quality_widget,\n",
    "    coverage_widget,\n",
    "    invasive_widget\n",
    "])\n",
    "\n",
    "button_box = widgets.HBox([generate_btn, generate_image_btn])\n",
    "\n",
    "# Vari√°veis globais para armazenar resultados\n",
    "current_prompt = \"\"\n",
    "current_config = None\n",
    "generated_image = None\n",
    "\n",
    "def generate_prompt_callback(btn):\n",
    "    global current_prompt, current_config\n",
    "    \n",
    "    with output_widget:\n",
    "        clear_output()\n",
    "        print(\"üé® Gerando prompt...\")\n",
    "        \n",
    "        # Criar configura√ß√£o\n",
    "        current_config = PastureConfig(\n",
    "            biome=Biome(biome_widget.value),\n",
    "            season=Season(season_widget.value),\n",
    "            quality=PastureQuality(quality_widget.value),\n",
    "            invasive_species=list(invasive_widget.value),\n",
    "            grass_coverage=coverage_widget.value,\n",
    "            soil_exposure=100 - coverage_widget.value\n",
    "        )\n",
    "        \n",
    "        # Gerar prompt\n",
    "        positive_prompt, negative_prompt = prompt_engine.generate_prompt(\n",
    "            current_config, variation=True\n",
    "        )\n",
    "        current_prompt = positive_prompt\n",
    "        \n",
    "        # Exibir resultados\n",
    "        print(\"‚úÖ Prompt gerado com sucesso!\")\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"üîπ CONFIGURA√á√ÉO:\")\n",
    "        print(f\"   Bioma: {current_config.biome.value.title()}\")\n",
    "        print(f\"   Esta√ß√£o: {current_config.season.value.title()}\")\n",
    "        print(f\"   Qualidade: {current_config.quality.value.title()}\")\n",
    "        print(f\"   Cobertura: {current_config.grass_coverage}%\")\n",
    "        print(f\"   Invasoras: {', '.join(current_config.invasive_species)}\")\n",
    "        \n",
    "        print(\"\\nüîπ PROMPT POSITIVO:\")\n",
    "        print(f'   \"{positive_prompt}\"')\n",
    "        \n",
    "        print(\"\\nüîπ PROMPT NEGATIVO:\")\n",
    "        print(f'   \"{negative_prompt}\"')\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        # Habilitar bot√£o de gera√ß√£o de imagem\n",
    "        generate_image_btn.disabled = False\n",
    "\n",
    "def generate_image_callback(btn):\n",
    "    global generated_image\n",
    "    \n",
    "    if not current_prompt:\n",
    "        with output_widget:\n",
    "            print(\"‚ùå Gere um prompt primeiro!\")\n",
    "        return\n",
    "        \n",
    "    with output_widget:\n",
    "        print(\"\\nüñºÔ∏è Gerando imagem...\")\n",
    "        print(\"‚è≥ Isso pode demorar alguns minutos na primeira vez...\")\n",
    "        \n",
    "        try:\n",
    "            # Carregar pipeline se necess√°rio\n",
    "            if pipeline_manager.base_pipeline is None:\n",
    "                print(\"üì• Carregando modelo Stable Diffusion...\")\n",
    "                pipeline_manager.load_base_pipeline()\n",
    "                \n",
    "            # Gerar imagem\n",
    "            start_time = time.time()\n",
    "            result = pipeline_manager.generate_image(\n",
    "                prompt=current_prompt,\n",
    "                negative_prompt=prompt_engine._generate_negative_prompt(current_config),\n",
    "                num_inference_steps=25,  # Reduzido para teste r√°pido\n",
    "                guidance_scale=8.0,\n",
    "                width=1024,\n",
    "                height=1024,\n",
    "                seed=42  # Seed fixa para reprodutibilidade\n",
    "            )\n",
    "            \n",
    "            generation_time = time.time() - start_time\n",
    "            generated_image = result['image']\n",
    "            \n",
    "            # P√≥s-processamento\n",
    "            print(\"üîß Aplicando p√≥s-processamento...\")\n",
    "            processed_image, quality_report = post_processor.process_image(\n",
    "                generated_image,\n",
    "                season=current_config.season.value,\n",
    "                biome=current_config.biome.value\n",
    "            )\n",
    "            \n",
    "            # Exibir resultado\n",
    "            print(f\"‚úÖ Imagem gerada em {generation_time:.1f}s\")\n",
    "            print(f\"üìä Score de qualidade: {quality_report.overall_score:.3f}\")\n",
    "            \n",
    "            # Mostrar imagem\n",
    "            fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 7))\n",
    "            \n",
    "            ax1.imshow(generated_image)\n",
    "            ax1.set_title(\"Imagem Original\", fontsize=14)\n",
    "            ax1.axis('off')\n",
    "            \n",
    "            ax2.imshow(processed_image)\n",
    "            ax2.set_title(f\"P√≥s-processada (Score: {quality_report.overall_score:.3f})\", fontsize=14)\n",
    "            ax2.axis('off')\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            \n",
    "            # Mostrar m√©tricas detalhadas\n",
    "            print(\"\\nüìä M√âTRICAS DE QUALIDADE:\")\n",
    "            print(f\"   Qualidade T√©cnica: {quality_report.technical_quality:.3f}\")\n",
    "            print(f\"   Realismo Agron√¥mico: {quality_report.agricultural_realism:.3f}\")\n",
    "            print(f\"   Consist√™ncia Sazonal: {quality_report.seasonal_consistency:.3f}\")\n",
    "            \n",
    "            if quality_report.recommendations:\n",
    "                print(\"\\nüí° RECOMENDA√á√ïES:\")\n",
    "                for rec in quality_report.recommendations[:3]:  # Mostrar apenas as 3 principais\n",
    "                    print(f\"   ‚Ä¢ {rec}\")\n",
    "                    \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Erro na gera√ß√£o: {e}\")\n",
    "            print(\"üí° Tente reiniciar o runtime se persistir\")\n",
    "\n",
    "# Conectar callbacks\n",
    "generate_btn.on_click(generate_prompt_callback)\n",
    "generate_image_btn.on_click(generate_image_callback)\n",
    "\n",
    "# Desabilitar bot√£o de imagem inicialmente\n",
    "generate_image_btn.disabled = True\n",
    "\n",
    "# Exibir interface\n",
    "display(widgets.VBox([\n",
    "    widgets.HTML(\"<h2>üé® Explorador de Prompts Interativo</h2>\"),\n",
    "    config_box,\n",
    "    button_box,\n",
    "    output_widget\n",
    "]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "batch-test-section"
   },
   "source": [
    "## üß™ 4. Teste em Lote - Compara√ß√£o de Biomas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "batch-test"
   },
   "outputs": [],
   "source": [
    "def compare_biomes_prompts(season='chuvas', quality='moderada'):\n",
    "    \"\"\"\n",
    "    Compara prompts gerados para diferentes biomas\n",
    "    \"\"\"\n",
    "    print(f\"üîç Comparando prompts para esta√ß√£o: {season}, qualidade: {quality}\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    biomes = ['cerrado', 'mata_atlantica', 'pampa']\n",
    "    biome_names = {'cerrado': 'Cerrado', 'mata_atlantica': 'Mata Atl√¢ntica', 'pampa': 'Pampa'}\n",
    "    \n",
    "    for biome in biomes:\n",
    "        print(f\"\\nüåø {biome_names[biome].upper()}\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        # Criar configura√ß√£o\n",
    "        config = PastureConfig(\n",
    "            biome=Biome(biome),\n",
    "            season=Season(season),\n",
    "            quality=PastureQuality(quality),\n",
    "            invasive_species=['capim_gordura'] if quality != 'boa' else [],\n",
    "            grass_coverage=75 if quality == 'boa' else 60,\n",
    "            soil_exposure=25 if quality == 'boa' else 40\n",
    "        )\n",
    "        \n",
    "        # Gerar prompt\n",
    "        positive, negative = prompt_engine.generate_prompt(config, variation=False)\n",
    "        \n",
    "        print(f\"Prompt: {positive[:100]}...\")\n",
    "        print(f\"Caracter√≠sticas: {config.invasive_species}, {config.grass_coverage}% cobertura\")\n",
    "\n",
    "# Executar compara√ß√£o\n",
    "compare_biomes_prompts('chuvas', 'moderada')\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "compare_biomes_prompts('seca', 'degradada')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "seasonal-analysis-section"
   },
   "source": [
    "## üå¶Ô∏è 5. An√°lise de Varia√ß√µes Sazonais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "seasonal-analysis"
   },
   "outputs": [],
   "source": [
    "def analyze_seasonal_variations(biome='cerrado'):\n",
    "    \"\"\"\n",
    "    Analisa como os prompts variam entre esta√ß√µes para um bioma espec√≠fico\n",
    "    \"\"\"\n",
    "    print(f\"üå¶Ô∏è An√°lise sazonal para: {biome.title()}\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    seasons = ['seca', 'chuvas', 'transicao']\n",
    "    season_names = {\n",
    "        'seca': 'Esta√ß√£o Seca',\n",
    "        'chuvas': 'Esta√ß√£o Chuvosa', \n",
    "        'transicao': 'Transi√ß√£o'\n",
    "    }\n",
    "    \n",
    "    seasonal_data = []\n",
    "    \n",
    "    for season in seasons:\n",
    "        print(f\"\\n‚òÄÔ∏è {season_names[season]}\")\n",
    "        print(\"-\" * 30)\n",
    "        \n",
    "        # Gerar m√∫ltiplas configura√ß√µes para an√°lise\n",
    "        configs = []\n",
    "        for quality in ['boa', 'moderada', 'degradada']:\n",
    "            config = PastureConfig(\n",
    "                biome=Biome(biome),\n",
    "                season=Season(season),\n",
    "                quality=PastureQuality(quality),\n",
    "                invasive_species=[] if quality == 'boa' else ['capim_gordura'],\n",
    "                grass_coverage=85 if quality == 'boa' else (65 if quality == 'moderada' else 40),\n",
    "                soil_exposure=15 if quality == 'boa' else (35 if quality == 'moderada' else 60)\n",
    "            )\n",
    "            configs.append(config)\n",
    "        \n",
    "        # Analisar prompts gerados\n",
    "        prompts = []\n",
    "        for config in configs:\n",
    "            positive, _ = prompt_engine.generate_prompt(config, variation=False)\n",
    "            prompts.append(positive)\n",
    "        \n",
    "        # Extrair palavras-chave caracter√≠sticas\n",
    "        common_words = set()\n",
    "        for prompt in prompts:\n",
    "            words = prompt.lower().split()\n",
    "            for word in words:\n",
    "                if len(word) > 4 and word.isalpha():\n",
    "                    common_words.add(word)\n",
    "        \n",
    "        # Filtrar palavras relevantes para esta√ß√£o\n",
    "        seasonal_keywords = {\n",
    "            'seca': ['golden', 'yellow', 'brown', 'dried', 'sparse', 'exposed', 'harsh', 'intense'],\n",
    "            'chuvas': ['green', 'lush', 'vibrant', 'dense', 'vigorous', 'humid', 'diffuse'],\n",
    "            'transicao': ['mixed', 'variable', 'transition', 'changing', 'moderate']\n",
    "        }\n",
    "        \n",
    "        found_keywords = [w for w in common_words if w in seasonal_keywords[season]]\n",
    "        \n",
    "        print(f\"Palavras-chave t√≠picas: {', '.join(found_keywords[:5])}\")\n",
    "        print(f\"Cobertura m√©dia: {np.mean([c.grass_coverage for c in configs]):.1f}%\")\n",
    "        \n",
    "        seasonal_data.append({\n",
    "            'season': season,\n",
    "            'keywords': found_keywords,\n",
    "            'avg_coverage': np.mean([c.grass_coverage for c in configs]),\n",
    "            'configs': configs\n",
    "        })\n",
    "    \n",
    "    return seasonal_data\n",
    "\n",
    "# Executar an√°lise\n",
    "cerrado_analysis = analyze_seasonal_variations('cerrado')\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "mata_analysis = analyze_seasonal_variations('mata_atlantica')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "batch-generation-section"
   },
   "source": [
    "## üöÄ 6. Gera√ß√£o em Lote para Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "batch-generation"
   },
   "outputs": [],
   "source": [
    "def generate_test_batch(num_samples=6, fast_mode=True):\n",
    "    \"\"\"\n",
    "    Gera lote de imagens para teste r√°pido dos prompts\n",
    "    \"\"\"\n",
    "    print(f\"üöÄ Gerando lote de {num_samples} amostras de teste...\")\n",
    "    \n",
    "    if pipeline_manager.base_pipeline is None:\n",
    "        print(\"üì• Carregando pipeline...\")\n",
    "        pipeline_manager.load_base_pipeline()\n",
    "    \n",
    "    # Configura√ß√µes de teste diversificadas\n",
    "    test_configs = [\n",
    "        # Cerrado varia√ß√µes\n",
    "        PastureConfig(Biome.CERRADO, Season.CHUVAS, PastureQuality.BOA, [], 85, 15),\n",
    "        PastureConfig(Biome.CERRADO, Season.SECA, PastureQuality.DEGRADADA, ['capim_gordura'], 35, 65),\n",
    "        \n",
    "        # Mata Atl√¢ntica varia√ß√µes  \n",
    "        PastureConfig(Biome.MATA_ATLANTICA, Season.CHUVAS, PastureQuality.MODERADA, ['samambaia'], 65, 35),\n",
    "        PastureConfig(Biome.MATA_ATLANTICA, Season.TRANSICAO, PastureQuality.BOA, [], 80, 20),\n",
    "        \n",
    "        # Pampa varia√ß√µes\n",
    "        PastureConfig(Biome.PAMPA, Season.SECA, PastureQuality.MODERADA, ['carqueja'], 55, 45),\n",
    "        PastureConfig(Biome.PAMPA, Season.CHUVAS, PastureQuality.BOA, [], 90, 10)\n",
    "    ]\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for i, config in enumerate(test_configs[:num_samples]):\n",
    "        print(f\"\\nüé® Gerando amostra {i+1}/{num_samples}...\")\n",
    "        print(f\"   {config.biome.value} | {config.season.value} | {config.quality.value}\")\n",
    "        \n",
    "        try:\n",
    "            # Gerar prompt\n",
    "            positive, negative = prompt_engine.generate_prompt(config, variation=True)\n",
    "            \n",
    "            # Par√¢metros otimizados para teste r√°pido\n",
    "            generation_params = {\n",
    "                'prompt': positive,\n",
    "                'negative_prompt': negative,\n",
    "                'num_inference_steps': 15 if fast_mode else 25,\n",
    "                'guidance_scale': 7.5,\n",
    "                'width': 512 if fast_mode else 1024,\n",
    "                'height': 512 if fast_mode else 1024,\n",
    "                'seed': 42 + i  # Seeds diferentes para variedade\n",
    "            }\n",
    "            \n",
    "            # Gerar imagem\n",
    "            start_time = time.time()\n",
    "            result = pipeline_manager.generate_image(**generation_params)\n",
    "            generation_time = time.time() - start_time\n",
    "            \n",
    "            # P√≥s-processamento simples\n",
    "            processed_image, quality_report = post_processor.process_image(\n",
    "                result['image'],\n",
    "                season=config.season.value,\n",
    "                biome=config.biome.value\n",
    "            )\n",
    "            \n",
    "            results.append({\n",
    "                'config': config,\n",
    "                'image': processed_image,\n",
    "                'prompt': positive,\n",
    "                'quality_score': quality_report.overall_score,\n",
    "                'generation_time': generation_time\n",
    "            })\n",
    "            \n",
    "            print(f\"   ‚úÖ Gerado em {generation_time:.1f}s | Score: {quality_report.overall_score:.3f}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ùå Erro: {e}\")\n",
    "            continue\n",
    "    \n",
    "    # Exibir resultados em grid\n",
    "    if results:\n",
    "        print(f\"\\nüñºÔ∏è Exibindo {len(results)} imagens geradas...\")\n",
    "        \n",
    "        cols = 3\n",
    "        rows = (len(results) + cols - 1) // cols\n",
    "        \n",
    "        fig, axes = plt.subplots(rows, cols, figsize=(15, 5*rows))\n",
    "        if rows == 1:\n",
    "            axes = axes.reshape(1, -1)\n",
    "        \n",
    "        for i, result in enumerate(results):\n",
    "            row, col = divmod(i, cols)\n",
    "            \n",
    "            axes[row, col].imshow(result['image'])\n",
    "            \n",
    "            # T√≠tulo com informa√ß√µes\n",
    "            config = result['config']\n",
    "            title = f\"{config.biome.value.title()} - {config.season.value.title()}\\n\"\n",
    "            title += f\"Qualidade: {config.quality.value} | Score: {result['quality_score']:.3f}\"\n",
    "            \n",
    "            axes[row, col].set_title(title, fontsize=10)\n",
    "            axes[row, col].axis('off')\n",
    "        \n",
    "        # Remover subplots vazios\n",
    "        for i in range(len(results), rows * cols):\n",
    "            row, col = divmod(i, cols)\n",
    "            axes[row, col].axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Estat√≠sticas\n",
    "        avg_quality = np.mean([r['quality_score'] for r in results])\n",
    "        avg_time = np.mean([r['generation_time'] for r in results])\n",
    "        \n",
    "        print(f\"\\nüìä ESTAT√çSTICAS DO LOTE:\")\n",
    "        print(f\"   Qualidade m√©dia: {avg_quality:.3f}\")\n",
    "        print(f\"   Tempo m√©dio: {avg_time:.1f}s\")\n",
    "        print(f\"   Taxa de sucesso: {len(results)}/{num_samples} ({len(results)/num_samples*100:.0f}%)\")\n",
    "        \n",
    "    return results\n",
    "\n",
    "# Widget para execu√ß√£o\n",
    "batch_size_widget = widgets.IntSlider(\n",
    "    value=6,\n",
    "    min=3,\n",
    "    max=12,\n",
    "    description='Amostras:'\n",
    ")\n",
    "\n",
    "fast_mode_widget = widgets.Checkbox(\n",
    "    value=True,\n",
    "    description='Modo r√°pido (512px, 15 steps)'\n",
    ")\n",
    "\n",
    "batch_btn = widgets.Button(\n",
    "    description='üöÄ Gerar Lote',\n",
    "    button_style='warning'\n",
    ")\n",
    "\n",
    "batch_output = widgets.Output()\n",
    "\n",
    "def batch_callback(btn):\n",
    "    with batch_output:\n",
    "        clear_output()\n",
    "        generate_test_batch(batch_size_widget.value, fast_mode_widget.value)\n",
    "\n",
    "batch_btn.on_click(batch_callback)\n",
    "\n",
    "display(widgets.VBox([\n",
    "    widgets.HTML(\"<h3>üöÄ Gera√ß√£o em Lote</h3>\"),\n",
    "    batch_size_widget,\n",
    "    fast_mode_widget,\n",
    "    batch_btn,\n",
    "    batch_output\n",
    "]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "export-section"
   },
   "source": [
    "## üíæ 7. Exporta√ß√£o de Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "export"
   },
   "outputs": [],
   "source": [
    "def export_prompt_collection(num_prompts=50, filename=\"brazilian_pasture_prompts.json\"):\n",
    "    \"\"\"\n",
    "    Exporta cole√ß√£o diversificada de prompts para uso posterior\n",
    "    \"\"\"\n",
    "    print(f\"üíæ Gerando cole√ß√£o de {num_prompts} prompts...\")\n",
    "    \n",
    "    # Gerar configura√ß√µes diversificadas\n",
    "    prompt_collection = []\n",
    "    \n",
    "    for i in tqdm(range(num_prompts), desc=\"Gerando prompts\"):\n",
    "        # Configura√ß√£o aleat√≥ria balanceada\n",
    "        biome = np.random.choice(list(Biome))\n",
    "        season = np.random.choice(list(Season))\n",
    "        quality = np.random.choice(list(PastureQuality))\n",
    "        \n",
    "        # Invasoras baseadas na qualidade\n",
    "        invasive_options = ['capim_gordura', 'carqueja', 'samambaia', 'cupinzeiro']\n",
    "        if quality == PastureQuality.BOA:\n",
    "            invasives = []\n",
    "        elif quality == PastureQuality.MODERADA:\n",
    "            invasives = np.random.choice(invasive_options, \n",
    "                                       size=np.random.randint(0, 2), \n",
    "                                       replace=False).tolist()\n",
    "        else:  # DEGRADADA\n",
    "            invasives = np.random.choice(invasive_options,\n",
    "                                       size=np.random.randint(1, 3),\n",
    "                                       replace=False).tolist()\n",
    "        \n",
    "        # Cobertura baseada na qualidade e esta√ß√£o\n",
    "        if quality == PastureQuality.BOA:\n",
    "            base_coverage = np.random.randint(75, 95)\n",
    "        elif quality == PastureQuality.MODERADA:\n",
    "            base_coverage = np.random.randint(50, 80)\n",
    "        else:\n",
    "            base_coverage = np.random.randint(20, 55)\n",
    "            \n",
    "        # Ajuste sazonal\n",
    "        if season == Season.SECA:\n",
    "            coverage = max(15, base_coverage - np.random.randint(10, 20))\n",
    "        elif season == Season.CHUVAS:\n",
    "            coverage = min(95, base_coverage + np.random.randint(0, 15))\n",
    "        else:\n",
    "            coverage = base_coverage\n",
    "        \n",
    "        # Criar configura√ß√£o\n",
    "        config = PastureConfig(\n",
    "            biome=biome,\n",
    "            season=season,\n",
    "            quality=quality,\n",
    "            invasive_species=invasives,\n",
    "            grass_coverage=coverage,\n",
    "            soil_exposure=100 - coverage\n",
    "        )\n",
    "        \n",
    "        # Gerar prompts\n",
    "        positive, negative = prompt_engine.generate_prompt(config, variation=True)\n",
    "        \n",
    "        # Adicionar √† cole√ß√£o\n",
    "        prompt_data = {\n",
    "            'id': i,\n",
    "            'config': asdict(config),\n",
    "            'positive_prompt': positive,\n",
    "            'negative_prompt': negative,\n",
    "            'generation_params': {\n",
    "                'biome': config.biome.value,\n",
    "                'season': config.season.value,\n",
    "                'quality': config.quality.value,\n",
    "                'coverage': config.grass_coverage,\n",
    "                'invasives': config.invasive_species\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        prompt_collection.append(prompt_data)\n",
    "    \n",
    "    # Estat√≠sticas da cole√ß√£o\n",
    "    stats = {\n",
    "        'total_prompts': len(prompt_collection),\n",
    "        'biome_distribution': {},\n",
    "        'season_distribution': {},\n",
    "        'quality_distribution': {},\n",
    "        'avg_coverage': np.mean([p['config']['grass_coverage'] for p in prompt_collection]),\n",
    "        'generated_at': time.strftime('%Y-%m-%d %H:%M:%S')\n",
    "    }\n",
    "    \n",
    "    # Calcular distribui√ß√µes\n",
    "    for dist_key, enum_class in [('biome_distribution', Biome), \n",
    "                                 ('season_distribution', Season),\n",
    "                                 ('quality_distribution', PastureQuality)]:\n",
    "        for enum_val in enum_class:\n",
    "            count = sum(1 for p in prompt_collection \n",
    "                       if p['config'][dist_key.split('_')[0]] == enum_val.value)\n",
    "            stats[dist_key][enum_val.value] = count\n",
    "    \n",
    "    # Salvar cole√ß√£o\n",
    "    export_data = {\n",
    "        'metadata': {\n",
    "            'description': 'Brazilian Pasture Prompt Collection',\n",
    "            'version': '1.0',\n",
    "            'model_optimized_for': 'stable-diffusion-xl-base-1.0'\n",
    "        },\n",
    "        'statistics': stats,\n",
    "        'prompts': prompt_collection\n",
    "    }\n",
    "    \n",
    "    output_path = f\"outputs/{filename}\"\n",
    "    with open(output_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(export_data, f, indent=2, ensure_ascii=False)\n",
    "    \n",
    "    print(f\"\\n‚úÖ Cole√ß√£o exportada para: {output_path}\")\n",
    "    print(f\"üìä Estat√≠sticas:\")\n",
    "    print(f\"   Total: {stats['total_prompts']} prompts\")\n",
    "    print(f\"   Cobertura m√©dia: {stats['avg_coverage']:.1f}%\")\n",
    "    print(f\"   Biomas: {dict(stats['biome_distribution'])}\")\n",
    "    print(f\"   Esta√ß√µes: {dict(stats['season_distribution'])}\")\n",
    "    print(f\"   Qualidades: {dict(stats['quality_distribution'])}\")\n",
    "    \n",
    "    return output_path\n",
    "\n",
    "# Interface de exporta√ß√£o\n",
    "export_size_widget = widgets.IntSlider(\n",
    "    value=50,\n",
    "    min=10,\n",
    "    max=200,\n",
    "    step=10,\n",
    "    description='Quantidade:'\n",
    ")\n",
    "\n",
    "export_filename_widget = widgets.Text(\n",
    "    value=\"brazilian_pasture_prompts.json\",\n",
    "    description='Nome do arquivo:'\n",
    ")\n",
    "\n",
    "export_btn = widgets.Button(\n",
    "    description='üíæ Exportar Prompts',\n",
    "    button_style='success'\n",
    ")\n",
    "\n",
    "export_output = widgets.Output()\n",
    "\n",
    "def export_callback(btn):\n",
    "    with export_output:\n",
    "        clear_output()\n",
    "        export_prompt_collection(export_size_widget.value, export_filename_widget.value)\n",
    "\n",
    "export_btn.on_click(export_callback)\n",
    "\n",
    "display(widgets.VBox([\n",
    "    widgets.HTML(\"<h3>üíæ Exporta√ß√£o de Prompts</h3>\"),\n",
    "    export_size_widget,\n",
    "    export_filename_widget,\n",
    "    export_btn,\n",
    "    export_output\n",
    "]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "memory-cleanup-section"
   },
   "source": [
    "## üßπ 8. Limpeza de Mem√≥ria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "memory-cleanup"
   },
   "outputs": [],
   "source": [
    "def cleanup_memory():\n",
    "    \"\"\"Limpa mem√≥ria GPU e cache\"\"\"\n",
    "    global pipeline_manager, generated_image\n",
    "    \n",
    "    print(\"üßπ Limpando mem√≥ria...\")\n",
    "    \n",
    "    # Limpar vari√°veis globais\n",
    "    generated_image = None\n",
    "    \n",
    "    # Descarregar modelos\n",
    "    if pipeline_manager:\n",
    "        pipeline_manager.unload_models()\n",
    "    \n",
    "    # Limpar cache GPU\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "        print(\"‚úÖ Cache GPU limpo\")\n",
    "    \n",
    "    # Informa√ß√µes de mem√≥ria\n",
    "    if torch.cuda.is_available():\n",
    "        allocated = torch.cuda.memory_allocated() / 1024**3\n",
    "        reserved = torch.cuda.memory_reserved() / 1024**3\n",
    "        print(f\"üìä Mem√≥ria GPU: {allocated:.2f}GB alocada, {reserved:.2f}GB reservada\")\n",
    "    \n",
    "    print(\"‚úÖ Limpeza conclu√≠da!\")\n",
    "\n",
    "cleanup_btn = widgets.Button(\n",
    "    description='üßπ Limpar Mem√≥ria',\n",
    "    button_style='danger'\n",
    ")\n",
    "\n",
    "cleanup_output = widgets.Output()\n",
    "\n",
    "def cleanup_callback(btn):\n",
    "    with cleanup_output:\n",
    "        clear_output()\n",
    "        cleanup_memory()\n",
    "\n",
    "cleanup_btn.on_click(cleanup_callback)\n",
    "\n",
    "display(widgets.VBox([\n",
    "    widgets.HTML(\"<h3>üßπ Gerenciamento de Mem√≥ria</h3>\"),\n",
    "    widgets.HTML(\"<p>Use para liberar mem√≥ria GPU quando necess√°rio</p>\"),\n",
    "    cleanup_btn,\n",
    "    cleanup_output\n",
    "]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "summary-section"
   },
   "source": [
    "## üìã Resumo e Pr√≥ximos Passos\n",
    "\n",
    "### ‚úÖ O que voc√™ pode fazer neste notebook:\n",
    "\n",
    "1. **Explora√ß√£o Interativa**: Use o widget para testar diferentes configura√ß√µes\n",
    "2. **An√°lise de Prompts**: Compare prompts entre biomas e esta√ß√µes\n",
    "3. **Gera√ß√£o de Amostras**: Teste r√°pido com m√∫ltiplas configura√ß√µes\n",
    "4. **Exporta√ß√£o**: Salve cole√ß√µes de prompts para uso posterior\n",
    "\n",
    "### üîç Insights importantes:\n",
    "\n",
    "- Cada bioma tem caracter√≠sticas visuais √∫nicas nos prompts\n",
    "- Varia√ß√µes sazonais afetam cores, cobertura e ilumina√ß√£o\n",
    "- Qualidade da pastagem influencia presen√ßa de invasoras e solo exposto\n",
    "- Sistema de p√≥s-processamento melhora realismo das imagens\n",
    "\n",
    "### üìö Pr√≥ximos notebooks:\n",
    "\n",
    "1. **02_Generate_Dataset.ipynb**: Gera√ß√£o de datasets completos\n",
    "2. **03_Quality_Control.ipynb**: An√°lise detalhada de qualidade\n",
    "3. **04_YOLO_Training.ipynb**: Treinamento de modelos YOLO\n",
    "\n",
    "### üí° Dicas de uso:\n",
    "\n",
    "- Use modo r√°pido para testes iniciais (512px, 15 steps)\n",
    "- Monitore uso de mem√≥ria GPU\n",
    "- Salve configura√ß√µes interessantes\n",
    "- Exporte prompts de qualidade para reuso\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}