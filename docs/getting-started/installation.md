# üì• Guia de Instala√ß√£o Completo

Este guia abrange todas as formas de instalar e configurar o Brazilian Pasture Synthetic Image Generator, desde o setup mais simples no Google Colab at√© instala√ß√µes avan√ßadas em servidores de pesquisa.

---

## üöÄ **Instala√ß√£o R√°pida (Google Colab) - Recomendada**

### **Op√ß√£o 1: Notebook Pr√©-configurado (Mais F√°cil)**

1. **Abrir o notebook principal**:
   ```bash
   # Clique no badge para abrir diretamente no Colab:
   ```
   [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Kiwiabacaxi/img-sinth/blob/main/notebooks/00_Setup_Environment.ipynb)

2. **Executar c√©lulas de setup**:
   - Execute a primeira c√©lula para clonar o reposit√≥rio
   - Execute a segunda c√©lula para instalar depend√™ncias
   - Aguarde ~5-10 minutos para conclus√£o

3. **Verificar instala√ß√£o**:
   ```python
   # Esta c√©lula deve mostrar ‚úÖ para todos os componentes
   from src.utils.system_check import verify_installation
   verify_installation()
   ```

### **Op√ß√£o 2: Setup Manual no Colab**

```python
# 1. Clonar reposit√≥rio
!git clone https://github.com/Kiwiabacaxi/img-sinth.git
%cd img-sinth

# 2. Setup autom√°tico
!python setup_colab.py

# 3. Verificar GPU
import torch
print(f"CUDA: {torch.cuda.is_available()}")
print(f"GPU: {torch.cuda.get_device_name() if torch.cuda.is_available() else 'CPU'}")

# 4. Teste r√°pido
from src.diffusion.pipeline_manager import PipelineManager
pipeline = PipelineManager()
print("‚úÖ Instala√ß√£o conclu√≠da com sucesso!")
```

---

## üíª **Instala√ß√£o Local (Linux/Windows/macOS)**

### **Pr√©-requisitos**
- Python 3.8 ou superior
- Git
- CUDA 11.8+ (para GPU NVIDIA)
- 16GB+ RAM recomendado
- 50GB+ espa√ßo livre

### **Passo 1: Clonar Reposit√≥rio**
```bash
git clone https://github.com/Kiwiabacaxi/img-sinth.git
cd img-sinth
```

### **Passo 2: Criar Ambiente Virtual**

**Linux/macOS:**
```bash
python3 -m venv venv
source venv/bin/activate
```

**Windows:**
```cmd
python -m venv venv
venv\Scripts\activate
```

### **Passo 3: Instalar Depend√™ncias**

**Instala√ß√£o Completa (Recomendada):**
```bash
pip install -r requirements.txt
```

**Instala√ß√£o M√≠nima (Apenas Infer√™ncia):**
```bash
pip install -r requirements-minimal.txt
```

**Instala√ß√£o de Desenvolvimento:**
```bash
pip install -r requirements-dev.txt
```

### **Passo 4: Configurar CUDA (GPU)**

**Para NVIDIA GPUs:**
```bash
# Verificar vers√£o CUDA
nvidia-smi

# Instalar PyTorch com CUDA (ajuste a vers√£o conforme necess√°rio)
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
```

**Para AMD GPUs (ROCm):**
```bash
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/rocm5.4.2
```

### **Passo 5: Verificar Instala√ß√£o**
```python
python -c "
from src.utils.system_check import verify_installation
verify_installation()
"
```

---

## üê≥ **Instala√ß√£o com Docker**

### **Op√ß√£o 1: Imagem Pr√©-constru√≠da**
```bash
# Baixar e executar
docker pull ghcr.io/kiwiabacaxi/img-sinth:latest
docker run --gpus all -p 8888:8888 ghcr.io/kiwiabacaxi/img-sinth:latest
```

### **Op√ß√£o 2: Build Local**
```bash
# Clonar reposit√≥rio
git clone https://github.com/Kiwiabacaxi/img-sinth.git
cd img-sinth

# Build da imagem
docker build -t pasture-synthesis .

# Executar com GPU
docker run --gpus all -v $(pwd):/workspace -p 8888:8888 pasture-synthesis
```

### **Docker Compose para Desenvolvimento**
```yaml
# docker-compose.yml
version: '3.8'
services:
  pasture-synthesis:
    build: .
    volumes:
      - ./:/workspace
      - ./data:/data
      - ./outputs:/outputs
    ports:
      - "8888:8888"
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
```

```bash
docker-compose up -d
```

---

## ‚òÅÔ∏è **Instala√ß√£o em Cloud (AWS/GCP/Azure)**

### **AWS EC2 com Deep Learning AMI**

1. **Criar inst√¢ncia EC2**:
   - AMI: Deep Learning AMI (Ubuntu)
   - Tipo: p3.2xlarge ou superior
   - Storage: 100GB+ EBS

2. **Conectar e instalar**:
   ```bash
   ssh -i sua-chave.pem ubuntu@seu-ip-ec2
   
   # Ativar ambiente conda
   conda activate pytorch_p39
   
   # Clonar e instalar
   git clone https://github.com/Kiwiabacaxi/img-sinth.git
   cd img-sinth
   pip install -r requirements.txt
   ```

### **Google Cloud Platform (Compute Engine)**

1. **Criar VM com GPU**:
   ```bash
   gcloud compute instances create pasture-synthesis-vm \
     --zone=us-central1-a \
     --machine-type=n1-standard-4 \
     --accelerator=type=nvidia-tesla-t4,count=1 \
     --image-family=pytorch-latest-gpu \
     --image-project=deeplearning-platform-release \
     --boot-disk-size=100GB \
     --maintenance-policy=TERMINATE
   ```

2. **SSH e setup**:
   ```bash
   gcloud compute ssh pasture-synthesis-vm
   
   # Setup do projeto
   git clone https://github.com/Kiwiabacaxi/img-sinth.git
   cd img-sinth
   pip install -r requirements.txt
   ```

### **Azure Machine Learning**

1. **Criar Compute Instance**:
   - Tipo: Standard_NC6s_v3
   - OS: Ubuntu 18.04

2. **Setup via terminal**:
   ```bash
   git clone https://github.com/Kiwiabacaxi/img-sinth.git
   cd img-sinth
   pip install -r requirements.txt
   ```

---

## üîß **Configura√ß√£o Avan√ßada**

### **Configurar Modelos Base**
```python
# Download autom√°tico dos modelos (primeira execu√ß√£o)
from src.diffusion.pipeline_manager import PipelineManager

pipeline = PipelineManager(
    model_name='stabilityai/stable-diffusion-xl-base-1.0',
    cache_dir='/seu/caminho/para/cache'  # Opcional: definir localiza√ß√£o
)
```

### **Configurar Datasets de Refer√™ncia**
```bash
# Criar diret√≥rio para datasets de refer√™ncia
mkdir -p ./assets/reference_images

# Download de datasets p√∫blicos (opcional)
python scripts/download_reference_datasets.py
```

### **Configurar Vari√°veis de Ambiente**
```bash
# .env file
HF_TOKEN=seu_huggingface_token
WANDB_API_KEY=seu_wandb_key  # Para logging
CUDA_VISIBLE_DEVICES=0,1     # GPUs a usar
PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:512  # Gest√£o mem√≥ria
```

### **Configura√ß√£o de Mem√≥ria (GPUs Limitadas)**
```python
# config/memory_config.yaml
memory_optimization:
  enable_attention_slicing: true
  enable_cpu_offload: true
  enable_sequential_cpu_offload: false
  enable_model_cpu_offload: true
  enable_xformers: true
  gradient_checkpointing: true
```

---

## ‚úÖ **Verifica√ß√£o de Instala√ß√£o**

### **Teste B√°sico de Funcionamento**
```python
# test_installation.py
import sys
import torch
from src.diffusion.pipeline_manager import PipelineManager
from src.dataset.generator import DatasetGenerator
from src.training.yolo_trainer import YOLOTrainer

print("üîç Testando instala√ß√£o...")

# 1. Verificar Python e pacotes
print(f"Python: {sys.version}")
print(f"PyTorch: {torch.__version__}")
print(f"CUDA: {torch.cuda.is_available()}")

# 2. Testar componentes principais
try:
    pipeline = PipelineManager()
    print("‚úÖ Pipeline Manager")
except Exception as e:
    print(f"‚ùå Pipeline Manager: {e}")

try:
    generator = DatasetGenerator()
    print("‚úÖ Dataset Generator")
except Exception as e:
    print(f"‚ùå Dataset Generator: {e}")

try:
    trainer = YOLOTrainer()
    print("‚úÖ YOLO Trainer")
except Exception as e:
    print(f"‚ùå YOLO Trainer: {e}")

print("üéâ Teste de instala√ß√£o conclu√≠do!")
```

### **Teste de Gera√ß√£o R√°pida**
```python
# Teste r√°pido de gera√ß√£o (5 minutos)
from src.pipeline.quick_test import run_quick_test

results = run_quick_test(
    num_test_images=3,
    resolution=(512, 512),
    steps=10
)

print(f"‚úÖ Teste conclu√≠do: {results}")
```

---

## üêõ **Solu√ß√£o de Problemas Comuns**

### **Erro: "CUDA out of memory"**
```python
# Solu√ß√µes ordenadas por efetividade:

# 1. Reduzir batch size
config.batch_size = 1

# 2. Ativar CPU offload
config.enable_cpu_offload = True

# 3. Reduzir resolu√ß√£o
config.resolution = (512, 512)

# 4. Usar attention slicing
config.enable_attention_slicing = True
```

### **Erro: "ModuleNotFoundError"**
```bash
# Reinstalar com depend√™ncias completas
pip install --upgrade --force-reinstall -r requirements.txt

# Verificar instala√ß√£o pip
python -m pip install --upgrade pip

# Limpar cache
pip cache purge
```

### **Erro: "Hugging Face Model Download Failed"**
```bash
# Configurar token Hugging Face
huggingface-cli login

# Download manual (se necess√°rio)
python -c "
from diffusers import DiffusionPipeline
pipeline = DiffusionPipeline.from_pretrained('stabilityai/stable-diffusion-xl-base-1.0')
"
```

### **Performance Lenta**
```python
# Otimiza√ß√µes de performance
import torch
torch.backends.cudnn.benchmark = True  # Para inputs de tamanho fixo
torch.backends.cuda.matmul.allow_tf32 = True  # Para A100/H100

# Usar compila√ß√£o de modelo (PyTorch 2.0+)
pipeline.unet = torch.compile(pipeline.unet)
```

---

## üìä **Benchmark de Instala√ß√£o**

Execute este benchmark para verificar a performance da sua instala√ß√£o:

```python
from src.utils.benchmark import run_installation_benchmark

results = run_installation_benchmark()
print(f"""
üìä BENCHMARK DE INSTALA√á√ÉO
=========================
GPU: {results['gpu_name']}
Mem√≥ria GPU: {results['gpu_memory_gb']:.1f}GB
Tempo de gera√ß√£o (512x512): {results['generation_time_512']:.2f}s
Tempo de gera√ß√£o (1024x1024): {results['generation_time_1024']:.2f}s
Throughput: {results['images_per_hour']:.0f} imagens/hora
Score geral: {results['overall_score']}/10
""")
```

---

## üîÑ **Atualiza√ß√µes**

### **Atualizar para Nova Vers√£o**
```bash
# Backup de configura√ß√µes personalizadas
cp -r configs/custom configs_backup

# Atualizar c√≥digo
git pull origin main

# Atualizar depend√™ncias
pip install --upgrade -r requirements.txt

# Restaurar configura√ß√µes personalizadas
cp -r configs_backup/* configs/custom/
```

### **Verificar Vers√£o**
```python
from src import __version__
print(f"Vers√£o atual: {__version__}")
```

---

## üìû **Suporte**

Se voc√™ ainda tiver problemas ap√≥s seguir este guia:

1. **Documenta√ß√£o**: Consulte [Troubleshooting](troubleshooting.md)
2. **Issues**: Abra uma issue no [GitHub](https://github.com/Kiwiabacaxi/img-sinth/issues)
3. **Discord**: Entre no [servidor da comunidade](https://discord.gg/pastagens-ia)
4. **Email**: pastagens.ia@projeto.br

---

<div align="center">

**‚úÖ Instala√ß√£o conclu√≠da com sucesso? [Pr√≥ximo: Quick Start Guide ‚Üí](quick-start.md)**

</div>